[
    {
        "position": "Machine Vision System Engineer",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Boston Scientific",
        "sector": "Medical Equipment Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Galway, County Galway, Ireland",
        "post": "About the job \n More than the opportunity of a lifetime...the chance to improve lives\n Boston Scientific is one of the world\u2019s largest medical device companies, employing over 36,000 employees. It develops, manufactures and markets more than 13,000 products in over 120 countries, treating approximately 30 million patients annually. The medical devices are used in various interventional medical specialities, including interventional cardiology, peripheral interventions, neuromodulation, neurovascular intervention, electrophysiology, cardiac surgery, vascular surgery, endoscopy, oncology, urology and gynaecology.\n We are excited to add a new Machine Vision System Engineer to our Equipment Engineering Group here at our Galway site.\n As our successful candidate, you will work with our manufacturing partners to develop new and innovative vision solutions in line with our Industry 4.0-Smart Factory strategies. Innovative vision solutions offer the opportunity to deliver intelligent manufacturing machines and optimise production systems while working in a purpose-built technology innovation laboratory. You will also have the chance to assist R&D and Operations on New Product Development Programs and Sustaining Programs by participating in the Prototyping, Design, Build, Commissioning and Qualification of New Equipment as well as Equipment Upgrades.\n The role is primarily based in Galway, a world-class facility, although travelling abroad may be required from time to time for short periods. Working times are usually Monday to Friday, although some periodic weekend work may be needed per production schedules.\n\nKey Activities Of The Role\n\nDefine, implement and maintain architectures to retrieve, archive and analyse production image data. Develop, test, validate and deploy computer vision systems using open-source and proprietary tools such as VisionPro, Insight and MVTech. Provide strong leadership and problem solving to enable equipment technology innovation. Work closely with the customer to understand product visual inspection requirements and propose creative and cost-effective solutions to automate inspections. Generate quotations, concepts and business cases for new and upgraded business systems. Ensure equipment and business requests are processed promptly and effectively and manage the execution of results. Determine project schedules and work with the team and other departments across the plant to ensure adherence. Manage projects and portions of projects as part of a larger team. Lead and participate in cross-functional Design Reviews. Draft and Review Design and Compliance Quality System documentation. Write detailed functional design requirements. Contribute to all phases of software development, including design, implementation, unit test, integration, release and validation support. \n\n\nQualifications & Experienced\n\nEngineering qualification equivalent to or above NFQ Level 8 Three plus years of experience developing Vision Systems is essential. Proprietary Machine Vision / Image Processing tools (e.g. Cognex VisionPro and Insight, MVTec, LabVIEW). Optics, sensors and lighting applied to industrial machine vision. C#.NETor similar. Digital Image Processing techniques and dataflows applied to industrial machine vision. Advance Statistical analysis knowledge. Proprietary Machine Learning software (e.g. Cognex VIDi, MVTec, Matlab) is preferred. Basic knowledge of deep learning theory and techniques is desirable. TensorFlow 2+, OpenCV, and Pandas in Python environments are desirable. Knowledge of Robotics and Controls. GAMP / Documentation life cycle for regulated industries Imaginative and creative approach to problem-solving and continuous improvement. \n\n\nAt Boston Scientific, we recognise that nurturing a diverse and inclusive workplace helps us be more innovative. It is essential in advancing science for life and improving patient health. We stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific is proud to be an equal opportunity and affirmative action employer. #IJ"
    },
    {
        "position": "Senior Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Crayon",
        "sector": "IT Services and IT Consulting",
        "companySize": "1,001-5,000 employees",
        "location": "Sweden",
        "post": "About the job \n\n\nInterested in an exceptional career opportunity for a true data enthusiast?\nEnjoy a role that involves the latest cloud data platform technologies and frameworks?\nKeen to join a technologist driven growing global company?\n\n\nApply now and join our global team as a Senior Data Engineer for Crayon!\n\n\nCrayon's data platform is developed as the cornerstone that enables the company to be data-driven, from enabling business intelligence, to supporting products and services, to AI-enabled solutions for greater efficiency across Sales, Finance and more. We leverage modern technologies and best practices, including Azure DevOps, Synapse and Purview, a hybrid data mesh ownership model on top of a lake house, ability to build self-service reporting. All with proper security, privacy and governance in mind.\n\n\nAs a data platform team member, you will drive best practices to make data sources available to business, including dependency resolution and data governance. You will also have the opportunity to work with the team in building the overall platform, from data architecture design to CI/CD pipelines, from implementing privacy by design to defining the access model.\n\n\nKey responsibilities to highlight:\n\nIdentify data sources, design and integrate entities that allow meeting requirements from business stakeholders\nDiagnose data quality issues and liaise with data source owners to come up with potential preventive or corrective measures\nImplement pipelines using a combination of technologies, including git, SQL, Spark, Python and the Azure data tech stack \nBuild datasets that create data-driven insight, influence operational decision-making, and enable data-driven products and services\nWork with your colleagues to build a flexible and scalable platform, both implementation-wise and operationally\n\n\n\nWe envisage you to be a self-managing and self-motivated individual, with strong organizational and time management skills, who works structured and methodically through your daily tasks. Furthermore, you are a team player with effective collaboration and communication skills. Moreover, you have solution-oriented mindset, and you deliver excellent service to our clients.\n\n\nDesired competency & experience:\n\n5 years+ professional experience in designing, building, and maintaining scalable, high-performance data solutions\nFluency in Python\nStrong practical experience with ETL and ELT, as well as with the Azure data ecosystem (DevOps, ADF, ADLS, Synapse) or, alternatively, equivalent in another cloud\nUnderstanding of software development best practices\nExperience with Delta Lake, APIs (REST, GraphQL), data from CRM and/or ERP systems, Spark, and related technology ecosystem, as well as Azure Data Engineer Associate certification are valuable \n\n\n\nPRACTICAL INFORMATION:\n\nLocation for this job: Remote, Sweden, Austria, Serbia, UK or Spain\nLanguage requirements: Excellent written and verbal English skills\nApplication deadline: ASAP. We will evaluate candidates continuously.\nVisa requirements: Must have work permit/visa. We are looking for someone who is ideally already based in one of the mentioned countries, and that could start relatively quickly"
    },
    {
        "position": "NLP Data Scientist/Engineer",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Roche",
        "sector": "Biotechnology Research",
        "companySize": "10,001+ employees",
        "location": "Pozna, Wielkopolskie, Poland",
        "post": "About the job \n The Position\n\nNLP Data Scientist/Engineer\n\nIT INNOVATORS IN HEALTHCARE\n\nWe do #Code4lLife creating innovative software that helps doctors, patients, and scientists around the world.\n\nWho We Seek\nIdeal candidate for this position has:\n\nUnderstanding of basic concepts from area of Text Mining, NLP and NLU, hands-on experience with regular expressions\nKnowledge from area of embedding representations and deep learning based solutions for NLP (word2vec, Gensim)\nExperience with our typical NLP tools used in daily work:\nscikit learn, numpy, pandaspytorch or tensorflowspaCy, NLTK\n\n\n\nExperience in NLP/AI software engineering, especially\n\nproficiency with Python\nexperience with Git, Gitlab\nknowing Jira, CI/CD tools is nice to have\nunderstanding of software testing (unit tests, integration tests, smoke tests)\nbash/shell scripting\n\n\nEXAMPLE PROJECTS ACTIVITIES YOU MAY WORK ON\n\n\nDeveloping pipelines for solving NLP tasks (predictions, clustering, deviations detection) for generating insights and extracting knowledge from millions of internal documents\nImplementing fully working AI/NLP powered applications for supporting our colleagues from all the departments, for instance: pharma, molecules development, clinical trials, sales, marketing, people & culture or IT\nBuilding toolset and re-usable components for our future projects and ideas\n\n\nWhat We Appreciate\n\n\nAbility to learn new technologies (we can teach you them as well!)\nAnalytical mindset and critical thinking\nGood communication skills\nOpenness for knowledge sharing\n\n\nWhat You Get\n\n\nSalary range 10 000 - 14 000 PLN gross\nAnnual bonus payment based on your performanceContract of employment \nEmphasis on continuous personal and professional self-development supported by a dedicated training budget (training, certifications, conferences, diversified career paths etc.)\nExperienced and professional colleagues and workplace that supports innovation and new ideas\nHighly flexible working hours (starting your day at 7-11) and workplace according to employee\u2019s needs and preferences* (regular office/home office)\nA chance to work on solutions which can improve patients\u2019 lives\n\n\nAdditional Benefits\n\n\nRelocation package\nPrivate healthcare and insurance\nHealth, well-being and sport promotion\nSupport for parents and families\nStock share purchase additions\nYearly sales of company laptops and cars\nAdditional vacation time for long-term employees and more\n\n\nAPPLY DIRECTLY\n\nApply directly via Workday, pressing the blue button at the top.\n If you feel this offer suits a friend of yours, we\u2019ll appreciate you letting them know! Simply copy and share the link from the browser.\n If you have any questions regarding the offer and would like to contact us directly, please write to us at <\n katarzyna.wisniewska@roche.com>\n WANT TO KNOW MORE?\n Check our website for more details, e.g. the career path, recruitment process, etc.\n https://it.roche.pl/work-with-us\n Want to know what it\u2019s like to be a part of Roche IT first-hand? Check out our blog! You will meet the community members there, sharing their experience and impressions from diverse perspectives, not only about their job but also their lives.\n https://www.roche.com/careers/weareroche.htm\n Please note that during the pandemic we are working and recruiting 100% remotely.\n \u2026..\n\nRoche is an equal opportunity employer. We care about inclusion in terms of gender, age, race, skin colour, nationality, religion, marital status, sexual orientation, background, physical or mental disabilities and on every other grounds. Applying for our position, we assure you that we will assess your application solely on the basis of your competencies.\n\nAdministratorem Pani/Pana danych osobowych jest sp\u00f3\u0142ka Roche Polska Sp. z o.o., ul. Domaniewska 39 B, 02-672 Warszawa. Dane przetwarzane s\u0105 w celu prowadzenia rekrutacji. Przys\u0142uguje Pani/Panu prawo dost\u0119pu do tre\u015bci swoich danych, ich sprostowania, usuni\u0119cia, ograniczenia przetwarzania, przenoszenia oraz \u2013 w sytuacji, gdy s\u0105 one przetwarzane na podstawie udzielonej zgody \u2013 cofni\u0119cia tej\u017ce zgody w dowolnym momencie. Kontakt do Inspektora Ochrony Danych:ochrona.danych@roche.com. Wi\u0119cej informacji o zasadach przetwarzania przez Roche Pani/Pana danych osobowych pod linkiem: \n\n https://www.roche.pl/pl/content/klauzula-informacyjna-rekrutacja-pl.html\n\nThe controller of your personal data is Roche Polska Sp. z o.o., ul. Domaniewska 39 B, 02-672 Warsaw. The data is processed for the purpose of recruitment. You have the right to access your data, rectify it, delete it, limit processing, transfer it and - if processing is based on your consent - withdraw this consent at any time. Contact the Data Protection Officer at: Ochrona.danych@roche.com. More information on the principles of processing your personal data by Roche at the link: \n\n https://www.roche.pl/pl/content/klauzula-informacyjna-rekrutacja-en.html\n Who we are\n At Roche, more than 100,000 people across 100 countries are pushing back the frontiers of healthcare. Working together, we\u2019ve become one of the world\u2019s leading research-focused healthcare groups. Our success is built on innovation, curiosity and diversity.\n At Roche Poland, we are more than 800 professionals working together on one mission. We are proud of who we are, what we do and how we do it. Join us in the area of Clinical Research, Medical, Marketing, IT or business departments.\n Roche is an Equal Opportunity Employer."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Roche",
        "sector": "Biotechnology Research",
        "companySize": "10,001+ employees",
        "location": "Pozna, Wielkopolskie, Poland",
        "post": "About the job \n The Position\n Data Engineer\n\nIT INNOVATORS IN HEALTHCARE\n\nWe do #Code4Life creating innovative software that helps doctors, patients, and scientists around the world.\n\nWho We Seek\n\n\nProven experience in the designing and delivery of complex Data Engineering solutions\nKnowledge about designing and developing at-scale ETL/ELT processes and frameworks on the cloud platforms - preferably AWS \nProgramming skills in scripting languages like Python, R, and Bash as well as knowledge about data processing using SQL\nExperience with Docker and Kubernetes and knowledge about designing CI/CD data processing pipelines\n\n\nYour main responsibilities will be:\n\n\nCollaboration with Architects, Tech Leaders and development team to identify and implement automation strategies that enable high-quality, faster delivery of data products\nWork on strategy, plan, and execution of Data Engineering / DataOps concepts on a large scale\nActing as a Data Engineering evangelist promoting DataOps culture among development teams within the organization\n\n\nWhat We Appreciate\n\n\nExperience with data processing tools like Airflow (standalone or AWS MWAA), AWS Glue, Lambda, and AWS Step Functions, DBT\nExperience with the data quality tools and frameworks \n\n\nWhat You Get\n\n\nSalary range 16 000 - 21 000 PLN gross\nAnnual bonus payment based on your performance\nEmphasis on continuous personal and professional self-development supported by a dedicated training budget (training, certifications, conferences, diversified career paths etc.)\nExperienced and professional colleagues and workplace that supports innovation and new ideas\nHighly flexible working hours (starting your day at 7-11) and workplace according to employee\u2019s needs and preferences* (regular office/home office)\nA chance to work on solutions which can improve patients\u2019 lives\n\n\nAdditional Benefits\n\n\nRelocation package\nprivate healthcare and insurance\nhealth, well-being and sport promotion\nsupport for parents and families\nstock share purchase additions\nyearly sales of company laptops and cars\nadditional vacation time for long-term employees and more\n\n\nAPPLY DIRECTLY\n\nApply directly via Workday, pressing the blue button at the top.\n If you feel this offer suits a friend of yours, we\u2019ll appreciate you letting them know! Simply copy and share the link from the browser.\n If you have any questions regarding the offer and would like to contact us directly, please write to us at katarzyna.wisniewska@roche.com\n\nWANT TO KNOW MORE?\n\nCheck our website for more details, e.g. the career path, recruitment process, etc.\n https://it.roche.pl/work-with-us\n Want to know what it\u2019s like to be a part of Roche IT first-hand? Check out our blog! You will meet the community members there, sharing their experience and impressions from diverse perspectives, not only about their job but also their lives.\n https://www.roche.com/careers/weareroche.htm\n Please note that during the pandemic we are working and recruiting 100% remotely.\n\nRoche is an equal opportunity employer. We care about inclusion in terms of gender, age, race, skin colour, nationality, religion, marital status, sexual orientation, background, physical or mental disabilities and on every other grounds. Applying for our position, we assure you that we will assess your application solely on the basis of your competencies.\n\nAdministratorem Pani/Pana danych osobowych jest sp\u00f3\u0142ka Roche Polska Sp. z o.o., ul. Domaniewska 39 B, 02-672 Warszawa. Dane przetwarzane s\u0105 w celu prowadzenia rekrutacji. Przys\u0142uguje Pani/Panu prawo dost\u0119pu do tre\u015bci swoich danych, ich sprostowania, usuni\u0119cia, ograniczenia przetwarzania, przenoszenia oraz \u2013 w sytuacji, gdy s\u0105 one przetwarzane na podstawie udzielonej zgody \u2013 cofni\u0119cia tej\u017ce zgody w dowolnym momencie. Kontakt do Inspektora Ochrony Danych:ochrona.danych@roche.com. Wi\u0119cej informacji o zasadach przetwarzania przez Roche Pani/Pana danych osobowych pod linkiem: \n\n https://www.roche.pl/pl/content/klauzula-informacyjna-rekrutacja-pl.html\n\nThe controller of your personal data is Roche Polska Sp. z o.o., ul. Domaniewska 39 B, 02-672 Warsaw. The data is processed for the purpose of recruitment. You have the right to access your data, rectify it, delete it, limit processing, transfer it and - if processing is based on your consent - withdraw this consent at any time. Contact the Data Protection Officer at: Ochrona.danych@roche.com. More information on the principles of processing your personal data by Roche at the link: \n\n https://www.roche.pl/pl/content/klauzula-informacyjna-rekrutacja-en.html\n Who we are\n At Roche, more than 100,000 people across 100 countries are pushing back the frontiers of healthcare. Working together, we\u2019ve become one of the world\u2019s leading research-focused healthcare groups. Our success is built on innovation, curiosity and diversity.\n At Roche Poland, we are more than 800 professionals working together on one mission. We are proud of who we are, what we do and how we do it. Join us in the area of Clinical Research, Medical, Marketing, IT or business departments.\n Roche is an Equal Opportunity Employer."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Tyson Foods",
        "sector": "Food and Beverage Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Lisbon, Portugal",
        "post": "About the job \n\nTechnical qualifications\nRequired Skills:\n\u00b7 Experience building analytics solutions in cloud-based platforms such as GCP (Big Query, Dataflow, Cloud Storage) & AWS (Redshift, S3, AWS Glue, Greengrass).\n\u00b7 Hands on experience with SQL and Query Optimization.\n\u00b7 Java/Apache Beam.\n\u00b7 Python.\n\u00b7 The ideal candidate would have 3 years of data ingestion and integration experience.\nPreferred Skills:\n\u00b7 CI/CD & DevOps Principles.\n\u00b7 Kubernetes.\n\u00b7 Terraform.\n\u00b7 Metadata management, data quality, data visualization, and agile methodologies.\n\n\nAbout the job\nTyson Foods Core+ Development team is seeking a Senior Data Engineer who will build Analytics solutions on cloud platforms like GCP & AWS. The primary focus is to design and build data pipelines using open-source technologies to bring in data from IoT devices, external data sources, and internal data sources. This role will translate requirements to build integrated solutions with automated deployments and monitoring following cloud platform best practices. \nYou can be part of a team that is constantly fostering the innovation and the implementation of cutting-edge technologies while building high-performance and scalable solutions. This team is primarily responsible for data integration across Tyson\u2019s applications and will be collaborating with most areas within IT. If you enjoy working in a rapidly changing environment and influencing the strategic direction of a large global organization, this position will provide you with that opportunity.\n\n\nCheck out Tyson Technology!\n\n\nTyson Foods\u2019 Equal Opportunity Employer Statement:\n\nTyson Foods is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will be considered without regard to race, national origin, color, religion, age, genetics, sex, sexual orientation, gender identity, disability or veteran status.\n\n\n*** In case we do not contact you within three weeks of your application please consider this a negative response. Thank you for understanding ***"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Amgen",
        "sector": "Biotechnology Research",
        "companySize": "10,001+ employees",
        "location": "Lisboa, Lisbon, Portugal",
        "post": "About the job \n\nHOW MIGHT YOU DEFY IMAGINATION?\n\nTHE AMGEN CAPABILITY CENTER IN LISBON, PORTUGAL (ACCP) will be home to over 300 multi-national and multi-cultural employees, representing a broad range of cross functional capabilities, including Commercial, General and Administrative, Research and Development and more. The ACCP will offer rich career growth and development opportunities, regional and global exposure and the opportunity to LIVE, WIN and THRIVE in one of Europe\u2019s most attractive cities.\n Our ACCP offices will be temporarily located at the Maleo \u2013 Saldanha, Av. da Rep\u00fablica 18, 1050-191 Lisbon, while we work toward finding a permanent office in the vibrant city center of Lisbon.\n\nData Engineer\n\nLive\n\nWhat You Will Do\n\nLet\u2019s do this. Let\u2019s change the world. Global Commercial Operational IS is looking for a talented Data Engineer, who is curious to learn and able to develop data engineering and data analytics solution in a fast-moving environment. Candidate will work closely with senior data engineer and product owner/business analyst to understand the requirement. This role will be part of the newly established technical/engineering team, develop data flow pipelines to extract, transform, and load data from various data sources in various data format to enterprise data lake and data warehouse system in three regions in AWS. Provide data analytics and predictive analysis to business users.\n The Data Engineer will be based out of Amgen\u2019s Capability Center in Lisbon. At Amgen, our mission is simple: to serve patients. Our Capability Center provides essential services that enable us to better pursue this mission. This state-of-the-art center serves as a base for finance, information systems, and human resources professionals to make a meaningful impact at one of the world\u2019s leading biotechnology companies.\n\n\nBe a key team member assisting in design and development of the data pipeline for Global Data and Analytics team\nCollaborate with Data Architects, Business SME\u2019s, and Data Scientists to design and develop end-to-end data pipeline to meet fast paced business need across geographic regions\nServe as system admin to manage AWS and Databricks platform; \nAdhere to best practices for coding, testing and designing reusable code/component\nAble to explore new tools, technologies that will help to improve ETL platform performance\nParticipate in sprint planning meetings and provide estimations on technical implementation; Collaborate and communicate effectively with the product teams\n\n\nWin\n\nWhat We Expect Of You\n\nWe seek a self-starter with these qualifications:\n\nBasic Qualifications\n\nMaster\u2019s Degree\n OR\n Bachelor\u2019s degree with 2 years Data Engineering and/or and Software Engineering experience\n OR\n Associate\u2019s degree 6 years of Data Engineering and/or Software Engineering experience\n OR\n High school diploma and 8 years of Data Engineering and/or Software Engineering experience\n\nPreferred Qualifications\n\n\n\nExperience with software development (Java, Python preferred), end-to-end system design\nExperience with data modeling for both OLAP and OLTP databases, hands-on experience with SQL, preferred Oracle, PostgreSQL, and Hive SQL; SQL performance tuning\nExperience with web development, java script, html, CSS, any web framework or microservice architecture\nExperience with software DevOps CI/CD tools, such Git, Jenkins \nExperience on AWS, familiar with EC2, S3, Redshift/Spectrum, Glue, Athena, RDS, Lambda, DynamoDB, and API gateway\nExperience with docker container, Kubernetes container orchestration\nExperience with Apache Airflow and Apache Spark; Spark performance turning\nExperience with Tableau Dashboard and Tableau Server\nSupport the creation of customizations and integrations required to solution delivery\nDevelop technical designs for new features and capabilities\nAccountability of technical implementation aspects of new features including planning, architecture, design, development, and testing\nAbility to learn quickly, be organized and detail oriented\nAgile/SAFe experience and/or understanding\n\n\nThrive\n\nSome of the vast rewards of working here\n\nAs we work to develop treatments that take care of others, so we work to care for our teammates\u2019 professional and personal growth and well-being.\n\n\nFull support and career-development resources to expand your skills, enhance your expertise, and maximize your potential along your career journey\nA diverse and inclusive community of belonging, where teammates are empowered to bring ideas to the table and act\nGenerous Total Rewards Plan\u2014comprising health, finance and wealth, work/life balance, and career benefits\u2014with compensation and benefits rated above 4 stars (out of 5) on Glassdoor\n\n\nApply now\n\nfor a career that defies imagination\n\nObjects in your future are closer than they appear. Join us.\n\ncareers.amgen.com\n\nReady to Apply for the Job?\n\nJoin Us\n If you're seeking a career where you can truly make a difference in the lives of others, a career where you can work at the absolute forefront of biotechnology with the top minds in the field, you'll find it at Amgen.\n Amgen, a biotechnology pioneer, discovers, develops and delivers innovative human therapeutics. Our medicines have helped millions of patients in the fight against cancer, kidney disease, rheumatoid arthritis and other serious illnesses.\n As an organization dedicated to improving the quality of life for people around the world, Amgen fosters an inclusive environment of diverse, ethical, committed and highly accomplished people who respect each other but compete intensely to win. Together, we live the Amgen values as we continue advancing science to serve patients."
    },
    {
        "position": "Data Scientist / Data Engineer (m/f/d)",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Siemens",
        "sector": "Automation Machinery Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Lisbon, Lisbon, Portugal",
        "post": "About the job \n\nThe time to change is now! \n\nIt's time to build a sustainable future and define how we evolve through technology with purpose.\n At Lisbon Tech Hub we create value in the business digital transition, from Portugal to the world, and IT solutions with purpose. Our team has more than 1300 experts working in areas such as Analytics & Business Intelligence, Application Lifecycle Management, Cybersecurity, IT Infrastructure Management, IT Project & Service Management and IT Strategy & User Experience.\n Lisbon Tech Hub innovates, designs, transforms the information technology solutions and services for Siemens through our delivery units.\n Transforming our future starts with every day!\n Lisbon Tech Hub is the home of the new technologists - Dream Builders, Impact Creators & Future Makers.\n Are you one of them? Join us!\n\nWhat role will you play?\n\n\n\nPerform strategic data analysis to support business processes and strategy and discuss results with team leads and customers. \nProcess large amounts of data from multiple sources and extract relevant insights.\nBuild and operationalize predictive models.\nArchitect and build cloud infrastructure for both the data engineering and the analytics pipelines\nBe part of an international team of data scientists and machine learning engineer with diverse backgrounds, utilizing AI and data analytics methods to accelerate Siemens internal digitalization\n\nWe are looking for:\n\n\n\nA degree in Mathematics, Physics, Statistics, Computer Science, Engineering, a similar quantitative field, or equivalent practical experience.\nExperience with statistical software and scripting languages (e.g., R, Python, SAS).\nFirst experience with cloud technology (AWS, Azure, GCP) and infrastructure as code (e.g., Terraform)\nProficiency in SQL.\nExperience analyzing and modeling data sets.\nExperience with statistical and machine learning methods.\nThe ability to communicate technical concepts into simple terms to present to non-technical audiences.\nEffective written and verbal communication skills\n\nWhat we have to offer: \n\nA flexible home office and schedule policy, virtual budget to improve your home office setup, health insurance, a Pension Plan and a Siemens Share Program time and financial support to your studies, medical center in the facilities, sport groups, 2 days for volunteering initiatives and a cool and relaxed environment.\n Access to e-learning platforms (Learnlight, Linkedin Learning and more), discounts with partners.\n\n#Siemens #LXTechHub #ITMakesUsMove \n\nWe recognize that building a diverse workforce is crucial to the success of our business. Therefore, Siemens provides equal employment opportunities to all qualified individuals without regard to race, creed, color, religion, national origin, age, gender, marital status, sexual orientation, or non-disqualifying physical or mental handicap or disability.\n We strongly encourage applications from a diverse talent pool and welcome the opportunity to discuss workplace adjustments with all our applicants to develop agile working and innovation.\n\nOrganization: Smart Infrastructure\n\nCompany: Siemens S.A.\n\nExperience Level: Experienced Professional\n\nJob Type: Full-time"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "GreenVolt - Energias Renovveis",
        "sector": "Renewable Energy Semiconductor Manufacturing",
        "companySize": "201-500 employees",
        "location": "Lisbon, Portugal",
        "post": "About the job \n\nGreenVolt is looking for a Data Engineer to integrate our international IT Development team, with the following main responsibilities:\n\nWorking with project team to clarify the requirements and then implement them;\nResearch, Design, Plan and Develop Azure Cloud-based Data Acquisition and Data Engineering solutions for developed Use Cases;\nDesigning and develop functionality and solution data pipelines as a data engineer developer and data architect;\nDevelop data transformation functions and database processing mechanism (SQL Server)\nDesigning, testing and implementing application - C#, ASP.NET, Blazor, Azure;\nDesign data pipeline test cases, Conducting performance test; \nTroubleshoot and resolve technical problems in timely and accurate manner to improve application performance and functionality;\nPlanning and reporting project work progress.\n\nProfile:\n\nBSc/MSc degree in Computer Science, Information Systems or equivalent;\n3-5 years of experience in development team, with strong competences in the following areas:\n\n-Software Programming Languages (SQL, Scala, PySpark, Python, Java) \n-Data Collection / Transformation Tools (Azure EventHub, Azure Functions, Azure Data Factory)\n-Azure Platform (Compute component, Containers component, Networking component, Storage component, Analytics component, Azure Data Explorer (ADX), Azure tools CLI)\n-Analytics Engine (e.g. Azure Synapse)\n-Agile and continuous Delivery and methodologies\n\nAbility to identify problems, analyze key information and propose the best solution;\nLearn quickly and want to expand your knowledge;\nFluent English (work 100% in international environment).\n\n\n\nWhat do we have to offer?\n\nCompetitive salary aligned with experience;\nAttractive benefits package including health insurance, pension plan and meal card;\nFlexible work environment and work-life balance;\n25 days of holidays;\n75 days per year of flexible work;\nFree birthday day;\nBeing part of an international environment.\n\n\n\n\n\nWe want an energy transition for everyone from everyone!"
    },
    {
        "position": "Data Engineer with Development Skills",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "H&M Group",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nCompany Description\n\nAt H&M, we are on an exciting journey where fashion and tech make magic together. As rapid technological development and new customer behaviors are transforming the fashion retail industry, our mission is to meet and exceed our customers' expectations. All while keeping in mind sustainable practices. We know that the best ideas evolve when great minds with different backgrounds and perspectives get together.\n At H&M, we are all on the same team in a global environment where we learn from each other and grow together. We live our values and know that sharing knowledge is the best way to continuously improve our ways of working and creating.\n We are proud to foster a workplace free from discrimination. We strongly believe that diversity of experience, perspectives, and background will lead to a better environment for our employees and a better product for our users. H&M Group \u2013 Business Tech.\n There are countless reasons for you to consider joining H&M, but here is a list we think summarizes the most important ones:\n\nThere are tremendous amounts of growth opportunities: we have many courses and workshops running so that you can become your best-self;\nYou will be surrounded by incredible colleagues from all around the globe;\nYou will experience what being part of a large organization means;\nThe opportunity to always be on the forefront of tech and fashion\n\nAre you a Data Engineer with development skills. Do you have a passion for large scale cutting edge analytics and data platforms? Do you think Kubernetes is the way forward in a multi cloud world? Do you think that everything could be automated with pipelines? Do you want to work in an enablement team building cool stuff that empowers a multitude of product teams? Then this is the opportunity for you!\n\nJob Description\n\nIn Common Tools and Services we empower all product teams by building the tools and services that makes sure H&M Group\u2019s data and analytic platforms are awesome. You will build self-service data platforms and integrations solutions at enterprise level. You will join a team of amazing professionals with great opportunity to contribute with your own creative ideas. As a team we have innovation sprints and lab days so we can evolve and develop new ideas.\n\nSome of your daily tasks include:\n\n\nDesign and develop our large scale Apache Kafka platform in Kubernetes. You will work both on a strategic level and with hands-on implementation and also support other teams in data platform and integration advisory including advanced troubleshooting.\nDesign and develop our test automation framework that is an important tool for our data engineers.\nDesign and develop our deployment pipelines used by many product teams.\nTranslate strategies and requirements into modern, innovative and scalable solutions\n\nQualifications\n\nWe are looking for someone that is smart, humble and hungry in helping us build our next modern data platform, you will play a key role in our data transformation journey. We believe you have the ability to understand and\u202fanalyze\u202fcomplex information as well as being able to communicate with others regardless of their IT knowledge.\n You work proactively and with continuous improvements in a fast transforming environment. You enjoy working with implementation and taking operational aspects into account.\n\nTo do this, we think you have a curious mindset, excellent communication skills as well as:\n\n\nExperience in Cloud (Azure, GCP)\nExperience in Kubernetes, Docker and containerization.\nExperience in Python and/or Java\nMeritorious with experience in Devops\nMeritorious with experience in Apache Kafka\n\nLeadership? In this role you will act as a thought leader towards other product team. You should be in the frontline on both new technology and H&M strategies.\n\nAdditional Information\n\nThis is a full-time position with a placement in Stockholm.\n Please apply with CV and cover letter as soon as possible, as a part of the process you may be asked to complete a test connected to engineering. Interviews will be held continuously. And We love code! So If you have contributed to Github project(s), also send those to us together with the CV. We are more than happy to take a look!"
    },
    {
        "position": "Senior Data Engineer (Advanced Engineering & Analytics)",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "TVNZ",
        "sector": "Broadcast Media Production and Distribution",
        "companySize": "501-1,000 employees",
        "location": "Auckland, New Zealand",
        "post": "About the job \n\nTe Reo Tataki (TVNZ) translates to \"the leading voice\" and our kaupapa (purpose) is to \"inspire the conversations of Aotearoa.\" Each day TVNZ reaches more than two million Kiwis through channels TVNZ 1, 2, DUKE and our digital entertainment platform, TVNZ+. TVNZ's news site 1news.co.nz and our digital news youth brand Re: ensure we connect with people on the issues that matter to them wherever they are. \n\n\nThe opportunity - Te t\u016branga \n\n\nWe are looking for a curious and collaborative Senior Data Engineer (Advanced Engineering & Analytics), reports to Data & Integration Lead who is passionate about building data solutions and driving change through data to join our Data Engineering team. \nThis is an exciting new role within our Data Engineering team. As the Senior Data Engineer (Advanced Engineering and Analytics) you will act as the bridge between our data engineering squad and TVNZ's business users, data analysts, data scientists & research analysts. \nYou will be responsible for: \n\n\n\nPartnering with internal stakeholders to build complex engineering solutions that answer strategic business questions with data \nLeading the development of advanced data engineering solutions using our Azure Data Platform\nDeveloping and maintaining highly complex feature layer data models & pipelines that allow TVNZ to get maximum value from its data, with high quality, clean, maintainable analytic code. \nBuilding a robust, repeatable MLOpsframework that allows the Data Engineering team to rapidly deliver predictive model input layer datasets to Data Scientists. \nCurating, organising and documenting data definitions, metrics and reporting environments across Azure Data Lake, Synapse and PowerBI to unlock value and drive efficiency while ensuring data quality.\nCollaborate with data engineers, data analysts & data scientists to develop innovative analytical products.\nWork closely with stakeholders to drive automation and identify where we can leverage our data to improve processes & decision making across the company\nSupporting the Data Engineers and Data Visualisation teams to build, maintain and provide self-serve data and corporate dashboarding and reporting\nProviding technical support to Data Scientists, Research Analysts and Data Analysts \n\n\n\nWhat we're looking for - Ta matou e kimi nei \n\n\nAnalytics Engineering: \n\nRelevant experience in the data space as an analyst, scientist, engineer or similar role\nDemonstratable experience leading multiple advanced engineering projects from concept to operationalisation\nDemonstratable hands-on experience with SQL, Python or other statistical programming languages \nFamiliarity with using Juypter Notebooks or cloud data workbenches is preferrable\nExperience tackling Big Data problems using the Hadoop ecosystem \nExperience with metadata management and data governance \n\n\n\nData visualisation \n\nRelevant experience building and operationalising end-to-end data analytics visualisations and dashboards, delivering demonstrable value to the business and stakeholders.\nSolid and demonstrable experience synthesising complex functional requirements into clean, intuitive visuals that provide insight and support decision making\nExperience a broad knowledge of data visualisation approaches including the use of rapid prototyping to create positive and engaging user experience\n\n\n\nData Engineering: \n\nExperience adapting software engineering Best Practice to data analytics\nFamiliar with the design and build of robust ELT pipelines using ARM templates and automation for resources provisioning (Azure PowerShell)\nGood working understanding of Azure services (Synapse Studio, Azure Data Lake, Databricks, Cognitive Services, Azure ML, Azure App Service, Azure SQL, Databricks, LogicApps)\nExperience with source control collaborative tools such as Git \nFamiliarity with SCALA an advantage\n\nWorking at TVNZ - Te mahi ki Te Reo Tataki\n\nA vibrant culture where we celebrate our content and our successes, and where we're encouraged to continue learning and growing our careers\nA $350 up front allowance to contribute to home office set up expenses.\nComprehensive parental leave - topping up the Government's offering to 6 months at full pay, as well as 6 weeks working at 80% of your normal time at full pay when you return to work, plus 4 week's paid leave and an optional extra 2 week's unpaid for partners.\nLifestyle Leave - the option to buy an extra week or two of leave annually if you want it, to take leave without pay if circumstances allow, or to cash up leave if you've got more than you need.\nA $350 annual wellbeing allowance, discounted Southern Cross health insurance, free flu shots, and access to a confidential support, guidance and counselling service.\nSuperannuation covered - with employee contributions matched up to 5% of salary.\nHauora Leave - A bonus 5th week off annually to find your balance and focus on you - whether that's by connecting with whanau, taking time for yourself, or escaping the everyday.\nA new Broadband and Mobile benefit offer so you'll be able to work from anywhere and be free to stream and binge watch with no limits.\n\n\n\nIf you would like to find out more about this amazing opportunity, please feel free to call our Head of Talent Acquisition, Philly Irvine, mobile 021 564 691, she loves to chat about new careers."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "HEMA",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Amsterdam, North Holland, Netherlands",
        "post": "About the job \n\nDo you have experience in end-to-end design and deploy of data pipelines and analytics solutions?\n\n\nHEMA is looking for a Data Engineer for our Data & Analytics team\n\n\nyou have\n\nExperience in Design, Build, Test and Deploy data pipelines to process massive amount of data\nExperience in building data pipelines to collect, transform, and load data from various sources (e.g. REST, Kafka) into data lakes and/or databases\nAdvanced knowledge of data processing and analysis (e.g. with SQL, Pyspark)\nExtensive programming know-how (e.g. in Python, Scala, Java, NodeJs)\nExperience with some IaC framework (terraform, cloud formation) \nExtensive knowledge of software engineering best practices, tools and methods (e.g. TDD, CI/CD, GIT)\nExperience in using workflow orchestration tools (e.g., Apache Airflow)\nExperience working in self-organised, cross-functional teams \n\n\n\na day as Data Engineer\nHEMA is a data-driven company. Many decisions are made on data, which requires that this data is available, complete and correct. As a Data Engineer, you are responsible for end-to-end design and deploy of data pipelines and analytics solutions that all HEMA employees and partners can work with data by making it available via a state-of-the-art platform and tooling.\nTogether with the others Data Engineers, you have open space to discuss, test and implement new ideas and concepts related with new technologies. You help HEMA to have the most curated up to date dataset available in the AWS Analytics platform supporting business questions, machine learning models and stakeholders to improve internal process and support business decisions.\nYou work in a data platform team together with the data engineers. Together with Business intelligence, data science and analytics & insights, you form the Data & Analytics team at HEMA."
    },
    {
        "position": "Data Engineer - Economics & Experimentation (all genders)",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Zalando",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Berlin, Berlin, Germany",
        "post": "About the job \n\nTHE OPPORTUNITY\n\nYou will join a brand-new team in Economics and Experimentation to productionalize causal machine learning models developed by our Applied Scientists. Our team is highly visible. The causal models and experimentation platforms we develop are used for decision-making for both the senior management board and all Zalando product teams.\n As one of the very first hires in this new team, you are key to bridge the gap between research and production. You also have opportunities to shape ways of working in this new team. Your technical decisions will help people across the whole company benefit from our causal machine learning models reliably.\n\n\nWHERE YOUR EXPERTISE IS NEEDED\n\n\nCollaboratively design and implement a reliable and performant data infrastructure Continuously improve existing data systems with the aspiration of stress-free operations and a sustainable work pace Provide high-quality, performant datasets for machine learning and causal inference research. Provide guidance and supportive feedback for your colleagues\u2019 work to help them grow as professionals \n\nWHAT WE\u2019RE LOOKING FOR\n\n\nBachelor or higher in computer science, software engineering, mathematics, or closely related discipline Demonstrated real-world working experience in designing and setting up high volume, performant databases (experience with feature stores is a big plus) Strong understanding of data engineering tools (e.g. Spark, database, data format) Proficiency in programming skills in Python (Scala or other JVM language is a plus). Proficiency with professional software engineering practices (e.g. software design, data structure) Hands-on experience with cloud infrastructure, ideally AWS Experience working with Applied Scientists \n\nPERKS AT WORK\n\n\nA workplace run on trust, empowerment and feedback; positive, inspiring working atmosphere Competitive salary, employee share shop, 40% Zalando shopping discount, discounts from external partners, centrally located offices, public transport discounts, municipality services, great IT equipment, flexible working times, additional holidays and volunteering time off, free beverages and fruits, diverse sports and health offerings Mentoring and personal development opportunities and an international team of experts Relocation assistance for internationals, PME family service and parent & child rooms We celebrate diversity and are committed to building teams that represent a variety of backgrounds, perspectives and skills. All employment is decided on the basis of qualifications, merit and business need. \n\nABOUT ZALANDO\n\n\nZalando is Europe\u2019s leading online platform for fashion, connecting customers, brands and partners across 23 markets. We drive digital solutions for fashion, logistics, advertising and research, bringing head-to-toe fashion to more than 45 million active customers through diverse skill-sets, interests and languages our teams choose to use.\n\nPlease note that all applications must be completed using the online form - we do not accept applications via email."
    },
    {
        "position": "Analytics Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Cabify",
        "sector": "Technology, Information and Internet",
        "companySize": "1,001-5,000 employees",
        "location": "Madrid, Community of Madrid, Spain",
        "post": "About the job \n\nAbout the job\nDo you want to change the world? At Cabify, that's what we're doing. We aim to make cities better places to live by improving mobility for the people living in them, connecting riders to drivers at the touch of a button. Maybe one day cities will be places where nobody needs a private car. But we've still got a long way to go\u2026fancy joining us?\n\n\nAbout the position:\n\n\nAt Cabify we claim to be a data-driven company. Our team builds and maintains a robust warehouse where the Analytics team can find not only raw data, but also complex etls processes to provide the insights they need.\n\n\nBut where can I see all that data? We have a Tableau server instance that contains thousands of workbooks and is consulted by many users every day. We own that instance so we work hard to make sure everything works properly. We also created, and keep on creating, tooling around Tableau and our data warehouse, in order to keep on improving the way our users interact with data.\n\n\nAt Analytics Engineering we manage our own cloud infrastructure (AWS). Our in-house etls platform has more than 300 processes (Python, Airflow, Redshift, S3, Spectrum, Glue, RDS) that we visualize with our Tableau server instance (Tableau Server, Ec2, Python).\n\n\nYou will:\n\n\nWe are looking for new members, and this is how you will play an important part in helping us achieve our mission:\n\nMaintain & evolve our data warehouse, making sure the data is easily accessible, reliable & accurate.\nCreate data models, applying business logic to data. Evaluate all proposals and requests to improve the structure of the data warehouse.\nCoordinate with other data stakeholders to ensure overall health and performance of the data warehouse environment.\nDesign, develop, test, monitor, manage, and validate data warehouse activity. Including defining standards for the data warehouse as well as troubleshooting ETL processes and resolving issues effectively.\n\n\n\nOur Ideal candidate has:\n\nGreat alignment with our principles, we take this very seriously.\nAt least 5 years tenure in coding and delivering complex data projects.\nProven track record in Data Modeling.\nYou continuously find ways to derive more value in our raw data and lower the amount of effort our end users spend on getting answers.\nYou have proper DBA skills, with which you should ensure high standards in DWH data accessibility, integrity, security & performance monitoring.\nYou have intermediate level SQL skills, which allows you to understand subqueries, pivots, joins, and how indexes work.\nYou can take a complex concept and make it sound simple. You're accomplished at orienting business users within the data domain, understanding their needs, and translating them into technical requirements to ultimately design effective data solutions.\nYou have experience integrating data from multiple sources including DBs, product tracking, and APIs. You get excited by seeing your jobs run like clockwork.\nUnderstanding of Microsoft technologies (Azure, Data Factory and Microsoft SQL) is a plus.\n\n\n\nThe good stuff:\n\n\nWe're a company full of happy, motivated people and we never want that to change. Here are some more reasons why it rocks to be part of our family.\n\nExcellent Salary conditions: L3: 40000EUR - 48000EUR, L4: 45000EUR - 65000EUR\nWe also offer a very competitive stock options plan.\nRecharge day: Every 3rd Friday monthly off!\nRemote Position\nFlexible work environment & hours.\nRegular team events.\nCabify staff free rides.\nPersonal development programs based on our career paths.\nAnnual budget for training.\nFlexible compensation plan: Restaurant tickets, transport tickets, healthcare and childcare\nAll the equipment you need (you only have to bring your talent). \nA pet room ,so you don't have to leave your furry friend at home \nAnd last but not least...free coffee and fruit!\n\n\n\nSounds good? Joing us!!"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Stuart",
        "sector": "Transportation, Logistics, Supply Chain and Storage",
        "companySize": "501-1,000 employees",
        "location": "France",
        "post": "About the job \n\nStuart (DPD Group) is a sustainable \ud83c\udf31 last-mile logistics company that connects retailers and e-merchants to a fleet of geolocalised couriers across several countries in Europe.\n\n\nOur Mission \ud83d\ude80\nWe are an impact-driven company that aims to build the future of logistics for a more sustainable world: shared, efficient and reliable. We are committed to creating a new standard for urban deliveries that meet today\u2019s environmental and social challenges while offering a premium delivery experience blending speed, flexibility and convenience.\n\n\nOur motto: \u201cMake every delivery a moment all of us can truly celebrate!\u201d More than 3000+ leading brands already partner with us across Restaurants, Grocery, Retail & Luxury, eCommerce and Professional Services to deliver all types of goods at the tap of a button. Stuart is a highly diverse and inclusive company of 600+ talents from 90+ countries working in Paris \ud83c\uddeb\ud83c\uddf7, London \ud83c\uddec\ud83c\udde7, Barcelona, Madrid \ud83c\uddea\ud83c\uddf8, Poland \ud83c\uddf5\ud83c\uddf1, Portugal \ud83c\uddf5\ud83c\uddf9 and remotely around the world \ud83c\udf0d\n\n\nIt\u2019s the right moment and the right place for us to make an impact on millions of people, as home delivery services hit a record high. And guess what? You can help us fulfil our vision \ud83d\ude4c\n\n\nWe are looking for a Data Engineer \ud83e\udd16 to take part in the scaling of our data platform and support the team\u2019s and company\u2019s growth.\n\n\nOur stack currently relies mostly on the Python & Scala languages and It includes technologies like Apache Airflow, Docker, Apache Kafka, Tensorflow, etc. and we extensively use AWS products like S3, Redshift, and Athena.\n\n\nWhat will I be doing? \ud83e\udd14\n\nDesigning, implementing and maintaining a solid Data Lake and Data Warehouse that collects, stores, and processes data, focusing on scalability and reliability.\nWorking closely with the Business Intelligence and Data Science teams to help them design and build machine-learning algorithms and tooling to explore and visualize data.\nGrowing with us and sharing: https://medium.com/stuart-engineering \ud83e\udd13\n\n\n\nWhat do we need from you? \ud83d\ude0e\n\nFluency in English\n3+ years experience working with Python or Scala\n3+ years of experience design and implementing data platforms \nExperience with Apache Kafka or other streaming platforms\nExperience with query engines like AWS Athena, Hive, SparkSQL or similar technologies\n\nWant to put a smile on our face?\n\nExperience in designing data lakes in Amazon S3\nExperience with Apache Airflow\nExperience with Hadoop, Apache Spark, Flink or similar technologies\nExperience with data quality processes\n\n\n\nThe stuff you wanna know \ud83d\ude09\n\nFamily-friendly work-life balance - work from home and flexible hours \ud83c\udfe1\nOption to work remotely anywhere in Spain \ud83c\uddea\ud83c\uddf8\nTicket Restaurant by Edenred (\u20ac11 daily) \ud83e\udd57\nUnlimited access to Udemy for all your learning and development needs \ud83d\udcda\nPersonal Engineering Learning Budget of \u20ac1,000 per year \ud83e\uddd1\u200d\ud83d\udcbb \nStuart Academy with regular workshops, Stu-Classes, and Stu-Talks \ud83c\udf93\nStuart is putting Mental Health Awareness first! Wellness Allowance (\u20ac40 monthly) to use in any gym or sport class \ud83e\uddd8\nPrivate healthcare provided by Sanitas \ud83e\uddd1\u200d\u2695\ufe0f\nWork in an international, dynamic and passionate environment with a company culture focused on learning and development \ud83c\udf89 \n\n\n\nYou\u2019ve read all this way but you\u2019re missing a skill or two? No problem, it\u2019s our job to up-skill you to take your career to the next level. What we\u2019re trying to say is, don\u2019t be afraid to apply if you don\u2019t tick all the boxes \ud83d\udcaa\n\n\nAt Stuart, we believe that employees today want to evolve in collaborative, high-growth environments where they can demonstrate their abilities and thrive both professionally and personally. We are convinced that employees need to find alignment between their inner values and their company\u2019s culture and mission to unlock their full potential. We work to create a culture of empowerment, continuous learning and growth where everyone can bring expertise, own projects and easily measure their impact \ud83d\ude4c\n\n\nStuart is proud to be an equal opportunity workplace dedicated to promoting diversity. We don\u2019t discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status \ud83d\udc99\n\n\nWant to learn more about us? Visit https://stuart.com/about-us/"
    },
    {
        "position": "Data Modeller",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Flight Centre Travel Group",
        "sector": "Travel Arrangements",
        "companySize": "5,001-10,000 employees",
        "location": "West End, Queensland, Australia",
        "post": "About the job \n\nAbout your opportunity...\n\n\nDo you enjoy untangling complex, enterprise information? Do you enjoy the challenge of ensuring that the right information is delivered to the right people at the right time to drive the business? Do you thrive in a fast-paced environment that presents new challenges every day that also nurtures talent and emphasizes collaboration?\n\n\nWithin Flight Centre Travel Group (FCTG) Australia, we are seeking a highly motivated Data Modeller with experience in logical/conceptual data design, semantic layer modelling, and data stewardship to take on the challenge of transforming how FCTG manages and shares critical information assets.\n\n\nIn this role you will provide a graphical representation of the entities that interoperate within the organisation in support of the organisation business processes and the relationships among these entities. You will be responsible for developing the data models. They transform business information into models by engaging with the business users and soliciting their requirements and iteratively refine the conceptual, logical, and physical data models. You will work with the business intelligence, artificial intelligence, data analysts and data scientists on modelling of the curated data and the common semantic layer.\n\n\nReporting to the Data Governance Manager within the Data Science and Engineering (DSE) team, this role goes beyond the role of a typical application level \"data modeller\" in that it requires modelling not just from a single business perspective but from an organisational perspective with Global reach. Additionally, this role will have responsibilities in working on data governance initiatives within DSE and be an advocate for data governance best practices throughout the organisation.\n\n\n\n\nWhat You\u2019ll Do...\n\n\n\nEngage the business users to assess their information needs\nReview the business process and conceptualize the entities that interoperate within the business process\nDetermine how the various entities are related and develop entity relationship diagrams that represent the connections among the entities\nIdentify each entity's characteristics and properties and ensure that the entities can be differentiated within the model\nDevelop a logical data model and validate the model to ensure that it serves the needs of the business application and its consumers\nTransform the logical representation of the model into a physical representation and work with data engineers to instantiate and manage the data\nCollaborate with the BI and Analytics teams on creating the optimized, reusable semantic models, complete with metadata and lineage information\n\n\n\nWho you are\u2026\n\n\n\nExperience with Business Intelligence products e.g., Power BI \nExcellent teaming and communication skills\nStrong consultative, facilitation and consensus building skills \nProven experience in an enterprise environment developing relational datasets\nProven experience developing models for Business Intelligence solutions\nStrong analytical, data profiling and problem-solving skills \nStrong verbal and written communication skills\nAdvanced SQL skills\nIn depth knowledge of Azure technologies\nIn depth knowledge of Databricks \n\n\n\nDesirable Competencies...\n\n\n\n3+ years of data modelling experience\nIn depth knowledge of the data modelling tools being proficient in at least one\nExperience with Microsoft\u2019s Purview\nMandatory: Bachelor's degree in management Information Systems, Computer Science, Computer Information Systems, or equivalent Information Technology discipline\n\n\n\nLet\u2019s skip to the good part\u2026\n\n\n\nGenerous remuneration structure\nTravel discounts, in-house financial and health services, access to internal 24/7 gym\nGlobal career opportunities in a network of brands and businesses\nOngoing training and professional development\nFun and flexible work environment\nProud Corporate Social Responsibility platform through the Flight Centre Foundation\nRole can be a contract or full-time\n\n\n\nWe do things a little differently\u2026\n\n\nWe do things a little differently around here. We do things the FCTG Way.\n\n\nWe have a unique culture and an irreverent DNA based on a proven mix of ideas, values and ways of working that have helped shape our business over the past 40+ years.\n Across all our brands, we take our business seriously but not ourselves. We take leaps of faith, have trust in our teams and work collaboratively to achieve our goals. That\u2019s the FCTG Way.\n\n\nIf you think you have FCTG DNA, reach out today."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Mars",
        "sector": "Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Netherlands",
        "post": "About the job \n\nData and Analytics is foundational to Royal Canin and will drive our transformation to a business that is powered by data. To deliver on this ambition we are looking to recruit a Data Engineer who will work remotely from the Netherlands and be able to attend meetings in Amsterdam and travel to the Global HQ in South of France.\nThe role reports to the Royal Canin Global Data Engineering Lead. \nWhat are we looking for?\n\nDeep and rich experience in working with data (Python / Spark / Databricks) and delivering robust data transformation pipelines. \nPrevious experience working in a cloud environment would be a plus (Azure preferred). \nGreat at developing new relationships, driving positive change, and matching analytics opportunities to data acquisition strategy.\nExcellent planning and prioritization skills.\nGood understanding of Data Protection and Privacy principles and practices including GDRP.\nWork comfortably in an agile and fast paced environment.\n\nWhat will be your key responsibilities?\n\nEngineer and orchestrate data flows & pipelines using high quality, easily deployable,\nrepeatable and extensible codebases that ingest and integrate data from many disparate\ndata sources in a cloud environment using a progressive tech stack.\nDesign and build complex data models to support performant and accurate analytical insight, science research and marketing activation purposes removing excessive data preparation from the solution users to expedite their processes and reduce effort duplication and subsequent errors. \nSupporting the global data engineering lead to adapt data architectures, analytical data platforms & related processes (i.e. designing and specifying data structures and processing frameworks based on local functional and technical requirements. )\nDeveloping local strategies for data acquisition and democratization\nManaging data transformation and troubleshooting data processing issues\nEU Platform Support, alerting and monitoring to ensure high platform reliability in compliance with Mars\nCyber Security Standards and Privacy Policies\nData Lifecycle Management through Global Metadata and Access Control Management\nPartner with functions and divisions to ensure RC data capabilities roadmap, operating model and governance principles are best serving the organization data strategy and are effectively activated across RC Europe\n\nWhat can you expect from Mars?\n\nAt Mars, we believe in a relationship of mutual trust, dignity and respect between our company and Associates that is more meaningful than the standard employer/employee relationship. \nAs Associates, we can expect to be respected, supported and valued as individuals, to be treated fairly and equitably.\nThe opportunity to learn and develop, taking charge of your own career across Mars.\nAn environment where you are empowered to be proactive and to take initiatives to make a difference.\nYou will work in a multicultural environment (more than 40 nationalities)"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Wilhelmsen group",
        "sector": "Maritime Transportation",
        "companySize": "10,001+ employees",
        "location": "Oslo, Norway",
        "post": "About the job \n\nFounded in Norway in 1861, Wilhelmsen is now a comprehensive global maritime group providing essential products and services to the merchant fleet, along with supplying crew and technical management to the largest and most complex vessels ever to sail. Committed to shaping the maritime industry, we also seek to develop new opportunities and collaborations in renewables, zero-emission shipping, and marine digitalization. Supporting a diverse and inclusive workplace, with thousands of colleagues in more than 70 countries, we take competence, sustainability, innovation, and unparalleled customer experiences one step further.\n\n\nAnchor your career in the maritime industry and dive into a sea of opportunities with us now! Empowering people through technology is our aspiration and so is setting the standard for how we work with technology across Wilhelmsen as shapers of the maritime industry. Creating actionable insights from data is a strategic priority and we are continuing to build and invest in our data & analytics platforms to support our ever-changing data driven ambitions as a company.\n\n\nThe Data & Analytics team plays a key role in Wilhelmsen Ships Service delivering operational, financial and management reporting to business divisions across the organization. This agile team consists of both internal and external data engineers, having full responsibility for both development and operations, from creating the data pipelines to visualising the data to end users. Our ideal candidate is looking for new challenges and would like to join a team of experienced professionals who are passionate about innovation, technology, and transformation.We can offer a great culture and work environment, career development, work-life balance and a job that is both challenging and stimulating.\n\n\nWe are looking for a Data Engineer to strengthen our Data & Analytics team by taking a key role in making our data driven ambitions a reality. We have recently completed our migration to Snowflake in Azure and are now looking for someone who can play a key role in the journey of taking it to the next level. The right person will help with designing and developing data pipelines, data models, reports, and dashboards, as well as functioning as our Power BI subject matter expert.\n\n\nYou will also be involved in continuously improving Self Service BI as well as driving Power BI competence within the organization. The right candidate will also have the possibility to work with use-cases related to advanced analytics, including Process Mining, ML and IoT/streaming data. The role will report to the Data & Analytics Manager.\nThis is the perfect role for you if you enjoy getting your hands dirty with data and code, and thrive in solving complex challenges and testing out new technologies.\n\n\n\n\nYour main responsibilities:\n\nDevelop and maintain Power BI reports in collaboration with key stakeholders across the organization\nDesign, develop and quality assure data pipelines and dimensional models (star-schema)\nMaintain Power BI service, including workspace, report and app management\nDrive the competency build related to Power BI throughout the organisation, to ensure that WSS are in the forefront when it comes to utilizing Power BI and the surrounding Microsoft application eco-system\nRun bi-weekly \u201cCenter of Excellence\u201d forums, with Power BI as one of the focus areas to share ideas, best-practices and other cool stuff\n\n\n\n\n\nQualifications:\n\nMinimum 2 years of experience with Power BI and building data visualisations, as well as building and maintaining data pipelines and dimensional data-modelling\nBachelor\u2019s degree from business/finance, computer science, engineering or similar.\nExperience with Power BI, Snowflake, WhereScape and/or other ETL and visualisation tools\nExperience with Azure and/or other cloud platforms\nExperience with DAX/SQL/Python and/or other data preparation languages\nProficient in English, written and verbal with great communication skills\n\n\n\nThe firm aspires to be the leading enablers of sustainable global trade. Committed to shaping the maritime industry, we also seek to develop new opportunities and collaborations in renewables, zero-emission shipping, and marine digitalization. Please apply for the position to be a part of the change!\n\n\nWe will review applicants on a rolling basis."
    },
    {
        "position": "Software Engineer (Data) - Economics & Experimentation",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Zalando",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Berlin, Berlin, Germany",
        "post": "About the job \n\nTHE OPPORTUNITY\n\nYou will join a brand-new team in Economics and Experimentation to productionalize causal machine learning models developed by our Applied Scientists. Our team is highly visible. The causal models and experimentation platforms we develop are used for decision-making for both the senior management board and all Zalando product teams.\n As one of the very first hires in this new team, you are key to bridge the gap between research and production. You also have opportunities to shape ways of working in this new team. Your technical decisions will help people across the whole company benefit from our causal machine learning models reliably.\n\n\nWHERE YOUR EXPERTISE IS NEEDED\n\n\nCollaboratively design and implement a reliable and performant data infrastructure Continuously improve existing data systems with the aspiration of stress-free operations and a sustainable work pace Provide high-quality, performant datasets for machine learning and causal inference research. Provide guidance and supportive feedback for your colleagues\u2019 work to help them grow as professionals \n\nWHAT WE\u2019RE LOOKING FOR\n\n\nBachelor or higher in computer science, software engineering, mathematics, or closely related discipline Demonstrated real-world working experience in designing and setting up high volume, performant databases (experience with feature stores is a big plus) Strong understanding of data engineering tools (e.g. Spark, database, data format) Proficiency in programming skills in Python (Scala or other JVM language is a plus). Proficiency with professional software engineering practices (e.g. software design, data structure) Hands-on experience with cloud infrastructure, ideally AWS Experience working with Applied Scientists \n\nPERKS AT WORK\n\n\nA workplace run on trust, empowerment and feedback; positive, inspiring working atmosphere Competitive salary, employee share shop, 40% Zalando shopping discount, discounts from external partners, centrally located offices, public transport discounts, municipality services, great IT equipment, flexible working times, additional holidays and volunteering time off, free beverages and fruits, diverse sports and health offerings Mentoring and personal development opportunities and an international team of experts Relocation assistance for internationals, PME family service and parent & child rooms We celebrate diversity and are committed to building teams that represent a variety of backgrounds, perspectives and skills. All employment is decided on the basis of qualifications, merit and business need. \n\nABOUT ZALANDO\n\n\nZalando is Europe\u2019s leading online platform for fashion, connecting customers, brands and partners across 23 markets. We drive digital solutions for fashion, logistics, advertising and research, bringing head-to-toe fashion to more than 45 million active customers through diverse skill-sets, interests and languages our teams choose to use.\n\nPlease note that all applications must be completed using the online form - we do not accept applications via email."
    },
    {
        "position": "Senior Data Engineer (GNFR Conversion)",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Woolworths Group",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Auckland, Auckland, New Zealand",
        "post": "About the job \n\n\nJoin one of the biggest Data & Analytics teams in Aotearoa \nArtificial Intelligence & Machine Learning Environment\nPurpose-built offices in Ponsonby, Agile delivery model\n\nReady to make an impact? We are!\n\nAnalytics and Insights underpin Countdown\u2019s business operations, customer experience, critical decision making and strategy development. Our team is highly talented and works with some of the latest Google technologies to deliver data-driven insights through advanced analytics. You\u2019re going to love working with our fast paced A&I team-they understand, collaborate, analyse and solve! They disseminate vast and complex information, bringing it to life in a variety of new and different ways.\n We are innovators, instigators and love solving complex problems. We test and we learn but remain humble whilst sharing our success. We work end-to-end within an Agile model that allows us to deliver quickly and be ahead of the game.\n\nAbout the Role | M\u014d te T\u016branga\n\nAs a Senior Data Engineer you will be part of a high performing, cross functional Analytics and Insights team. You have the opportunity to work alongside a group of talented architects, data engineers, data scientists and senior analytics professionals.\n We are famous for focusing on outcomes and delivering tangible business value right across our retail operation. We make a difference by working collaboratively on high impact business problems for the Countdown supermarket chain and our digital stores.\n This is a key role responsible for designing, building, manipulating and optimising our data, data pipelines and data architecture in our ambition to be a data driven business to create the best experiences for our customers through analytics led decisions. We are responsible for analytics across all aspects of our business so there is no limit to what you will get to experience & learn working in our team.\n\nAbout You | M\u014du\n\nYou must be comfortable working on cloud data platforms, handling large volumes of data and be passionate about the influence and value you will create from data. You will need to understand the importance of managing our data assets in a high integrity environment that always strives to do the right thing for our customers, our partners and our employees. Whether you prefer - solution design, new technology, engineering, constant learning of cutting edge skills and knowledge of tools such as Python and SQL, you will be in a tightly knit and supportive community that cares for your career development.\n If you are looking to broaden your horizons and work within some of the largest datasets in the country-apply today!\n\nWorking with Countdown | Te Mahi ki Countdown\n\nOur purpose is to make Kiwis' lives a little better every day.\n We\u2019re friendly, down-to-earth, and energetic - we work hard and we have a great time doing it, and we are passionate about what we do. There is plenty of scope for new ideas, lots of room for you to add value, and importantly, you\u2019ll be working with a business that touches the lives of three million New Zealanders a week.\n\nCome as you are | Haere mai r\u0101\n\nWe\u2019re an equal opportunity employer and are committed to the principle of equal opportunity for all.\n If you\u2019re smart and good at what you do, come as you are."
    },
    {
        "position": "Data Analyst (f/m/d) technical lead at Computed Tomography",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Siemens Healthineers",
        "sector": "Hospitals and Health Care",
        "companySize": "10,001+ employees",
        "location": "Forchheim, Bavaria, Germany",
        "post": "About the job \n Do you want to help create the future of healthcare? Our name, Siemens Healthineers, was selected to honor our people who dedicate their energy and passion to this cause. It reflects their pioneering spirit combined with our long history of engineering in the ever-evolving healthcare industry.\n We offer you a flexible and dynamic environment with opportunities to go beyond your comfort zone in order to grow personally and professionally. Sound interesting?\n\nThen come and join our global team as Data Analyst (f/m/d) technical lead at Computed Tomography (CT) to shape the future of CT by applying your technical skills, analytical mindset and product intuition.\n\nChoose the best place for your work - within the scope of this position, it is possible, in consultation with your manager, to work mobile (within Germany) up to an average volume of 60% of the respective working hours.\n\nThis position is limited to 24 months.\n\nYour tasks and responsibilities:\n\n\n\nYou will drive the mindset of data driven decisions and promote the benefits and value of our data analytics solutions\nAs a product owner of business-critical data analytics applications, you will support the analysis of stakeholder objectives, assess the problems needing to be solved using Data Analytics methods and communicate the requirements to other Data Analysts and Data Scientists\nYou will design, ideate, implement, validate, and deploy data analytics and data science projects in CT to analyze data, generate insights, create business value, and support decision-making\nAs a recognized Data Science expert, you will actively contribute to our Communities of Practice and knowledge sharing events and thereby shape our analytics methods, standards, and guidelines\nYou will provide a technical leadership to the team of data analysts and data scientists\n\n\nTo find out more about the specific business, have a look at Computed tomography\n\nYour qualifications and experience:\n\n\n\nYou hold a Master's degree in science, technology, engineering and mathamatics or a related field with a strong quantitative focus\nYou have several years of experience as a data analyst with successful execution of a variety of practical projects\nYou have strong understanding and experience in execution of data science workflows like CRISP-DM\nYou know the principles of agile development and have already worked as a member of an agile development team\nYou have solid understanding of Machine Learning (supervised and unsupervised learning, NLP, explainable AI) and you are strong in exploratory data analysis and feature engineering\nYou have a successful track record of running diverse data analytics / data science projects\nYou have experience in Visual Analytics, building data-driven applications for end users with BI tools (Qlik, Power BI)\n\n\nYour attributes and skills:\n\n\n\nYou have excellent professional communication skills (English, written and oral), German would be a plus\nYou are flexible and curious to learn new technologies and business areas fast\nYou confidently interact with developers and business stakeholders and can present your work to technical and non-technical audiences\nYou have an entrepreneurial and performance-driven mindset and a team player mentality with the ability to drive results under own initiative in an agile and fast driving environment\nYou have strong technical grasp on task prioritization and effort estimation\nYou are motivated to drive a range of data analytics projects and to lead strategic visions and benefit our team with your active, energetic mindset\nYou have experience / strong potential to functionally lead the team\n\n\nOur global team:\n\nSiemens Healthineers is a leading global medical technology company. 66,000 dedicated colleagues in over 70 countries are driven to shape the future of healthcare. An estimated 5 million patients across the globe benefit every day from our innovative technologies and services in the areas of diagnostic and therapeutic imaging, laboratory diagnostics and molecular medicine, as well as digital health and enterprise services.\n\nOur culture:\n\nOur culture embraces different perspectives, open debate, and the will to challenge convention. Change is a constant aspect of our work. We aspire to lead the change in our industry rather than just react to it. That\u2019s why we invite you to take on new challenges, test your ideas, and celebrate success.\n Check our Careers Site at https://www.siemens-healthineers.com/de/careers\n As an equal opportunity employer, we welcome applications from individuals with disabilities.\n Wish to find out more before applying? Contact us: +49 (9131) / 17 \u2013 1717, if you wish to discuss any initial questions with our recruitment team. The contact person handling this job ad is\n Laura Roos.\n We care about your data privacy and take compliance with GDPR as well as other data protection legislation seriously. For this reason, we ask you not to send us your CV or resume by email. We ask instead that you create a profile in our talent community where you can upload your CV. Setting up a profile lets us know you are interested in career opportunities with us and makes it easy for us to send you an alert when relevant positions become open. Click here to get started.\n Siemens Healthineers Germany was awarded the Great Place to Work\u00ae certificate.\n\nOrganization: Siemens Healthineers\n\nCompany: Siemens Healthcare GmbH\n\nExperience Level: Mid-level Professional\n\nJob Type: Full-time"
    },
    {
        "position": "Data Scientist",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Sanofi",
        "sector": "Pharmaceutical Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Barcelona, Catalonia, Spain",
        "post": "About the job \n\nAbout Sanofi:\n\nWe are an innovative global healthcare company, driven by one purpose: we chase the miracles of science to improve people\u2019s lives. Our team, across some 100 countries, is dedicated to transforming the practice of medicine by working to turn the impossible into the possible. We provide potentially life-changing treatment options and life-saving vaccine protection to millions of people globally, while putting sustainability and social responsibility at the center of our ambitions.\n\nOur vision for digital, data analytics and AI\n\nSanofi has recently embarked into a vast and ambitious digital transformation program. A cornerstone of this roadmap is the acceleration of its data transformation and of the adoption of artificial intelligence (AI) and machine learning (ML) solutions. This has enabled us, to accelerate R&D, improve manufacturing and commercial performance, and bring novel drugs and vaccines to patients faster, all in order to improve health and save lives.\n The Digital Team at Sanofi is a unique data-driven team. We pride ourselves on being data obsessed and highly focused on using state of the art processes along with global technologies to drive impact to our solutions. We measure our insights and products based on how they preform across the globe and hold ourselves to the highest regard as our solutions can impact millions of lives. When tackling a problem, we do not just ask how we will create a solution, but how we will create a solution that reaches across the world with the best possible societal outcome.\n If you are passionate about improving the health and wellness of people across the globe using Data as your means, then you should look no farther than the Digital Team here at Sanofi.\n Join us on our journey in enabling Sanofi\u2019s Digital Transformation through becoming an AI first organization. This means:\n\n\nAI Factory - Versatile Teams Operating in Cross Functional Pods: Utilizing digital and data resources to develop AI products, bringing data management, AI and product development skills to products, programs and projects to create an agile, fulfilling and meaningful work environment.\nLeading Edge Tech Stack: Experience build products that will be deployed globally on a leading-edge tech stack.\nWorld Class Mentorship and Training: Working with renowned, published leaders and academics in machine learning to further develop your skillsets\n\n\nThere are multiple vacancies across our Digital organisation. Further assessments will be completed to determine specific function and level of hired candidates. \n\nJob Highlights: \n\n\n\nApply data science expertise in machine learning, statistics, text-mining/NLP, forecasting and optimization to multiple analytics projects. \nBuild models, algorithms, simulations, and experiments by writing highly optimized code and using state-of-the art machine learning technologies. \nWork on full-spectrum of activities, from conducting ML experiments to delivering production-ready models. \nUse data analysis, visualization, storytelling, and data technologies to scope, define and deliver AI-based data products. \nWork with developers, engineers, and MLOps to deliver AI/ML solutions. \n\n\nKey Functional Requirements & Qualifications:\n\n\n\nHands-on AI/ML modeling experience of complex datasets combined with strong understanding of theoretical foundations of AI/ML. \nExpertise within most of the following areas: supervised learning, unsupervised learning, deep learning, reinforcement learning, federated learning, time series forecasting, Bayesian statistics, optimization \nExperience developing deployable code and deploying models in product-focused development under an agile environment \nComfortable working in cloud and high-performance computing environments (e.g. AWS, GCP, Databricks, Apache Spark) \nExperience in production-ready software development \nExcellent written and verbal communication, business analysis, data visualization and data storytelling skills \nA demonstrated ability to work and collaborate in a team environment \nNice to have: Experience in life sciences and healthcare and experience in a complex global organization \n\n\nKey Technical Requirements & Qualifications:\n\n\n\nPhD in mathematics, computer science, engineering, physics, statistics, economics, or a related quantitative discipline with strong coding skills, OR Master\u2019s\u202fDegree in relevant domain with 4+ years of analytical experience \nExpertise with core data science languages (such as Python, R, Scala), and familiarity with different database systems (e.g. SQL, NoSQL) \nDisciplined AI/ML development (CI/CD, Orchestration) \nKnowledge of\u202fTableau, Power BI, Plotly or similar \nExperience with various enterprise-level Application Programming Interfaces (APIs) \n\n\nLocation: \n\nGlobal Innovation center - Barcelona - Spain\n At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all.\n Sanofi is committed to welcoming and integrating people with disabilities.\n\nNote:\n\nOnly those candidates selected for interviews will be contacted.\n Thank you in advance for your interest.\n You can learn more about our opportunities:\n www.sanofi.com\n www.linkedin.com/company/sanofi\n\nPursue Progress. Discover Extraordinary.\n\nOwn your future. Make your move!\n\n#DDBBCN \n\n#Hybrid\n At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all."
    },
    {
        "position": "CSCE-A Data Scientist: Real-World Analytics and Machine Learning",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Intel Corporation",
        "sector": "Semiconductor Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Leixlip, County Kildare, Ireland",
        "post": "About the job \n\nJob Description\n\nCorporate Services (CS) touches the lives of every Intel employee every day. CS creates an environment where employees can prosper while creating the innovative technologies that make amazing possible. Our scope is vast and includes operating and maintaining all Intel sites, offices, labs and factories globally as well onsite services and experiences that help employees stay safe and productive. CS also helps to make Intel and our community a greener place by supporting Intel commitment to environmental sustainability, including investing in conservation projects, setting company-wide environmental targets and driving reductions in greenhouse emissions, energy use, water use and waste generation.\n CS Central Engineering (CSCE) owns the strategic and systematic development, standardization, implementation, and measurement of key central engineering functions to drive efficiency, reliability, and world class cost optimization to support our global facilities portfolio. The scope of the Central Engineering Organization within Corporate Serviced consists of asset management, cost engineering, enabling growth, and automation.\n Central Engineering - Automation team is looking for an innovative, creative, and intellectually curious Data Scientist with experience in developing Machine Learning software to join our CS Central Engineering Automation team. This is an exciting opportunity to work in one of the world's leading semiconductor manufacturers working with real-world analytics to help our clients maximize equipment uptime, reduce risk and make more informed decisions. We are at a unique point in our company's journey. As we scale to more manufacturing sites worldwide, we must be efficient in the way we monitor and maintain our systems. Only by striving for excellence in our maintenance strategy and remaining at the technological edge can we ensure that we achieve our mission of creating world-changing technology that improves the life of every person on the planet.\n\nAs a CSCE-A Data Scientist your responsibilities will include but are not limited to:\n\n\nWork alongside our multi-disciplinary Automation team and apply data science techniques to predict anomalies and faults in complex, large-scale time-series data.\nApply your data science skills and statistical knowledge to build an autonomous fault detection and root cause platform using Machine Learning methodologies.\nSupport consulting activities to identify data availability, quality, and modelling requirements and participate in our customers' engagement.\n\nWhat We Offer\n\n\nWe give you opportunities to transform technology and create a better future, by delivering products that touch the lives of every person on earth. As a global leader in innovation and new technology, we foster a collaborative, supportive, and exciting environment-where the brightest minds in the world come together to achieve exceptional results.\nWe offer a competitive salary and financial benefits such as bonuses, life and disability insurance, opportunities to buy Intel stock at a discounted rate, and Intel stock awards (eligibility at the discretion of Intel Corporation).\nWe provide benefits that promote a healthy, enjoyable life: excellent medical plans, wellness programs and amenities, flexible work hours, time off, recreational activities, discounts on various products and services, and many more creative perks that make Intel a Great Place to Work.\nWe're constantly working on making a more connected and intelligent future, and we need your help. Change tomorrow. Start today.\n\nMinimum Qualifications\n\nQualifications\n\n\nBachelors/Masters with 8 yrs experience in Computer Science or related field or a PhD in Computer Science or related field with 4 yrs experience in Statistical analysis, machine learning and deep learning methodologies.Large datasets and scaling ML models and information extraction. Computing fundamentals in algorithm design, data structures, complexity analysis, problem-solving and diagnosis.\nGood understanding of data science concepts, such as regression analysis, predictive modelling, and data visualization.\n\nPreferred Qualifications\n\n\nUnderstanding of what it takes to write clean code and experience with software development lifecycle.\nKnowledge of system identification of dynamic models and control systems.\nExperience with Vibration analysis, Fault Detection and Root Cause Diagnosis.\nPractical experience of predicting Remaining Useful Life.\nExtraction of conditional indicators using signal processing techniques and analyzing data from physical sensors.\n\nAt Intel inclusion means we recognize and respect the worth and dignity of every employee. We promote and sustain a sense of belonging, valuing diverse talents, beliefs, backgrounds, and experiences to help Intel win. Our success depends on Intel\u2019s amazing employees. Make Intel your workplace of choice today. Intel provides equal employment opportunity for all applicants and employees in all areas of employment.\n Intel does not discriminate based on race, characteristics that are commonly or historically associated with race including hair, color, religion, religious creed, sex, national origin, ancestry, age, physical or mental disability, medical condition, genetic information, military and veteran status, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or ordinance.\n\nInside this Business Group\n\nAs the world's largest chip manufacturer, Intel strives to make every facet of semiconductor manufacturing state-of-the-art -- from semiconductor process development and manufacturing, through yield improvement to packaging, final test and optimization, and world class Supply Chain and facilities support. Employees in the Technology Development and Manufacturing Group are part of a worldwide network of design, development, manufacturing, and assembly/test facilities, all focused on utilizing the power of Moore\u2019s Law to bring smart, connected devices to every person on Earth.\n\nWork Model for this Role\n\nThis role will be eligible for our hybrid work model which allows employees to split their time between working on-site at their assigned Intel site and off-site."
    },
    {
        "position": "Big Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Solera, Inc.",
        "sector": "IT Services and IT Consulting",
        "companySize": "5,001-10,000 employees",
        "location": "Madrid, Community of Madrid, Spain",
        "post": "About the job \n\nThe Role\n\n\nOn this position, you will be required to have:\n\n\n\nStrong analytical skills with the ability to collect, organize, analyze, and disseminate significant \n\namounts of information with attention to detail and accuracy. Enhance data collection procedures to \ninclude information that is relevant for building analytic systems. \n\nObsession by accuracy data and automate processes.\nSolid problem-solving skills, supported by a logical, methodical, and thorough approach to \n\nimplementation.\n\nKnowledge of data cleaning, wrangling, visualization, and reporting, with an understanding of the best, \n\nmost efficient use of associated tools and applications to complete these tasks\n\nSpecify quality checks that assure QA in data and one SVOT\nExcellent interpersonal and communication skills to establish and maintain collaborative work \n\nrelationships at all levels.\n\nFluent English on business level (written and spoken)\n\n\n\n\n\nWhat You\u2019ll Do\n\n\n\nRead, extract, transform, stage and load data to selected tools and frameworks (cloud and on \n\npremise)\n\nWork closely to product and reporting team to integrate your work into current production solutions.\nProcess unstructured data into a form suitable for analysis\nSupport business decisions with ad hoc analysis as needed\nFilter and \u201cclean\u201d data by reviewing computer reports, printouts, and performance indicators to locate \n\nand correct code problems\n\nMonitoring data performance and modifying infrastructure as needed\nImprove big data performance jobs and adapt them to different environments\n\n\n\n\n\nWhat You\u2019ll Bring\n\n\n\nBachelor\u2019s degree in computer science or numerate discipline \nExperience with SQL \nTechnical expertise on big data environments such Hadoop or Azure Ecosystem\nExperience processing large amounts of structured and unstructured data, including integrating data from multiple sources.\nProgramming experience ideally in Spark, Java or Python and ability to learn new coding languages and programs\nTechnical expertise regarding data models, database design development and data mining.\nExperience in production support and troubleshooting.\nHands on with \u201ccan do\u201d attitude.\nDeep knowledge of data mining, machine learning, natural language processing, or information retrieval\nExperience in MapReduce is a plus.\nAgile methodologies\nPlatform experience, JIRA, Confluence"
    },
    {
        "position": "Algorithm Engineer - Natural Language Processing, Search",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Shopee",
        "sector": "Technology, Information and Internet",
        "companySize": "5,001-10,000 employees",
        "location": "Singapore, Singapore",
        "post": "About the job \n\nAbout The Team\n\nThe search algorithm team is responsible for Shopee\u2019s product and store search. Our main mission is to continuously build world class search algorithms and become a power engine for the company's sustainable growth. We welcome passionate and experienced talents to join us and serve our customers from all over the world.\n\nJob Description\n\n\nResponsible for the design and optimisation algorithms, including category prediction, entity matching, semantic models, etc.\nDesign and optimisation of the recall algorithm model, including query rewriting, vector retrieval, deep personalised retrieval model, multi-modal retrieval model, etc.\nConstruct and apply knowledge graphs and knowledge bases, data annotation and data mining and apply them to relevance, query rewrite and etc.\nEnhance user shopping experience through improving features such as prefill, suggestion and related search.\n\n\nRequirements\n\n\nMore than 4 years of relevant work experience\nMaster degree or above in computer science, computational linguistics and other related majors\nHave excellent coding skills, hands-on online code development experience, and proficiency in at least one language among C++/Golang/Python/Java"
    },
    {
        "position": "Software Engineer",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "The Coca-Cola Company",
        "sector": "Food and Beverage Services",
        "companySize": "10,001+ employees",
        "location": "Sofia, Sofia City, Bulgaria",
        "post": "About the job \n\nPosition Overview\n\nCoca-Cola is one of the most recognizable brands in the world. We were the first company to ever utilize coupons and for decades our marketing practices have been cutting edge. Today we\u2019re using world class Marketing Technology (MarTech) to continue to market our brands to billions of consumers globally.\n The Coca-Cola Company\u2019s IT organization is in the midst of a digital transformation that allows our employees to use world class technology to connect our products to our customers all over the world. This journey is a very exciting time for Coca-Cola and our employees are big contributors to our Success and Growth. Our large, scale and complex environment offers an incredible opportunity to address challenges, enable innovative solutions to make a difference for our customers, leveraging technology such as Adobe Experience Platform (AEP), AWS, MS Azure, and many more.\n To continue this digitalization, we are looking for a software engineer to join our dynamic team to help build scalable, cutting-edge technologies for today and tomorrow. This position is part of a globally networked team that utilizes deep technical skills to create and improve software applications that empower the Coca-Cola Company to reach our growth objectives. If you enjoy a dynamic, innovative environment, are eager to learn and highly motivated, we\u2019d love to speak with you!\n\nWhat You\u2019ll Do For Us\n\n\nDevelop and implementation of new capabilities and enhancements within Coca-Cola\u2019s Adobe Experience Platform (AEP) and Cloud environments\nIntegrate AEP with Coca-Cola\u2019s internal Consumer Data Services (CDS) platform, Adobe\u2019s Experience Cloud ecosystem (Target, Magento, Campaign), and 3rd party destinations including: social, mobile, Google, Demand Side Platforms (DSPs), and other Ad Tech capabilities\nDesign and code the interfaces between TCCC\u2019s Consumer Data Services (CDS) platform and AEP, AEP to TCCC\u2019s enterprise data lake, identity graph, Google Big Query, and Adobe Web SDK JavaScript library\nCreate Customer Journey Analytics dashboards providing insights to business stakeholders\n\nQualifications And Requirements\n\n\nBachelor's degree in Computer Science, Computer or Electrical Engineering or related fields\n2 years as Full Stack Software Engineer with experience of creating elegant, efficient, and testable code\nBack-end programming experience with Java, JavaScript, Python, plus front-end JavaScript development frameworks such as ReactJS, NodeJS, AngularJS, SQL, etc.\nWorking knowledge of AWS and/or Azure serverless products (network, storage, compute, database)\nExperience using cloud database systems and services such as AWS Aurora/Dynamo DB/Redshift or Azure alternatives\nExperience implementing REST APIs and web services\nExperience in dev-ops delivery/support models as well as iterative software delivery methodologies \u2013 Agile, SCRUM, etc. \nSolid understanding of Git-based version control\n\nPreferred Experience \u2013 if you don\u2019t have it, we\u2019ll train you on it!\n\n\nAt least 1 year of experience with Adobe Experience Platform including managing Experience Data Model (XDM) schemas, AEP setup through API, REST & Postman\nMarketing Automation experience with Consumer Data Platforms (CDPs) including: audience segmentation & activation, multichannel campaign management, and real-time interaction management, and consumer database, work for diverse global companies preferred\nAmazon Web Services (AWS) and/or Microsoft Azure Certifications \nExperience with personal (PII) data privacy and security best practices\nExperience with Azure B2C and Consumer Data (Consumer Identity and Access Management) is a strong plus\nExperience working in a multinational, distributed team, with in-house and external delivery resources\nProficiency in Jira, or similar Agile life cycle management tools\n\nWhat We Can Do For You\n\n\nInnovation & Technology: The ability to work with an award-winning team that is on the cutting edge of innovation. \nLearning & Development:\u202fAt\u202fThe\u202fCoca-Cola Company we believe innovation can't happen without continuous learning and we provide our employees many ways to grow professional and personally.\nAgile Work Environment: We embrace agile with management that believes in removing barriers, so you are empowered to experiment, iterate and innovate.\n\nSkillsAngularJS; Hyper Text Markup Language (HTML); React.js; Cascading Style Sheets (CSS); Customer Service; Chatbots; Algorithms; Agile Methodologies; Adobe Experience; Data Modeling; Natural Language Processing (NLP); Analytical Techniques; Oral Communications; Server Side Development; Azure Bot Service; JavaScript; Artificial Intelligence Technologies; Written Communication; Problem Solving; Data Mining; Teamwork; Adaptability; Adobe Experience Platform; Self-Starter; Machine Learning\n\nOur Purpose And Growth Culture\n\nWe are taking deliberate action to nurture an inclusive culture that is grounded in our company purpose, to refresh the world and make a difference. We act with a growth mindset, take an expansive approach to what\u2019s possible and believe in continuous learning to improve our business and ourselves. We focus on four key behaviors \u2013 curious, empowered, inclusive and agile \u2013 and value how we work as much as what we achieve. We believe that our culture is one of the reasons our company continues to thrive after 130+ years. Visit Our Purpose and Vision to learn more about these behaviors and how you can bring them to life in your next role at Coca-Cola.\n We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and/or expression, status as a veteran, and basis of disability or any other federal, state or local protected class. When we collect your personal information as part of a job application or offer of employment, we do so in accordance with industry standards and best practices and in compliance with applicable privacy laws.\n R-74898"
    },
    {
        "position": "Data Scientist",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Symptoma",
        "sector": "Hospitals and Health Care",
        "companySize": "51-200 employees",
        "location": "Vienna, Vienna, Austria",
        "post": "About the job \n\nWE WANT TO SAVE LIVES. ARE YOU ON BOARD?\n\nWe are doers. Our amazing team joined forces for a bold mission worth fighting for: To give every patient access to the right diagnosis and treatment.\n We know that each and every one of us can make a difference with our unique skills, powers & passions. As a team, we are powerful and overcome even the biggest challenges. Take this chance to become part of Symptoma - read on!\n\nTHESE TASKS AWAIT YOU:\n\n\nDesign and implement models to improve the diagnostic capabilities of Symptoma\nCommunicate data-driven results to both key stakeholders and company-wide\nOwn projects from development to deployment, either working independently or as part of a team\n\nWHAT YOU BRING ALONG:\n\nMust-haves:\n\nDegree in a quantitative field (e.g., computer science, statistics, math, physics, informatics)\nWorking experience in data science\nAbility to work independently or as part of a team\nExperience in Python\nExperience with LINUX operating systems\nFluency in English, both written and spoken\n\nNice-to-haves:\n\nExperience with Java\nExperience in Natural Language Processing (NLP), especially when applied to medical data\nExperience in Deep Learning and neural nets\nExperience with ElasticSearch\nExperience in software engineering, including code versioning and test-driven development\nExperience with containerization (Docker) and cloud computing \nDomain knowledge in medical informatics and/or digital health\n\nWHY YOU SHOULD APPLY:\n\n\nImpact: Leave a dent in this universe and use your skills for a good cause.\nGrowth: Work at a fast-growing scale-up company with great opportunities for career progression.\nAppreciation: Your input and creative ideas are highly appreciated \u2013 we want YOU with all your abilities, talents and (soft) skills.\nResponsibility: You are responsible for what you do - you\u2019re not only able to implement what you envision but also to work without supervision. Don\u2019t hesitate to bring in all your strengths, knowledge and experience to reach your full potential.\nFlexibility: Being productive before the earliest early birds, taking an extra long coffee break or working in the dark, you can find your rhythm with us.\nHome Office: We have an output-orientated mindset and trust our team members to decide for themselves where they can work the best (amount of home office days may differ depending on the position).\nDiversity: Our team is anything but boring \u2013 Do you speak Arabic, Swedish or Chinese? We\u2019ll be able to understand you! \nEquipment: We offer state-of-the-art workstations (multiple monitors, powerful laptops, height-adjustable desks)\nAmazing office: in vibrant Vienna (excellent accessibility in the heart of the third district)\n\nGreat performers must be paid appropriately. We offer a monthly salary starting at 3.200 Euro gross per month following internal company agreements for this position. Your professional experience, qualifications, and industry standards will guide the actual remuneration package.\n\nWE MIGHT BE THE PERFECT FIT FOR YOU. LET'S FIND OUT!\n\n__Please send us the following file:\n\nonly your CV (Please include the code-word \"Better Diagnosis\" as text in your CV)\n\nApply now and help us take healthcare to the next level.__"
    },
    {
        "position": "Data Scientist - Senior Level",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Temple & Webster",
        "sector": "Retail",
        "companySize": "201-500 employees",
        "location": "Sydney, New South Wales, Australia",
        "post": "About the job \n\nSenior Data Scientist \n\n\n\nAustralia's #1 furniture and homewares online retailer\nGrowing business with a fantastic culture\nHybrid working arrangement - work from home and our St Peters Office\n\n\n\nTo lead and execute data science activities for Temple & Webster, empowering this business to make better decisions when it comes to designing and importing new product.\n\n\nWhat we\u2019re looking for\n\n\n\n\nMain responsibilities of this role include:\n\n\n\nDevelop scalable machine learning solutions to support forecasting, purchasing and pricing.\nUtilising modern NLP methods to derive additional features and insights from products and customer behaviour\nLead data projects that support business growth, e.g. drive increases in customer acquisition and retention, engagement, purchase frequency and average order value\nManage data projects end to end, including opportunity identification, data gathering, data cleansing and analysis, \nAnalyse customer behavioural data to develop insights and identify performance improvement and growth opportunities\nCollaborate with the data team (Data Science, Data Engineering, BI and Analytics), reviewing solutions, sharing knowledge, and improving coding standards\nCoach cross-functional teams to understand where and when different models or analyses should be used and can create value.\n\n\n\nWhat you already have\n\n\n\n5+ years of experience as a Data Scientist or related working experience, e.g. Machine Learning Engineer\nTertiary qualification in a quantitative discipline (e.g. Statistics, Engineering, Mathematics)\nBackground in statistical analysis techniques, including logistical regression, linear regression, K-Means clustering, random forest, factor analysis, and text analysis.\nExperience with Prediction/Forecasting economic growth from transactions and customer behaviour\nExperience extracting informations from images and text\nStrong technical experience using SQL, Python or R (GCP is a bonus)\nExperience developing machine learning algorithms\nCapable of working with high volumes of structured and unstructured data\n\n\n\nNice to have\u2026\n\neCommerce experience\nExperience in a high-growth digital business\nExcellent communication and presentation skills\nAble to work directly with a variety of internal and external stakeholders\nStrong planning and project management skills\nComfortable working in a fast-moving environment\nCurious mind and strong problem-solving skills\n\n\n\nIt is expected that you will also make a contribution to:\n\n\n\nCultural, social and behavioural standards within the business through leadership by example (i.e. Walk the Talk)\nManagement presentations as required\nAny other responsibilities/duties as required by the group\n\n\n\nNaturally, there's the expectation that you'll bring good humour, a strong sense of personal style!\n\n\nAdditional benefits\n\nAmazing culture\nCompetitive salary\nGenerous employee discounts across our entire range\nFlexible working arrangements\nPaid leave on your birthday\nPaid parental leave\nCatered lunch provided 3 days per week\nSubsidised breakfast daily\nFree mindfulness practice daily\nRegular celebrations and team socials\nOpportunities to volunteer with our charity partner"
    },
    {
        "position": "Data Warehouse Developer/Data Modeler",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Watercare Services Limited",
        "sector": "Utilities",
        "companySize": "501-1,000 employees",
        "location": "Auckland, New Zealand",
        "post": "About the job \n\nWatercare is the largest water and wastewater utility in New Zealand more than 400 million litres of water to Auckland every day. Now is an exciting time to join Watercare, we're planning to spend $18.5 billion over the next 20 years to ensure we can continue to support our growing city in a climate-resilient way. When you average that out, that's an investment of $2.5 million every day.\nIt doesn't just stop there; we ensure that sustainability lies at the heart of everything that we do to help protect our water resources for future generations. This means that we are continuously focused on how we can reduce our carbon footprint with initiatives likes solar panels, electric cars, revegetation programmes and much, much more. We really are a company that wants to make a positive difference.\n\n\nHe whakam\u0101rama m\u014d te t\u016branga mahi | About the role\n\n\n\nAs the provider of water to the majority of Auckland, Watercares data is critical to understanding the ins-and-outs of our services to Tamaki Makaurau. We thrive on the optimism and innocation of current systems and learning new technologies to provide better visibility, allow more informed decisions to improve out business processes and the end experience for our customers.\nAs our Date Warehouse Developer/Data Modeler, you will design, implement and document data modelling solutions which include the use of relational, dimensional and NoSQl databases. In this role you will be responsible for the development of conceptual, logical and physical data models, the implementation of RDBMS, operational data store, data marts and data lakes on target platforms. Additionally, you will define and govern data modelling and design standards, tools, best practices and related development methodologies. You will also oversee and govern the expansion of existing data architecture and the optimisation of data query performance based on best practices.\n\n\nYou will work closely with our Data Engineering team to create optimal physical data models of datasets, as well as creating and maintain data maps and system interrelationship diagrams. This is a key enabler role for Analytics at Watercare - you will open up a world of opportunities related to data for our internal and external customers.\n\n\n\n\nNg\u0101 p\u016bkenga e rapu nei m\u0101tou | About you\n\n\nWe are looking for passionate, analytical people who have a high attention to detail. In this role you will bring:\n\n\n\nTertiary level qualification in an appropriate discipline\n3+ years of hands-on relational, dimensional, and/or analytic experience (using RDBMS, dimensional, NoSQL data platform technologies, and ETL and data ingestion protocols)\nExperience in collecting and translating business rules into conceptual, logical & physical models for data platforms. \nExperience with building data models using Kimball methodology - alternatively, experience in data vault would also be considered.\nProven commercial experience working in an agile environment, as well as recognised and relevant technology industry qualifications\nExperience with data warehouse, data lake and enterprise big data platforms in multi-data-centre contexts required\nGood knowledge of metadata management, data modelling, and related tools (Erwin, ER Studio or others)\n\n\n\nNg\u0101 hua m\u014du | What's in it for you\n\n\nWe offer a competitive salary and staff benefits package including: \n\n\n\nTraining and development opportunities\nLife and income protection insurance plans\nGenerous parental leave\nEmployee discounts at a range of large retailers\nKiwisaver contribution\nFree on-site gym\nDiscounted parking options available\n\n\n\nMe p\u0113hea te tono mai | How to Apply\n\n\nCome and join our team! If you are looking for an exciting career opportunity with a fantastic team then please apply online today - www.careers.watercare.co.nz."
    },
    {
        "position": "Data Modeling Specialist",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "PepsiCo",
        "sector": "Food and Beverage Services",
        "companySize": "10,001+ employees",
        "location": "Barcelona, Catalonia, Spain",
        "post": "About the job \n\nAuto req ID: 284447BR\n\nJob Description\n\n#Locations: Barcelona, Spain; Vitoria-Gasteiz, Spain\n PepsiCo is using the power of data to transform the way our world-famous portfolio of brands are sold every day. Our Data Science & Analytics group influences every aspect of how we sell and move our products. In just a short period of time, they\u2019ve built new capabilities that have defined the data science roadmap across all of our brands. Members of our team solve complex problems facing our rapidly changing business and get to see their work come to life in the real world.\n Join PepsiCo\u2019s Enterprise Data Operations team which develops quality data collection processes, maintains the integrity of our data foundations and enables business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation.\n As a Data Modeling Specialist, your focus would be to partner with D&A Data Foundation team members to create data models for Global projects. This would include independently analyzing project data needs, identifying data storage and integration needs/issues, and driving opportunities for data model reuse, satisfying project requirements. The role will advocate Enterprise Architecture, Data Design, and D&A standards, and best practices. You will be a key technical expert performing all aspects of Data Modeling working closely with Data Governance, Data Engineering and Data Architects teams.\n As a member of the data modeling team, you will create data models for very large and complex data applications in public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. The primary responsibilities of this role are to work with data product owners, data management owners, and data engineering teams to create physical and logical data models with an extensible philosophy to support future, unknown use cases with minimal rework. You'll be working in a hybrid environment with in-house, on-premise data sources as well as cloud and remote systems. You will establish data design patterns that will drive flexible, scalable, and efficient data models to maximize value and reuse.\n Key Accountabilities:\n\nIndependently complete conceptual, logical and physical data models for any supported platform, including SQL Data Warehouse, EMR, Spark, DataBricks, Snowflake, Azure Synapse or other Cloud data warehousing technologies.\nGoverns data design/modeling \u2013 documentation of metadata (business definitions of entities and attributes) and constructions of database objects, for baseline and investment-funded projects, as assigned.\nProvides and/or supports data analysis, requirements gathering, solution development, and design reviews for enhancements to, or new, applications/reporting.\nSupports assigned project contractors (both on- & off-shore), orienting new contractors to standards, best practices, and tools.\nAdvocates existing Enterprise Data Design standards; assists in establishing and documenting new standards.\nContributes to project cost estimates, working with senior members of team to evaluate the size and complexity of the changes or new development.\nEnsure physical and logical data models are designed with an extensible philosophy to support future, unknown use cases with minimal rework.\nDevelop a deep understanding of the business domain and enterprise technology inventory to craft a solution roadmap that achieves business objectives, maximizes reuse.\nPartner with IT, data engineering and other teams to ensure the enterprise data model incorporates key dimensions needed for the proper management: business and financial policies, security, local-market regulatory rules, consumer privacy by design principles (PII management) and all linked across fundamental identity foundations.\nDrive collaborative reviews of design, code, data, security features implementation performed by data engineers to drive data product development.\nAssist with data planning, sourcing, collection, profiling, and transformation.\nCreate Source To Target Mappings for ETL and BI developers.\nShow expertise for data at all levels: low-latency, relational, and unstructured data stores; analytical and data lakes; data streaming (consumption/production), data in-transit.\nDevelop reusable data models based on cloud-centric, code-first approaches to data management and cleansing.\nPartner with the Data Governance team to standardize their classification of unstructured data into standard structures for data discovery and action by business customers and stakeholders.\nSupport data lineage and mapping of source system data to canonical data stores for research, analysis and productization.\n\n\nQualifications/Requirements\n\nQualifications:\n\n\n8+ years of overall technology experience that includes at least 6+ years of data modeling and systems architecture.\n3+ years of experience with Data Lake Infrastructure, Data Warehousing, and Data Analytics tools.\n6+ years of experience developing enterprise data models.\nExpertise in data modeling tools (ER/Studio, Erwin, IDM/ARDM models).\nExperience with integration of multi cloud services (Azure) with on-premises technologies.\nExperience with data profiling and data quality tools like Apache Griffin, Deequ, and Great Expectations.\nExperience with at least one MPP database technology such as Redshift, Synapse, Teradata or SnowFlake.\nExperience with version control systems like Github and deployment & CI tools.\nExperience with building solutions in the retail or in the supply chain space is a plus\nExperience of metadata management, data lineage, and data glossaries is a plus.\nWorking knowledge of agile development, including DevOps and DataOps concepts.\nBA/BS in Computer Science, Math, Physics, or other technical fields.\n\n\nSkills, Abilities, Knowledge:\n\n\nExcellent communication skills, both verbal and written, along with the ability to influence and demonstrate confidence in communications with senior level management.\nStrong change manager. Comfortable with change, especially that which arises through company growth.\nAbility to understand and translate business requirements into data and technical requirements.\nPositive and flexible attitude to enable adjusting to different needs in an ever-changing environment.\nStrong organizational and interpersonal skills; comfortable managing trade-offs.\nProactively drives impact and engagement while bringing others along.\nConsistently attain/exceed individual and team goals\nAbility to work with virtual teams (remote work locations); lead team of technical resources (employees and contractors) based in multiple locations across geographies\nLead technical discussions, driving clarity of complex issues/requirements to build robust solutions\n\n\nWhat makes us different?\n\n\nHybrid work model & collaborative office experience to enable innovation\nEntrepreneurial environment in leading international company \nProfessional growth possibilities & learning opportunities \nVariety of benefits to support your physical, emotional and financial wellbeing\nVolunteering opportunities to help external communities\nDiverse team from over 25 countries\nHave a stake in D&I strategy and Bring your whole self to work \n\n\nAbout PepsiCo\n\nWe believe that culture should be at the cornerstone of everything we do at PepsiCo. We operate with start-up mindset \u2013 agile, innovative and not afraid of failure. We want our team to come to work every day excited to explore new ways bring enjoyment, refreshment and fun to the world.\n PepsiCo Positive (pep+) is the future of our organization \u2013 a strategic end-to-end transformation, with sustainability at the center of how we will create growth and value by operating within planetary boundaries and inspiring positive change for the planet and people. https://www.youtube.com/watch?v=PO5CdBmWjUY\n So, if you\u2019re ready to be a part of a playground for those who think big, we\u2019d love to chat.\n\nWe encourage the diversity of applicants across gender, age, ethnicity, nationality, sexual orientation, social background, religion or belief and disability\nRelocation Eligible: Eligible for Standard Relocation\n\nJob Type: Regular"
    },
    {
        "position": "Remote | Data Scientist - Pricing and Valuation team",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "OLX Group",
        "sector": "Software Development",
        "companySize": "10,001+ employees",
        "location": "Pozna\u0144, Wielkopolskie, Poland",
        "post": "About the job \n WELCOME TO OLX GROUP\nOver 300 Million monthly active users; US $1.6 billion in revenue and 18% revenue growth (FY 2021; 36% growth in FY2020); Part of Naspers\u2019 Prosus, one of the biggest technology investors in the world (An early investor in Tencent and the owner of StackOverFlow). +30 countries. +20 Brands. Powered by +10,000 employees representing 81 nationalities. \nThat\u2019s what\u2019s on our plate at OLX Group.\nAnd that's why we need your help. Join Us. Shape your career with us.\nThe team\nThe Pricing and Valuation team at OLX Group is responsible for unlocking hidden value using data and artificial intelligence. We analyze the status quo, improve buyer & seller interactions, optimize the user experience and monetize on the delivered customer value. For us revenue growth is the good fruit of our work and not the goal itself. We invite you to join a team which works with OLX, Real Estate platforms (Otodom, Storia) and Automotive platforms (Otomoto, Standvirtual) across the entire EU region. A team that breaks through walls and builds cross-functional connections with everyone around. A team where a common mission and goals matter more than reporting lines. We build on each other, asking for help and support when needed, and we proactively support others. In your day to day routine you will have the opportunity to develop supervised models for behavioral classification, deep learning models for image classification, regression models for value estimation as well as NLP models for object and actor entity recognition. All in Python and the AWS cloud. You will be exposed to key stakeholders, having direct contact with internal customers. You will have the carte-blanche to experiment and test things. And most importantly, you will also witness how your work impacts the day to day business of OLX Group customer units. We have offices in Poznan and Warsaw, but this role can be based anywhere in Poland. \nWhat You Will Be Doing\n\n\nYour primary role will be to increase business value by finding opportunities where data science and machine learning can make an impact.\nYou will maintain strong relationships with stakeholders. This means asking a lot of questions to business people, translating their requirements into achievable projects. It also means collaborating with other teams, like infrastructure and data engineering to get things done in an elegant and timely manner. \nYou will build models, tinker around them to make them work, test them and eventually deploy to production. You will see your stuff in action and you will be able to measure the true impact of your models.\nYou will work in multi-functional teams, in a diverse, multinational environment, filled with people from Portugal, Bulgaria, Romania, Poland, Ukraine, Kazakhstan and Uzbekistan. \nMost importantly you will have fun working with us :)\n\nWhat Are We Looking For\n\n\nAnalytics and Modeling: \n\nVery strong analytical skills. Like really strong! So strong that truth and light are your two middle names. Solid background in statistics and modeling. Good knowledge of Python, which means having experience with at least one of the following: Scikit-Learn, TensorFlow, PyTorch, Pandas.\n\nMachine Learning Engineering: \n\nGood understanding of engineering best practices, that is: testing, CI/CD, monitoring, alerting, containers. Hands-on experience with SQL. Ability to work with big data at scale: experience with columnar storage clusters.\n\nStakeholder Management:\n\nProficient in English with excellent written and oral communication skills! Strong presentation skills. Able to work in multi-functional teams with people from different backgrounds.\nNice To Have\n\n\nDeploying models to production and serving models at scale.\nUsing AWS for deploying machine learning solutions.\nBuilding data pipelines using tools like Spark and Airflow.\nA/B testing.\nDocker.\n\nWhat We Offer\n\n\nStrengths-based personal career development.\nCompany mobile phone, MacBook Pro or Windows Dell along with necessary accessories to make your work comfortable.\nCompetitive compensation and benefits (medical care, sports package and others).\nTraining and conference budget.\nThe opportunity to learn from each other and become better every day.\nA passionate and diverse team of data scientists spanning across several tech hubs in Europe and around the world.\n\nWe look forward to receiving your application! OLX Group Talent Acquisition team\na Bit More About Us\nCheck our careers website here. Discover why you should join the OLX Group Now Check out our talent, product, engineering and design blogs here Follow us on Linkedin We encourage people of all races, ethnicities, disabilities, ages, gender identity or expression, backgrounds and experiences to consider applying for this role. We are committed to building an inclusive culture that seeks out the diverse perspectives and experiences of our people and becomes a company superpower and strategic competitive advantage. The OLX Group (OLX Group consists of OLX Global B.V. and its affiliated companies) will handle your personal data with care and will process your personal data to assess your fit for the position you are applying for. You can give your consent (optional) to allow us to store your data for up to 12 months after the application process. So that in case you are not fit for the role at stake we can consider you for other suitable roles. Please refer to our Privacy Statement to find out more about how your application data will be processed."
    },
    {
        "position": "Data Scientist",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "DEPT\u00ae",
        "sector": "Technology, Information and Internet",
        "companySize": "1,001-5,000 employees",
        "location": "Veenendaal, Utrecht, Netherlands",
        "post": "About the job \n Apply\n For our Data Science team, we are looking for a Data Scientist who knows exactly how to handle Algorithms, Big Data, Machine Learning and build predictive models. Please note you MUST HAVE at least 2 years of hands-on working experience in a data science role, preferably related to digital marketing data and/or working at a digital agency to be eligible for this role. Please only send in your application if you can confidently say you have this experience.\n\nThis vacancy is open for relocation to the Netherlands. Read all about our relocation process here.\n\nAs a data scientist, you know how to structure and clean giant datasets meticulously, in order to apply your algorithms on them. You recognise patterns in data that no-one else would and this enables you to make our campaigns better and smarter. From the output of a calculated dataset, you can start with the analysis for a client and eventually you are able to communicate your advice in a clear fashion to your team and your client.\n You will be working on new concepts and innovations regarding:\n\nPredicting customer propensity.\nForecasting supply and demand.\nSegmenting customer groups based on behavioural data.\nRecommending products and/or content. \n\n\nYou will work in a vibrant environment with clever minds who work for a variety of large global clients. Yes, we are eager to hire the most talented experts in the game but we are also looking for a perfect DEPT\u00ae-fit. Someone who is eager to learn, inspires, strives towards a better world, takes the stage, a futurist at heart, and someone who will toast to a successful week with us.\n\nYOU:\n\n\nMUST HAVE at least 2 years of hands-on working experience in a data science role, preferably related to digital marketing data and/or working at a digital agency;\nHave studied Business IT or similar (Computer Science, Data Science, Information Management);\nHave experience with Amazon Web Services, Azure or Google Cloud Platform;\nHave experience with Google Analytics and/or other Web Analytics software;\nAre an expert in Python (MUST);\nAre experienced in SQL;\nHave experience with both supervised and unsupervised problems and solutions;\nAre having knowledge of NLP;\nAre familiar with MLOps;\nHave an affinity with marketing and technology;\nAre analytical, flexible, independent and communicatively strong;\nAre one of those ambitious people who can switch from serious to play in a heartbeat.\n\n\nWE OFFER:\n\n\nAn open company culture; \nPossibilities to work from our offices and hubs in Rotterdam, Amsterdam, Veenendaal, Zwolle, and Maastricht \u2013 or from the comfort of your own home; \nWorking from home setup;\nPension scheme;\nPossibilities to develop your skills even further via training and certifications; \nHealthy and tasty food; \nFree Bootcamp training twice a week; \nFriday drinks/open bar to wrap up the week; \nGreat fringe benefits; laptop, mobile phone, NS business card and many other goodies.\n\n\nAbout DEPT\u00ae:\n\nDEPT\u00ae is a pioneering technology and marketing services company that creates integrated end-to-end digital experiences for brands such as Google, KFC, Philips, Audi, Twitch, Patagonia, eBay and more. Its team of 2,500+ digital specialists across 30+ locations on 5 continents delivers pioneering work on a global scale with a boutique culture. DEPT\u00ae is committed to making a positive impact on the planet and since 2021 has been Climate Neutral and B Corporation certified. www.deptagency.com\n Learn more about our diversity, equity, and inclusion efforts here."
    },
    {
        "position": "DATA SCIENTIST",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Ferrero",
        "sector": "Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Kirchberg, Luxembourg, Luxembourg",
        "post": "About the job \n Job Location: Luxembourg\n\nCompany Description\n\nFerrero is a family-owned company with a truly progressive and global outlook and iconic brands such as Nutella\u00ae, Tic Tac\u00ae, Ferrero Rocher\u00ae, Raffaello\u00ae, Kinder Bueno\u00ae and Kinder Surprise\u00ae. As the love for our brands continues to grow, so too does our global reach. Represented in 55 countries, with products sold in more than 170, the Ferrero Group is loved by generations around the world. The secret to our global success? Nearly 35,000 dedicated employees who celebrate care and quality to craft a business, careers and brands we are proud of. Join us, and you could be one of them.\n Diversity Statement\n Ferrero is committed to building a diverse and inclusive culture in which all employees feel welcomed and appreciated and have the same opportunities. We believe all of our people are equally talented in their own way. In nurturing the curiosity and natural abilities of our employees, we provide them, generation after generation, the means to succeed personally and professionally, enabling them to craft their journey at Ferrero. The diversity of our talents is what makes our work environment multicultural, innovative and highly rewarding.\n\nAbout the Role:\n\nFor our Ferrero Headquarter in Luxembourg we are currently looking for a talented DATA SCIENTIST supporting our Advanced Analytics pillar.\n Reporting to the Advanced Analytics Leader, the successful candidate will be focal point for:\n\nBusiness stakeholders across categories and geographies\nFerrero Luxembourg IT department\nColleagues in BI&A Unit working in Business Partnership pillar to support identification of potential solutions for business problems\nColleagues in BI&A Unit working in Data Governance pillar to identify current and new potential datasets for use in analysis \nPotentially work with external agencies and data brokers as needed.\n\n\nMain Responsibilities:\n\n\nDevelop, test and rollout statistical models to support analytics and business reporting functions\nCreate procedures to clean and classify data from disparate sources like retail sell-out, shopper behavior, consumer surveys, marketing and other 3rd party sources for use in modeling and reporting\nPractical experience of media measurement including digital to support business decision making\nScript automation procedures for analytical flows\nVisualizing analytic results for business stakeholders in PowerBI\nCreate dashboard templates and help BI colleagues to create and customize their own\nGuide and mentor junior data scientists on existing analyses and new capabilities creation.\n\n\nWho we are looking for:\n\nProfile\n\n\nBachelor\u2019s degree in quantitative area like Mathematics, Econometrics, Statistics, Engineering etc. Advanced degree preferred\nMinimum 3 \u2013 5 years of experience in applied work on Advanced Analytics, preferably at a FMCG manufacturer company\nExperience in modeling techniques and advanced statistical concepts: Regression, Classification, Text mining, Random Forest etc\nAnalytical creativity and desire to test & learn. Interpretation of analytic outputs from business standpoint\nExperience using external third-party data sources including Nielsen, IRI, consumer surveys\nStrong understanding of media data including traditional and digital\nRelevant communication skills.\n\n\nIT Skills\n\n\nExcellent knowledge and best practice analysis/programming of SQL, PowerBI, Azure, Spark, Scala, Power BI, Google Analytics, SAP HANA\nStrong knowledge of best practice analysis and programming techniques with R and Python.\n\n\nLanguages\n\n\nFluent in English is mandatory\nAny other language is a plus.\n\n\nHow to be successful in the role and at Ferrero:\n\nConsumers, quality and care are at the heart of everything we do. So, to be successful at Ferrero, you\u2019ll need to be just as consumer and product centric as we are - dedicated to crafting brilliant results for consumers around the world."
    },
    {
        "position": "Data Scientist",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Lufthansa Systems Hung\u00e1ria",
        "sector": "IT Services and IT Consulting",
        "companySize": "501-1,000 employees",
        "location": "Szeged, Csongr\u00e1d, Hungary",
        "post": "About the job \n\nJoin us as a Data Scientist and work on our market leading Operations Control solution, a machine learning module, preventing disruptions at the day of operations and automating the work of the Ops Controller.\n\n\nYour tasks will include:\n\nWork with aviation data to build a new data-driven product and develop innovative uses of machine learning for the airline industry\nProvide clarity and generate new insights from complex data sets by applying advanced analytical models\nContribute to the development of end-to-end data solutions in collaboration with cross-functional data experts and business stakeholders.\n\n\n\nYou are looking for us if you have experiences/ qualification in the following fields:\n\nA Master\u2019s or Bachelor\u2019s degree in a quantitative discipline such as computer science, mathematics, physics, or a related subject\nProficiency using one or more programming or scripting language to work with data, especially Python\nSome experience and/or project course work performing data analysis and applying statistics\nGood knowledge of machine learning fundamentals\nExperience with version control systems (e.g. Git)\nFamiliarity with the fundamentals of SQL\nStrong communication skills (our working language is English) and comfort delivering results to stakeholders and colleagues \nA strong desire to learn every day and a self-starter mentality \n\n\n\nYou will be successful in this position if you have the following skills or experience:\n\nApplying machine learning in fields such as Computer Vision, NLP, or Reinforcement Learning\nWorking in cloud computing environments, especially Microsoft Azure\nData science software platforms (e.g. SAS, Databricks)\nData science libraries (e.g. pandas, NumPy, SciPy, scikit-learn) \nProject management, particularly knowledge of agile project setups (e.g. Kanban, Scrum)\n\n\n\nAdvantage if You have\n\nAirline know-how, OPS basics knowledge\n\n\n\nWhat are the benefits of joining us as an employee?\n\n\nEven when you work hard, you will still have time for your personal life: our flexible working hours based on core time, the exact observance of the designated number of working hours, the occasional option of working from home, and the benefits that can be extended to cover your family you can also improve your non-working life!\nWe have long-term plans for you! We have carefully designed career paths (and a career management system), we provide the appropriate training courses and projects to accomplish your aims.\nOur community is characterized by mutual respect and an attitude of helpfulness. This high professional quality level and the colorful personalities will help you spend your everyday life in a good mood, why you make the best of your skills and talents. \nWe are happy when you are open and help you discover the world: after six months you will receive substantial discounts that you can use to visit any place in the world taking Lufthansa flights!\nIn addition to an inclusive and helpful atmosphere, trust is also an important value for us. You can rely on us with anything right from your first day, and we also trust you to the utmost extent."
    },
    {
        "position": "Senior Data Scientist",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Orange Quarter",
        "sector": "Staffing and Recruiting",
        "companySize": "11-50 employees",
        "location": "Berlin, Berlin, Germany",
        "post": "About the job \n We are working with a MedTech company who have just been acquired by an industry giant in a bid to destabilise the monopoly held by corporate giants in the US market. How long have you spent on hold waiting to get through to a doctor so you can ask them a simple question you probably already knew the answer to? This is one of the problems they are solving by building an asynchronous communication platform so you can instant message your doctor. Additionally, they are introducing telemedicine solutions as well as features that allow you to book/amend/cancel appointments and renew prescriptions, and book video appointments for appointments that can be done remotely. The mission is simple, to improve patient care and communications as much as possible.\n\nIndustry\n\nOQ-industries MedTech\n\nWhat To Expect\n\nYou will be part of a small cross functional team of data professionals. You will be tasked with owning E2E machine learning products, from working with your product stakeholders to identify problem areas, translating these into data science problem statements and then developing and deploying these products to add business value. They already have strong machine learning infrastructure resources in place to the emphasis of this role is on the earlier \u2018data science\u2019 part of the ML pipeline. This is a communications product at its core so much of the products you will build will leverage NLP so experience is this space is a must for this role, although you do not need production experience.\n\nPerks\n\n\nWork on a truly impactful product, bettering the lives of millions\nGet the chance to build real Data Science and ML products\nFully remote, but they have an office in Berlin if you want to use it\nGreat salary and benefits package, including unlimited paid holiday\n\nRequirements\n\n\n3+ years of experience in Data Science and Machine Learning\nGood knowledge of NLP-specific machine learning tools and libraries\nYou want to create business value through machine learning and NLP, you need to have a product mindset\nSounds good?Apply now"
    },
    {
        "position": "Natural Language Processing Scientist",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Novo Nordisk",
        "sector": "Pharmaceutical Manufacturing",
        "companySize": "10,001+ employees",
        "location": "M\u00e5l\u00f8v, Capital Region, Denmark",
        "post": "About the job \n As part of the digitalisation of early research at Novo Nordisk we are looking for outstanding candidates with a strong background in computational science and natural language processing (NLP) who can bring value to the organisation by turning text into data for analysis and insights, via application of NLP and analytical methods.\n This is an exciting position where you will help scientists in the early research organisation to transform their decision-making from a document-centric view of finding documents and reading them, to a data-centric view of uncovering new insights by the use of natural language processing-based text mining. This will help the researchers to overcome the limitations of unstructured data and uncover previously hidden relationships.\n This is your chance to join forces with a competent information research department and help democratize external and internal scientific information and data. The position offers you a unique combination of science and information research.\n\nAbout The Department And Area\n\nYou will join 20 dedicated colleagues within the Novo Nordisk Global Information and Analysis department (GLIA), which offers a worldwide information service and scientific intelligence function to Research & Early Development (R&ED), at headquarter and affiliates.\n Our purpose is to provide modern digital solutions to the organisation and to ensure that internal customers have easy and global access to quality information sources and professional information research services supporting their needs.\n GLIA is part of a new area, Digital Research & Intelligence, which is being establised to provide a modern scientific intelligence unit, drive external collaborations and access to emerging technologies in the digital space of drug discovery, facilitate idea maturation and develop an educational framework to drive our digital jounney.\n Digital & Research Intelligence is part of Digital Science & Innovation (DSI), which was recently established to drive digitalisation across R&ED. DSI participates in drug development projects across the value chain, from early discovery to pre-clinical development.\n\nThe position\nYou will work as a NLP specialist and be a key expert within your field. By combining NLP text mining, artificial intelligence, mechanistic modelling and knowledge graphs you will help scientists in early research to extract key information from unstructured text, rapidly and effectively, to provide decision support. You will be working with textual documents of multiple format like scientific literature, patents, patient literature, internal safety reports, drug labels, clinical trial data, social media, electronic health records, Google slides, Electronic Lab Notebooks etc.\n\nKey Responsibilities\n\n\nDevelopment of algorithms for information extraction \nRelationship extraction/semantic similarities, summarization, Natural Language inference\nNeural network models for language understanding tasks like BERT, GTP-3 etc\nEvaluate the performance of neural models and validate the accuracy of extracted knowledge\nSupport GLIA and relevant part of DSI with knowledge enriching analysis results via natural language generation \nWork closely with relevant Digital Science & Innovation teams to translate best-performance techniques into production \nResponsible for presentation and reporting of scientific results \nParticipate in line/digital projects progression with strong NLP and knowledge graph expertise\nEncourage, propose and participate in projects boosting the use of advanced text mining and knowledge graphs\n\n\nQualifications\n\nWe are looking for a highly motived person preferable with a PhD in Computer Science, AI, Computational Linguistics, Applied Mathematics, Physics or similar. Further we expect you to have the skills and expertise listed below:\n\nProfound knowledge of Deep Learning methods applied to NLP\nStrong Experience with Natural Language Processing and Machine Learning technologies\nDemostrated strong track record of developing and applying NLP solutions\nExcellent written, verbal presentation and graphical communication skills \nEffective communication skills with the desire to work with dispersed teams across multiple time zones\nAttention to detail, diligent and tenacious\nHigh degree of personal motivation and ability to self-manage\n\n\nTitle and conditions are evaluated based on the individual experience and contribution.\n\nContact\nFor further information, please contact Lilian Nilsson by email lznl@novonordisk.com\n\nDeadline\nAugust 31, 2022\n We commit to an inclusive recruitment process and equality of opportunity for all our job applicants.\n At Novo Nordisk we recognize that it is no longer good enough to aspire to be the best company in the world. We need to aspire to be the best company for the world and we know that this is only possible with talented employees with diverse perspectives, backgrounds and cultures. We are therefore committed to creating an inclusive culture that celebrates the diversity of our employees, the patients we serve and communities we operate in. Together, we\u2019re life changing."
    },
    {
        "position": "Data Engineering Manager (open to full remote in Germany)",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Back Market",
        "sector": "Internet Marketplace Platforms",
        "companySize": "501-1,000 employees",
        "location": "Berlin, Berlin, Germany",
        "post": "About the job \n Back Market is the world\u2019s leading refurbished electronics marketplace with a team of more than 650, powering operations in 16 countries (and counting!).\n Back Market is undergoing meteoric growth and has raised $884 million, with a valuation of $5.7 billion. Our mission is simple: empowering people to buy tech sustainably by offering folks a high quality, accessible, and more eco-friendly alternative to buying new electronics. Why? Refurbished tech helps lower our collective environmental impact .\n Be part of a great and growing adventure that will change the way the world consumes tech.\n Data is a key enabler for a company like Back Market. Do you want to help your team build reliable, high-performing and secure data infrastructures and tools? Do you want to have a meaningful impact through your job? Here is your opportunity.\n Data engineering at Back Market is split into three teams, based on their stakeholders: Customer (Back Market\u2019s end users), Supply (sellers at Back Market), and Finance & Customer Care. We are looking for a manager to lead the Supply data team (data engineers and analytics engineers) and develop this scope from end to end. The supply data scope includes all data (from collecting to serving the data to internal and external stakeholders like our sellers) linked to the Back Market catalog, sellers\u2019 performance and the pricing of our offer.\n This senior team of 5 people is distributed between our different offices and full remote.\n\nWhat you'll be doing :\n\n\nManagers at Back Market build sustainable and efficient teams, by empowering people and building the proper environment.\nCollaborating with your product manager and your stakeholders: the BI, and other tribes to align the team with company objectives and initiatives across engineering and the wider business\nEnsuring the development of people and teams through open communication, feedback, and continuous coaching\nCreating an inclusive team environment, where team members feel like they belong and are supported to do their best work\nWorking in an agile \"build it and run it\" environment where engineering teams build, launch, monitor and support the sections they own\nWorking with the team to identify and make improvements in our processes, practices, and product\nHelp your team take the right technical decisions thanks to a strong technical data background\n\n\nYou are in the right place if : \n\n\nYou are people-first oriented and know how to build and run a high-performing team ;\nYou embrace the servant leadership principles as much as you value empathy and cordial debates over a \"top-down\" management posture ;\nProduction health is a priority for you ;\nYou are able to understand the tech challenges of your team and guide them through decisions. Our stack is AWS (Lambda, dynamodb), GCP (Big Query, Data Catalog), Spark (Delta), Terragrunt, Terraform, Datadog, Python, Scala. \nYou have great communication skills in English\n\n\nWHY SHOULD YOU JOIN US ?\n\nA meaningful job: through hard work, you will help avoid thousands of tons of electronic waste and fight against planned obsolescence. It counts!An attractive salary, equity, multiple benefits (meal tickets, health insurance, etc...), parental benefits, #remote friendly company, relocation package, internal events, etc\u2026Technical challenges all day every day: you will have the freedom to innovate and adopt new ideas!Work with passionate experts who will share their knowledge and help you develop and grow! (Backademy, technical guilds, Meet-up & Conference)Grow your career with a flexible career path, BackMarket can help you evolve!A booming scale-up: our environment is rapidly growing in Europe, the USA and soon in Asia!A lot of fun: you will have the opportunity to work in a fast-paced, open-minded and friendly environment.\n\n\nBackMarket is an Equal Opportunity Employer for any minority, disability, gender identity or sexual orientation."
    },
    {
        "position": "Engineering Manager, Data Engineering Team",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Toptal",
        "sector": "Software Development",
        "companySize": "1,001-5,000 employees",
        "location": "Slovakia",
        "post": "About the job \n\nAbout Toptal\n\nToptal is a global network of top freelance talent in business, design, and technology that enables companies to scale their teams, on-demand. With $200+ million in annual revenue and over 40% year-over-year growth, Toptal is the world\u2019s largest fully remote company.\n We take the best elements of virtual teams and combine them with a support structure that encourages innovation, social interaction, and fun. We see no borders, move at a fast pace, and are never afraid to break the mold.\n Position Description\n As an Engineering Manager for the Data Engineering team, you will be leading and growing a team of data engineers to scale our data warehouse and pipelines. You will work with Business Analysts on improving and adding more sources to our data lake. The team will look to you for advice on data and operational issues facing the team, you will mentor your team across stakeholder management, project management, and overall technical architecture.\n Data Engineering Team is responsible for delivering a top-notch data warehousing experience for Toptal, making sure data is correct and accessible on demand. Data Engineers are working closely with Business Analysts and Data Scientists and they are responsible for building and maintaining data processing infrastructure and building new data and automation tools.\n This is a remote position that can be done from anywhere. Due to the remote nature of this role, we are unable to provide visa sponsorship. Resumes and communication must be submitted in English.\n\nResponsibilities\n\nYou will be leading a team of highly skilled professionals to create and maintain world-class data products used by our Business Analysts, Data Scientists, and engineering teams across the company.\n\nIn The First Week, Expect To\n\n\nStart at the team by being introduced to Toptal and its culture, meeting colleagues, and get access to documentation and repositories.\n\nIn The First Month, Expect To\n\n\nComplete onboarding, understand the team\u2019s immediate roadmap and become acquainted with your team and processes.\nConduct regular 1:1s with your teammates, and begin to understand their strengths and aspirations.\n\nIn The First Three Months, Expect To\n\n\nShip impactful initiatives that significantly changes the way in which clients interact with us\nBe working with your team and understand its mission and domain. \nBe leading your team\u2019s efforts from planning to delivery.\n\nIn The First Six Months, Expect To\n\n\nSet and follow through at least one full quarter of OKRs.\nBuild a deep understanding of the mission, constraints, and capabilities of your team and squad.\nDevelop relationships with engineers, engineering managers, and other colleagues to maximize cross-collaboration whenever beneficial.\nContribute improvement suggestions at an Engineering-wide and even Company-wide level.\n\nIn The First Year, Expect To\n\n\nMake a big impact on the product.\nOrganize at least one team gathering.\nDefine yearly OKRs with and for your team.\n\nRequirements\n\n\nHave 2+ years of previous experience leading a data engineering or a product development team.\nHave 5+ years of data engineering experience.\nHave a track record of making an impact as an engineer and as an engineering manager.\nHave a solid understanding of development and quality assurance methodologies and concepts.\nHave experience guiding the continuous improvement of processes and technology.\nThrive on providing and receiving honest but always constructive feedback.\nOutstanding communication and interpersonal skills.\nBe eager to help your teammates, share your knowledge with them, and learn from them.\nBe first and foremost a leader, not a developer. However, you are able to code and you stay up to date with programming-related topics and work shoulder-to-shoulder with your team when required.\nYou must be a world-class individual contributor to thrive at Toptal. You will not be here just to tell other people what to do.\n\nFor Toptal Use Only: #individualcontributoreurope #individualcontributorSA"
    },
    {
        "position": "Team Lead (f/m/d) Data Engineering",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Siemens Energy",
        "sector": "Renewable Energy Semiconductor Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Lisbon, Lisbon, Portugal",
        "post": "About the job \n You will be building and guiding your team of Data Engineers who are responsible for enabling technically the translated business requirements into analytical products, helping to bring new insights alive. As a leader, you are part of our transformation journey to become a data driven company in future.\n Passionate about the environment and climate change? Ready to be part of the future of the energy transition? The Siemens Energy Data Analytics & AI team plays a significant role in driving the energy transformation.\n Honestly, we don\u2019t have all the answers. Honestly, given the scale of the challenge we need many types of perspectives to help reimagine the future. And honestly, we can\u2019t do it alone.\n Our team is looking for innovative, enthusiastic, and versatile data, digital, and AI professionals that will drive us forward on this exciting venture.\n\nLet\u2019s Talk About You\n\nYour profile\n\n\n\nCollege degree in information technology or related field\nExtensive experience leading data architecture and data-related initiatives \nIn-depth knowledge of data acquisition, data modeling and analytics, and the ability to deal with performance and development issues on Hadoop\nExperience with database modeling (e.g., Snowflake, Star) and experience developing streaming and batch data pipelines for cloud and hybrid infrastructures\nKnowledge of streaming frameworks (e.g. Spark, Storm, or Kafka) and hands-on experience with modern software development tools such as GitHub, Jenkins, and other build automation tools\nExtensive knowledge of data analytics and the ability to slice and dice data as needed\nExperience in data architecture for cloud providers (e.g., AWS, Azure, GCP)\nKnowledge of data warehouses that support analytical workloads (e.g., Snowflake)\nInitial exposure to working with ETL, ESB and web service containers\nExcellent writing and communication skills in English, German language skills or knowledge of another language is a plus\nStrong customer focus and excellent communication skills and exceptional leadership and coaching skills to collaborate and develop technical talent in multicultural, global teams\nOpen-minded and willing to learn and continuously improve your skills\nEnthusiasm for data and analytics and leveraging data across all aspects of a business and ecosystem \n\n\nYour Responsibilities\n\n\n\nLead a team of data engineers focused on leveraging data and information across the SE to improve data-related operations and drive risk-related insights\nDrive technical implementation and accountability for strategy and execution\nDetermine the scope of the Minimum Viable Product (MVP) for upcoming initiatives and outline the future roadmap for enhancements and potential improvements\nCollaborate with data owners on planning and execution of key initiatives\nOversee the performance and quality of integration pipelines created in close collaboration with the data integration team \nDrive architecture design and discussions, advising teams\nDrive data literacy towards visualization through self-service capabilities for end user communities\nEnsure that the development model supports high velocity and good quality deliverables, with the ability to develop faster, develop in parallel, and release frequently\nAdvocate for modern software development methodologies and use Scrum and SAFe frameworks\nConduct code reviews and ensure teams adhere to appropriate standards, as well as develop and monitor KPIs / metrics to optimize data quality\nDocument and present methodologies, procedures, and project deliverables to senior stakeholders across multiple functions \nKnowledge of emerging technologies and latest trends in the data science space\nLeading a team and helping team members reach their full potential\nParticipate in an inspiring team of true thought leaders and data science experts within the global ED&AA team\n\n\nLet\u2019s Talk About Us\n\n\"Let\u2019s make tomorrow different today\" is our genuine commitment at Siemens Energy to all customers and employees on the way to a sustainable future.\n In our Business Functions we enable our organization to reach their targets by providing best-in class services and solutions in the areas of IT, HR, Finance, Real Estate, Strategy & Technology and more.\n Check out this video to see what we do here! https://bit.ly/3IfnlaR\n\nMORE INSIGHTS\n\nBe Energized. Be you.\n Lucky for us, we are not all the same. Through diversity we generate power. We run on inclusion and compassion. Our combined creative energy is fueled by at least 130 nationalities. Siemens Energy celebrates character \u2013 no matter what ethnic background, gender, age, religion, identity, or disability. We energize society. All of society.\n\nJobs & Careers: https://www.siemens-energy.com/global/en/company/jobs.html\n We value equal opportunities and welcome applications from people with disabilities."
    },
    {
        "position": "Big Data Engineer for the Services Analytics Plateau (d/f/m)",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Airbus",
        "sector": "Aviation and Aerospace Component Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Manching, Bavaria, Germany",
        "post": "About the job \n\nJob Description\n\nAirbus Defence and Space is looking for a\n\nBig Data Engineer for the Services Analytics Plateau (d/f/m)\n\nThe successful applicant will join the department TASSI6 Data Diagnostics & Analysis Systems.\n The project you will be working on introduces Airbus Defence and Space's Analytics capabilities to our largest customers. The project is the cornerstone of data consolidation and analytics for the Eurofighter programme. It delivers improved performance and customer experience and enables a rapid understanding of the potential of digitalisation for our customers.\n You will be at the forefront of further developing our Data Analytics solutions. The main task will be to find new ways to address challenges with data and digital technologies and support the creation of new services.\n We are in production and already have a large pool of data.\n\nYour location\n\nLocated about an hour\u2019s drive north of Munich, Manching is an up-and-coming market town that offers a wide range of leisure and cultural activities. Here, you can enjoy the quality of life in the countryside while the pleasures of near-by cities are still within easy reach.\n\nYour Benefits\n\n\n\nAttractive salary including holiday pay, Christmas bonus and profit sharing\n30 days holidays and extra days-off for special occasions\nExcellent upskilling opportunities and great development prospects\nSpecial benefits: employer-funded pension, employee stock options, discounted car leasing, special conditions for insurances, public transport subsidy, discounts at local businesses\nOn-site-facilities: Medical officer for check-ups and other health-related services, canteen and cafeteria, kindergarten nearby\n\n\nAt Airbus, we support you to work, connect and collaborate more easily and flexibly. Wherever possible, we foster flexible working arrangements to stimulate innovative thinking.\n\nYour Tasks And Responsibilities\n\n\n\nCollecting data and \"data wrangling\", i.e. transforming, cleansing and linking with other data\nProvide data sets for (machine learning) data models; determine relationships between data source attributes\nApply data mining techniques and perform statistical analysis \nDevelopment and implementation of prototypes, e.g. in Python and Bash, Java or similar\nSupport in the implementation of proof-of-concept and projects within the Military Air Systems Community\nPromote new working methods and new data governance models\n\n\nDesired Skills And Qualifications\n\n\n\nM.Sc. or equivalent in Computer Science or a similar field\nExpertise in data integration and management, in particular in the automated integration of a variety of data sources as well as a Secure handling of the usual software engineering practices: continuous integration (Jenkins, etc.), DevOps (Ambari, etc.), version control (git, etc.), code quality (pylint, etc.), design reviews, ETL (Airflow, etc.), testing (DocTest, pyTest, etc.)\nExpertise in automated data pre-processing\nKnowledge of HDFS or other file systems \nDeep knowledge of programming in Python (in particular: pySpark, pandas, matplolib, sci-kit learn, etc.); ideally also working knowledge of C# and/or R\nBeing fluent in English; knowledge of German is not strictly necessary but recommended\n\n\nNot a 100% match? No worries! Airbus supports your personal growth with customized development solutions.\n You have a question regarding this job offer? Please do not hesitate to get in touch by writing to questions@airbus.com.\n Take your career to a new level and apply online now!\n This job requires an awareness of any potential compliance risks and a commitment to act with integrity, as the foundation for the Company\u2019s success, reputation and sustainable growth.\n\nCompany\n\nAirbus Defence and Space GmbH\n\nContract Type\n\nPermanent Contract / CDI / Unbefristet / Contrato indefinido\n\nExperience Level\n\nProfessional / Exp\u00e9riment\u00e9(e) / Professionell / Profesional\n\nJob Family\n\nCustomer Eng.&Technical Support&Services\n By submitting your CV or application you are consenting to Airbus using and storing information about you for monitoring purposes relating to your application or future employment. This information will only be used by Airbus.\n Airbus is committed to achieving workforce diversity and creating an inclusive working environment. We welcome all applications irrespective of social and cultural background, age, gender, disability, sexual orientation or religious belief.\n Airbus is, and always has been, committed to equal opportunities for all. As such, we will never ask for any type of monetary exchange in the frame of a recruitment process. Any impersonation of Airbus to do so should be reported to emsom@airbus.com.\n At Airbus, we support you to work, connect and collaborate more easily and flexibly. Wherever possible, we foster flexible working arrangements to stimulate innovative thinking."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Hemnet",
        "sector": "Real Estate",
        "companySize": "51-200 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nHemnet has more than 60 million visits every month. People come to us to find joy, inspiration and - most important - their new homes. We are now looking for a Data Engineer to join us as we are strengthening our platform team.\nThe Platform Team\nOur team's mission is to enable the product development teams to release and maintain their products by providing a powerful, approachable and stable application platform. The team consists of six developers and a development manager with different focus areas such as Data and Devops/Infrastructure. We work closely together to develop and evolve our platform.\n\n\nSome of the team\u2019s main responsibilities:\n\nApplication and data infrastructure\nServing analytics and product teams with high integrity data \nTools for CI/CD, release pipeline and monitoring\nSystem security, performance, stability and data integrity\nExternal integrations\n\n\n\nA peek at our tech stack\n\nAWS\nRedshift\nPostgres\nDatadog\nDocker\nRuby & Python\nBash/Shellscript\nSnowplow\nCircleCI\nTerraform\n\n\n\nWhat you\u2019ll do:\nAs part of the platform team at Hemnet you\u2019ll be working with core functionality in an area that is being highly prioritized in the company. We see great opportunities ahead leveraging from our vast data sources to both broaden and deepen our analytics department and build new data driven products to serve our customers. This will put increasing demands on both infrastructure and data engineering to keep data fresh and accessible with a high integrity. You\u2019ll be part of a team that puts great emphasis on using the right tool for the right task and keeping our data stack modern and up to date. This includes among other things:\n\n\n\nBuilding and managing ELT data pipelines (Extract, Load & Transform).\nEnsuring data integrity and observability.\nDeploying machine learning models\n\n\n\nWho are you?\nWe believe you are an experienced Data Engineer or an Developer who recently started your journey within Data Engineering. You have previously worked with data pipelines and infrastructure, and have good knowledge of best practices. Personal qualities are important for us, and you should be someone who thrives in a very collaborative environment, and who continuously strives to get the best solution in place.\n\n\nBackground/Skills:\n\nSkilled in at least one programming language (e.g. Ruby, Python, Java or C#)\nExperience working with SQL\nExperience with working with Git\nKnows your way around databases (relational & non-relational)\n\n\n\nBonus points:\n\nAWS\nsnowplow\ndbt\nPostgreSQL\nredshift\nstatistics/machine learning\ndynamoDB\nRuby\ngraphQL\n\n\n\nWay of working after the pandemic:\nAll employees at Hemnet will have the possibility to work from the office in the central parts of Stockholm. We will also have the opportunity to work the majority of time (but not 100%) remotely from home.\n\n\nDoes this sound intriguing? We look forward to reading your application and learning more about what makes you tick!"
    },
    {
        "position": "Director Data & ML Engineering",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Brenntag",
        "sector": "Chemical Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Amsterdam, North Holland, Netherlands",
        "post": "About the job \n Our team in Amsterdam currently has an opening for a Director Data & ML Engineering\n\nBrenntag is undergoing a group-wide transformation to deliver profitable organic growth and sustained group efficiencies. Data & Analytics is a key pillar which will allow us to \u2018liberate\u2019 our data and thus improve our decision-making at speed.\n As part of the Data & Analytics leadership team, this role has accountability for the creation of Data Products to enable decision-making throughout Brenntag. You will serve as an evangelist for the power of analytics, engaging key stakeholders to illustrate proven successes.\n You will lead Brenntag Data & ML Engineering function who is responsible for:\n Liberating our data from source system, making them fit for consumption by analytics and other systems across the organization.\n Working with data scientist to create machine learning models and embed them in our systems and processes.\n\nYOUR ROLE & RESPONSIBILITIES\n\n\nEstablish and drive organization\u2019s strategic direction for enterprise, end-to-end data analytics solutions in alignment with Brenntag\u2019s strategic priorities.\nSet strategy, roadmap, plans and priorities to ensure reliable, high quality development operations to support speedy deployment and improved performance of data solutions.\nPromote the development of innovative products in collaboration across D&A, Digital, Core IT and Architecture.\nLead engineering and delivery of data lineage capabilities intended to trace data usage across Brenntag\u2019s Analytics Platforms.\nCollaborate with Data Governance team to create data management capabilities that enhance data quality data and prevent bad data propagation to downstream processes.\nContribute to organizational wide initiatives around Machine Learning and Automation.\nActs as a business owner and manages long-term and short-term strategic initiatives for analytics products within analytics platforms and analytics APIs to operational systems.\nThe role will work with cross-functional at a global and market to ensure successful design, development, and delivery of unified analytics data platform.\nDevelop and lead DevOps professionals responsible for supporting data and analytics solutions deployment and maintenance.\nPartner across D&A teams to accelerate and leverage data capabilities and insights as part of the Brenntag\u2019s integrated data offense.\nBuild, manage, mentor, and inspire team(s); managing performance, goals and development potential.\n\n\n\nYOUR PROFILE\n\n\nBachelor\u2019s degree in computer science, engineering or related field, or relevant equivalent.\n10 years of experience specializing in advanced data analytics, BI, and/or data products .\nStrong experience in DevOps, DataOps or systems administration. \nStrong understanding of data structures and algorithms.\nStrong understanding of solution and technical design.\nStrong problem solving and analytical mindset.\nExperience with cloud environments such as Microsoft Azure, Google Cloud, and AWS. Experience with Big Data and NoSQL technologies like Hadoop, HBase, Spark, Impala, Cassandra, Storm, Flume, Pig, or Hive.\nAble to influence and communicate effectively, both verbally and written, with team members and business stakeholders.\nAble to quickly pick up new programming languages, technologies, and frameworks.\nProven ability to influence critical business outcomes in a matrix based, global environment.\nExcellent critical thinking skills.\nExpert understanding of and proven ability to deliver complex data systems.\nExperience leading or working with DevOps / DataOps / MLOps engineers.\nSolid understanding of software development life cycle, test driven development, Agile methodologies, continuous integration, continuous delivery.\nAbility to educate, inform, persuade, and achieve understanding and buy-in on technical and business needs across different functions, levels and customers.\nGood understanding of key topics in data science and applied analytics.\nUnique greenfield environment to drive change in a global business\nOpen space in a vibrant start-up corporate incubator\nLots of possibilities for professional development\nInternational team\nFriendly and supportive colleagues\nCompetitive compensation package\n\n\n\nINTERESTED?\n\nWe look forward receiving your application."
    },
    {
        "position": "Senior Software Engineer -  Data Engineering",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Kindred Group plc",
        "sector": "Gambling Facilities and Casinos",
        "companySize": "1,001-5,000 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nThe role \nKindred is looking for a highly skilled developer to join the Data Engineering team whose vision is to drive and support Kindred to be the most data-driven sports betting and gambling company in the world! \nAs a Data Engineer in Kindred, you will be part of the Data Department under the overall Technology organization. Joining this team, you will be playing a big part in the way we shape our business by closely collaborating with different stakeholders across the business, ensuring they get the most out of the data in terms of reporting, statistics and to form the basis of decision making and analytical processes. \nThe successful candidate will be responsible for the end to end solution from data ingestion, preparation of data to building segmentations and reporting solutions in both Cloud and On-Prem Data Warehouse. \nWhat you will do \n\nDesign, build and operationalize data solutions on our AWS data platform \nBuild data pipelines and applications that handle multiple sources of data to create exceptional quality data products \nDesign, enhance and implement data ingestion from wider range of data sources into our Data platform. \nDeveloping advanced Oracle PL/SQL, writing and optimizing/tuning queries over large data sets. \nDeveloping dashboards and reporting solutions \nData investigations and problem-solving from internal and external stakeholders. \nSetting up Apache Kafka streaming jobs. \nProactively engage with stakeholders and deliver their requirements. \nSupporting Data products maintenance and monitoring initiatives (including occasional on-call support & incident management). \nWork in an Agile way with open communication, while delivering top quality products and services. \n\nAbout you \n\nExtensive knowledge and hands on experience on Apache Spark/EMR, AWS Glue, Lambda, S3. \nStrong background of working with RDBMS \nExperience with dealing with large data volumes. \nPreferably 5+ years working with data. \nHands on experience on Kafka. \nWorking knowledge with Java/Spring/Spring boot \nGood understanding of Data Warehouse concepts. \nExperience deploying software into containerised environments, including Docker and Kubernetes. \nImplementation of ETL processes and data structure. \nKnowledge of any basic cloud architecture (e.g., AWS). \nGood attitude and willingness to learn new skills and technologies. \nA problem-solving growth mindset with the ability to pick up new tools and concepts quickly \nOpen-mindedness, able to interact in a constructive manner with the Data Engineering teams, stakeholders and other contributors to Data solutions. \n\nIn addition, it would be an advantage if you also have: \n\nExperience with cloud formation and terraform. \nExperience with building pipeline through Matillion or similar. \n\nApplication Process \nClick on the \"Apply Now\" button and complete the short web form. Please add a covering letter in English to let us know your motivation for applying and your salary expectation. Our Talent Acquisition team will be in touch soon. \nKindred is an equal opportunities employer committed to employing a diverse workforce and an inclusive culture. As such we oppose all forms of discrimination in the workplace. We create equal opportunities for all our applicants and will treat people equally regardless of and not limited to, gender, age, disability, race, sexual orientation. We are committed not only to our legal obligations but also to the positive promotion that equal opportunities bring to our operations as set out in our sustainability framework. \nJob Alerts \nNot suited to this role but interested in working at Kindred Group? \nWe are always on the lookout for talented, passionate people to join our global teams so if you'd like us to let you know when suitable jobs come up, please click on \u201cRegister for Alerts\u201d."
    },
    {
        "position": "Data Engineering Manager (Remote)",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Stuart",
        "sector": "Transportation, Logistics, Supply Chain and Storage",
        "companySize": "501-1,000 employees",
        "location": "France",
        "post": "About the job \n\nStuart (DPD Group) is a sustainable \ud83c\udf31 last-mile logistics company that connects retailers and e-merchants to a fleet of geolocalised couriers across several countries in Europe.\n\n\nOur Mission \ud83d\ude80\nWe are an impact-driven company that aims to build the future of logistics for a more sustainable world: shared, efficient and reliable. We are committed to creating a new standard for urban deliveries that meet today\u2019s environmental and social challenges while offering a premium delivery experience blending speed, flexibility and convenience.\n\n\nOur motto: \u201cMake every delivery a moment all of us can truly celebrate!\u201d More than 3000+ leading brands already partner with us across Restaurants, Grocery, Retail & Luxury, eCommerce and Professional Services to deliver all types of goods at the tap of a button. Stuart is a highly diverse and inclusive company of 700+ employees with 90+ nationalities working across France \ud83c\uddeb\ud83c\uddf7, Italy \ud83c\uddee\ud83c\uddf9, Poland \ud83c\uddf5\ud83c\uddf1, Portugal \ud83c\uddf5\ud83c\uddf9, Spain \ud83c\uddea\ud83c\uddf8 and the U.K. \ud83c\uddec\ud83c\udde7\n\n\nIt\u2019s the right moment and the right place for us to make an impact on millions of people, as home delivery services hit a record high. And guess what? You can help us fulfil our vision \ud83d\ude4c\n\n\n\ud83d\udc8e The Position\n\n\nWe are looking for an Engineering Manager to join us at Stuart to drive our machine learning initiatives. Engineers at Stuart operate as part of cross-functional teams: you will join a team of five Python and Scala Data Engineers collaborating with data scientists, product managers and product analysts.\n\n\nYou will ensure a good collaboration between the engineers and the other teams by helping them refine their ways of working and development trajectories. Your team will deliver solutions for fraud detection, supply & demand management and time of arrival estimation.\n\n\nOur vision is twofold: \n\ntake down the barriers between data science and data engineering by encouraging constant collaboration in unified teams\nbuild a common MLOps infrastructure while working on our key product initiatives\n\n\n\nYou will collaborate closely with our ML Staff Engineer in charge of the technical aspects of our ML efforts and benefit from the support and experience of our Managers and Directors.\n\n\nLearn more about our team via our engineering blog: Stuart Engineering \u2013 Medium \ud83e\udd13\n\n\nWhat will I be doing? \ud83e\udd14\n\nBe responsible for the sustainable delivery of your team focusing on reliable, scalable, and maintainable software.\nMentor and support the engineers on your team, helping them grow via coaching, mentoring, regular feedback, and performance reviews.\nWork in partnership with the product manager and product designer of the team, helping to define roadmaps, OKRs, and manage projects.\nEnsure organisational agility and efficiency, both inside the team and in the ways they collaborate with other teams.\nBe active in the hiring process, and pro-actively hire to ensure the continued delivery of the team.\nShare company vision and strategy with the team and provide clear context.\n\n\n\nWhat do we need from you? \ud83d\ude0e\n\n2 years or more experience in a leadership role.\nSolid technical experience (as an individual contributor at a senior level or above) \nGood grasp of the key management concepts we support: servant leadership and agility.\nExcellent written and spoken communication skills.\nFluent in English.\n\n\n\nNot sure if this is you?\nWe understand that experiences are broad and come from many places. We appreciate that everyone potentially has something to contribute to our team and we'd still love to hear from you if your background doesn't completely match!\n\n\nThe stuff you wanna know \ud83d\ude09\n\nFamily-friendly work-life balance - work from home and flexible hours \ud83c\udfe1\nOption to work remotely anywhere in France \ud83c\uddeb\ud83c\uddf7 \nTicket Restaurant by Swile (\u20ac13 daily with 60% paid by the company) \ud83e\udd57\nUnlimited access to Udemy for all your learning and development needs \ud83d\udcda\nStuart Academy with regular workshops, Stu-Classes, and Stu-Talks \ud83c\udf93\nStuart is putting Mental Health Awareness first! Wellness Allowance (\u20ac40 monthly) to use in any gym or sport class \ud83e\uddd8\nPrivate healthcare provided by Alan \ud83e\uddd1\u200d\u2695\ufe0f\nWork in an international, dynamic and passionate environment with a company culture focused on learning and development \ud83c\udf89 \n\n\n\nYou\u2019ve read all this way but you\u2019re missing a skill or two? No problem, it\u2019s our job to up-skill you to take your career to the next level. What we\u2019re trying to say is, don\u2019t be afraid to apply if you don\u2019t tick all the boxes \ud83d\udcaa\n\n\nAt Stuart, we believe that employees today want to evolve in collaborative, high-growth environments where they can demonstrate their abilities and thrive both professionally and personally. We are convinced that employees need to find alignment between their inner values and their company\u2019s culture and mission to unlock their full potential. We work to create a culture of empowerment, continuous learning and growth where everyone can bring expertise, own projects and easily measure their impact \ud83d\ude4c\n\n\nStuart is proud to be an equal opportunity workplace dedicated to promoting diversity. We don\u2019t discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status \ud83d\udc99\n\n\nPlease note: Our Talent Acquisition Team is international coming from across the world \ud83c\udf0d We kindly ask you to please submit your CV and application in English so that it can be reviewed correctly (unless the job posting is in a language other than English). Thank you \ud83e\udd17"
    },
    {
        "position": "Senior IT Professional - Natural Language Processing",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Roche",
        "sector": "Biotechnology Research",
        "companySize": "10,001+ employees",
        "location": "Pozna\u0144, Wielkopolskie, Poland",
        "post": "About the job \n The Position\n\nSenior IT Pro - Natural Language Processing\n\nIT INNOVATORS IN HEALTHCARE\n\nWe do #Code4lLife creating innovative software that helps doctors, patients, and scientists around the world.\n\nWho We Seek\nA person who has:\nUnderstanding of basic concepts from area of Text Mining, NLP \nExperience with modern deep learning architectures for NLP (encoder-decoder, transformers, attention), including:\nhands-on experience with using Huggingface Transformers, SBert, GPT-2/GPT-3 (one of) capability to build ML/DL pipeline for training/tuning model\n\nAt least 3 years of experience with our typical NLP tools used in daily work:\nscikit learn, numpy, pandaspytorch or tensorflowspaCy, NLTK\n\n3+ years of general experience in NLP/AI software engineering, especially\n\nproficiency with Python\nexperience with Git\nCI/CD tools is nice to have\nunderstanding of software testing (unit tests)\nbash/shell scripting\nexperience with Docker, API development\nexperience with cloud platforms (preferred AWS) and ready to use tools (SageMaker)\n\nAbility to deliver fully working products (deployment activities):\nGeneral understanding of SCRUM and its principles (PSM I or PSD certificate is nice to have)\n\n\nEXAMPLE PROJECTS ACTIVITIES YOU MAY WORK ON\n\n\nDesigning and developing pipelines for solving NLP tasks (predictions, clustering, deviations detection) for generating insights and extracting knowledge from millions of internal documents\nImplementing fully working AI/NLP powered applications for supporting our colleagues from all the departments, for instance: pharma, molecules development, clinical trials, sales, marketing, people & culture or IT\nBuilding toolset and re-usable components for our future projects and ideas\n\n\nWhat We Appreciate\n\n\nAbility to learn new technologies (we can teach you them as well!)\nAnalytical mindset and critical thinking\nGood communication skills\nOpenness for knowledge sharing\n\n\nWhat You Get\n\n\nSalary range 13 000 - 17 500 PLN gross\nAnnual bonus payment based on your performanceContract of employment \nEmphasis on continuous personal and professional self-development supported by dedicated training budget (training, certifications, conferences, diversified career paths etc.)\nExperienced and professional colleagues and workplace that supports innovation and new ideas\nHighly flexible working hours (starting your day at 7-11) and workplace according to employee\u2019s needs and preferences* (regular office/home office)\nA chance to work on solutions which can improve patients\u2019 lives\n\n\nAdditional Benefits\n\n\nRelocation package\nPrivate healthcare and insurance\nHealth, well-being and sport promotion\nSupport for parents and families\nStock share purchase additions\nYearly sales of company laptops and cars\nAdditional vacation time for long-term employees and more\n\n\nAPPLY DIRECTLY\n\nApply directly via Workday, pressing the blue button at the top.\n If you feel this offer suits a friend of yours, we\u2019ll appreciate you letting them know! Simply copy and share the link from the browser.\n If you have any questions regarding the offer and would like to contact us directly, please write to us at katarzyna.wisniewska@roche.com\n\nWANT TO KNOW MORE?\n\nCheck our website for more details, e.g. the career path, recruitment process, etc.\n https://it.roche.pl/work-with-us\n Want to know what it\u2019s like to be a part of Roche IT first-hand? Check out our blog! You will meet the community members there, sharing their experience and impressions from diverse perspectives, not only about their job but also their lives.\n https://www.roche.com/careers/weareroche.htm\n Please note that during the pandemic we are working and recruiting 100% remotely.\n \u2026..\n\nRoche is an equal opportunity employer. We care about inclusion in terms of gender, age, race, skin colour, nationality, religion, marital status, sexual orientation, background, physical or mental disabilities and on every other grounds. Applying for our position, we assure you that we will assess your application solely on the basis of your competencies.\n\nAdministratorem Pani/Pana danych osobowych jest sp\u00f3\u0142ka Roche Polska Sp. z o.o., ul. Domaniewska 39 B, 02-672 Warszawa. Dane przetwarzane s\u0105 w celu prowadzenia rekrutacji. Przys\u0142uguje Pani/Panu prawo dost\u0119pu do tre\u015bci swoich danych, ich sprostowania, usuni\u0119cia, ograniczenia przetwarzania, przenoszenia oraz \u2013 w sytuacji, gdy s\u0105 one przetwarzane na podstawie udzielonej zgody \u2013 cofni\u0119cia tej\u017ce zgody w dowolnym momencie. Kontakt do Inspektora Ochrony Danych:ochrona.danych@roche.com. Wi\u0119cej informacji o zasadach przetwarzania przez Roche Pani/Pana danych osobowych pod linkiem: \n\n https://www.roche.pl/pl/content/klauzula-informacyjna-rekrutacja-pl.html\n\nThe controller of your personal data is Roche Polska Sp. z o.o., ul. Domaniewska 39 B, 02-672 Warsaw. The data is processed for the purpose of recruitment. You have the right to access your data, rectify it, delete it, limit processing, transfer it and - if processing is based on your consent - withdraw this consent at any time. Contact the Data Protection Officer at: Ochrona.danych@roche.com. More information on the principles of processing your personal data by Roche at the link: \n\n https://www.roche.pl/pl/content/klauzula-informacyjna-rekrutacja-en.html\n Who we are\n At Roche, more than 100,000 people across 100 countries are pushing back the frontiers of healthcare. Working together, we\u2019ve become one of the world\u2019s leading research-focused healthcare groups. Our success is built on innovation, curiosity and diversity.\n At Roche Poland, we are more than 800 professionals working together on one mission. We are proud of who we are, what we do and how we do it. Join us in the area of Clinical Research, Medical, Marketing, IT or business departments.\n Roche is an Equal Opportunity Employer."
    },
    {
        "position": "Principal Scientist, Natural Language Processing",
        "jobType": "Full-time",
        "jobLevel": "Director",
        "company": "Amazon",
        "sector": "Technology, Information and Internet",
        "companySize": "10,001+ employees",
        "location": "Berlin, Berlin, Germany",
        "post": "About the job \n\nDescription\n\nAs a Principal Scientist on this growing team, you will take on a leading role in the Natural Language Processing (NLP) teams for Amazon Search. We are developing NLP components that cover a wide range of languages, from English and other Indo-European languages to Turkish, Arabic, Japanese and many more, and play a central role in search query processing, product description indexing, string normalization and vector embeddings for queries and products.\n You will guide team members on the use of machine learning, tuned on terabytes of product and traffic data, to build or improve NLP technology that we integrate with the production search engine and evaluate using techniques like A/B tests. You will work with the Amazon Search leadership to set direction for the NLP approaches, model architectures and training methods, balancing business-defined performance indicators with the needs of millisecond response times. You will propose and explore publication-worthy innovation.\n You will build relationships with stakeholders and partner teams across multiple countries, analyze data for trends, track down the source and meaning of anomalies, select suitable rule-based or machine-learning based techniques and advise team members as they make improvements, closing the loop through data, model, application and customer feedback.\n\nResponsibilities\n\nDefine standards for the analysis of customer-focused problems in an industrial settingGuide team members and the leadership team on accurate, efficient and innovative NLP/ML solutionsGet hands-on when building NLP models that can be applied to multiple languagesPublish the developed innovative solutions in leading academic scientific venues in NLP/ML\n\n\nBasic Qualifications\n\nBASIC QUALIFICATIONS\n\nPhD degree or equivalent, in a quantitative field (computer science, mathematics, natural language processing, artificial intelligence, or similar)At least 3 recent publications in a leading journal or conference related to computer science, natural language processing or applied mathematics10+ years experience using machine learning or other NLP techniques, including but not limited to Deep Learning4+ years experience implementing machine learning related techniques using Python or Scala in a distributed system, suitable for large scaleExperience coaching or mentoring team mates (not necessarily in a manager role)Fluency in written and spoken English (German is not required)\n\n\nPreferred Qualifications\n\nPREFERRED QUALIFICATIONS\n\nExperience working in data or applied science in a consumer product companyExperience using Java or C++ writing production-ready codeFamiliarity with Deep Learning and machine learning frameworks such as SageMaker, PyTorch or TensorFlowExperience in low-level optimization of large-scale neural networksFluency in one or more languages other than English\n\n\nCompany - Amazon Development Center DEU\n Job ID: A1088214"
    },
    {
        "position": "Data Scientist - Text Analytics and Natural Language Processing",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Merck Group",
        "sector": "Pharmaceutical Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Mollet del Vall\u00e8s, Catalonia, Spain",
        "post": "About the job \n Job description:\n\n\n\nA career at our company is an ongoing journey of discovery: our 60,300 people are shaping how the world lives, works and plays through next generation advancements in Healthcare, Life Science and Electronics. For more than 350 years and across the world we have passionately pursued our curiosity to find novel and vibrant ways of enhancing the lives of others.\n\n\n\n\n\n\nWho you are: As the Data Scientist, you will work in our global Reporting and Analytics team of the CFO Digital Strategy & Realization Organization. Our mission is to architect, design and refines analytics solutions supplying substantial and effective answers to business problems. We provide Digital Leadership for Analytics Initiatives across the Group Functions such as Finance, Procurement and HR. With our expertise, we support initiatives to produce practical and impactful analytic solutions for our customers. Operating in an agile environment, we closely work with internal and external partners like our Product Owners, Scrum Masters, Functional Experts, Data Architects, Data Scientists and IT Engineers to deliver sustainable analytical solutions and drive informed business decisions.\n\n\nYour focus will be on performing analytics in the area of Natural Language Processing (NLP), Machine Learning and Predictive Modelling, from gaining data and business understanding through data preparation and modeling, model evaluation to the result presentation and the solution deployment. In your role, you will apply a variety of models on large-scale datasets to address various business problems using advanced techniques. You will write high-quality production code, build and maintain robust, scalable project pipelines, document and validate the approach, set up processes to monitor, operate and continually improve the efficiency and performance of the implemented solutions.\n\n\nWith your passion for data and analytics, let\u2019s create new business insights from unstructured and structured data!\n\n\n\n\nYour Profile\n\n\n\u2022 Graduated with a higher degree in computer science, information technology, information science, or similar fields\n\n\n\u2022 5+ years of working experience in designing, developing and implementing machine learning/deep learning models (supervised or unsupervised), preferably applied to the text data\n\n\n\u2022 Strong programming skills in Python\n\n\n\u2022 Excellent knowledge of commonly used NLP, machine learning, and deep learning libraries such as PyTorch, Keras, Transformers, SKLearn, Gensim, SpaCy, or NLTK.\n\n\n\u2022 Experience in preprocessing and parsing text data stored in various formats such as PPT, DOC, PDF, and especially scanned documents using OCR technology\n\n\n\u2022 Good understanding of document indexing systems such as Elastic search or Solr\n\n\n\u2022 Expertise in agile software development, version control (git), continuous integration/deployment (CI/CD)\n\n\n\u2022 Experience with distributed computing with Apache Spark (pyspark)\n\n\n\u2022 Knowledge of microservices, RESTful APIs, Dockers and AWS Container Services is a plus\n\n\n\u2022 Experience in services offered by cloud technologies, preferably AWS.\n\n\n\u2022 Proficient in English in written and verbal communication\n\n\n\nProfile description:\n\nPlease see Job Description\n\n\n\nWe offer:\n\nWhat we offer: We are curious minds that come from a broad range of backgrounds, perspectives, and life experiences. We celebrate all dimensions of diversity. Applications from individuals are encouraged regardless of age, disability, sex, gender reassignment, sexual orientation, pregnancy and maternity, race, religion or belief and marriage and civil partnerships. We believe that it drives excellence, innovation, and human progress. We care about our customers, patients, and our rich mix of people. This diversity strengthens our ability to lead in science and technology. We are committed to creating access and opportunities for all and empower you to fulfil your ambitions. Our diverse businesses offer various career moves to seek new horizons. Join us in building a culture of inclusion and belonging that impacts millions and empowers everyone to bring their curiosity to life!\n\n\n\n\nCurious? Chat with one of our curious minds on our interactive Q&A platform and catch a glimpse of our people, values, and culture. You can also apply and find more information at https://jobs.vibrantm.com\n\n\n\n\nIf you would like to know more about what diversity, equity, and inclusion means to us, please visit https://www.merckgroup.com/en/company/press-positions.html"
    },
    {
        "position": "\tData Scientist- Natural Language Processing",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Harnham",
        "sector": "Staffing and Recruiting",
        "companySize": "201-500 employees",
        "location": "Leiden, South Holland, Netherlands",
        "post": "About the job \n\nData Scientist - Natural Language Processing \nUp to \u20ac90,000\nLeiden\nThe Company\nThis company sits within the pharmaceutical industry and is using AI solutions to support the health care ecosystem. This company uses a suite of products that have been built in partnership with top life science companies- all with a focus on empowering the people to take action. They are the leaders in AI analytics for life sciences and pride themselves in giving their employees creative freedom in order to do their work and take pride in what they are doing. \nThe Role\nThe company is seeking a Data Scientist with a strong background in NLP to develop solutions based on the company's ground-breaking technologies. They pride themselves on their ability for their employees to influence the design, architecture, and refinement of the data processing applications in health care.\nYou will:\n\nPlay a crucial role in designing and building solutions using the leading AI engine for health care. \nBe part of a close team who have extensive experience in implementing machine learning for real-world applications.\nDefine and build systems to generate insights for clinical problems that NLP can solve \n\nDay to Day\n\nApply NLP techniques and statistical analysis to extract unstructured Textual Data Sets\nBuild and prototype NLP pipelines\nContribute to the defining and testing of products\nWork closely with the engineering and data science teams\n\n\n\nYour Skills and Experience\nThe ideal fit for this role is someone who:\n\nHas applied experience and knowledge of Natural Language Processing\nHas a Masters or PhD in NLP, Data Science, or other relevant quantitative fields\nIs comfortable with Python and solving problems using AI\nEnjoys and has strong problem-solving skills \nLanguage: English (Excelling verbal and written abilities)\n\n\n\nBenefits\n\nHybrid\nMonthly WFH budget and one-off set-up budget\n25 days holiday\nExcellent pension scheme\nPrivate health care\nFully covered public transport (NL)\n\n\n\nHow to Apply\nPlease register your interest by sending your CV via the Apply link on this page.\nKEYWORDS\nData science \u2013 Data scientist \u2013 NLP \u2013 Natural Language Processing - Healthcare"
    },
    {
        "position": "Natural Language Processing Specialist (m/f/diverse)",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Continental",
        "sector": "Motor Vehicle Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Berlin, Berlin, Germany",
        "post": "About the job \n\nDescription\n\nWould you like to accelerate Continental's journey towards an AI-empowered company?\n As a Natural Language Processing Specialist in the Artificial Intelligence and Robotics Labs you will drive innovation projects with focus on artificial intelligence technologies for a broad range of application fields in industry 4.0 and automotive domains. This includes also the development of sophisticated solutions to improve our company's internal processes and operations.\n We look for a highly motivated and creative person with proven experience in NLP technologies. A profound knowledge of related methods, solution frameworks and a solid scientific background are of advantage. You will drive the development of novel concepts and the implementation of the technical solutions. Many challenging problems demand exploration of the latest achievements from the scientific community. You will work in collaboration with excellent Universities and Research Institutes in this field.\n In this position you will also support the definition of our strategy for Artificial Intelligence, consult business, innovation managers, product, and process owners about these technologies. Excellent communication and presentation skills are of advantage.\n\nDescription\n\n\n\nDrive innovation projects in the field of artificial intelligence and cognitive process automation, focusing natural language processing (NLP), machine learning based dialog systems, knowledge representation and semantic technologies, smart digital assistants\nDevelop novel application concepts using artificial intelligence to enhance company\u2019s internal processes (Sales, Marketing, HR, Engineering, Quality etc.)\nDevelop novel application concepts using artificial intelligence for mobility and industry 4.0 services\nPromote adoption of state-of-art and novel technologies in this field\nConsult business, innovation managers and product owners\nUnderstand and translate business and application specific needs into technical requirements\nElaborate solution concepts. Contribute hands-on to implementation of prototypes and technology demonstrators\nCollaborate close with other specialists: IT, System Engineers, Data Engineers, Software developers etc.\nEnsure hand-over from innovation to solution industrialization \nTechnical responsible for projects executed collaboration with Universities and Research Institutes\nMonitor technologies, open source frameworks, commercial tools and supplier offers in this field\nContribute to shaping Continental's Artificial Intelligence and Machine Learning strategy\n\n\nWorking in the AI Campus in Berlin means being part of a highly motivated and growing team of researchers working in the field of artificial intelligence. Being located in one of the German centers for AI, we strive to work on the frontier of research by having open exchange with experts and highly influential players in the community. Frequent talks, gatherings, and discussions as well as formal and informal team events ensure prompt spread of information. In our freshly established team of mostly Ph.D. students, we are maintaining an harmonious atmosphere of easy-going collaboration and exchange. Despite this inviting culture of togetherness, we will provide you with enough flexibility in terms of working time and location. Doing a Ph.D. in Continental is going to equip you with exceptional qualification, network, and industrial experience in the future field of autonomous driving. We are looking forward to meet you at the campus!\n\nQualifications\n\n\n\nStudied or did the Ph.D. in artificial intelligence, (business) computer science, mathematics, physics, robotics, computational neuroscience, or related fields\nWorked for several years with artificial-intelligence-related algorithms, neural language processing and related technologies like NLU or NLG, machine learning based chatbots, question-answering systems, and/or digital assistants\nKnow about machine learning frameworks like Tensorflow, Theano/Keras, Scikit-Learn, Spark/Mlib, R, etc.\nImplemented algorithms in object oriented programming languages \nDesirable to know about autonomous systems or to be interested in\nAble to professionally speak and write in English language\nSpeaking or eager to learn German\nIndependent, creative, and proactive working style\nCommunicate effectively with the ability to present technical concepts to all stakeholders\nAttitude towards driving customer and quality needs\n\n\nApplications from severely handicapped people are welcome.\n\nWhat We Offer\n\n\n\nIn addition to the interesting field of activity of the function, the city of Berlin offers a high recreational value and stands for quality of life\nYou will work in an innovative work environment, namely the \"co-working space AI Campus\"\nBecome part of our motivated team - we are looking forward to you"
    },
    {
        "position": "Data Engineering Manager, Database Migration Accelerator",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Amazon",
        "sector": "Technology, Information and Internet",
        "companySize": "10,001+ employees",
        "location": "Gda\u0144sk, Pomorskie, Poland",
        "post": "About the job \n\nJob Summary\n\nDESCRIPTION\n\nAmazon\u2019s mission is to be the most customer centric company in the world. Database Migration Accelerator team helps our customers to migrate their solutions from legacy on-premise and cloud enterprise workloads into modern AWS native application architectures. This is accomplished through a variety of cutting edge tools, sophisticated engineering systems and database expertise. We provide fixed price and high speed migrations to the cloud. Database Migration Accelerator is combining various AWS cloud platform services into one product which would serve our customers.\n We are a team of professionals that are forward-looking and using latest technology offerings to build new capability to operationalise and automate migration methodologies. Databases Services at AWS cover a range of data platforms including: Amazon Aurora, DynamoDB, Redshift, Athena, QuickSight as well as AWS Database Migration Service, Data Pipeline, Glue and more. As each service grows, so does adoption by customers world-wide.\n We are looking for Data Engineer Managers to apply their talents on modernizing ETL/BI/DWH solutions, migrating them into AWS cloud. And also developing strong working relationships with other teams to analyze business demands and create automated solutions to accelerate migrations.\n Joining the AWS Database Migration Accelerator team as a Data Engineering Manager gives you the opportunity to:\nWork for a company that\u2019s at the forefront of the cloud computing space.Be involved in the fast growing managed services space \u2013 help build new service offering from scratch.\n\nMentorship & Career Growth\n Our team is dedicated to supporting new team members in an environment that celebrates knowledge sharing and mentorship. Our senior engineers mentor more junior engineers through one-on-one mentoring and collaborative code reviews.\n Projects and tasks are assigned in a way that leverages your strengths and helps you further develop your skillset.\n Inclusive Team Culture\n We get to build a really cool service and the mains contributing factor to our success is the inclusive and welcoming culture that we embody every day.\n We welcome teammates who are enthusiastic, empathetic, curious, motivated, reliable, and able to collaborate with a diverse team of peers\n As a Data Engineering Manager you will manage a team of Data and Database Engineers, which perform the following tasks:\nAnalyze ETL, ELT flows to determine the most appropriate migration strategies.Leverage the latest technologies and products to convert legacy ETL, ELT tools into modern AWS Glue and AWS Lambda solutions. Identify and remediate technical obstacles to migrations.Research and identify new opportunities for AWS to innovate on behalf of our customers.Operate test and development environments in the cloud, run and analyze test results, perform diagnostics and troubleshooting, open, prioritize, and help triage defects, track and report test status and results.Design solutions and tooling to execute automated deployments, upgrades and migrations.\n\nWhat makes this role different than all the others out there? Simple: scope. You get the opportunity to work with every product in AWS Services plus external customers ranging from the very small to the very large \u2013 everyone has data. You be working on a large number of complex migration projects and be given a lot of independence. This is a new focus area for AWS so you have the opportunity to put your stamp on it. Andy\u2019s tweets on DB Freedom have been frequent \u2013 here\u2019s your chance for visibility while delivering some results!\n Key job responsibilities\n Manage a team of Data and Database Engineers (career development, ongoing operational issues resolution, mentoring, team events). Team long-term strategy and tactical activities creation.\n\n\nBasic Qualifications\n\n\n3+ years of experience as Technical Manager or Data Engineer, or the similar role\nExperience with data modeling, data warehousing, and building ETL pipelines\nSkilled with writing, tuning, and troubleshooting SQL queries \nExperience with Big Data technologies such as Hive, Spark, Hadoop, NoSQL, AWS EMR, Glue, Lambda, Kinesis\nProficiency with Python, Java, or Scala\nGood grasp of software development life cycle and/or agile development environment\nStrong organizational and planning skills with attention to detail\nExperience in understanding system limitations, scaling factors, boundary conditions, and the reasons for architectural decisions \nExperience in Designing and building scalable data pipelines\n\nPreferred Qualifications\n\n\n5+ years of industry experience as Technical Manager or Data Engineer, or the similar role (e.g. Software Engineer, Business Intelligence Engineer, Data Scientist, ETL Developer) with a track record of manipulating, processing, and extracting value from large datasets\nExperience with orchestration tools such as AWS Step Functions. \nDeep knowledge of data warehouses, architecture, infrastructure components, ETL and reporting tools and environments\nNice to have experience with some enterprise ETL tool (IBM Datastage, Informatica, Talend or MS SSIS)\nExperience with orchestration tools such as AWS Step Functions\n\nExperience with Massively Parallel Processing (MPP) databases - Redshift, Teradata etc.\nExperience directing medium to large-scale data warehousing and BI projects, including using AWS technologies \u2013 Redshift, S3, EC2, Data-pipeline and other big data technologies\nGood communication skills and able to work with business owners to develop and define key business questions and to build data sets that answer those questions\nExperience providing technical direction and mentorship of engineers and scientists on best practices in the data engineering space\nComfort working with the Linux command line and shell scripting \nBe self-motivated and show ability to deliver on ambiguous situations and projects\n\nAmazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We make recruiting decisions based on your experience and skills. We value your passion to discover, invent, simplify and build. Protecting your privacy and the security of your data is a longstanding top priority for Amazon. Please consult our Privacy Notice (https://www.amazon.jobs/en/privacy_page) to know more about how we collect, use and transfer the personal data of our candidates.\n\n\nCompany - AMZN Dev Cntr Poland sp. z.o.o\n Job ID: A2193620"
    },
    {
        "position": "Lead Data Engineering",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "miDiagnostics",
        "sector": "Medical Equipment Manufacturing",
        "companySize": "51-200 employees",
        "location": "Leuven, Flemish Region, Belgium",
        "post": "About the job \n\nAbout miDIAGNOSTICS \nSpun out of the world-leading R&D and innovation hub in nanoelectronics and digital technologies, Imec, and a research collaboration with Johns Hopkins University, the leading US research and medical centre, miDiagnostics\u2019 goal is to enable fast, comprehensive and cost-effective health analysis, regardless of location. Based in Leuven, Belgium, miDiagnostics is a privately held company created in 2015.\nmiDiagnostics is using silicon chip technology which will bring miniaturized, rapid, easy-to-use, lab-quality PCR tests with built-in connectivity direct to the patient and clinician. Combining a nanofluidic processor on a chip and a compact reader, miDiagnostics can measure virtually any biomarker from an easily accessed sample such as drops of finger prick blood. The Company is developing an extensive portfolio of tests for screening, diagnosis and monitoring of a wide range of health conditions, including infectious diseases.\n\n\n\n\nThe Job\nmiDiagnostics is releasing its first product, an ultra-fast PCR test, into the market. This market introduction means rapid organization scaling and supporting the international growth ambitions of the company. For the further development of the Software team, miDiagnostics is looking for a Lead Data Engineering, who will report to the Director Software Engineering.\n\n\nJoin us on our exciting journey to enable the next generation of lab-on-a-chip diagnostics.\n\n\nAs our Lead Data Engineering, your responsibilities will include:\n\nLeads the Data Engineering team (small team of 3 in total) and has the ability to lead teams working in an agile set-up;\nDevelops, constructs, tests and maintains the data pipeline architectures;\nAligns data architecture with business requirements;\nSupports data acquisition from the lab all the way to cloud infrastructure and connected data visualization tools;\nUses structured tools, environments and coding languages to support and further develop sophisticated analytics programs, machine learning and statistical methods;\nIdentifies ways to improve data reliability, efficiency and quality;\nConducts research for industry and business questions;\nUses large data sets to address business issues;\nPrepares data for predictive and prescriptive modelling;\nData cleaning;\nData visualization;\nCascades the company priorities to the Data Engineering team and defines clear objectives and key results;\nEnsures the right talent is hired and supports hiring via his/her network;\nActs as an inspirational leader and promotes a growth mindset across the company;\n\n\n\n\n\nYour profile and competencies\n\nPhD or masters in a scientific field or equivalent through experience;\nExperience within the medical device industry, or other heavily regulated industries is considered a strong plus;\nExperience in IEC62304 and 13485 are considered a strong plus; \nSolid experience in cybersecurity aspects of data engineering; \nA solid experience in data cleaning, data mining, data analysis, data visualization, and shares our passion for accurate, accessible and transparent data;\nExperience with data visualization tools (experience in Tableau is a plus);\nExperience with the python and javascript (knowledge of additional programming languages is a plus);\nDeep understanding of databases and SQL (experience with mySql is a plus);\nFamiliarity with software for data cleanup (experience with OpenRefine is a plus);\nFamiliarity with Amazon Web Services (AWS) and REST API;\nFluent in English (written and verbal);\nStrong communication skills;\nService-minded, detail-oriented, result-focused and quality driven;\nStrong analytical and planning skills;\nAbility to build a high-performing team;\nTrue team-player;\nOur offices are located in Leuven (Belgium). Relocation to Belgium is needed. It is essential that you hold entitlement to work and live in Belgium.\n\n\nThe offer\n\nA job in a fast-growing and ambitious start-up in the medical diagnostics industry.\nmiDiagnostics is an international-oriented company with close connections to two world-class research institutions (imec and Johns Hopkins University).\nOpportunity to grow in a new and exciting cutting-edge field in point-of-care diagnostics.\n\n\n\nInterested? Please apply via our career website https://jobs.midiagnostics.com/"
    },
    {
        "position": "Data Engineering Manager",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Kraken Digital Asset Exchange",
        "sector": "Financial Services",
        "companySize": "1,001-5,000 employees",
        "location": "Ireland",
        "post": "About the job \n\nAbout Kraken\n\nAs one of the largest and most trusted digital asset platforms globally, we are empowering people to experience the life-changing potential of crypto. Trusted by over 8 million consumer and pro traders, institutions, and authorities worldwide - our unique combination of products, services, and global expertise is helping tip the scales towards mass crypto adoption. But we\u2019re only just getting started. We want to be pioneers in crypto and add value to the everyday lives of billions. Now is not the time to sit on the sidelines. Join us to bring crypto to the world.\n To ensure Kraken is the right fit for you, please ensure you read Kraken Culture Explained to find out more about us!\n The data engineering team is responsible for designing and implementing scalable solutions that allow Kraken to make data-driven decisions fast and accurately, while dealing with high volumes of data. The team maintains the company\u2019s data warehouse and data-lake, replicating data among different platforms, and answering the critical business needs that help Kraken scale and succeed. The data engineering teams deal with different both batch and streamed data, and split into different responsibilities and focus areas depending on Kraken\u2019s objectives.\n\nResponsibilities\n\n\n\nManage a team of highly qualified and experienced data engineers \nLead the building of scalable and reliable data pipelines that collect, transforms, loads and curates data from internal systems\nDrive data systems to be as accurate and performant as possible while advocating the engineers in the team.\nSupport design and deployment of the distributed data store that act as a central source of truth across the organization (EMs may remain partially hands-on)\nHelp scaling the team, hiring, interviewing, and assist in planning the right healthy growth and career progression\nCommunicate with different business owners and stakeholders, set OKRs aligned with Kraken\u2019s vision, then lead initiatives and people to achieve these goals\nMaintain a high security attitude from both technical and cultural perspectives\n\n\nRequirements\n\n\n\n9+ years of work experience in relevant fields around data engineering, data-warehousing, distributed-systems and software development\n8+ years of work experience in a major programming language (e.g. Scala, Python, Golang,..)\n5+ years of experience leading teams, preferably engineering and/or data teams\n3+ years of experience managing remote teams\nYou have a strong servant-leadership management style geared towards supporting, mentoring and growing engineers on the team \nYou are strategic and think at a high level, but are also hands-on, execution-oriented, and capable of getting things done quickly\nYou have a strong experience in data engineering, data-lakes, data warehousing, and building robust scalable organization-wide data solutions\nYou have experience leading teams of engineers across all levels of skill and experience with a track record of managing, recruiting, and retaining strong engineering leadership and engineering talent\nYou have an ability to translate a long-term vision into a near-term, executable plan\nYou have experience working in different development methodologies, understand the trade-offs, and can iterate to a process that supports you, the team, and the business\nYou are interested in cryptocurrency and actively involved in the space\nYou care deeply about people and their success\nYou\u2019re not afraid of hard conversations and are gifted at coaching your colleagues through difficult situations\n\n\nLocation Tagging: #EU #US\n We\u2019re powered by people from around the world with their own unique and diverse experiences. We value all Krakenites and their talents, contributions, and perspectives, regardless of their background. We encourage you to apply for roles where you don't fully meet the listed requirements, especially if you're passionate or knowledgable about crypto!\n As an equal opportunity employer we don\u2019t tolerate discrimination or harassment of any kind. Whether that\u2019s based on race, ethnicity, age, gender identity, citizenship, religion, sexual orientation, disability, pregnancy, veteran status or any other protected characteristic as outlined by federal, state or local laws.\n\nStay in the know\nKraken Culture Explained \nFollow us on Twitter \nCatch up on our blog \nFollow us on LinkedIn"
    },
    {
        "position": "Microsoft Data Analytics - Engineering Lead - Manager",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Accenture Italia",
        "sector": "IT Services and IT Consulting",
        "companySize": "10,001+ employees",
        "location": "Assago, Lombardy, Italy",
        "post": "About the job \n Are you ready to step up to the New and take your technology expertise to the next level? Join Accenture and help transform leading organizations and communities around the world in achieving their goals faster and more efficiently. The sheer scale of our capabilities and client engagements and the way we collaborate, operate, and deliver value provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career. As part of our Accenture Microsoft Business Group (AMBG) practice, you will lead Technology Innovation to Shape World-Class Business Solutions for our Clients and deliver them at scale. There will never be a typical day and that\u2019s why people love it here. The opportunities to make a difference within exciting Client initiatives are unlimited in the ever-changing technology landscape. You will be part of a growing network of technology experts who are highly collaborative taking on today\u2019s biggest, most complex business challenges. We will nurture your talent in an inclusive culture that values diversity. Come grow Your Career in technology at Accenture! Microsoft Data Analytics-Engineering Lead - Manager will be responsible for working with our Clients and internal teams to help shape Industry Transformation solutions using the Microsoft technology platform and its wide eco-system of partners. Companies and entire Industries need help to reinvent themselves during these challenging times and your job will be to help Companies transform themselves to emerge stronger above and beyond complex contexts such as the current one.\n A solid understanding of challenges that Clients in an Industry are facing, and how to address them using Microsoft technology ecosystem is key for delivering value. This should be combined with experience and understanding of considerations for large scale cloud analytics solutions architecting, helping Clients transforming into a data driven business, developing new data service and data platforms using digital, becoming more agile and resilient.\n We are looking for candidates who have a broad set of technology skills across these areas and who can demonstrate an ability to design the right solutions with an appropriate combination of Microsoft and its 3rd party technologies for deploying on the Microsoft Intelligent Data Platform. Key responsibilities may include:\n\n\n\nAs a data analytics-engineering lead, you will work with implementation teams from concept to delivery, providing data and applied intelligence expertise for successfully deploying large scale digital data and analytics solutions in the enterprise, using modern digital technologies on premise and cloud\n\n\nYou will play a key role in leading the data engineering workstream of analytics transformation projects across multiple areas / domains, such as sales, marketing, supply chain, revenue management, etc.\n\n\nYou will act as lead and supervisor in data ingestion, preparation, and storage activities, such as:\n\n\ndefining Microsoft data architecture layers and data models for proof of concepts, pilots, projects\n\n\ndefining key data interfaces and transformation logics\n\n\ndefining and reviewing code for data cleansing, data checks and data transformations / preparations steps for data science (i.e. time series preparation, internal vs external data matching, base price smoothing, price imputation).\n\n\nLead cloud analytics solution and scoping to generate estimates and approaches for proposals and SOWs for Clients\n\n\nYou will work closely with:\n\n\nClient data leads to transfer / explain input data requirements and perform data assessment\n\n\nAccenture data engineering programmers to coach and grow junior resources on data curation and data transformation / harmonization activities\n\n\nAccenture and Client data scientists to gather advanced analytics data preparation requirements, back and forth on statistical data validation / QA, \u2026\n\n\nCreate detailed target state technical, security, data and operational architecture and design blueprints incorporating modern digital technologies and cloud services, demonstrating modernization value proposition\n\n\nCo-lead and/or support detail technical assessments of current state of analytics architectures and data platforms and architect a path to transformation into a modern data powered enterprise / landscape\n\n\nConduct full technical discovery, identifying pain points, business, and technical requirements, \u201cas is\u201d and \u201cto be\u201d scenarios\n\n\nCompare solution alternatives across both technical and business parameters which support the definition of cost and service requirements\n\n\nApply methodology, reusable assets, and previous work experience to deliver consistently high-quality work\n\n\nDeliver written or oral status reports regularly\n\n\nStay educated on new and emerging analytics technologies/patterns/methodologies and market offerings that may be of interest to our Clients\n\n\nAdapt to existing methods and procedures to create possible alternative solutions to moderately complex problems\n\n\nUse considerable judgment to define solutions and seeks guidance on complex problems\n\n\nSupport answers to RFPs issued by Clients\n\nRequired Qualifications\n\nTechnical\n\n\n\n\nAn academic degree on Computer Science / Information Technology or Industrial Engineering\n\n\nSignificant experience in technical solutions implementation, architecture design, and engineering programming / coding on MSFT platform\n\n\nSignificant experience (or similar) in the following technologies and tools:\n\n\nAzure Databricks (primary)\n\n\nPython (PySpark)\n\n\nScala\n\n\nSQL\n\n\nAzure SQL DWH / Synapse (primary)\n\n\nAzure Datafactory (ADF)\n\n\nPower BI\n\n\nDAX\n\n\nPower Query / M\n\n\nSpecial focus on Dynamics Customer Insights, Customer Data Platform (CDP), Customer Data Architecture (CDA), Microsoft Common Data Model (CDM / IDW), etc.\n\n\nKnowledge of the Microsoft technologies including Microsoft Azure, Microsoft 365 (Office 365), Dynamics-365, Power-Platform\n\nFunctional\n\n\nDeep and strong knowledge and expertise in the broad analytics area cross industry\n\n\nMultiyear experience in activities such as: data maturity assessment and analysis, data ingestion, data cleansing and harmonization, data preparation and advanced analytics transformation through data science, machine learning, data visualization, data architecture, data security, etc.\n\n\nSpecific industry knowledge required with preference on Consumer Goods & Services and/or Retail\n\n\nKnowledge in Revenue Management (Trade Promotion Optimization, Pack Price Architecture, Assortment Optimization, Customer Segmentation, ...) is good to have\n\n\nKnowledge in Sales & Marketing topics (Customer Business Planning, Account Planning, Trade Promotion Management) is good to have"
    },
    {
        "position": "Data Engineering Specialist",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "HP",
        "sector": "IT Services and IT Consulting",
        "companySize": "10,001+ employees",
        "location": "Sant Cugat del Vall\u00e8s, Catalonia, Spain",
        "post": "About the job \n We are looking for a Software Developer/Data Engineer to join our data engineering team. If you are passionate about data and technology, we are eager to talk to you. The ideal candidate has both a willingness and desire to work in a dynamic environment, is able to apply Agile methodologies in day to day activities, and is a self-motivated developer who also enjoys working in a team environment. Our people have a creative, innovative, fun, and collaborative attitude, and are dedicated to creating new and valuable solutions for HP.\n The Data Engineering Specialist applies developed subject matter knowledge to solve common and complex business issues within established guidelines and recommends appropriate alternatives. Works on problems of diverse complexity and scope. May act as a team or project leader providing direction to team activities and facilitates information validation and team decision making process. Exercises independent judgment within generally defined policies and practices to identify and select a solution. Ability to handle most unique situations. May seek advice in order to make decisions on complex business issues.\n\nResponsibilities\n\nYou will design, develop, test, modify, deploy, and document solutions and services in both local and cloud based deployments of our Big Data infrastructure. Create solutions using current programming languages and tools and interact with team members, customers, and partners to define requirements. Collaborate with stakeholders and data scientists to analyze, extract, and report meaningful insights from data collected.\n\nThe Data Engineering Specialist\n\n\nDesigns and establishes secure and performant data architectures, enhancements, updates, and programming changes for portions and subsystems of data pipelines, repositories or models for structured/unstructured data.\nAnalyzes design and determines coding, programming, and integration activities required based on general objectives and knowledge of overall architecture of product or solution.\nWrites and executes complete testing plans, protocols, and documentation for assigned portion of data system or component; identifies and debugs, and creates solutions for issues with code and integration into data system architecture.\nLeads a project team of other data engineers to develop reliable, cost effective and high-quality solutions for assigned data system, model, or component.\nCollaborates and communicates with project team regarding project progress and issue resolution.\nRepresents the data engineering team for all phases of larger and more-complex development projects.\nProvides guidance and mentoring to less experienced staff members.\n\nQualifications\n\n\nTypically 4+ years of experience in software or data engineering.\nSolid experience in data modeling, data integration and processing of structured and unstructured data.\nProficient in one or more programming languages (Python preferred).\nStrong SQL proficiency as well as experience with NoSQL.\nExperienced with Apache Spark (PySpark experience - advantage). \nExcellent communication skills; mastery in English and local language.\nAbility to effectively communicate product architectures, design and change proposals.\n\nAdditional Preferred Qualifications\n\n\nData transformation using AWS services\nDatabricks\nDataiku\nFamiliar with best practices of the data and software engineering lifecycle and/or best practices of the above platforms and tools.\n\nWhat We Offer\n\n\nOpportunity to work in an international organization with colleagues coming from all over the world.\nAn attractive benefits package\nDiverse, continued internal growth and career opportunities. Including HP\u2019s own learning platform and LinkedIn Learning.\nHP product discount\nWork life balance /flexible working hours\nWomen, Pride, Young employees, Multicultural and DisAbility! Just a few of our fantastic global business networks you can get involved with locally.\n\nAbout HP\n\nYou\u2019re out to reimagine and reinvent what\u2019s possible\u2014in your career as well as the world around you.\n So are we. We love taking on tough challenges, disrupting the status quo, and creating what\u2019s next. We\u2019re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference.\n HP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere.\n Our history: HP\u2019s commitment to diversity, equity and inclusion \u2013 it's just who we are.\n From the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you\u2019re more innovative and that helps grow our bottom line. Come to HP and thrive!"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Flying Tiger Copenhagen",
        "sector": "Retail",
        "companySize": "5,001-10,000 employees",
        "location": "Copenhagen, Capital Region, Denmark",
        "post": "About the job \n\nFlying Tiger Copenhagen is looking for a Data Engineer with ambitions and a strong desire to learn\n\n\nDo you have a desire to work with Data Platform development and engineering? Do you thrive in an environment where you can develop your skills and do you want to be part of developing and deploying leapfrog technologies in global company? Then you are exactly the person we are looking for at Flying Tiger Copenhagen.\n\n\nThe position:\nYou will become part of an international and highly competent team that is responsible for the further development of our Data Platform architecture. In your work, you will play a key role in ensuring that the current solution is further developed in accordance with applicable requirements and the interest of stakeholders in the business as well as ensuring that the required documentation is in place.\n\n\nThe task portfolio is broad - you will, among other things, help us implement BI, AA, ML and Insights solutions that are among the finest in Retail here in Denmark.\n\n\nAs Data Engineer, you will help bring our data platform solutions to a level where we can really benefit from all the data we have available. You are excellent in delivering effective and innovative solutions that will support our Advanced Analytics mindset. You are able to keep track of your tasks and ensure they are implemented while remaining focused on business needs.\n\n\nYour profile:\nYou are ambitious and take proactively responsibility for the development and implementation of the individual solutions. We expect you to be able to always challenge our current practice for the better. Additionally, we except that you are familiar with various cloud platforms such as Microsoft Azure, AWS and Google Cloud technologies that can be utilized in our Data Platform solutions and leapfrog technology to achieve innovative and state-of-the-art setup.\n\n\nIt is important that you have an eye for the details as well as having the ability to comply with deadlines. As a person, you are open and curious about all kinds of tasks and you want to help to contribute to a good climate in the team. You would also enjoy working together across the entire organization. You must be professional, analytically strong and be able to focus on multiple tasks without losing sight in a busy day with many working streams. \n\n\nWe expect you to have a good knowledge of the following:\n\nMS Azure product portfolio\nOn hands knowledge of Azure Data Lake and Azure Data Factory \nSQL skills and experience with stored procedures on MS SQL Server\nMicrosoft SQL Server\n\n\n\nIn addition, it would an advantage to be familiar with:\n\nAmazon Web Services\nGoogle Cloud technology\n\n\n\nYour success at work is measured in your ability to achieve high stability in relation to business-specific solutions developed through various platforms.\n\n\nAs Data Engineer you will report directly to the Head of BI, Insights & Digital Solutions.\n\n\nAbout us:\nAt Flying Tiger Copenhagen, we are undergoing a digital transformation where we are moving our services into new technologies and platforms. We offer a business-oriented and ambitious environment, where your professional and personal development are in outmost focus.\n\n\nYou will be part of a committed department with experienced and competent employees who work with the latest BI, AA, ML and insights principles on various platforms. We have a strong focus on supporting the business with data-driven solutions.\n\n\nFurthermore, you will be part of a highly engaged team where we work together and support each other. Along the way we make sure we also have fun and are very socially well-functioning team.\n\n\nApplication:\nWe are looking forward to hearing from you.\nSubmit your application and CV via the link below as soon as possible.\nWe are continuously calling in for conversations."
    },
    {
        "position": "Data Engineering Manager - BI (They/She/He)",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Glovo",
        "sector": "Consumer Services",
        "companySize": "1,001-5,000 employees",
        "location": "Barcelona, Catalonia, Spain",
        "post": "About the job \n\nAbout Glovo\n\nWe\u2019re a Barcelona-based startup and the fastest-growing delivery player in Europe, Hispanic America and Africa. With food at the core of the business, Glovo delivers any product within your city at any time of day.\n Our vision and ambition are not only to make everything immediately available in your city but it is also to offer our employees the job of their lives. A job where you'll be challenged and have the most fun working in through tech-enabled experiences.\n\nYour Work-life Opportunity\n\nWe are a product-centered company, and data is at the core of product development. In this role, you'll work with key business and product leads, analysts and data scientists to understand the business domain and how data can empower them. Your day-to-day will involve engaging with fellow engineers to develop a robust and scalable platform, to make the process of producing data and deriving insights efficient. You are passionate about the quality of the data you produce and take pride in having your data drive our business.\n\nBe a Part Of a Team Where You Will\n\n\nRecruit, lead and manage a team of Data Engineers- BI of different seniority levels\nCollaborate with business, product and engineering stakeholders to prioritise the most impactful work and ensure the teams' needs are accounted for\nManage the entire lifecycle of your team's projects\nDesign, implement and maintain pipelines that produce business-critical data reliably and efficiently using cloud technologies \nCollect, process, and clean data from different sources using SQL, Python, or other scripting languages \nImprove data discovery and literacy: create exploration and visualisation interfaces in our BI tools and promote the use of these sources across the company \nThink big and contribute to the strategy for better data quality within Glovo \nDesign and develop nimble dashboards to support the analytical needs of the business \nCollaborate with many Product, Engineering and Business teams to produce relevant data solutions that can be used across multiple use cases \n\nYou Have\n\n\nBetween 2 to 3 years of experience in a similar role, managing a team (5+ people) or multiple projects. Preferably in the digital/tech space \nExperience designing and building scalable and robust data pipelines to enable data-driven business decisions \nExperience in collecting requirements and creating data modeling designs \nKnowledge of modern data warehouses (Snowflake, Redshift, BigQuery) and big data structures \nExperience implementing enterprise dashboarding tools \nStrong proficiency and experience with SQL and Python \nExperience working with modern BI tools like Tableau, Looker, Qlikview \nGood understanding of software development and agile methodologies \nPassion for analyzing large complex datasets and converting them into information which drives business decisions \nExcellent spoken and written English. \n\nExperience Our Glovo Life Benefits\n\n\nEnticing Phantom Shares plan \nAttractive Relocation package (if applicable ;)) \nComprehensive Private Health Insurance \nCobee discounts on kindergarten, transportation, and food \nFree monthly Glovo credits to spend on our restaurant products (and zero Glovo delivery fee on all Glovo orders!) \nCool perks such as fresh fruit and healthy snacks every day, beers on Fridays, Culture Days every 2 months! \nDiscounted Gym memberships \nFlexible working environment \n\nWhat You\u2019ll Find When Working At Glovo\n\n\nGAS: Driven to deliver quality results quickly\nGood Vibes: Bring positivity and communicate openly\nStay Humble: Self-aware and open to learning\nCare: Uplift people and the planet\nGlownership: Act as proud owners\nHigh Bar: Focus on Top Performance\n\nIf you believe you match these values, we look forward to meeting you!\n At Glovo we believe that diversity adds incredible value to our teams, our products, and our culture. We know that the best ideas and solutions come by bringing together people from all over the world and by fostering a culture of inclusion where everyone feels heard and has the chance to make a real impact. It's because of this that we are committed to providing equal opportunities to talent from all backgrounds.\n Wanna take a peek into what it's like to work at Glovo? Follow us on Instagram and like us on Facebook!\n Glovo is transforming the way consumers access local goods, enabling anyone to get almost any product delivered in minutes. Our on-demand logistics connect customers with independent local couriers who acquire goods from any restaurant or store in a city, as well as deliver urgent packages for a variable fee. As of September 30, 2019, we\u2019re currently present in more than 26 countries across Europe, Latin America, Africa, and Asia.\n For additional information on Glovo, please visit https://glovoapp.com/ | Twitter: @Glovo_ES | Facebook: https://www.facebook.com/glovoappES/ | LinkedIn: https://www.linkedin.com/company/glovo-app/"
    },
    {
        "position": "Software Engineer, Data Engineering",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Bolt",
        "sector": "Internet Marketplace Platforms",
        "companySize": "1,001-5,000 employees",
        "location": "Berlin, Berlin, Germany",
        "post": "About the job \n\nBolt engineering teams are working on unique product challenges: complex algorithms for demand prediction, optimal real-time pricing, routing, fraud detection, distributed systems and much more. Volumes are growing at a steady pace. We are looking for an experienced engineer who is well-versed in data technologies.\n\n\nYour daily adventures will include:\n\nDesigning, building and optimizing elements of Bolt\u2019s Data Platform. Main areas include development of Storage and Analytical Systems (Data Lake, Data Warehouse), Data Pipelines (ETLs, ELTs, stream processing) and Machine Learning models infrastructure\nInvestigating and prototyping of new services to improve different aspects of our Data Platform: data quality, monitoring, alerting, performance and costs efficiency\nCoding mostly in Java, Python and TypeScript (previous experience is not required), occasionally in other languages. \nDesigning and optimizing SQL queries and data storage formats \nProactively solving technical challenges and fixing bugs\nContributing ideas to our product development roadmap\nWe are looking for language-agnostic generalists that are able to pick up new tools to solve the problems they face. Check out our blog to know more about all the exciting projects that we are working on: https://medium.com/bolt-labs.\n\nWe are looking for:\n\nExperience in at least one of the modern OO languages (Python, Scala, Java, JavaScript, C++, etc)\n4+ years of experience in software development\nExcellent English and communication skills\nExperience with micro-service and distributed systems\nSolid understanding of algorithms and data structures\nGood knowledge of SQL and experience in at least one of the popular online analytical processing (OLAP) technologies (AWS Redshift, ClickHouse, Presto, Snowflake, Google BigQuery, DataBricks etc)\nA university degree in a technical subject (Computer science, Mathematics or similar)\n\nYou will get extra credits for:\n\nExperience in building and designing real-time and asynchronous systems\nFamiliarity with streaming data technologies for low-latency data processing (Apache Spark/Flink, Apache Kafka, RabbitMQ, Hadoop ecosystem)\nUnderstanding of NoSQL databases (Redis, ElasticSearch, Apache Cassandra)\nExperience in building systems based on cloud service providers (AWS, Azure, Google Cloud)"
    },
    {
        "position": " Data Engineering Manager",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Travix International",
        "sector": "Technology, Information and Internet",
        "companySize": "501-1,000 employees",
        "location": "Amsterdam, North Holland, Netherlands",
        "post": "About the job \n\nAbout Travix\nTravix is one of the leading global online travel agencies, operating with four brands: CheapTickets, Vliegwinkel, BudgetAir and Flugladen. In 2020 we took our next step becoming part of the Trip.com Group family, one of the largest online travel companies in the world, consisting of Trip.com, Ctrip, Skyscanner, Make my Trip and Qunar. Travix currently operates in over 40 countries expanding in 5 continents, so a global mindset comes natural to us. Our purpose is \u2018the next journey at your fingertips\u2019 which goes for both our customers and employees. We bring together passionate people, global partners, and an innovative platform to deliver the best end-to-end booking experience for our customers.\n\n\nMake your career at Travix\nAt Travix, everyone is welcome. Our global team has over 40 different nationalities and we embrace everyone\u2019s authenticity. We have proven to grow people internally, we are proud of our passionate company culture and we love to dream big. Ever since our company was founded, our aim has been to create a work environment where people can thrive, be creative and ultimately build their own legacy within the company. More now than ever we are at a pivotal moment in our company\u2019s existence: where we are preparing for when the world is ready to travel again. With cutting-edge technology, strong partnerships, a strategic vision and the resources and stability of the Trip.com Group, we provide an international playground where our employees can truly impact the future of traveling.\nTo accelerate this momentum, we're looking to grow our team. If you share the same values as we do, you are just as passionate and ready to build your own legacy, then there is plenty of room here at Travix.\n\n\nJob Purpose\nAs a hands-on Engineering Manager, you will work as part of a team to build products and services on Travix's data platform which runs on Google Cloud Platform. In addition, you will provide direct functional leadership to a group of Data Engineers, where you are responsible for the effectiveness and quality of the delivery of high-value products. You will foster an environment that will encourage creative thinking and an environment of innovation. You will leverage your technical experience to develop and nurture the engineers to create high performing and motivated developers.\n\n\nKey Responsibilities\n\nProviding direct functional leadership to a group of Data Engineers within a scrum team\nGuiding a team of Data Engineers in terms of developing products and services\nWorking with other Engineering Managers to provide technical alignment across teams\nInnovating and creating an environment that fosters innovation \nMentoring, coaching and supporting the career development of the Data Engineers\nLeveraging your deep software engineering expertise to coach less experienced engineers and guide them to solve challenging problems\nNurturing and encouraging creativity, as Travix offers a huge amount of freedom from a technology and ownership stand-point. \n\n\n\nWhat you bring to the table\n\nA degree in computer science, or a related degree, or similar work experience\nAt least 6-8 years of relevant work experience\nPrevious management or team lead experience\nProven experience in business intelligence products like data lake, data warehousing and data engineering (ETL/ELT)\nExperience developing data products in Java or Python in the cloud\nProficient in T-SQL\nExcellent interpersonal and communication skills\nFluent English speaker\nAffinity with working in an Agile development environment and established e-Commerce businesses\nProven experience in working with high volume websites and e-Commerce b2c retail product development.\nExperience with Google Cloud Platform is a plus\nAll this is in the travel industry is definitely an advantage but not essential.\n\n\n\nWhat you can expect from us\n\nCompetitive salary and other amazing benefits, such as covered travel costs, discounted ongoing cancellation / travel insurances and a bike plan.\n30,5 days of paid leave, so plenty of time to enjoy your global travel adventures!\nMany internal development courses to keep on learning and growing.\nAn environment where you can keep a healthy work-life balance: even when we can go back to the office to collaborate as teams, you will still continue having a balance between working from home and from the office.\nFlat hierarchy where your voice can be heard, welcomed and appreciated at all levels in the organization.\nA diverse, inclusive and multicultural working environment\nTop floor office in Amsterdam (close to Central Station) with an amazing view!\nFree fruit, company bar (free beer!), team drinks and company events.\n\n\n\nReady to start your own Travix journey?\nThink you have what it takes? Then, we would love to hear from you."
    },
    {
        "position": "IIoT Solution Architect - Smart Factories",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Quotacom",
        "sector": "Staffing and Recruiting",
        "companySize": "11-50 employees",
        "location": "Gothenburg, Vastra Gotaland County, Sweden",
        "post": "About the job \n\nQuotacom is proudly partnered with one of Sweden's largest and most respected manufacturers after they have recently embarked on a massive, global digital factories transformation program.\n\n\nWe are actively hiring for a number of key, pivotal roles across this exciting program and welcome inquiries outside the scope of this post.\n\n\nInitially we are seeking an experienced IIoT Solution Architect to spearhead core architectural development of solutions that will serve the entire ecosystem of factories and manufacturing sites. You will play a pivotal role in transforming and equipping the business with digital solutions, skills, and knowledge to strengthen the business\u2019s competitive advantage.\n\n\nIf you are an experienced developer or architect who thrives on the development of cutting-edge technologies at scale within a smart factory context, we\u2019d love to hear from you as soon as possible.\n\n\nKey skills and experience:\n\n\n\nStrong hands-on experience in software team management with a focus on DevOps\nHands-on programming capabilities (C#, Java, JavaScript, TypeScript, Python, R) with a strong understanding of containerization and delivery automation (CI/CD)\nGood fundamental knowledge of Cloud-Native Architectures such as REST and APIs, Microservices, Docker, K8S, SQL, NoSQL, etc.\nSound foundational knowledge of Cloud and Hybrid-Cloud services in Microsoft Azure\nExperience or exposure to Industrial IoT technologies, such as OPC-UA, MQTT/AMQP, Event-Driven Architectures, or Time Series Databases\nExcellent communication and interpersonal skills with English fluency\nUniversity degree in Computer Science or STEM equivalent\n\n\n\nFor more information, with discretion guaranteed, please contact Ben Watson: bw@quotacom.com or Ashur Roberts: ar@quotacom.com\n\n\nAt Quotacom, we take the security and privacy of your personal data seriously; any data we hold will be in accordance with data protection legislation. Full details of our privacy notice can be found at www.quotacom.com/privacy-notice"
    },
    {
        "position": "Software Design Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "NTS-Group",
        "sector": "Industrial Machinery\n                                                            Manufacturing",
        "companySize": "1,001-5,000 employees",
        "location": "Eindhoven, North Brabant, Netherlands",
        "post": "About the job \n\nWhy are we looking for you\n\n\nThe world around us is in a constant race for improvement. Stronger, faster and better are key words. This can only be achieved if technology and technology companies keep on developing and improving the business and the market. NTS-Group is one such company, and our Development & Engineering (D&E) department provides a very important service to our customers. We need you to be part of our technological development; accelerating the future!\n\n\n\n\nWhat are you going to do\n\n\nAs Software Design Engineer, you will work with (lead) engineers, architects and colleagues from related disciplines and focus on (embedded) software in precision development. The teams you work with consist of people from different competences, such as mechanical, electrical and mechatronic engineers. You will be responsible for translating requirements to a final product. Part of the scope will be testing the results to meet the specifications for reliability and (end-user) usability. Your colleagues involve you in determining technical feasibility and risk analysis.\n\n\nThe Software Design Engineer is part of an Agile software development team whose work is unique in the sense that manufacturing almost invariably plays an integral role in the projects. That is why the in-house NTS manufacturing companies represent key stakeholders who are continuously kept up-to-date through participation in the team\u2019s Scrum ceremonies, where you will present the status and progress of your work. Together with the team, you make sure to stay ahead of the change curve regarding market developments, team growth, and personal development in your area of expertise, and be prepared for the challenges of tomorrow.\n\n\n\n\nWhich skills do you have \n\n\n(We are looking for the requirements below about multiple colleagues, so it's no problem if you don't meet all the requirements)\n\n\nYou bring a combination of technical background and development mentality to the table. Your main scope and responsibilities would cover a mix of the following competencies and experiences:\n\n\n\nBachelor degree in Software Engineering;\nMinimum of 5 years\u2019 experience in development of technical software;\nAdvanced experience on C#;\nSkills on PLC coding (PLC brand/range selection and programming);\nSupport Software Architect related skills (architecture activities): creating UML designs;\ndetailed estimations, discussions with stakeholders;\nKnowledgeble in reading UML;\nExperience with UI (GUI/UX) graphical userinterfaces and interaction, for creating intuitive tool interfaces;\nCloud experience (Azure, AWS, Google Cloud); partly for directing external specialists;\nExperience with databases (in the cloud and on premises); partly for the selection and/or directing of external parties;\nKnowledge of Machine Vision (Vision Library) would be a plus; \nHelp assess the team\u2019s development needs and growth path, i.e.: competencies, tools, skill level, etc.\n\n\nFurthermore, as a person, you would be best described as follows:\n\n\n\nEager to learn and develop in the high-tech market;\nA strong teamplayer: constant communication is key;\nWell-developed communication and social skills. You know how to convey complex topics in understandable wording;\nProficient English language skills.\n\n\n\nWhat do we offer\n\n\nIn our dynamic group of 1.700 people with headquarters in Eindhoven (NL) and other locations in the Netherlands, Czech Republic, Singapore, China and the USA, our employees work hard to support our customers in Semiconductors, Analytical and Life sciences.\nNTS offers the opportunity to work for a successful and dynamic business with a leading market position and an engaging project portfolio. Our organization has a characteristically informal and friendly atmosphere, and our staff looks out for each other. Drive, entrepreneurial spirit, a results-focused mindset and striving to be the best are what we aim for in everything that we make and do. Naturally, these are the traits that we are looking for in our new colleague.\n\n\nWhat can you expect?\n\n\nWe will take care to ensure that you quickly feel at home on our team. We will pair you up with one of our experienced colleagues who will show you the ropes and introduce you to your other co-workers. You will be given time to discuss what is expected of you in your new role with your supervisor. It\u2019s a given that you do your job well, but we think it\u2019s equally important to understand why you are doing it, and for whom. We are happy to answer any questions you may have in that regard. This approach will help you to quickly get the hang of how we operate and put you in a position to make a real difference and add value for our team and our clients.\n\n\nAre you ready to make a difference? Get in touch with us and apply for the position of Software Design Engineer. \n\n\nFor more information please contact Sabine van Rooij, Corporate Recruiter via +31 (0)6 21 33 29 11 or sabine.van.rooij@nts-group.nl"
    },
    {
        "position": "Operations Optimization Data Scientist",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Tesla",
        "sector": "Motor Vehicle Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Amsterdam, North Holland, Netherlands",
        "post": "About the job \n\nWhat To Expect\n\nThe Operations Optimization Data Scientist is responsible for driving the automation of the planning processes of the Business Planning and Fleet team across the different S&OP stages. As part of this team, you will support the integration of team\u2019s planning process with Giga Berlin S&OP and provide thought leadership on how we can improve our processes and drive efficiency in our operations. You will also have the opportunity to utilize your skills in quantitative analysis and optimization on elaborate studies on sales and beyond, providing powerful insights to the EMEA leadership team on key decisions for our strategy.\n You will have the opportunity to develop and continuously improve the way we project demand and resource requirements across the various vehicle markets. You will be instrumental in building the Business Planning function into a competency center and partner with various teams across the business to develop Tesla\u2019s forecasting and planning capabilities and processes.\n This role requires frequent interaction with all our EMEA HQ and Global Demand Planning teams, and you will work closely with the EMEA business analytics to identify improvement opportunities for our processes.\n\nWhat You\u2019ll Do\n\n\nUse Python/SQL (preferred) to develop a holistic planning process that automates our current analysis and modeling around sales forecast, supply-demand analyses, delivery forecast, logistics, and fleet allocations \nOwn aspects of the planning process and manage communication with various cross-functional teams in order to ensure zero-error data quality and integrity\nIdentify and execute on areas for improvement across the planning process between various teams (sales, delivery, finance, demand planning, logistics, etc.)\nLead partner teams on process improvements, plan execution, and other planning-related initiatives\nDevelop expert teamwork skills and build excellent cross-functional stakeholder relationships to ensure engagement, execution speed, and highest quality of outcomes\nProvide thought leadership on how we can improve our planning processes and drive efficiency in sales operations\nAdeptly handle multiple priorities in an ambiguous and constantly changing environment and be willing to pivot as the business requiresWhat You\u2019ll Bring\n\n\n1-4 years of related experience in a planning, analytics or operations role\nMSc\u2019s degree in Engineering, Computer and/or Data Science, Operations Research, Industrial Engineering, Business/Supply Chain Management or equivalent experience and evidence of exceptional ability\nExperience in building Data Science and Optimization models and algorithms in Python and/or other programming languages (e.g. Matlab), using SQL from scratch\nStrong experience in data processing methods (e.g. building ETLs)\nStrong knowledge of Excel data processing and automation and solid experience in BI visualization and dashboarding (e.g. Tableau)\nGood understanding of S&OP (Sales & Operations Planning) elements and process\nHigh level of data quality and integrity\nProven track record in delivering change, process improvement, and root cause analytics\nDesired Attributes and Skills\nCross-functional teamwork experience\nRelentless hands-on problem-solver, unafraid of challenging the status quo\nExperienced in driving cross-functional initiatives and process improvements\nHighly collaborative and team-oriented, while also able to work independently\nThrives in a fast-paced environment of constant change\nAdept at prioritization, expert at and enjoys juggling multiple tasks and projects\nLoves working with data and understanding the \u201cwhy\u201d and the \u201cnow what\u201d behind the data\nStrong written and verbal communication skills\nSelf-aware and open-minded\nAbility to travel domestically and internationally"
    },
    {
        "position": "Senior Data & Business Intelligence Analyst",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "UPS",
        "sector": "Transportation, Logistics, Supply\n                                                            Chain and Storage",
        "companySize": "10,001+ employees",
        "location": "Eindhoven, North Brabant, Netherlands",
        "post": "About the job \n Explore your next opportunity at a Fortune Global 500 organization. Envision innovative possibilities, experience our rewarding culture, and work with talented teams that help you become better every day. We know what it takes to lead UPS into tomorrow\u2014people with a unique combination of skill + passion. If you have the qualities and drive to lead yourself or teams, there are roles ready to cultivate your skills and take you to the next level.\n\nJob Description:\n\nSummary\n\nJob Summary \u2013 Senior Data & Business Intelligence Analyst\n The Senior Data & Business Intelligence Analyst plans, organizes, coordinates, and tracks activities to develop, deploy, and upgrade software and hardware.\n He/She troubleshoots project issues to maintain schedules utilizing established processes and procedures and makes recommendations for preventing recurrences. This position coordinates deployments and implementations and facilitates activities to ensure programs and projects are implemented successfully and meet established deadlines.\n The role also has relation to Business Intelligence, you will be exposed to data warehouse, data-lakes and manipulating large datasets, data models and facilitating insightful solutions with advanced and predictive analytics.\n\nJob Duties\n\nManages I.S. Projects\n\n\n\nManages project life cycles (i.e., project scope, resources, schedule, budget, initiation, start-up, design, building, and deployment) to see projects from beginning to end\nForwards project documents to stakeholders to obtain sign-off, agreement on project costs, and needed resources\nCreates, prepares, and maintains project plans to estimate resources, plan schedules, define goals, establish metrics, assess risks, and develop cost plans and to provide stakeholder reports.\nProvides status communications for senior management on issues, concerns, and risks to recommend solutions and to ensure products meet customers' needs.\nBalances multiple projects and deployment schedules to meet stakeholder goals and expectations.\nDetermines decisions regarding tools, methods, and approaches to meet project goals.\nEnsure that the design and operation of the BI solutions to meet decision support requirements of the business\nLiaise with end user to develop and continuously improve BI solutions\nLiaise with external IT support providers to ensure effective delivery of relevant services for BI solutions\n\n\nManages System Analysis and Design\n\n\n\nCollaborates with domain and enterprise architects to participate in and drive designs internally and externally to comply with defined architecture governance processes.\nPrepares, reviews, and delivers designs according to standards, methods, and tools to ensure consistency and compliance with enterprise and solution architectures.\nAligns systems designs to balance functional and non-functional requirements.\nParticipates in business requirements and then drives functional requirements to ensure cost-effective technical solutions meet stated business needs.\nDefines technical visualization of proposed applications to obtain customers\u2019 approvals and implementation authorizations.\n\n\nManages Design and Development of Applications\n\n\n\nEvaluates programming tools and techniques usage to ensure team adherence to standards.\nGuides analysis, design, coding, and testing to meet project goals.\n\n\nManages Applications' Maintenance and Support\n\n\n\nLeads problem resolution to identify, recommend, and implement process improvements.\nLeads process improvements (i.e., application enhancements, procedure changes, and staff cross-training) to reduce costs for supporting and maintaining applications.\n\n\nEvaluates and Monitors Emerging Technologies and Products\n\n\n\nMonitors the industry to gain knowledge and understanding of currently emerging technologies.\nIdentifies new and emerging hardware and software technologies and products to maintain industry competitiveness.\nDetermines relevance and potential value of new technologies to present industry information to staff and management.\n\n\nManages And Develops Others\n\n\n\nManages resources and people processes (e.g., Quality Performance Review [QPR], Career Development, Training, Staffing, etc.) to ensure the day to day administration of processes and formal procedures.\nIdentifies individual and team skill gaps and developmental opportunities (e.g., training, special assignments, conferences, projects, etc.) to facilitate individual and team development. \nEnsures that direct and indirect reports have documented career goals and detailed plans for achieving these goals to develop them personally and professionally.\n\n\nEducation and Certifications\n\n\n\nProject Management Certification\nExperience with Agile Development, Data Analysis, Internet Development Architecture & Design and SQL Programming\nReporting and Dashboarding experience such as Google Data Studio or PowerBI\nFamiliarity with Technical Analysis\nMust be detail-oriented\nExcellent written and verbal communication skills\nBachelor's degree and/or Master's degree in Computer Science or related discipline or equivalent in education and work experience.\n\n\nNice to Have\n\n\n\nExposure and Experience on other BI tools outside Microsoft suit: IBM TM1, Oracle EBS, OBIEE, ODI, Enterprise Data Warehouse (Teradata, SAP BW, SAP BO) IBM Cognos, Tableau, Qlikview, Looker \nIndustry experience in Logistics and/or Manufacturing and/or Financial domains\nHands-on experience of using Predictive Analytics with Microsoft Power BI Service\nExperience with Dimensional Data modelling, Star Schema and Snowflakes\n\n\nWhat You'll Get\n\n\n\nA competitive salary based on experience\nA bonus depending on functioning\nExcellent benefits including 29 leave days based on a full-time position, 8% holiday allowance, travel allowance, company pension scheme, collective health insurance, phone/laptop/car (if needed), bicycle scheme and discounts at gym subscription. \nYou can enjoy our novel hybrid working model, choosing for up to 60% work from home.\nYou can enjoy various other secondary benefits such as bike allowance, gym discounts, insurance policy discounts.\n\n\nHow We Recruit\n\nUPS is committed to a policy of treating individuals fairly and recruiting, selecting, training, promoting and compensating based on merit, experience and other work-related criteria. We do not discriminate against any applicant based on age, race, religion, sex, disability, sexual orientation or gender identity.\n\nA Bit About a Big Business\n\nFounded in 1907 as a messenger company in the United States, UPS has grown into a multi-billion-dollar corporation by clearly focusing on the goal of enabling commerce around the globe. Today, UPS is a global company with one of the most recognised and admired brands in the world. We have become the world's largest package delivery company and a leading global provider of specialised transportation and logistics services. Every day, we manage the flow of goods, funds and information in more than 200 countries and territories worldwide.\n\nEmployee Type:\n\nPermanent\n UPS is committed to providing a workplace free of discrimination, harassment, and retaliation."
    },
    {
        "position": "Contract Manager - Data Centre Solutions - Netherlands",
        "jobType": "Contract",
        "jobLevel": "Associate",
        "company": "CBRE",
        "sector": "Real Estate",
        "companySize": "10,001+ employees",
        "location": "Amsterdam, North Holland, Netherlands",
        "post": "About the job \n Amsterdam '- Noord-Holland - Netherlands, Amsterdam-Zuidoost '- Noord-Holland - Netherlands\n\nJob Title: Contract Manager - Data Centre Solutions\n\nReporting to: Area General Manager\n\nLocation: Netherlands\n\nJob Purpose\n\n\nTo manage, motivate and develop the on-site Data Centre Critical Environment Operations team in a business critical 24/7/365 operating environment, providing the 2 service lines to the client of CE and FM.\nTo successful deliver contracted services to the client on the agreed site(s), ensuring performance of the site from a quality, health and safety and financial perspective.\nTo manage and develop a professional relationship with the client locally to create a positive customer experience. To deliver a performance level which achieves and goes beyond the KPI\u2019s and SLA\u2019s set down in the contract with the client.\n\nKey Responsibilities\n\n\nProvide leadership, and that contractual commitments are met and exceeded.\nEnsure that opportunities for the strategic development of the contract are explored, to deliver increased turnover and profitability, ensure additional services and projects are added, and contracts are re-won on re-tender. \nEnsure the provision of healthy and safe working conditions and that both clients and Company health and safety policy and process is effectively implemented across both our teams services and subcontractors activities, and are regularly review.\nEnsure contracts are staffed by fully competent teams, ensuring post holders are fully competent, and that effective succession planning arrangements are in place.\nEnsure appropriate control systems to ensure statutory, policy and contractual commitments are met.\nEnsuring a customer focus within all areas of operational activities, and that effective relationships are maintained with key client contacts.\nProvision of leadership and guidance, advice, coaching and direct support, where required to deliver best practice selection, training, assessment and recognition/reward. \nDelivering effective business communication through advice, review, leadership and direct contribution to management and team meetings, briefings, consultation forums, correspondence, publicity, monthly and ad-hoc reporting and other publications, as appropriate. \n\nExperience, Knowledge, Skills And Abilities\n\n\nProven track record in a senior or executive management role which has included responsibility for product, culture, people and business growth\nProven track record of operating in a senior role\nPrevious experience in Critical Environments and/or Data Centres \nDealing with a range of people from junior to senior level including site employees, suppliers and customers\nWorked within a matrix organisation\nCommercial awareness\nBusiness acumen\nStrong influencing skills\nAbility to understand commercial and financial metrics\nInternal and external client management\nNetworking skills\nIndustry knowledge in critical environment and/or data centre environments and one or more of the following: M&E, facilities management, projects, building services\nExcellent presentation skills - written, verbal and presentation \nHighly developed interpersonal and communication skills\nEnthused by a fast paced, high growth environment \nDemonstrates executive presence \nInfluencing skills \nConscious and methodical in approach\nAn excellent relationship builder\nAbility to inspire confidence\nHigh degree of integrity and sincerity \nHighly motivated and self-aware\nHighly organised with attention to detail\nAbility to network\nAbility to understand complex situations\nResults focused\nDrive to grow the business\n\nCompany Profile\n\nCBRE is the global leader in real estate services and leverages the industry's most powerful knowledge base to meet the commercial real estate needs of its clients worldwide. Our vision is to be the preeminent, vertically integrated, globally capable real estate service firm. Globally we employ over 70,000 employees and operate in 48 countries.\n Global Workplace Solutions (GWS) is a division of CBRE uniquely positioned to provide a complete set of services to corporate occupiers of commercial real estate across EMEA. GWS is redefining \u2018workplace\u2019 because we believe every place of work can become a competitive advantage for our clients. Productivity, reliability, engagement, quality, brand \u2014 the workplace contributes to business results, whether it\u2019s an office, a retail outlet, a laboratory, a data centre, a manufacturing environment or a virtual location.\n\nService line: None"
    },
    {
        "position": "Business Intelligence Analyst",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "UPS",
        "sector": "Transportation, Logistics, Supply\n                                                            Chain and Storage",
        "companySize": "10,001+ employees",
        "location": "Eindhoven, North Brabant, Netherlands",
        "post": "About the job \n Explore your next opportunity at a Fortune Global 500 organization. Envision innovative possibilities, experience our rewarding culture, and work with talented teams that help you become better every day. We know what it takes to lead UPS into tomorrow\u2014people with a unique combination of skill + passion. If you have the qualities and drive to lead yourself or teams, there are roles ready to cultivate your skills and take you to the next level.\n\nJob Description:\n\nThe role of \u201cBusiness Intelligence Analyst\u201d is to help in decision-making and solve business problems by converting data into information, selecting relevant data from data warehouse or data-lake, manipulating large datasets, building data models and facilitating insightful solutions with advanced and predictive analytics.\n\nWhat do you do on an average day?\n\n\n\nEnsure that the design and operation of the BI solutions to meet decision support requirements of the business\nLiaise with end user to develop and continuously improve BI solutions\nLiaise with external IT support providers to ensure effective delivery of relevant services for BI solutions\nBuild programs and algorithms with Artificial Intelligence and Machine Learning using R language, Python and Power BI Service \nDevelop the appropriate solution, Reports or Cubes using the Microsoft Power BI Suite\nSupport and maintain existing dashboards and BI systems\nImplement changes to existing Power BI dashboards and reports \nReview SQL Code and SSIS packages to ensure compliance with the defined standards and best practices (with assistance from back-end developer and DBAs)\nEnsure optimal performance of BI Solution when released to the production environment\nMaintain full documentation for BI solutions and related services together with associated communications documents\n\n\nWhat do we expect of you?\n\n\n\nBachelor's degree in Computer Science or Information Systems or Business Management \nProject Management Certification \nRelevant Technical Certification on Business Intelligence Tools \n10 years of strong hands-on project experience of Business Intelligence projects\n10 or more years of experience with multi-cultural teams and delivering projects under pressure\nHands-on experience of using Predictive Analytics with Microsoft Power BI Service\nExperience with Dimensional Data modelling, Star Schema and Snowflakes\nPrimary skills \u2013 R or Python language, Microsoft Power BI Suit, SQL, ETL Tools - Microsoft SQL Server Integration Services (SSIS),\nSecondary skills \u2013DevSecOps methodology with Business Intelligence, Azure DevOps; Machine Learning algorithms for Regression, Classification or Clustering\nNice to have:Exposure and Experience on other BI tools outside Microsoft suit: IBM TM1, Oracle EBS, OBIEE, ODI, Enterprise Data Warehouse (Teradata, SAP BW, SAP BO) IBM Cognos, Tableau, Qlikview, Looker Industry experience in Logistics and/or Manufacturing and/or Financial domains\n\n\nEmployee Type:\n\nPermanent\n UPS is committed to providing a workplace free of discrimination, harassment, and retaliation."
    },
    {
        "position": "Data Analytics Lead",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Mars",
        "sector": "Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Veghel, North Brabant, Netherlands",
        "post": "About the job \n Mars Wrigley (MW) Europe is looking for an Operations Data Analytics Lead who will own, lead and implements the strategic vision and roadmap for Data, AI and Digital Twin technologies with MW Supply Operations. He/she will be responsible for building the data driven culture development within MW Supply.\n This role requires good communication skills and the ability to communicate complex analytical results, both written and verbally, in a clear and easy-to-understand way. The candidate will be an advocate and thought leader of data, educating associates and keeping a pulse on new best practices and technology. The ideal candidate will think big, work effectively cross-functionally, and enjoy the challenge of forming and testing hypotheses in a fast-paced, ambiguous space. A successful candidate will have exceptional written and verbal communication skills and will be comfortable meeting with senior stakeholders regularly.\n\nWhat are we looking for?\n\n\n4+ years proven work experience as a Product Owner or Product Manager or Head of Analytics\nStrong understanding of data management processes (governance, quality, metadata, privacy)\nStronger technical background, ideally in Data Science\nExperience leveraging artificial intelligence and machine learning for root-cause analysis\nExperience with Digital Twin technology\nExperience with Manufacturing Operations Data concepts and domain\nExperience with computing and software infrastructure development life cycles\nStrong knowledge of SQL, Python and ML methods\nExperience using cloud computing services: Azure Data Lake, Databricks, Data Catalog, etc.\nExperience visualizing/presenting data for stakeholders\nUnderstanding of data architecture and modeling\nUnderstanding of UX design principles and experience working with end-users and stakeholders as part of a design process\nStrong problem-solving skills with an emphasis on usability\nStrong verbal and written communication skills\nAbility to adapt to ambiguity and be excited by data exploration \nSelf-starter who welcomes responsibility, along with the ability to thrive in an evolving organization and an ability to bring structure to unstructured situations\nFluent English (spoken and written)\nDutch, French and/or German (spoken and written) are a plus\n\nWhat will be your key responsibilities?\n\n\nLead and own the operations data and AI strategic vision and roadmap of MW Europe;\nManage and validate P&L, risks management\nDefine criteria and mechanics of hypothesis validation process (PoC, MVP, Roll out)\nBuild, edit, and maintain the team backlog, consisting mostly of user stories;\nTranslate strategy into detailed requirements and prototypes; \nWork closely with engineering and operations at the various MW Europe sites;\nAnalyze large data sets using a variety of database query and visualization tools\nProvide technical expertise in extracting, integrating, and analyzing critical data\nTackle short/long term quantitative/qualitative problems and questions with technical analysis\nArchitect data flows for new and products and services\nPerform ongoing monitoring, automation and refinement of algorithms and technical logic\nPerform analysis to identify and understand issues or events \nLead data integration products by creating requirement documentation, data mapping, version control and release planning\nAct as an internal consultant, advocate, mentor, and change agent for the Supply organization\nProvide team members and partners with thought leadership and coaching on data standards and practices"
    },
    {
        "position": "Test Scientist, Artificial Intelligence",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "BSI",
        "sector": "International Trade and\n                                                            Development",
        "companySize": "1,001-5,000 employees",
        "location": "Netherlands",
        "post": "About the job \n Great that you're thinking about a career with BSI!\n\nJob Title: Test Scientist AI\n\nReports to: AI Operations Team Leader\n\nLocation: Home Based\n\nOverview / Purpose Of The Position\n\nTest Scientist AI (TS-AI) is part of the Artificial Intelligence Notified Body, AI Conformity Assessment model testing team. The position is for an experienced Engineer/Scientist in Artificial Intelligence Systems. The role is twofold:\n\nto participate in the conformity assessment process of AI models, in terms of testing and reporting regulatory compliance of AI models as part of the AI/ML conformity assessment process of AI NB.\nto support planning and developing of BSI AI/ML projects.\n\n\nAdditionally, the TS-ML will have to participate in shaping and updating tools and procedures relevant to the conformity assessment process. He/She will be supporting training needs on AI/ML for the AI NB team.\n\nResponsibilities & Accountabilities\n\n\nSupport Global Quality and Accreditation in maintenance of accreditation.\nSupport Internal Training to develop and deliver training to ensure that the Regulatory Requirements and BSI\u2019s QMS fully understood.\nCooperating with Project Management team for appropriate allocation of technical assessments according to impartiality and competence.\nSupport technical assessment process by providing guidance and solutions.\nTest with the use of appropriate tools AI models from multiple industries (e.g. Medical Devices, Robotics, Biometrics) and report for compliance with EU regulations for stand-alone or embedded SW using AI/ML.\nProvide advice and support on certifications in area of expertise that may have a regulatory challenge.\nParticipate in client meetings to facilitate CE marking processes.\nProvide AI/ML expertise leadership and mentoring in areas of competence to AI NB personnel.\nSupport AI/ML technical personnel in conformity assessment of AI/ML SW.\nCommunicate and coordinate actions effectively during assessment process.\nProactively identify areas of AI/ML application to BSI business and processes.\nParticipate in internal BSI projects for developing & testing AI/ML tools for augmenting BSI\u2019s assessment process. \nParticipate in the procurement of AI testing tools.\nRecording of time on the BSI Time system.\nProvide feedback to Operation manager on issues such as procedures, workflows, client complaints.\n\n\nKey Success / Performance Indicators\n\n\nAchievement \u2013 delivering results and creating value.\nTimely completion of assigned tasks / total assigned tasks.\nNumber of test reviews peer reviewed with no observations/ Total completed test reviews.\nNumber of business AI projects lead and participation/ Total number of AI business projects.\nTraining completion/Assigned training.\nPlanning and organising.\nSupporting internal procedures, training, and tools procurement. \nBuilding and retaining relationships.\nTeam working. \n\n\nLanguage Requirements\n\n\nBusiness English\nDutch Language (Optional)\n\n\nPerson Specification\n\nEssential Criteria (required to do the job)\n\nKnowledge and Experience (e.g. Type, level)\n\n\nAn understanding of BSI, its role and the approach of Regulatory Services to Conformity Assessment Activities and Certification for CE / UK marking.\nAt least three (3) years' post-graduate experience in AI/ML model development, either in a regulated industry or as part of funded research projects.\nAwareness of quality systems, philosophies and principles and internal auditing principles and practices.\nAwareness of AI regulations and released standards/guidance. \nExperience in at least two of the following areas:\nInference (Fuzzy Logic)\nExpert systems (Symbolic Reasoning, Knowledge Representation) \nConvolutional Neural Networks (CNNs)\nArtificial Neural Networks & Deep Learning,\nClustering/Classifier methods (K-Means, K-Medoids, Self-Organizing Map, Gaussian Mixture, Fuzzy c-Means, Logistic Regression, kNN, SVM, Na\u00efve Bayes),\nRegression algorithms (Linear, Nonlinear, Gaussian Process, SVM Regression, Generalized Linear Model, Regression Tree),\nSupervised/Unsupervised learning\n\n\nSkills And Abilities (e.g. Teamwork, IT, Communication, Relationships)\n\n\nConceptual and analytical thinking, efficiency and results orientation.\nA team player good at relationship building internally and externally with authorities and clients and other stakeholders. \nAbility to handle personalized data based on GDPR framework.\n\n\nEducation / Qualifications (e.g. Technical)\n\n\nBSc/MSc degree or higher in a discipline relevant to AI/ML such as SW algorithm development, Robotics, Medical Devices SW, Biometrics or equivalent qualification.\n\n\nDesirable Criteria \n\nKnowledge and Experience (e.g. Type, level)\n\n\nComprehensive knowledge of AI Regulations and related Guidance documents.\nAt least three (3) years' post-graduate experience in one of the following areas: product development in relevant industries (e.g., robotics, MD, IVD), SW development, AI models development-testing.\nExperience in relevant fields, i.e., Quality Management System processes and R&D \u2013 Product Development and Manufacturing processes, Risk management Process and Regulatory aspects of Device Certification/Registration.\nHands on knowledge of AI/ML tools (e.g. Python, Matlab, Java-ML, SHARK, FuzzyEngine, FUNZY, pyfuzzy, TensorFlow, Amazon SageMaker, Google Cloud AI, Azure ML, PyTorch, Keras, Cafee, Torch)\nAwareness of SW lifecycle and risk analysis.\n\n\nSkills And Abilities (e.g. Teamwork, IT, Communication, Relationships)\n\n\nBackground of remote and multinational working environment is considered a strong benefit.\n\n\nEducation / Qualifications (e.g. Technical)\n\n\nCertification on AI/ML development tools or AI testing tools.\n\n\nOur Excellence Behaviours: Client-centric, Agile, Collaborative. These three behaviours represent how we do things at BSI. They help us ensure that BSI is a great place to work and a highly successful business.\n BSI is conducting face-to-face interviews where appropriate and possible. If you are invited to a face-to-face interview but feel more comfortable with conducting the interview virtually, please speak to a member of our recruitment team."
    },
    {
        "position": "Lead Computer Vision Engineer",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Amgen",
        "sector": "Biotechnology Research",
        "companySize": "10,001+ employees",
        "location": "Breda, North Brabant, Netherlands",
        "post": "About the job \n If you feel like you\u2019re part of something bigger, it\u2019s because you are. At Amgen our shared mission\u2014to serve patients\u2014drives all that we do. It is key to becoming one of the world\u2019s leading biotechnology companies. We are global collaborators who achieve together\u2014researching, manufacturing and delivering ever-better products that reach over 10 million patients worldwide. It\u2019s time for a career you can be proud of. Join us as:\n\nLead Computer Vision Engineer\n\nAt Amgen Breda medicines are labelled, assembled, packed, stored and eventually shipped to various countries worldwide. Every day more than 1000 people with 38 different nationalities are working on supply chain processes, manufacturing, marketing and sales of our medicines and clinical research into new medicines.\n\nDigital strategy\n\nWhat We Want To Achieve\n\nAmgen is moving into a new era in which process innovation and transformation will be key to our continued success to serve patients. Digital Advancement is one of key focus areas in our overall worldwide strategy! As a value driven company, we are building a Digital Advancement Team to drive our transformation in years to come. This team is tasked to conceptualize, design and implement business process solutions with a strong Digital Innovation focus. This is a great opportunity to join our journey early on and make an impact!\n\nLive\n\nWhat You Will Do\n\nAs the Lead Computer Vision Engineer you will be part of Agile Product Development teams and report to the Director Business Performance & Digital Advancement. In this role you will support the Operations organization with innovative solutions to improve process efficiency and quality. This is done through design test and building Machine Learning models that simulates human-like vision. By developing and automating computer vision models, that make work and life easier within our manufacturing facility, you will enable us to use real-life data in our decision-making process!\n Let\u2019s do this. Let\u2019s change the world. In this vital role you will also:\n\n\nWork in collaboration with the Agile Product Teams or Engineering Project Teams to find opportunities to improve vision systems, increasing detectability rates of defects and reducing false reject rates.\nStaying abreast of industry trends, especially in the realms of inspection systems and artificial intelligence exploring novel tools and techniques to improve inspections.\nDevelop process solutions to a variety of technical problems of extensive scope and complexity enabling new equipment and technology.\nDesign, develop and implement vision systems used for parts identification, cosmetic defect detection, label presence and variable data character recognition.\nCollaborate with other functions to develop mathematical models that could be applied in the automatic visual inspection and offline bench scale models.\n\n\nWin\n\nWhat We Expect Of You\n\nWe are all different, yet we all use our unique contributions to serve patients. The computer vision and machine learning professional we seek is a strong collaborator with these qualifications:\n\n\nBachelor\u2019s or Master\u2019s degree, in Computer Science, Engineering, or related technological field of equivalent combination of education and experience.\nTypically, 5+ years of relevant work experience in Engineering, Operations / Manufacturing environment.\nPractical experience with the implementation of computer vision and Machine Learning applications.\nFamiliarity with Agile Scrum framework and developed project management techniques.\nStrong communication skills and proficiency in English, both in oral and written communication.\nKnowledge of (personal) computer software, specifically: MS-Office, MS-Teams\nExperience with Programming languages (e.g., Python, C++, Microsoft Visual Basic, .Net, Visual C#, jscript, vbscript, others)\n\n\nThrive\n\nWhat You Can Expect Of Us\n\nAs we work to develop treatments that take care of others, so we work to care for our teammates\u2019 professional and personal growth and well-being. Therefore, Amgen is recognized as World's Best Workplace 2021 \u00a9.\n\n\nVast opportunities to learn and move up and across our global organization.\nDiverse and inclusive community of belonging, where teammates are empowered to bring ideas to the table and act.\nGenerous Total Rewards Plan comprising competitive salary, bonus structure, fixed 13th month, holiday allowance and a collective health insurance.\nFocus on vitality with an on-site gym, vitality program and a restaurant with healthy food.\nFlexible work arrangement with days in the office and days working from home.\n\n\nJoin Us\n If you're seeking a career where you can truly make a difference in the lives of others, a career where you can work at the absolute forefront of biotechnology with the top minds in the field, you'll find it at Amgen.\n Amgen, a biotechnology pioneer, discovers, develops and delivers innovative human therapeutics. Our medicines have helped millions of patients in the fight against cancer, kidney disease, rheumatoid arthritis and other serious illnesses.\n As an organization dedicated to improving the quality of life for people around the world, Amgen fosters an inclusive environment of diverse, ethical, committed and highly accomplished people who respect each other but compete intensely to win. Together, we live the Amgen values as we continue advancing science to serve patients."
    },
    {
        "position": "Data Scientist, Data & Analytics, Global IT",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "DSV - Global Transport and Logistics",
        "sector": "Transportation, Logistics, Supply\n                                                            Chain and Storage",
        "companySize": "10,001+ employees",
        "location": "Lisbon, Lisbon, Portugal",
        "post": "About the job \n Job Req Number: 40102\nAt DSV we are looking for a Data scientist with business understanding to be part of our Data & Analytics team in Global IT. The focus of our team is to build advanced end-2-end solutions that create direct business value for DSV\u2019s divisions, including for example: customs declaration automation; vendor invoices automation; address validation; ETA prediction; and many more to come\u2026\nThe word \u201cadvanced\u201d is used to underline that the use cases we solve tend to have a high degree of complexity, requiring non-deterministic problem solving (i.e. the use of ML/AI), near real-time data processing, a need for high availability, vertical and horizontal scalability and a very high volume of transactions. However, fancy technologies and accurate ML models do not solve the issues at hand alone; we strive to combine our competencies to build holistic solutions where the underlying complexity is hidden for the user to create simple and value-adding experiences.\nAs a Data Scientist your main responsibilities and activities will be:\n\n\nMeeting with stakeholders, discussing their needs and translating them into Data Science problems.Conduct data-driven analyses to provide input to decisions (e.g. which DSV country to start with for a specific use case). Identify proper solutions / models / pre-trained models for particular business cases.Preprocess the data (cleaning, transforming) for ML models. Train ML models on prepared training data using GPU on cloud and on premises.Test and evaluate ML models and present conclusions on further improvements.Use and tweak existing frameworks for running automated testing and evaluation of ML models.Mature models to be available as services for other components. Present your results on an ongoing basis to team mates and business stakeholders.\n\n\nWe expect you to have experience with most of the following technologies/areas:\n\n\nCode languages: Python (using both OOP as well as popular libraries such as Pandas, Scikit),Solid understanding of Machine Learning in practice: be able to speak about several projects you participated in,Very good knowledge of Deep Learning with focus on NLP: Transformers, Bert family and where it all came from,ML Frameworks: TensorFlow / PyTorch and other open-source frameworks,ML model serving: TensorFlow serving, Torch serving,Cloud: Azure,Modern software development: good understanding of DevOps, CI/CD, MLOps,Basic knowledge of database technologies such as:Relational database: We use MySQLNoSQL database: We use MongoDBVersion control: Git (we use Atlassian BitBucket as a GUI on top of Git)\n\n\nIt Is a Bonus If You Also Have Some Experience With Some Of The Other Technologies That Our Team Works With, Such As\n\n\nCode languages: Java, ScalaAuthentication: Open ID Connect 2.0 (we use Red Hat KeyCloak as identity broker)Containerization: DockerContainer orchestration: KubernetesCI/CD Pipelines: Jenkins (our templates are written in Groovy) Load balancing: NGINXInstallation scripts: AnsibleEvent streaming: Confluent Kafka, K streamsRequirements: JiraDocumentation: ConfluenceFrontend technologies: React JS, Material UI, JavaScript/TypeScript, ReduxTest framework: Jest\n\n\nYou Like To\n\n\nLearn new stuff from knowledgeable colleaguesAnalyze problems using data and statisticsPresent your results to teammates and business stakeholders to communicate your findingsSolve problems that are too complex for deterministic reasoning with the use of Machine LearningFind pragmatic solutions that balance the need between what is the \u201coptimal\u201d solution from a theoretical standpoint with what is possible within the constraints set by project deadlines, low data quality, etc.Understand the data and the business logic that is related to the ML models you test, train and improve, and you believe that this in-depth understanding is pivotal for being able to deliver valuable resultsTake a lot of responsibility \u2013 both for exciting R&D work to push the boundaries of ML, but also for doing the necessary nitty gritty work it takes to prepare data, evaluate results, debug errors, etc.Ensure that your models can be tested iteratively to compare the individual model\u2019s accuracy and the entire solution\u2019s accuracy over time and to make this visible to stakeholdersBreak down the solutions into iterations so they can deliver value quickly in MVP versions before they are enriched with more nice-to-have functionality in later iterationsReach out to others for help or clarifications whenever you need it and to ensure alignment with othersMake realistic mockups of data to allow you to test things swiftly on synthetic data before you get access to production data\n\n\nWe Are An Ambitious Team With a Flat Hierarchy And a Mix Of Young And Very Experienced Persons, Who Are Working According To The Following Principles\n\n\nWe celebrate victories togetherWe take responsibility for mistakes and learn from themWe design for scale but build only for the near futureWe value working software and informal alignment over tedious documentationWe make decisions based on knowledge and insight rather than hierarchical structuresDecisions are the product of conversations between people with different competencies (not one person)Everyone can speak their honest opinion\n\n\nWe have all the needed competencies to build awesome products inside the team: Product owner, Business analysts, Application developers (frontend + backend), Data engineers, Data scientists, ML engineers, DevOps engineers.\nJob / Environment\n\n\nYour job location will be Portugal (Lisboa, Saldanha) and you will be part of DSV Global IT with peers working in remote teams across the GlobeInternational EnvironmentPermanent Contract with 35h / week\n\n\nDSV \u2013 Global Transport and Logistics\n\nDSV is one of the very best performing companies in the transport and logistics industry. 75,000 employees in more than 90 countries work passionately to deliver great customer experiences and high-quality services \u2013 as part of the operation or in a variety of supporting roles. If you have drive and talent and enjoy responsibility, we\u2019ll give you the support you need to explore your potential and forward your career. \nRead more at www.dsv.com"
    },
    {
        "position": "Python Data Scientist - Sustainable Energy (m/f/d)",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Siemens",
        "sector": "Automation Machinery\n                                                            Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Lisbon, Lisbon, Portugal",
        "post": "About the job \n\nLooking for a chance to create a positive impact on our society? Join us!\n\nWith its 7.000 employees, Siemens Technology works hand in hand with the company\u2019s business units to ensure Siemens\u2019 future. Technology conducts research with internal and external partners, including leading universities and promising start-ups. These collaborative endeavors focus on a wide range of future technologies with a view to securing them with patents and supporting them through commercialization. Technology also provides development services for Siemens\u2019 business units and supports them with methods and tools related to business excellence.\nYou will be part of an international team based in Portugal and Germany and drive forward digital applications for solving the energy transition. You will work on energy management systems, solutions for e-car charging and further digital platforms. We are looking for a dedicated individual that wants to be part of this international team that re-defines how future digital energy applications are developed and used. You will work closely with other software engineers in a start-up type environment backed up by the substantial resources of a large-scale company.\nAt Lisbon Tech Hub we create value in the digital transition of companies from Portugal to the world. There are more than 1200 professionals working in Cybersecurity, Analytics Business Intelligence, Application Lifecycle Management, IT Project & Service Management and IT Infrastructure Management.\nCheck it out: www.siemens.pt/lxtechhub\nWhat role will you play?\n\n\n\nYou\u2019ll be working in an international team based in Portugal and Germany.\nYou\u2019ll contribute to solving the challenges of the energy transition by developing innovative applications such as energy management systems or data analytic applications for buildings and sites, e-car charging solutions and other digital tools and platforms.\nYou\u2019ll support the entire application development lifecycle from requirement analysis, effort estimation, design, development, testing (unit, integration, system), and operation.\nYou\u2019ll collaborate with cross-functional teams on the further development of existing and new solutions.\n\n\nWe are looking for:\n\n\n\nSuccessfully completed university degree in Computer Science or other equivalent disciplines.\n5+ years of professional experience.\nExperiences in working with Lean/Agile software development projects and processes.\nStrong verbal and written communication skills in English are a must.\nYou have a strong achievement drive and bring along curiosity for new things.\nVery good knowledge of programming languages, with a focus on Python (pandas, SciPy, NumPy, etc), \u2026 (.NET and TypeScript is a plus).\nExperienced in data analytic applications (machine learning - TensorFlow, Keras).\nExperience in developing prediction systems and machine learning algorithms (using the machine learning tools to create models and classifiers).\nExperience in pre processing of structured and unstructured data, pattern identification.\nExperience with data visualization tools (e.g., Plotly).\nStrong software engineering background.\nDeep understanding of current technology trends in the cloud, IoT, and software development.\nPassion for delivering high-quality solutions and learning new technologies.\nExperience in working with energy management systems, building automation technologies or other digital energy platforms are a plus.\n\n\nWhat we have to offer:\n\nA flexible home office and schedule policy, virtual budget to improve your home office setup, health insurance, a Pension Plan and a Siemens Share Program time and financial support to your studies, medical center in the facilities, sport groups, 2 days for volunteering initiatives and a cool and relaxed environment.\nAccess to e-learning platforms (Learnlight, Linkedin Learning and more), discounts with partners.\n#Siemens #LXTechHub #ITMakesUsMove\n\nPlease, send your CV in English as you'll be part of an international team.\n\nWe recognize that building a diverse workforce is crucial to the success of our business. Therefore, Siemens provides equal employment opportunities to all qualified individuals without regard to race, creed, color, religion, national origin, age, gender, marital status, sexual orientation, or non-disqualifying physical or mental handicap or disability.\n\nWe strongly encourage applications from a diverse talent pool and welcome the opportunity to discuss workplace adjustments with all our applicants to develop agile working and innovation.\n\nOrganization: Technology\nCompany: Siemens S.A.\nExperience Level: Experienced Professional\nFull / Part time: Full-time"
    },
    {
        "position": "Data Analyst - Analytics and Insights - Data Center of Excellence",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Bose Corporation",
        "sector": "Computers and Electronics\n                                                            Manufacturing",
        "companySize": "5,001-10,000 employees",
        "location": "Lisbon, Lisbon, Portugal",
        "post": "About the job \n\nJob Description\n\nData Analyst - Analytics and Insights - Data Center of Excellence\n\nDo you love working with data? Would you like to use your Data Analytics skills to solve real world problems and improve people\u2019s lives by analyzing App, product, operational and marketing data? Bose produces innovative products and experiences that improve our customer\u2019s lives. This is a unique opportunity to shape the experiences, technologies, and products that millions of people will use.\nAs part of the CoE team, you will evangelize a data-driven culture throughout the organization and enable products grounded in science and powered by AI which improve our customer\u2019s experience.\nThis Data Analyst role will drive analysis and reporting across many diverse data sets to make sure we deliver impact from our data products and services. This includes identifying and categorizing patterns across product usage, creating user profiles, analysis of review data and creating dashboards and reports that display actionable business metrics. This work will directly inform and influence multiple division\u2019s strategies.\nThe ideal candidate has a deep understanding of data analytics and visualization, coupled with creativity and business acumen. Because you will often serve as an internal expert about the data, what it means and how it can be used to solve business problems, you can demonstrate that you have experience deeply understanding the data structure and applying rigorous analytical methods to derive actionable recommendations. We are seeking a highly motivated, detail-oriented analyst who can transform raw data into meaningful insights, providing actionable recommendations. This individual will be part of an extended team.\nYou'll Be Responsible For\n\n\n\nData analytics across multiple apps and products \nCreates analytical data sets for ad-hoc analysis \nDevelops data visualizations and reporting to represent KPI\u2019s \nWill be an SME for specific data domains \nIdentify data quality issues \nOwns data sets and data visualizations they create\nEngage with key stakeholders in the business, product, and software teams to clearly understand and scope analytical requests. \nMine, analyze, and model large structured and unstructured datasets to create actionable business metrics and solve business questions. \nPartner with colleagues working with survey data or online review data to integrate these kinds of data into reporting and analysis to solve business questions. \nSupport one or more product categories with ad hoc analysis of product and app usage data to support business decisions. \nCreate custom, targeted reports and dashboards that deliver insights into the current product and app usage and customer response to new features/capabilities or marketing experiments. \nPartner with internal data and systems resources to understand the structure and format of data sources and ensure data integrity and availability to support analytical requirements. \nLead data analysis, synthesize results, and develop and present strategic recommendations for the executive leadership and product teams that inspire action. \nLead analytics requirement synthesis in the development of new hardware and software products and features. \nLead PowerBI development across the Data and Analytics group. \n\n\nWhat You'll Need To Succeed\n\n\n\nBachelor\u2019s or Master\u2019s degree in math, physics, computer science, engineering, business, finance, marketing, economics or related quantitative or computational field \n4+ years of related data analytics experience in relevant consulting, finance, data science or market intelligence functions \nPrevious technical experience in a consumer electronics environment is a definite plus\nPrevious experience with analyzing app and product data is a plus \nStrong PowerBI coding, visualization, and customization skills. Certifications a plus.\nExtensive background and demonstrated track record in obtaining and analyzing quantitative data to solve actual business problems. \nStrong technical skills, including experience with analytics, query and data visualization tools. SQL and PowerBI experience a must. Programming languages, e.g. Python is strongly desired. Experience with Snowflake a plus.\nExcellent communication and presentation skills, and the ability to explain deep technical results to diverse groups of stakeholders. \nA life-long learner who is curious, has a passion for solving hard, ill-defined problems, has comfort taking initiative and who continuously seeks to improve their skills and understanding. \nEnjoys working in a team environment as well as independently \nAbility to work with teams and stakeholders that are geographically displaced.\n\n\nWhat's In It For You\n\n\n\nBe a part of and work with a top notch, multidisciplinary, transparent, and agile team. \nCollaborate with people like you who want to solve problems and have fun together. \nExcellent work life balance and a continuous learning environment. \nHighly competitive package as well as a comprehensive benefits program. \nWe strive to help our employees and customers reach their fullest potential.\n\n\nAre you interested in this position?\n\nWe\u2019d love to know you better! Submit your application, by uploading your CV in English via the \u201cApply\u201d button above.\nFor further information about the position please contact us via ITCareers_Portugal@bose.com.\nNote\n\nThanks in advance for your application. After the online phase, the most successful candidates will be invited for an interview. In case you\u2019re not contacted in the next 15 days, we will keep your application for future opportunities that may suit your profile best."
    },
    {
        "position": "Data Scientist",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Solvay",
        "sector": "Chemical Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Lisbon, Lisbon, Portugal",
        "post": "About the job \n Solvay is a science company whose technologies bring benefits to many aspects of daily life. Our purpose\u2014we bond people, ideas and elements to reinvent progress\u2014is a call to go beyond, to reinvent future forms of progress and create sustainable shared value for all through the power of science. In a world facing an ever-growing population and quest for resources, we aim to be the driving force triggering the next breakthroughs to enable humanity to advance while protecting the planet we all share.\n We bond with customers and partners to address today and tomorrow\u2019s megatrends. As a global leader in Materials, Chemicals and Solutions, Solvay brings advancements in planes, cars, batteries, smart and medical devices, water and air treatment, to solve critical industrial, social and environmental challenges. You can count on our innovative solutions to contribute to safer, cleaner and more sustainable future.\n Role Overview We are looking for:\n\nWithin our Data, Analytics & AI Platform we are setting up hubs of expertise centers across our locations to be able to deliver cutting-edge data & analytics applications in support of our digital strategy and its products to transform Solvay.\nAs a Data Scientist you will join the Data Scientist Pool and you will drive the creation of actionable insight from our data lakes, develop new approaches/algorithms, to accelerate research & development (discover new formulations and materials), produce more efficiently (improve processes, planning and scheduling) and finally, accelerate sustainability.\n\n\nWe count on you for:\n\nConduct proof of concepts and projects in Data Science & Advanced Analytics where you will translate business needs in Analytics requirements & insights, locate the data sources (internal/external) to generate relevant models, gather, transform & clean the necessary dat leverage data science algorithms while prototyping (study) and operationalizing the solutions share and present the results\nDesign and develop robust algorithms & techniques using NLP/text analytics, optimization methods and shallow & deep machine learning models as part of a central advanced analytics team solving business problems in different domains including Finance, Purchasing, Supply Chain, R&I, Energy and Industrial.\nManage projects in predictive/prescriptive analytics projects while working with external consultants.\nSupport data analysts in industrializing their advanced analytics projects.\n\n\nYou can count on us for:\n\nJoin a team of experienced datascientists in a mature data analytics organisation with a full modern tech stack and cloud, using agile project methodogy and a data ops team.\n\n\nYou will bring:\n\nDegree / Masters in Computer Science/Information Technology, Analytics, Data Science, Mathematics/Statistics, Computational Science, Operations Research or related technical disciplines \nMinimum experience of 2 years in Data Analytics / Data Science / Machine Learning\nExperience in implementation of at least one machine learning project including industrialization / automation\nGood communication skills in English\nAppetency to learn various business domains.\nProactivity and willingness to explore is the key skill.\nCritical thinking and an innate curiosity to understand a problem to find suitable solutions is crucial for this role. \nPassionate about data science and the new technologies.\nSelf-motivated and independent: The candidate will need to be able to manage a full analytics process from business interview to modelisation to results explanation & automation.\nClear orientation toward business goals and associated business metrics\nProject management, AGILE methodology is welcome.\nGood communication & presentation skills.\nTeam player to interact with a large number of stakeholders in the business and the Solvay group\n\n\nYou will get:\n\nCompetitive salary\nHealth insurance\nLife insurance\n16 weeks of maternity/paternity and co-parenting leave\nFree language courses (24 languages available)\nAdditional local benefits\n\n\nDetails:\n\nLocation(s): Lyon, Auvergne-Rh\u00f4ne-Alpes (France), Carnaxide, Lisbon Region (Portugal), Brussels, Brussels-Capital (Belgium) \nRemote working\n\n\n\n\nAdditional Information\nSolvay\u2019s purpose is to bond people, ideas and elements to reinvent progress. We can only fulfill this purpose with a diverse workforce that feels respected and appreciated, and has equal opportunities to work, grow and thrive. Our differences, visible or not, are valued. As Solvay seeks to promote unity and not uniformity, we invite you - regardless of background, age, gender, race, national origin, ethnicity, religion, sexual orientation, ability or identity - to consider a future with us."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Wilhelmsen group",
        "sector": "Maritime Transportation",
        "companySize": "10,001+ employees",
        "location": "Oslo, Norway",
        "post": "About the job \n\nFounded in Norway in 1861, Wilhelmsen is now a comprehensive global maritime group providing essential products and services to the merchant fleet, along with supplying crew and technical management to the largest and most complex vessels ever to sail. Committed to shaping the maritime industry, we also seek to develop new opportunities and collaborations in renewables, zero-emission shipping, and marine digitalization. Supporting a diverse and inclusive workplace, with thousands of colleagues in more than 70 countries, we take competence, sustainability, innovation, and unparalleled customer experiences one step further.\n\n\nAnchor your career in the maritime industry and dive into a sea of opportunities with us now! Empowering people through technology is our aspiration and so is setting the standard for how we work with technology across Wilhelmsen as shapers of the maritime industry. Creating actionable insights from data is a strategic priority and we are continuing to build and invest in our data & analytics platforms to support our ever-changing data driven ambitions as a company.\n\n\nThe Data & Analytics team plays a key role in Wilhelmsen Ships Service delivering operational, financial and management reporting to business divisions across the organization. This agile team consists of both internal and external data engineers, having full responsibility for both development and operations, from creating the data pipelines to visualising the data to end users. Our ideal candidate is looking for new challenges and would like to join a team of experienced professionals who are passionate about innovation, technology, and transformation.We can offer a great culture and work environment, career development, work-life balance and a job that is both challenging and stimulating.\n\n\nWe are looking for a Data Engineer to strengthen our Data & Analytics team by taking a key role in making our data driven ambitions a reality. We have recently completed our migration to Snowflake in Azure and are now looking for someone who can play a key role in the journey of taking it to the next level. The right person will help with designing and developing data pipelines, data models, reports, and dashboards, as well as functioning as our Power BI subject matter expert.\n\n\nYou will also be involved in continuously improving Self Service BI as well as driving Power BI competence within the organization. The right candidate will also have the possibility to work with use-cases related to advanced analytics, including Process Mining, ML and IoT/streaming data. The role will report to the Data & Analytics Manager.\nThis is the perfect role for you if you enjoy getting your hands dirty with data and code, and thrive in solving complex challenges and testing out new technologies.\n\n\n\n\nYour main responsibilities:\n\nDevelop and maintain Power BI reports in collaboration with key stakeholders across the organization\nDesign, develop and quality assure data pipelines and dimensional models (star-schema)\nMaintain Power BI service, including workspace, report and app management\nDrive the competency build related to Power BI throughout the organisation, to ensure that WSS are in the forefront when it comes to utilizing Power BI and the surrounding Microsoft application eco-system\nRun bi-weekly \u201cCenter of Excellence\u201d forums, with Power BI as one of the focus areas to share ideas, best-practices and other cool stuff\n\n\n\n\n\nQualifications:\n\nMinimum 2 years of experience with Power BI and building data visualisations, as well as building and maintaining data pipelines and dimensional data-modelling\nBachelor\u2019s degree from business/finance, computer science, engineering or similar.\nExperience with Power BI, Snowflake, WhereScape and/or other ETL and visualisation tools\nExperience with Azure and/or other cloud platforms\nExperience with DAX/SQL/Python and/or other data preparation languages\nProficient in English, written and verbal with great communication skills\n\n\n\nThe firm aspires to be the leading enablers of sustainable global trade. Committed to shaping the maritime industry, we also seek to develop new opportunities and collaborations in renewables, zero-emission shipping, and marine digitalization. Please apply for the position to be a part of the change!\n\n\nWe will review applicants on a rolling basis."
    },
    {
        "position": "Big Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Solera, Inc.",
        "sector": "IT Services and IT\n                                                            Consulting",
        "companySize": "5,001-10,000 employees",
        "location": "Madrid, Community of Madrid, Spain",
        "post": "About the job \n\nThe Role\n\n\nOn this position, you will be required to have:\n\n\n\nStrong analytical skills with the ability to collect, organize, analyze, and disseminate significant \n\namounts of information with attention to detail and accuracy. Enhance data collection procedures to \ninclude information that is relevant for building analytic systems. \n\nObsession by accuracy data and automate processes.\nSolid problem-solving skills, supported by a logical, methodical, and thorough approach to \n\nimplementation.\n\nKnowledge of data cleaning, wrangling, visualization, and reporting, with an understanding of the best, \n\nmost efficient use of associated tools and applications to complete these tasks\n\nSpecify quality checks that assure QA in data and one SVOT\nExcellent interpersonal and communication skills to establish and maintain collaborative work \n\nrelationships at all levels.\n\nFluent English on business level (written and spoken)\n\n\n\n\n\nWhat You\u2019ll Do\n\n\n\nRead, extract, transform, stage and load data to selected tools and frameworks (cloud and on \n\npremise)\n\nWork closely to product and reporting team to integrate your work into current production solutions.\nProcess unstructured data into a form suitable for analysis\nSupport business decisions with ad hoc analysis as needed\nFilter and \u201cclean\u201d data by reviewing computer reports, printouts, and performance indicators to locate \n\nand correct code problems\n\nMonitoring data performance and modifying infrastructure as needed\nImprove big data performance jobs and adapt them to different environments\n\n\n\n\n\nWhat You\u2019ll Bring\n\n\n\nBachelor\u2019s degree in computer science or numerate discipline \nExperience with SQL \nTechnical expertise on big data environments such Hadoop or Azure Ecosystem\nExperience processing large amounts of structured and unstructured data, including integrating data from multiple sources.\nProgramming experience ideally in Spark, Java or Python and ability to learn new coding languages and programs\nTechnical expertise regarding data models, database design development and data mining.\nExperience in production support and troubleshooting.\nHands on with \u201ccan do\u201d attitude.\nDeep knowledge of data mining, machine learning, natural language processing, or information retrieval\nExperience in MapReduce is a plus.\nAgile methodologies\nPlatform experience, JIRA, Confluence"
    },
    {
        "position": "Big Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Lufthansa                                                                                                                        Systems                                                                                                                        Hung\u00e1ria",
        "sector": "IT Services and IT\n                                                            Consulting",
        "companySize": "5,001-10,000 employees",
        "location": "Madrid, Community of Madrid, Spain",
        "post": "About the job \n\nJoin us as a Data Scientist and work on our market leading Operations Control solution, a machine learning module, preventing disruptions at the day of operations and automating the work of the Ops Controller. \n\n\nYour tasks will include:\n\n\nWork with aviation data to build a new data-driven product and develop innovative uses of machine learning for the airline industry \nProvide clarity and generate new insights from complex data sets by applying advanced analytical models \nContribute to the development of end-to-end data solutions in collaboration with cross-functional data experts and business stakeholders. \n\n\n\nYou are looking for us if you have experiences/ qualification in the following fields:\n\n\nA Master\u2019s or Bachelor\u2019s degree in a quantitative discipline such as computer science, mathematics, physics, or a related subject \nProficiency using one or more programming or scripting language to work with data, especially Python \nSome experience and/or project course work performing data analysis and applying statistics \nGood knowledge of machine learning fundamentals \nExperience with version control systems (e.g. Git) \nFamiliarity with the fundamentals of SQL \nStrong communication skills (our working language is English) and comfort delivering results to stakeholders and colleagues \nA strong desire to learn every day and a self-starter mentality \n\n\n\nYou will be successful in this position if you have the following skills or experience:\n\n\nApplying machine learning in fields such as Computer Vision, NLP, or Reinforcement Learning \nWorking in cloud computing environments, especially Microsoft Azure \nData science software platforms (e.g. SAS, Databricks) \nData science libraries (e.g. pandas, NumPy, SciPy, scikit-learn) \nProject management, particularly knowledge of agile project setups (e.g. Kanban, Scrum) \n\n\n\nAdvantage if You have\n\n\nAirline know-how, OPS basics knowledge \n\n\n\nWhat are the benefits of joining us as an employee?\n\n\nEven when you work hard, you will still have time for your personal life: our flexible working hours based on core time, the exact observance of the designated number of working hours, the occasional option of working from home, and the benefits that can be extended to cover your family you can also improve your non-working life! \nWe have long-term plans for you! We have carefully designed career paths (and a career management system), we provide the appropriate training courses and projects to accomplish your aims. \nOur community is characterized by mutual respect and an attitude of helpfulness. This high professional quality level and the colorful personalities will help you spend your everyday life in a good mood, why you make the best of your skills and talents. \nWe are happy when you are open and help you discover the world: after six months you will receive substantial discounts that you can use to visit any place in the world taking Lufthansa flights! \nIn addition to an inclusive and helpful atmosphere, trust is also an important value for us. You can rely on us with anything right from your first day, and we also trust you to the utmost extent."
    },
    {
        "position": "Big Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Harnham",
        "sector": "IT Services and IT\n                                                            Consulting",
        "companySize": "5,001-10,000 employees",
        "location": "Madrid, Community of Madrid, Spain",
        "post": "About the job \n\n\n\nData Scientist - Natural Language Processing \n\nUp to \u20ac90,000\n\nLeiden\n\n\n\n\nThe Company\n\nThis company sits within the pharmaceutical industry and is using AI solutions to support the health care ecosystem. This company uses a suite of products that have been built in partnership with top life science companies- all with a focus on empowering the people to take action. They are the leaders in AI analytics for life sciences and pride themselves in giving their employees creative freedom in order to do their work and take pride in what they are doing. \n\n\n\nThe Role\n\nThe company is seeking a Data Scientist with a strong background in NLP to develop solutions based on the company's ground-breaking technologies. They pride themselves on their ability for their employees to influence the design, architecture, and refinement of the data processing applications in health care. \nYou will:\n\n\nPlay a crucial role in designing and building solutions using the leading AI engine for health care. \nBe part of a close team who have extensive experience in implementing machine learning for real-world applications. \nDefine and build systems to generate insights for clinical problems that NLP can solve \n\n\n\n\n\nDay to Day\n\n\nApply NLP techniques and statistical analysis to extract unstructured Textual Data Sets \nBuild and prototype NLP pipelines \nContribute to the defining and testing of products \nWork closely with the engineering and data science teams \n\n\n\n\n\nYour Skills and Experience\n\nThe ideal fit for this role is someone who: \n\nHas applied experience and knowledge of Natural Language Processing \nHas a Masters or PhD in NLP, Data Science, or other relevant quantitative fields \nIs comfortable with Python and solving problems using AI \nEnjoys and has strong problem-solving skills \nLanguage: English (Excelling verbal and written abilities) \n\n\n\n\n\nBenefits\n\n\nHybrid \nMonthly WFH budget and one-off set-up budget \n25 days holiday \nExcellent pension scheme \nPrivate health care \nFully covered public transport (NL) \n\n\n\n\n\nHow to Apply\n\nPlease register your interest by sending your CV via the Apply link on this page.\n\n\n\n\nKEYWORDS\n\nData science \u2013 Data scientist \u2013 NLP \u2013 Natural Language Processing - Healthcare"
    },
    {
        "position": "Data Scientist- Natural Language Processing",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Harnham",
        "sector": "Staffing and Recruiting",
        "companySize": "201-500 employees",
        "location": "Leiden, South Holland, Netherlands",
        "post": "About the job \n\nData Scientist - Natural Language Processing \n\nUp to 90,000\n\nLeiden\n\nThe Company\n\nThis company sits within the pharmaceutical industry and is using AI solutions to support the health care ecosystem. This company uses a suite of products that have been built in partnership with top life science companies- all with a focus on empowering the people to take action. They are the leaders in AI analytics for life sciences and pride themselves in giving their employees creative freedom in order to do their work and take pride in what they are doing.\n\nThe Role\n\nThe company is seeking a Data Scientist with a strong background in NLP to develop solutions based on the company's ground-breaking technologies. They pride themselves on their ability for their employees to influence the design, architecture, and refinement of the data processing applications in health care.\n\nYou Will\n\n\nPlay a crucial role in designing and building solutions using the leading AI engine for health care. \nBe part of a close team who have extensive experience in implementing machine learning for real-world applications.\nDefine and build systems to generate insights for clinical problems that NLP can solve \n\nDay to Day\n\n\nApply NLP techniques and statistical analysis to extract unstructured Textual Data Sets\nBuild and prototype NLP pipelines\nContribute to the defining and testing of products\nWork closely with the engineering and data science teams\n\nThe Ideal Fit For This Role Is Someone Who\n\nYour Skills and Experience\n\n\nHas applied experience and knowledge of Natural Language Processing\nHas a Masters or PhD in NLP, Data Science, or other relevant quantitative fields\nIs comfortable with Python and solving problems using AI\nEnjoys and has strong problem-solving skills \nLanguage: English (Excelling verbal and written abilities)\n\nBenefits\n\n\nHybrid\nMonthly WFH budget and one-off set-up budget\n25 days holiday\nExcellent pension scheme\nPrivate health care\nFully covered public transport (NL)\n\nHow To Apply\n\nPlease register your interest by sending your CV via the Apply link on this page.\n\nKEYWORDS\n\nData science - Data scientist - NLP - Natural Language Processing - Healthcare"
    },
    {
        "position": "Team Lead (f/m/d) Data Engineering",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Siemens Energy",
        "sector": "Renewable Energy Semiconductor\n                                                            Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Lisbon, Lisbon, Portugal",
        "post": "About the job \n You will be building and guiding your team of Data Engineers who are responsible for enabling technically the translated business requirements into analytical products, helping to bring new insights alive. As a leader, you are part of our transformation journey to become a data driven company in future.\n Passionate about the environment and climate change? Ready to be part of the future of the energy transition? The Siemens Energy Data Analytics & AI team plays a significant role in driving the energy transformation.\n Honestly, we don\u2019t have all the answers. Honestly, given the scale of the challenge we need many types of perspectives to help reimagine the future. And honestly, we can\u2019t do it alone.\n Our team is looking for innovative, enthusiastic, and versatile data, digital, and AI professionals that will drive us forward on this exciting venture.\n\nLet\u2019s Talk About You\n\nYour profile\n\n\n\nCollege degree in information technology or related field\nExtensive experience leading data architecture and data-related initiatives \nIn-depth knowledge of data acquisition, data modeling and analytics, and the ability to deal with performance and development issues on Hadoop\nExperience with database modeling (e.g., Snowflake, Star) and experience developing streaming and batch data pipelines for cloud and hybrid infrastructures\nKnowledge of streaming frameworks (e.g. Spark, Storm, or Kafka) and hands-on experience with modern software development tools such as GitHub, Jenkins, and other build automation tools\nExtensive knowledge of data analytics and the ability to slice and dice data as needed\nExperience in data architecture for cloud providers (e.g., AWS, Azure, GCP)\nKnowledge of data warehouses that support analytical workloads (e.g., Snowflake)\nInitial exposure to working with ETL, ESB and web service containers\nExcellent writing and communication skills in English, German language skills or knowledge of another language is a plus\nStrong customer focus and excellent communication skills and exceptional leadership and coaching skills to collaborate and develop technical talent in multicultural, global teams\nOpen-minded and willing to learn and continuously improve your skills\nEnthusiasm for data and analytics and leveraging data across all aspects of a business and ecosystem \n\n\nYour Responsibilities\n\n\n\nLead a team of data engineers focused on leveraging data and information across the SE to improve data-related operations and drive risk-related insights\nDrive technical implementation and accountability for strategy and execution\nDetermine the scope of the Minimum Viable Product (MVP) for upcoming initiatives and outline the future roadmap for enhancements and potential improvements\nCollaborate with data owners on planning and execution of key initiatives\nOversee the performance and quality of integration pipelines created in close collaboration with the data integration team \nDrive architecture design and discussions, advising teams\nDrive data literacy towards visualization through self-service capabilities for end user communities\nEnsure that the development model supports high velocity and good quality deliverables, with the ability to develop faster, develop in parallel, and release frequently\nAdvocate for modern software development methodologies and use Scrum and SAFe frameworks\nConduct code reviews and ensure teams adhere to appropriate standards, as well as develop and monitor KPIs / metrics to optimize data quality\nDocument and present methodologies, procedures, and project deliverables to senior stakeholders across multiple functions \nKnowledge of emerging technologies and latest trends in the data science space\nLeading a team and helping team members reach their full potential\nParticipate in an inspiring team of true thought leaders and data science experts within the global ED&AA team\n\n\nLet\u2019s Talk About Us\n\n\"Let\u2019s make tomorrow different today\" is our genuine commitment at Siemens Energy to all customers and employees on the way to a sustainable future.\n In our Business Functions we enable our organization to reach their targets by providing best-in class services and solutions in the areas of IT, HR, Finance, Real Estate, Strategy & Technology and more.\n Check out this video to see what we do here! https://bit.ly/3IfnlaR\n\nMORE INSIGHTS\n\nBe Energized. Be you.\n Lucky for us, we are not all the same. Through diversity we generate power. We run on inclusion and compassion. Our combined creative energy is fueled by at least 130 nationalities. Siemens Energy celebrates character \u2013 no matter what ethnic background, gender, age, religion, identity, or disability. We energize society. All of society.\n\nJobs & Careers: https://www.siemens-energy.com/global/en/company/jobs.html\n We value equal opportunities and welcome applications from people with disabilities."
    },
    {
        "position": "Team Lead (f/m/d) Data Engineering",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Back                                                                                                                    Market",
        "sector": "Renewable Energy Semiconductor\n                                                            Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Lisbon, Lisbon, Portugal",
        "post": "About the job \n Back Market is the world\u2019s leading refurbished electronics marketplace with a team of more than 650, powering operations in 16 countries (and counting!).\n Back Market is undergoing meteoric growth and has raised $884 million, with a valuation of $5.7 billion. Our mission is simple: empowering people to buy tech sustainably by offering folks a high quality, accessible, and more eco-friendly alternative to buying new electronics. Why? Refurbished tech helps lower our collective environmental impact .\n Be part of a great and growing adventure that will change the way the world consumes tech.\n Data is a key enabler for a company like Back Market. Do you want to help your team build reliable, high-performing and secure data infrastructures and tools? Do you want to have a meaningful impact through your job? Here is your opportunity.\n Data engineering at Back Market is split into three teams, based on their stakeholders: Customer (Back Market\u2019s end users), Supply (sellers at Back Market), and Finance & Customer Care. We are looking for a manager to lead the Supply data team (data engineers and analytics engineers) and develop this scope from end to end. The supply data scope includes all data (from collecting to serving the data to internal and external stakeholders like our sellers) linked to the Back Market catalog, sellers\u2019 performance and the pricing of our offer.\n This senior team of 5 people is distributed between our different offices and full remote.\n\nWhat you'll be doing :\n\n\nManagers at Back Market build sustainable and efficient teams, by empowering people and building the proper environment. \nCollaborating with your product manager and your stakeholders: the BI, and other tribes to align the team with company objectives and initiatives across engineering and the wider business \nEnsuring the development of people and teams through open communication, feedback, and continuous coaching \nCreating an inclusive team environment, where team members feel like they belong and are supported to do their best work \nWorking in an agile \"build it and run it\" environment where engineering teams build, launch, monitor and support the sections they own \nWorking with the team to identify and make improvements in our processes, practices, and product \nHelp your team take the right technical decisions thanks to a strong technical data background\n\n\nYou are in the right place if : \n\n\nYou are people-first oriented and know how to build and run a high-performing team ; \nYou embrace the servant leadership principles as much as you value empathy and cordial debates over a \"top-down\" management posture ;\nProduction health is a priority for you ;\nYou are able to understand the tech challenges of your team and guide them through decisions. Our stack is AWS (Lambda, dynamodb), GCP (Big Query, Data Catalog), Spark (Delta), Terragrunt, Terraform, Datadog, Python, Scala. \nYou have great communication skills in English\n\n\nWHY SHOULD YOU JOIN US ?\n\nA meaningful job: through hard work, you will help avoid thousands of tons of electronic waste and fight against planned obsolescence. It counts! An attractive salary, equity, multiple benefits (meal tickets, health insurance, etc...), parental benefits, #remote friendly company, relocation package, internal events, etc\u2026 Technical challenges all day every day: you will have the freedom to innovate and adopt new ideas! Work with passionate experts who will share their knowledge and help you develop and grow! (Backademy, technical guilds, Meet-up & Conference) Grow your career with a flexible career path, BackMarket can help you evolve! A booming scale-up: our environment is rapidly growing in Europe, the USA and soon in Asia! A lot of fun: you will have the opportunity to work in a fast-paced, open-minded and friendly environment.\n\n\nBackMarket is an Equal Opportunity Employer for any minority, disability, gender identity or sexual orientation."
    },
    {
        "position": "Software Engineer, Data Engineering",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Bolt",
        "sector": "Internet Marketplace\n                                                            Platforms",
        "companySize": "1,001-5,000 employees",
        "location": "Berlin, Berlin, Germany",
        "post": "About the job \n\nBolt engineering teams are working on unique product challenges: complex algorithms for demand prediction, optimal real-time pricing, routing, fraud detection, distributed systems and much more. Volumes are growing at a steady pace. We are looking for an experienced engineer who is well-versed in data technologies.\n\n\nYour daily adventures will include:\n\nDesigning, building and optimizing elements of Bolt\u2019s Data Platform. Main areas include development of Storage and Analytical Systems (Data Lake, Data Warehouse), Data Pipelines (ETLs, ELTs, stream processing) and Machine Learning models infrastructure\nInvestigating and prototyping of new services to improve different aspects of our Data Platform: data quality, monitoring, alerting, performance and costs efficiency\nCoding mostly in Java, Python and TypeScript (previous experience is not required), occasionally in other languages. \nDesigning and optimizing SQL queries and data storage formats \nProactively solving technical challenges and fixing bugs\nContributing ideas to our product development roadmap\nWe are looking for language-agnostic generalists that are able to pick up new tools to solve the problems they face. Check out our blog to know more about all the exciting projects that we are working on: https://medium.com/bolt-labs.\n\nWe are looking for:\n\nExperience in at least one of the modern OO languages (Python, Scala, Java, JavaScript, C++, etc)\n4+ years of experience in software development\nExcellent English and communication skills\nExperience with micro-service and distributed systems\nSolid understanding of algorithms and data structures\nGood knowledge of SQL and experience in at least one of the popular online analytical processing (OLAP) technologies (AWS Redshift, ClickHouse, Presto, Snowflake, Google BigQuery, DataBricks etc)\nA university degree in a technical subject (Computer science, Mathematics or similar)\n\nYou will get extra credits for:\n\nExperience in building and designing real-time and asynchronous systems\nFamiliarity with streaming data technologies for low-latency data processing (Apache Spark/Flink, Apache Kafka, RabbitMQ, Hadoop ecosystem)\nUnderstanding of NoSQL databases (Redis, ElasticSearch, Apache Cassandra)\nExperience in building systems based on cloud service providers (AWS, Azure, Google Cloud)"
    },
    {
        "position": "Data Engineering Manager - BI (They/She/He)",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Glovo",
        "sector": "Consumer Services",
        "companySize": "1,001-5,000 employees",
        "location": "Barcelona, Catalonia, Spain",
        "post": "About the job \n\nAbout Glovo\n\nWe\u2019re a Barcelona-based startup and the fastest-growing delivery player in Europe, Hispanic America and Africa. With food at the core of the business, Glovo delivers any product within your city at any time of day.\n Our vision and ambition are not only to make everything immediately available in your city but it is also to offer our employees the job of their lives. A job where you'll be challenged and have the most fun working in through tech-enabled experiences.\n\nYour Work-life Opportunity\n\nWe are a product-centered company, and data is at the core of product development. In this role, you'll work with key business and product leads, analysts and data scientists to understand the business domain and how data can empower them. Your day-to-day will involve engaging with fellow engineers to develop a robust and scalable platform, to make the process of producing data and deriving insights efficient. You are passionate about the quality of the data you produce and take pride in having your data drive our business.\n\nBe a Part Of a Team Where You Will\n\n\nRecruit, guide, manage and grow a high-performing team of Data Engineers of different seniority levels \nCreate synergies across Business, Product and Engineering to prioritize the most impactful Data Products, enabling Glovo\u2019s mission\nManage the entire lifecycle of your team's projects, from OKRs definition to efficient execution and value delivery\nContribute to Glovo\u2019s Data Mesh strategy and collaborate across departments to improve our overall Data capabilities\nRole Model in Technical Excellence and Engineering Best Practices (from Testing, to CI/CD, to Observability). You\u2019re comfortable acting as a Tech Lead, raising the bar of the team\u2019s competences\nLead architectural discussions (RFCs, Design Documents, \u2026), contribute to technical decisions and drive impactful contributions to our code base and ways of working. In our tech stack we primarily use: SQL, Python, Spark, Redshift, Presto, AWS, Terraform, Docker, Airflow, Luigi, Jenkins, Github, Datadog, Looker, \u2026\nExceptional People Manager, someone the team will admire and follow from day one. You: empathize with people, know how to adapt your leadership style to situations, create trustworthy relationships, show and lead the way, have great communication and influencing skills\nUltimately, you truly care about fostering an inclusive environment and serving your team while taking pride in seeing them grow and be successful, knowing you\u2019ve helped them to get there through continuous coaching and mentoring\n\nYou Have\n\n\n5+ years of experience working in Data Engineering, Business Intelligence, or a similar role and 2+ years of experience managing a team (5+ people) and multiple projects \nExperience designing and building scalable and maintainable data processing systems (both batch and near/real-time) and data models that enable data-driven business decisions and product development \nStrong Product Sense and Project Management, you would be comfortable to act as a Data Product Manager if required \nStrong proficiency and experience with SQL and Python, knowledge of cloud data warehouses (Redshift) and distributed data processing frameworks (Spark, Presto) \nGood understanding of Software Development best practices and Agile methodologies \n\nBonus Points\n\nYou have knowledge of the following:\n\nData Mesh principles with hands-on implementation experience \nData processing tools (dbt, Delta Lake) \nStreaming and Data Lake cloud architectures \nContainerization tools (Docker) \nCI/CD tools (Jenkins, Github Actions) \nAWS services such as EMR, Glue, MWAA and infrastructure as code \nData Analytics and Visualization tools (Looker, Amplitude) \n\nExperience Our Glovo Life Benefits\n\n\nAttractive Relocation package (if applicable ;)) \nComprehensive Private Health Insurance \nCobee discounts on kindergarten, transportation, and food \nFree monthly Glovo credits to spend on our restaurant products (and zero Glovo delivery fee on all Glovo orders!) \nCool perks such as fresh fruit and healthy snacks every day, beers on Fridays, and Culture Days twice a year! \nDiscounted Gym memberships \nFlexible working environment \n\nWhat You\u2019ll Find When Working At Glovo\n\n\nGAS: Driven to deliver quality results quickly \nGood Vibes: Bring positivity and communicate openly \nStay Humble: Self-aware and open to learning \nCare: Uplift people and the planet \nGlownership: Act as proud owners \nHigh Bar: Focus on Top Performance \n\nIf you believe you match these values, we look forward to meeting you!\n At Glovo we believe that diversity adds incredible value to our teams, our products, and our culture. We know that the best ideas and solutions come by bringing together people from all over the world and by fostering a culture of inclusion where everyone feels heard and has the chance to make a real impact. It's because of this that we are committed to providing equal opportunities to talent from all backgrounds.\n Wanna take a peek into what it's like to work at Glovo? Follow us on Instagram and like us on Facebook!\n Glovo is transforming the way consumers access local goods, enabling anyone to get almost any product delivered in minutes. Our on-demand logistics connect customers with independent local couriers who acquire goods from any restaurant or store in a city, as well as deliver urgent packages for a variable fee. As of September 30, 2019, we\u2019re currently present in more than 26 countries across Europe, Latin America, Africa, and Asia.\n For additional information on Glovo, please visit https://glovoapp.com/ | Twitter: @Glovo_ES | Facebook: https://www.facebook.com/glovoappES/ | LinkedIn: https://www.linkedin.com/company/glovo-app/"
    },
    {
        "position": "Microsoft Data Analytics - Engineering Lead - Manager",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Accenture Italia",
        "sector": "IT Services and IT Consulting",
        "companySize": "10,001+ employees",
        "location": "Assago, Lombardy, Italy",
        "post": "About the job \n Are you ready to step up to the New and take your technology expertise to the next level? Join Accenture and help transform leading organizations and communities around the world in achieving their goals faster and more efficiently. The sheer scale of our capabilities and client engagements and the way we collaborate, operate, and deliver value provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career. As part of our Accenture Microsoft Business Group (AMBG) practice, you will lead Technology Innovation to Shape World-Class Business Solutions for our Clients and deliver them at scale. There will never be a typical day and that\u2019s why people love it here. The opportunities to make a difference within exciting Client initiatives are unlimited in the ever-changing technology landscape. You will be part of a growing network of technology experts who are highly collaborative taking on today\u2019s biggest, most complex business challenges. We will nurture your talent in an inclusive culture that values diversity. Come grow Your Career in technology at Accenture! Microsoft Data Analytics-Engineering Lead - Manager will be responsible for working with our Clients and internal teams to help shape Industry Transformation solutions using the Microsoft technology platform and its wide eco-system of partners. Companies and entire Industries need help to reinvent themselves during these challenging times and your job will be to help Companies transform themselves to emerge stronger above and beyond complex contexts such as the current one.\n A solid understanding of challenges that Clients in an Industry are facing, and how to address them using Microsoft technology ecosystem is key for delivering value. This should be combined with experience and understanding of considerations for large scale cloud analytics solutions architecting, helping Clients transforming into a data driven business, developing new data service and data platforms using digital, becoming more agile and resilient.\n We are looking for candidates who have a broad set of technology skills across these areas and who can demonstrate an ability to design the right solutions with an appropriate combination of Microsoft and its 3rd party technologies for deploying on the Microsoft Intelligent Data Platform. Key responsibilities may include:\n\n\n\nAs a data analytics-engineering lead, you will work with implementation teams from concept to delivery, providing data and applied intelligence expertise for successfully deploying large scale digital data and analytics solutions in the enterprise, using modern digital technologies on premise and cloud\n\n\nYou will play a key role in leading the data engineering workstream of analytics transformation projects across multiple areas / domains, such as sales, marketing, supply chain, revenue management, etc.\n\n\nYou will act as lead and supervisor in data ingestion, preparation, and storage activities, such as:\n\n\ndefining Microsoft data architecture layers and data models for proof of concepts, pilots, projects\n\n\ndefining key data interfaces and transformation logics\n\n\ndefining and reviewing code for data cleansing, data checks and data transformations / preparations steps for data science (i.e. time series preparation, internal vs external data matching, base price smoothing, price imputation).\n\n\nLead cloud analytics solution and scoping to generate estimates and approaches for proposals and SOWs for Clients\n\n\nYou will work closely with:\n\n\nClient data leads to transfer / explain input data requirements and perform data assessment\n\n\nAccenture data engineering programmers to coach and grow junior resources on data curation and data transformation / harmonization activities\n\n\nAccenture and Client data scientists to gather advanced analytics data preparation requirements, back and forth on statistical data validation / QA, \u2026\n\n\nCreate detailed target state technical, security, data and operational architecture and design blueprints incorporating modern digital technologies and cloud services, demonstrating modernization value proposition\n\n\nCo-lead and/or support detail technical assessments of current state of analytics architectures and data platforms and architect a path to transformation into a modern data powered enterprise / landscape\n\n\nConduct full technical discovery, identifying pain points, business, and technical requirements, \u201cas is\u201d and \u201cto be\u201d scenarios\n\n\nCompare solution alternatives across both technical and business parameters which support the definition of cost and service requirements\n\n\nApply methodology, reusable assets, and previous work experience to deliver consistently high-quality work\n\n\nDeliver written or oral status reports regularly\n\n\nStay educated on new and emerging analytics technologies/patterns/methodologies and market offerings that may be of interest to our Clients\n\n\nAdapt to existing methods and procedures to create possible alternative solutions to moderately complex problems\n\n\nUse considerable judgment to define solutions and seeks guidance on complex problems\n\n\nSupport answers to RFPs issued by Clients\n\nRequired Qualifications\n\nTechnical\n\n\n\n\nAn academic degree on Computer Science / Information Technology or Industrial Engineering\n\n\nSignificant experience in technical solutions implementation, architecture design, and engineering programming / coding on MSFT platform\n\n\nSignificant experience (or similar) in the following technologies and tools:\n\n\nAzure Databricks (primary)\n\n\nPython (PySpark)\n\n\nScala\n\n\nSQL\n\n\nAzure SQL DWH / Synapse (primary)\n\n\nAzure Datafactory (ADF)\n\n\nPower BI\n\n\nDAX\n\n\nPower Query / M\n\n\nSpecial focus on Dynamics Customer Insights, Customer Data Platform (CDP), Customer Data Architecture (CDA), Microsoft Common Data Model (CDM / IDW), etc.\n\n\nKnowledge of the Microsoft technologies including Microsoft Azure, Microsoft 365 (Office 365), Dynamics-365, Power-Platform\n\nFunctional\n\n\nDeep and strong knowledge and expertise in the broad analytics area cross industry\n\n\nMultiyear experience in activities such as: data maturity assessment and analysis, data ingestion, data cleansing and harmonization, data preparation and advanced analytics transformation through data science, machine learning, data visualization, data architecture, data security, etc.\n\n\nSpecific industry knowledge required with preference on Consumer Goods & Services and/or Retail\n\n\nKnowledge in Revenue Management (Trade Promotion Optimization, Pack Price Architecture, Assortment Optimization, Customer Segmentation, ...) is good to have\n\n\nKnowledge in Sales & Marketing topics (Customer Business Planning, Account Planning, Trade Promotion Management) is good to have"
    },
    {
        "position": "Data Engineer with Development Skills",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "H&M Group",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nCompany Description\n\nAt H&M, we are on an exciting journey where fashion and tech make magic together. As rapid technological development and new customer behaviors are transforming the fashion retail industry, our mission is to meet and exceed our customers' expectations. All while keeping in mind sustainable practices. We know that the best ideas evolve when great minds with different backgrounds and perspectives get together.\n At H&M, we are all on the same team in a global environment where we learn from each other and grow together. We live our values and know that sharing knowledge is the best way to continuously improve our ways of working and creating.\n We are proud to foster a workplace free from discrimination. We strongly believe that diversity of experience, perspectives, and background will lead to a better environment for our employees and a better product for our users. H&M Group \u2013 Business Tech.\n There are countless reasons for you to consider joining H&M, but here is a list we think summarizes the most important ones:\n\nThere are tremendous amounts of growth opportunities: we have many courses and workshops running so that you can become your best-self;\nYou will be surrounded by incredible colleagues from all around the globe;\nYou will experience what being part of a large organization means;\nThe opportunity to always be on the forefront of tech and fashion\n\nAre you a Data Engineer with development skills. Do you have a passion for large scale cutting edge analytics and data platforms? Do you think Kubernetes is the way forward in a multi cloud world? Do you think that everything could be automated with pipelines? Do you want to work in an enablement team building cool stuff that empowers a multitude of product teams? Then this is the opportunity for you!\n\nJob Description\n\nIn Common Tools and Services we empower all product teams by building the tools and services that makes sure H&M Group\u2019s data and analytic platforms are awesome. You will build self-service data platforms and integrations solutions at enterprise level. You will join a team of amazing professionals with great opportunity to contribute with your own creative ideas. As a team we have innovation sprints and lab days so we can evolve and develop new ideas.\n\nSome of your daily tasks include:\n\n\nDesign and develop our large scale Apache Kafka platform in Kubernetes. You will work both on a strategic level and with hands-on implementation and also support other teams in data platform and integration advisory including advanced troubleshooting.\nDesign and develop our test automation framework that is an important tool for our data engineers.\nDesign and develop our deployment pipelines used by many product teams.\nTranslate strategies and requirements into modern, innovative and scalable solutions\n\nQualifications\n\nWe are looking for someone that is smart, humble and hungry in helping us build our next modern data platform, you will play a key role in our data transformation journey. We believe you have the ability to understand and\u202fanalyze\u202fcomplex information as well as being able to communicate with others regardless of their IT knowledge.\n You work proactively and with continuous improvements in a fast transforming environment. You enjoy working with implementation and taking operational aspects into account.\n\nTo do this, we think you have a curious mindset, excellent communication skills as well as:\n\n\nExperience in Cloud (Azure, GCP)\nExperience in Kubernetes, Docker and containerization.\nExperience in Python and/or Java\nMeritorious with experience in Devops\nMeritorious with experience in Apache Kafka\n\nLeadership? In this role you will act as a thought leader towards other product team. You should be in the frontline on both new technology and H&M strategies.\n\nAdditional Information\n\nThis is a full-time position with a placement in Stockholm.\n Please apply with CV and cover letter as soon as possible, as a part of the process you may be asked to complete a test connected to engineering. Interviews will be held continuously. And We love code! So If you have contributed to Github project(s), also send those to us together with the CV. We are more than happy to take a look!"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Roche",
        "sector": "Biotechnology Research",
        "companySize": "10,001+ employees",
        "location": "Pozna\u0144, Wielkopolskie, Poland",
        "post": "About the job \n The Position\nData Engineer\nIT INNOVATORS IN HEALTHCARE\n\nWe do #Code4Life creating innovative software that helps doctors, patients, and scientists around the world.\n\nWho We Seek\n\n\n\nProven experience in the designing and delivery of complex Data Engineering solutions\nKnowledge about designing and developing at-scale ETL/ELT processes and frameworks on the cloud platforms - preferably AWS \nProgramming skills in scripting languages like Python, R, and Bash as well as knowledge about data processing using SQL\nExperience with Docker and Kubernetes and knowledge about designing CI/CD data processing pipelines\n\n\nYour main responsibilities will be:\n\n\n\nCollaboration with Architects, Tech Leaders and development team to identify and implement automation strategies that enable high-quality, faster delivery of data products\nWork on strategy, plan, and execution of Data Engineering / DataOps concepts on a large scale\nActing as a Data Engineering evangelist promoting DataOps culture among development teams within the organization\n\n\n\nWhat We Appreciate\n\n\n\nExperience with data processing tools like Airflow (standalone or AWS MWAA), AWS Glue, Lambda, and AWS Step Functions, DBT\nExperience with the data quality tools and frameworks \n\n\n\nWhat You Get\n\n\n\nSalary range 16 000 - 21 000 PLN gross\nAnnual bonus payment based on your performance\nEmphasis on continuous personal and professional self-development supported by a dedicated training budget (training, certifications, conferences, diversified career paths etc.)\nExperienced and professional colleagues and workplace that supports innovation and new ideas\nHighly flexible working hours (starting your day at 7-11) and workplace according to employee\u2019s needs and preferences* (regular office/home office)\nA chance to work on solutions which can improve patients\u2019 lives \n\n\n\nAdditional Benefits\n\n\n\nRelocation package\nprivate healthcare and insurance\nhealth, well-being and sport promotion\nsupport for parents and families\nstock share purchase additions\nyearly sales of company laptops and cars\nadditional vacation time for long-term employees and more\n\n\nAPPLY DIRECTLY\n\nApply directly via Workday, pressing the blue button at the top.\n\nIf you feel this offer suits a friend of yours, we\u2019ll appreciate you letting them know! Simply copy and share the link from the browser.\n\nIf you have any questions regarding the offer and would like to contact us directly, please write to us at katarzyna.wisniewska@roche.com\nWANT TO KNOW MORE?\n\nCheck our website for more details, e.g. the career path, recruitment process, etc.https://it.roche.pl/work-with-us\nWant to know what it\u2019s like to be a part of Roche IT first-hand? Check out our blog! You will meet the community members there, sharing their experience and impressions from diverse perspectives, not only about their job but also their lives.https://www.roche.com/careers/weareroche.htm\nPlease note that during the pandemic we are working and recruiting 100% remotely.\nRoche is an equal opportunity employer. We care about inclusion in terms of gender, age, race, skin colour, nationality, religion, marital status, sexual orientation, background, physical or mental disabilities and on every other grounds. Applying for our position, we assure you that we will assess your application solely on the basis of your competencies.\n\nAdministratorem Pani/Pana danych osobowych jest sp\u00f3\u0142ka Roche Polska Sp. z o.o., ul. Domaniewska 39 B, 02-672 Warszawa. Dane przetwarzane s\u0105 w celu prowadzenia rekrutacji. Przys\u0142uguje Pani/Panu prawo dost\u0119pu do tre\u015bci swoich danych, ich sprostowania, usuni\u0119cia, ograniczenia przetwarzania, przenoszenia oraz \u2013 w sytuacji, gdy s\u0105 one przetwarzane na podstawie udzielonej zgody \u2013 cofni\u0119cia tej\u017ce zgody w dowolnym momencie. Kontakt do Inspektora Ochrony Danych:ochrona.danych@roche.com. Wi\u0119cej informacji o zasadach przetwarzania przez Roche Pani/Pana danych osobowych pod linkiem: \n\n https://www.roche.pl/pl/content/klauzula-informacyjna-rekrutacja-pl.html \nThe controller of your personal data is Roche Polska Sp. z o.o., ul. Domaniewska 39 B, 02-672 Warsaw. The data is processed for the purpose of recruitment. You have the right to access your data, rectify it, delete it, limit processing, transfer it and - if processing is based on your consent - withdraw this consent at any time. Contact the Data Protection Officer at: Ochrona.danych@roche.com. More information on the principles of processing your personal data by Roche at the link: \n\n https://www.roche.pl/pl/content/klauzula-informacyjna-rekrutacja-en.html \nWho we are\nAt Roche, more than 100,000 people across 100 countries are pushing back the frontiers of healthcare. Working together, we\u2019ve become one of the world\u2019s leading research-focused healthcare groups. Our success is built on innovation, curiosity and diversity.\nAt Roche Poland, we are more than 800 professionals working together on one mission. We are proud of who we are, what we do and how we do it. Join us in the area of Clinical Research, Medical, Marketing, IT or business departments.\nRoche is an Equal Opportunity Employer."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Crayon",
        "sector": "Biotechnology Research",
        "companySize": "10,001+ employees",
        "location": "Pozna\u0144, Wielkopolskie, Poland",
        "post": "About the job \n\n\n\n\nInterested in an exceptional career opportunity for a true data enthusiast?\n\nEnjoy a role that involves the latest cloud data platform technologies and frameworks?\n\nKeen to join a technologist driven growing global company?\n\n\n\n\n\nApply now and join our global team as a Senior Data Engineer for Crayon! \n\n\nCrayon's data platform is developed as the cornerstone that enables the company to be data-driven, from enabling business intelligence, to supporting products and services, to AI-enabled solutions for greater efficiency across Sales, Finance and more. We leverage modern technologies and best practices, including Azure DevOps, Synapse and Purview, a hybrid data mesh ownership model on top of a lake house, ability to build self-service reporting. All with proper security, privacy and governance in mind. \n\n\nAs a data platform team member, you will drive best practices to make data sources available to business, including dependency resolution and data governance. You will also have the opportunity to work with the team in building the overall platform, from data architecture design to CI/CD pipelines, from implementing privacy by design to defining the access model. \n\n\nKey responsibilities to highlight:\n\n\nIdentify data sources, design and integrate entities that allow meeting requirements from business stakeholders \nDiagnose data quality issues and liaise with data source owners to come up with potential preventive or corrective measures \nImplement pipelines using a combination of technologies, including git, SQL, Spark, Python and the Azure data tech stack \nBuild datasets that create data-driven insight, influence operational decision-making, and enable data-driven products and services \nWork with your colleagues to build a flexible and scalable platform, both implementation-wise and operationally \n\n\n\nWe envisage you to be a self-managing and self-motivated individual, with strong organizational and time management skills, who works structured and methodically through your daily tasks. Furthermore, you are a team player with effective collaboration and communication skills. Moreover, you have solution-oriented mindset, and you deliver excellent service to our clients. \n\n\nDesired competency & experience:\n\n\n5 years+ professional experience in designing, building, and maintaining scalable, high-performance data solutions \nFluency in Python \nStrong practical experience with ETL and ELT, as well as with the Azure data ecosystem (DevOps, ADF, ADLS, Synapse) or, alternatively, equivalent in another cloud \nUnderstanding of software development best practices \nExperience with Delta Lake, APIs (REST, GraphQL), data from CRM and/or ERP systems, Spark, and related technology ecosystem, as well as Azure Data Engineer Associate certification are valuable \n\n\n\nPRACTICAL INFORMATION:\n\n\nLocation for this job: Remote, Sweden, Austria, Serbia, UK or Spain\n\nLanguage requirements: Excellent written and verbal English skills \nApplication deadline: ASAP. We will evaluate candidates continuously. \nVisa requirements: Must have work permit/visa. We are looking for someone who is ideally already based in one of the mentioned countries, and that could start relatively quickly"
    },
    {
        "position": "Process Engineer II (Senior Data Engineer)",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Kite Pharma",
        "sector": "Biotechnology Research",
        "companySize": "1,001-5,000 employees",
        "location": "Hoofddorp, North Holland, Netherlands",
        "post": "About the job \n Kite is continuing to hire for all open roles. Our interview process may be conducted virtually and some roles will be asked to temporarily work from home. Over the coming weeks and months, we will be implementing a phased approach to bringing employees back to site to ensure the health and safety of our teams.\nFor Current Kite Pharma Employees and Contractors:\nPlease log onto your Internal Career Site to apply for this job.\n\nJob Description\n\nSenior Data Engineer - MSAT\nEveryone at Kite is grounded by one common goal \u2013 curing cancer. Every single day, we seek to establish a direct line between that purpose and our day-to-day work. Would you like to join us in this mission?\nKite is seeking a highly motivated individual with data engineering experience to work with structured and unstructured data and create data models to support for data science and data analytics team analyses innovative T cell therapies used for cancer treatment. As a Senior Data Engineer for Manufacturing Sciences and Technology (MSAT), you will develop data models and manage datasets to support decision making within MSAT. Act as an internal consultant by integrating different data sources and combine complex datasets to create the fundamentals for further advanced data analysis within the data science and data analytics team. You are a self-starter with experience and passion for data and big data scale processing. You enjoy working in fast-paced environments and making an impact. You are an exceptional communicator with the ability to translate technical concepts into easy-to-understand language for our stakeholders.\nCore Responsibilities\n\n\n\nPartner with MSAT teams, data scientists and data analysts to design and build data pipelines, and define the overall MSAT data strategy\nManage datasets on data infrastructure platforms\nUndertake preprocessing of structured and unstructured data\nDesign and implement end-to-end data pipelines: work closely with stakeholders to build instrumentation and define dimensional models, tables or schemas that support MSAT processes\nDevelop, execute, manage data validation tests and data quality checks and implement monitoring in the pipelines to ensure confidence in the data\nEnsures data appears in the right format and the right systems for analysts and scientists to use\nBuild actionable KPIs, production-quality dashboards, informative deep dives, and scalable data products\nDesign and build visualization tools\nIntegrate data collection for data automation\nDevelop and improve data-based process performance monitoring systems\nWork with systems that consolidate the data across the organization\nPerform SQL tuning as necessary\nCarry out ad-hoc analysis as necessary\nConduct technical and scientific training\nAdditional duties as assigned\n\n\nRequired Skills And Experience\n\n\n\nBachelor\u2019s degree, in Computer Science or related field. Master\u2019s degree preferred\n5+ years of experience working as a Business Analyst or Data Engineer\n3+ years of experience working with cloud data warehouses (Snowflake, Redshift, etc.)\nProficient in SQL and Data Modeling\nExperience working within cloud computing environments such as AWS, Azure, Google Cloud\nComfort working in a dynamic environment with several ongoing concurrent projects\nAbility to work independently and cross-functionally with team members of all levels\n3+ years of experience working with data visualization tool Power BI or Spotfire\nCuriosity about the problem domain and an analytical approach \nStrong sense of ownership and growth mindset\n\n\nApply now!\n\nKite is a biopharmaceutical company engaged in the development of innovative cancer immunotherapies with a goal of providing rapid, long-term durable response and eliminating the burden of chronic care. The company is focused on chimeric antigen receptor (CAR) and T cell receptor (TCR) engineered cell therapies designed to empower the immune system's ability to recognize and kill tumors. Kite is based in Santa Monica, CA. For more information on Kite, please visit www.kitepharma.com. Sign up to follow @KitePharma on Twitter at www.twitter.com/kitepharma.\nEqual Employment Opportunity (EEO)\nIt is the policy of Gilead Sciences, Inc. and its subsidiaries and affiliates (collectively \"Gilead\" or the \"Company\") to recruit select and employ the most qualified persons available for positions throughout the Company. Except if otherwise provided by applicable law, all employment actions relating to issues such as compensation, benefits, transfers, layoffs, returns from layoffs, company-sponsored training, education assistance, social and recreational programs are administered on a non-discriminatory basis (i.e. without regard to protected characteristics or prohibited grounds, which may include an individual\u2019s gender, race, color, national origin, ancestry, religion, creed, physical or mental disability, marital status, sexual orientation, medical condition, veteran status, and age, unless such protection is prohibited by federal, state, municipal, provincial, local or other applicable laws). Gilead also prohibits discrimination based on any other characteristics protected by applicable laws.\nFor Current Kite Pharma Employees and Contractors:\nPlease log onto your Internal Career Site to apply for this job."
    },
    {
        "position": "Data Science Internship (non-thesis): Optimization of SQL Database for Field Data Mining",
        "jobType": "Internship",
        "jobLevel": "Internship",
        "company": "ASML",
        "sector": "Semiconductor Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Veldhoven, North Brabant, Netherlands",
        "post": "About the job \n\nIntroduction\n\nIntroduction Are you a bachelor or master student in data science, computer science, or similar? Are you highly interested in cutting edge technology and big data? Do you have an affinity with Matlab, data engineering and MySQL? If so, this internship could be interesting for you!Background information\n\nIn Business Line Applications, we create application products that run in most modern semiconductor fabs in the world. Our department develops, integrates, and qualifies functional modules in products used to monitor and control on-product performance under high-volume manufacturing conditions. In our group On-product performance Technology Enablers, we believe that deep understanding of on-product performance and its contributors enables the development of the technology roadmap. One of our activities in collaboration with business line DUV, system performance investigation - field data mining (SPI-FDM), utilizes large amounts of customer scanner and on-product performance data from the field in order to enable this understanding. This data is stored, contextualized and managed using a custom-made SQL database. With increasing amounts of data and new data types gradually being added, the complexity of this database also increases steadily.\n\nYour assignment\n\nThe proposed assignment will help our project greatly by making our database future proof. As an intern in the team, you will\n\nSimplify, optimize and standardize the data ingestion procedure and tooling;\nSimplify and optimize the data base structure for ingestion and data retrieval speed, as well as ease of use;\nImplement additional features and the ingestion of new data file types;\nDocument the tooling and design (incl. tooling repository), prepare knowledge transfer material and script examples for users inside and outside SPI FDM.\n\nThis is an apprentice internship for a duration of 4 to 6 months, 5 days per week, starting as soon as possible.\n\nYour profile\n\nTo be the perfect match for this position, you\n\nAre a bachelor or master student in data science, computer science, or similar;\nHave an affinity with Matlab, MySQL and data engineering;\nAre proactive, eager to learn and not afraid to ask questions; \nHave a genuine interest towards cutting edge technology, semiconductors and big data;\nSpeak and write English proficiently.\n\nKnowlegde of hadoop and other non-SQL database formats is considered a plus.\n Please note that we may only consider students who remain enrolled at their educational facility for the entire duration of the internship.\n\nDiversity and inclusion\n\nASML is an Equal Opportunity Employer that values and respects the importance of a diverse and inclusive workforce. It is the policy of the company to recruit, hire, train and promote persons in all job titles without regard to race, color, religion, sex, age, national origin, veteran status, disability, sexual orientation, or gender identity. We recognize that diversity and inclusion is a driving force in the success of our company.\n\nOther Information\n\nChange the world \u2013 one nanometer at a time\n Become an intern at a Dutch company that\u2019s a global industry leader. You\u2019ll gain valuable experience in a highly innovative environment \u2013 one that sparks your imagination and creativity. In addition to a monthly internship allowance of maximum \u20ac600 (plus a possible housing and/or travel allowance), you\u2019ll get practical guidance from experts in the field and the chance to work in and experience a dynamic team environment.\n ASML be part of progress\n ASML is a high-tech company headquartered in the Netherlands. We manufacture the complex lithography machines that chipmakers use to produce integrated circuits, or computer chips. What we do is at the heart of all the electronic devices that keep us informed, entertained and connected. Every day, you use electronics that simply wouldn\u2019t exist without our machines.\n Behind ASML\u2019s innovations are engineers who think ahead. The people who work at our company include some of the most creative minds in physics, electrical engineering, mathematics, chemistry, mechatronics, optics, mechanical engineering, and computer science and software engineering.\n We believe we can always do better. We believe the winning idea can come from anyone. We love what we do \u2013 not because it\u2019s easy, but because it\u2019s hard.\n Students getting ready for real-world R&D\n We\u2019re a global team of about 29,000 people of 120 different nationalities and counting. Headquartered in Europe\u2019s top tech hub, the Brainport Eindhoven region in the Netherlands, our operations are spread across Europe, Asia and the US.\n In such an environment, your colleagues may be sitting next door, or they could be thousands of kilometers away in a different country \u2013 or even working for a different company.\n An internship at ASML is the opportunity to get to know not only the world of industrial-strength R&D, but yourself \u2013 you\u2019ll discover just what excites you most. Will you design a part of the machine, or make sure it gets built to the tightest possible specifications? Will you write software that drives the system to its best performance, or work side-by-side with the engineers of our customers in a fab, optimizing a system to the requirements of the customer?\n How will you be part of progress?"
    },
    {
        "position": "Data Science Internship (non-thesis): Optimization of SQL Database for Field Data Mining",
        "jobType": "Internship",
        "jobLevel": "Internship",
        "company": "ASML",
        "sector": "Semiconductor Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Veldhoven, North Brabant, Netherlands",
        "post": "About the job \n\nIntroduction\n\nIntroduction Are you a bachelor or master student in data science, computer science, or similar? Are you highly interested in cutting edge technology and big data? Do you have an affinity with Matlab, data engineering and MySQL? If so, this internship could be interesting for you!Background information\n\nIn Business Line Applications, we create application products that run in most modern semiconductor fabs in the world. Our department develops, integrates, and qualifies functional modules in products used to monitor and control on-product performance under high-volume manufacturing conditions. In our group On-product performance Technology Enablers, we believe that deep understanding of on-product performance and its contributors enables the development of the technology roadmap. One of our activities in collaboration with business line DUV, system performance investigation - field data mining (SPI-FDM), utilizes large amounts of customer scanner and on-product performance data from the field in order to enable this understanding. This data is stored, contextualized and managed using a custom-made SQL database. With increasing amounts of data and new data types gradually being added, the complexity of this database also increases steadily.\n\nYour assignment\n\nThe proposed assignment will help our project greatly by making our database future proof. As an intern in the team, you will\n\nSimplify, optimize and standardize the data ingestion procedure and tooling;\nSimplify and optimize the data base structure for ingestion and data retrieval speed, as well as ease of use;\nImplement additional features and the ingestion of new data file types;\nDocument the tooling and design (incl. tooling repository), prepare knowledge transfer material and script examples for users inside and outside SPI FDM.\n\nThis is an apprentice internship for a duration of 4 to 6 months, 5 days per week, starting as soon as possible.\n\nYour profile\n\nTo be the perfect match for this position, you\n\nAre a bachelor or master student in data science, computer science, or similar;\nHave an affinity with Matlab, MySQL and data engineering;\nAre proactive, eager to learn and not afraid to ask questions; \nHave a genuine interest towards cutting edge technology, semiconductors and big data;\nSpeak and write English proficiently.\n\nKnowlegde of hadoop and other non-SQL database formats is considered a plus.\n Please note that we may only consider students who remain enrolled at their educational facility for the entire duration of the internship.\n\nDiversity and inclusion\n\nASML is an Equal Opportunity Employer that values and respects the importance of a diverse and inclusive workforce. It is the policy of the company to recruit, hire, train and promote persons in all job titles without regard to race, color, religion, sex, age, national origin, veteran status, disability, sexual orientation, or gender identity. We recognize that diversity and inclusion is a driving force in the success of our company.\n\nOther Information\n\nChange the world \u2013 one nanometer at a time\n Become an intern at a Dutch company that\u2019s a global industry leader. You\u2019ll gain valuable experience in a highly innovative environment \u2013 one that sparks your imagination and creativity. In addition to a monthly internship allowance of maximum \u20ac600 (plus a possible housing and/or travel allowance), you\u2019ll get practical guidance from experts in the field and the chance to work in and experience a dynamic team environment.\n ASML be part of progress\n ASML is a high-tech company headquartered in the Netherlands. We manufacture the complex lithography machines that chipmakers use to produce integrated circuits, or computer chips. What we do is at the heart of all the electronic devices that keep us informed, entertained and connected. Every day, you use electronics that simply wouldn\u2019t exist without our machines.\n Behind ASML\u2019s innovations are engineers who think ahead. The people who work at our company include some of the most creative minds in physics, electrical engineering, mathematics, chemistry, mechatronics, optics, mechanical engineering, and computer science and software engineering.\n We believe we can always do better. We believe the winning idea can come from anyone. We love what we do \u2013 not because it\u2019s easy, but because it\u2019s hard.\n Students getting ready for real-world R&D\n We\u2019re a global team of about 29,000 people of 120 different nationalities and counting. Headquartered in Europe\u2019s top tech hub, the Brainport Eindhoven region in the Netherlands, our operations are spread across Europe, Asia and the US.\n In such an environment, your colleagues may be sitting next door, or they could be thousands of kilometers away in a different country \u2013 or even working for a different company.\n An internship at ASML is the opportunity to get to know not only the world of industrial-strength R&D, but yourself \u2013 you\u2019ll discover just what excites you most. Will you design a part of the machine, or make sure it gets built to the tightest possible specifications? Will you write software that drives the system to its best performance, or work side-by-side with the engineers of our customers in a fab, optimizing a system to the requirements of the customer?\n How will you be part of progress?"
    },
    {
        "position": "Analyst or Senior Analyst or Associate Manager(Bangkok Based, relocation provided)",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Agoda",
        "sector": "Technology, Information and\n                                                            Internet",
        "companySize": "5,001-10,000 employees",
        "location": "Amsterdam, North Holland, Netherlands",
        "post": "About the job \n\nAbout Agoda\n\nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 4,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u202fenhancing the ability for our customers to experience the world.Get to Know ourTeam: \n\nThe Performance Marketing Team of Agoda is a world leader in online marketing. This department is highly data-driven and focused on developing at-scale marketing programs that improve the lifetime value of Agoda customers through measurable marketing programs and channels. The team is a blend of the best analysts, marketing strategists, and data scientists in the world. The marketing leadership at Agoda have deep experience in data science, product, strategy, and other marketing fields and have built an organization that thrives on data, creative ideas, and technology. The Performance Marketing Team also fosters a great learning environment. You will be able to learn and grow by working closely with experts from a variety of backgrounds from all over the world.In this Role, you\u2019ll getto: \n\n\n\nSearch: Experiment with text ads, bidding, and campaign structures on Google, Bing, Baidu, Naver, and other search engines. Adapt to new product features and roll out changes from successful tests\nDisplay: Test, analyze, and optimize campaigns on Facebook, Twitter, Instagram, and others\nModeling: Analyze the vast amounts of data generated by experiments, develop models we can use for optimization, and build dashboards for account managers\n\nWhat you\u2019ll Need toSucceed: \n\n\n\nBachelor\u2019s Degree or higher from top university in a quantitative subject (computer science, mathematics, engineering, statistics or science)\nAbility to communicate fluently in English\nGood numerical reasoning skills\nProficiency in Excel\nIntellectual curiosity\n\nIt\u2019s Great if youHave: \n\n\n\nExposure to one or more data analysis packages or databases, e.g., SAS, R, SPSS, Python, VBA, SQL\nExperience in digital marketing\nAcademic research experience\n\n\n#STRA#ANLS#MRKT#3 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis\ndata representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics microsoft power bi java finance shopee traveloka google facebook ctrip trip.com makemytrip grab amazon pandas (software) artificial intelligence (ai) information technology capital one accenture upwork deloitte mckinsey bain microsoft uber lyft gojek lazada alibaba shopify expedia skyscanner\nEqual Opportunity Employer \n\nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u2019s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy .\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes."
    },
    {
        "position": "Analyst or Senior Analyst or Associate Manager(Bangkok Based, relocation provided)",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Agoda",
        "sector": "Technology, Information and\n                                                            Internet",
        "companySize": "5,001-10,000 employees",
        "location": "Amsterdam, North Holland, Netherlands",
        "post": "About the job \n\nAbout Agoda\n\nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 4,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u202fenhancing the ability for our customers to experience the world.Get to Know ourTeam: \n\nThe Performance Marketing Team of Agoda is a world leader in online marketing. This department is highly data-driven and focused on developing at-scale marketing programs that improve the lifetime value of Agoda customers through measurable marketing programs and channels. The team is a blend of the best analysts, marketing strategists, and data scientists in the world. The marketing leadership at Agoda have deep experience in data science, product, strategy, and other marketing fields and have built an organization that thrives on data, creative ideas, and technology. The Performance Marketing Team also fosters a great learning environment. You will be able to learn and grow by working closely with experts from a variety of backgrounds from all over the world.In this Role, you\u2019ll getto: \n\n\n\nSearch: Experiment with text ads, bidding, and campaign structures on Google, Bing, Baidu, Naver, and other search engines. Adapt to new product features and roll out changes from successful tests\nDisplay: Test, analyze, and optimize campaigns on Facebook, Twitter, Instagram, and others\nModeling: Analyze the vast amounts of data generated by experiments, develop models we can use for optimization, and build dashboards for account managers\n\nWhat you\u2019ll Need toSucceed: \n\n\n\nBachelor\u2019s Degree or higher from top university in a quantitative subject (computer science, mathematics, engineering, statistics or science)\nAbility to communicate fluently in English\nGood numerical reasoning skills\nProficiency in Excel\nIntellectual curiosity\n\nIt\u2019s Great if youHave: \n\n\n\nExposure to one or more data analysis packages or databases, e.g., SAS, R, SPSS, Python, VBA, SQL\nExperience in digital marketing\nAcademic research experience\n\n\n#STRA#ANLS#MRKT#3 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis\ndata representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics microsoft power bi java finance shopee traveloka google facebook ctrip trip.com makemytrip grab amazon pandas (software) artificial intelligence (ai) information technology capital one accenture upwork deloitte mckinsey bain microsoft uber lyft gojek lazada alibaba shopify expedia skyscanner\nEqual Opportunity Employer \n\nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u2019s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy .\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes."
    },
    {
        "position": "Data Scientist",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Coop Sverige",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Solna, Stockholm County, Sweden",
        "post": "About the job \n\nAre you looking for an opportunity to make a difference with data and analytics? Then look no further - at Coop we are boldly going where no one has gone before. We are creating a new standard in the food industry as a whole. We are on a journey to innovate new ways of interacting and helping our customers through data and insights.\n\n\nOur awesome AI team is growing and we are looking for a Data Scientist to join us in our journey. Our focus is on developing machine learning solutions that help our needs in saving time, money, improving health and providing sustainable food to Coops customers and members.\n\n\nAbout the role\nIn this position you will:\n\nBuild advanced machine learning models that play a central role in Coop\nWork with massive amounts of data: from digital to physical touchpoints, from items to recipes, from assortment to suppliers, from locations to routes, etc\nDevelop in a full-fledged data science environment, entirely on cloud\nWork in a team of data scientists/engineers, in cross collaboration with many different parts of Coop\nBe part of the whole lifecycle of a data-driven product, from framing a problem to deploying a model in production and monitor performance\n\n\n\nSome of the tools we work with daily are Kubernetes, Azure, Spark among others.\n\n\nSkills & Requirements\n\n\nWe encourage applications from candidates with most of the following skills:\n\nDegree in Computer Science, Engineering or numerate subject\nThorough understanding of machine learning techniques\nHands-on experience with different types of problems, datasets and procedures\nStrong programming competency in Python and Spark\nFluency in relational databases (eg. SQL, Hive)\nExperience working with large datasets on cloud (eg. GCP, Azure) \nFamiliar with the full stack of data science technologies (eg. Kubernetes, Git, Docker, etc)\nGood presentation skills and ability to communicate technical content to both peers and other domain experts\n\n\n\nPreferred skills include:\n\nSolid skills in a deep learning framework (eg. Pytorch, Tensorflow)\nProficiency in Spark\nAbility to write production-level code and build CI pipelines \nInitiative and drive to solve problems, test new technologies and contribute to the team\n\n\n\nWelcome with your application today!"
    },
    {
        "position": "Data Scientist",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Landmark Group",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Lisbon, Portugal",
        "post": "About the job \n\nThe Opportunity\nTo gather data from multiple sources, data processing, exploratory data analysis, measurement, unstructured data analysis , predictive analysis, interpretation of findings and system implementation \n\n\nRole Responsibilities \n\u00b7 Set a strategic direction for data identification, collection and qualification activities\n\u00b7 Develop best practices for data science, considering the full analytical lifecycle\n\u00b7 Clean, consolidate, verify the integrity of data used in analysis \n\u00b7 Develop relevant dashboards for optimising commercial offerings\n\u00b7 Understand customer behaviour using data insights and identify opportunities to develop business solutions\n\u00b7 Create analytics to gauge the patterns in customer data to assist in outlook forecasting\n\u00b7 Interpret large amounts of data using advanced visualization techniques and tools\n\u00b7 Maintain up to date knowledge of latest technology trends \n\n\nRole Requirements\n\n\nExperience & Knowledge\n\u00b7 Master\u2019s degree in statistics, computer science, mathematics or any related field\n\u00b7 Minimum 8 years of experience in relevant position \n\u00b7 Deep understanding of Machine Learning \n\u00b7 Must have worked on data science projects to functionally build algorithms for any retail optimization areas (space, price, promotion, markdown, competition, consolidation, demand)\n\u00b7 Comprehensive analytical skills that thrive on data analysis, monitoring dashboards, and reviewing reports to drive informed forecasting decisions\n\u00b7 Experience working in cross-functional teams and environments\n\u00b7 Strong communications skills with both technical and non-technical stakeholders\n\u00b7 End to end quantitative thinking \n\u00b7 Understanding of statistical computer language (Python, R, SAS) to analyse large data sets \n\nSkills\n\u00b7 Outstanding communication, presentation, and leadership skills\n\u00b7 Excellent organizational and time management skills\n\u00b7 Sharp analytical and problem-solving skills\n\u00b7 Attention to detail\n\u00b7 Ability to coordinate multiple assignments, organize, set priorities, and meet deadlines"
    },
    {
        "position": "Global People Data Analyst",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Scania Group",
        "sector": "Motor Vehicle Manufacturing",
        "companySize": "10,001+ employees",
        "location": "S\u00f6dert\u00e4lje, Stockholm County, Sweden",
        "post": "About the job \n Scania is undergoing a transformation from a supplier of trucks, buses and engines to a supplier of end-to-end sustainable transport solutions. We are on the road to a shift towards digitalization, electrification and automation. Scania operates in over 100 countries around the world, in areas ranging from production of heavy vehicles to optimizing transport and logistical flows. Scania is a part of the TRATON Group listed in the Frankfurt and Stockholm stock exchange. A prerequisite for Scania to be successful in the transformation is a strong and business-driven HR. The Global People & Culture function will be an efficient and people-centric organisation signified by great engagement and capability, working in a robust operating model with a value-driven & People Experience culture.\n\nWe are looking for a Global People Data Analyst to the Global People Analytics team. You will have an important role together with your colleagues in the team in developing the work to collect, analyse, visualize data and make it easy accessible across the Scania organization.\n\nIn Your Role, You Will\n\n\nUse data from a wide range of sources and develop ways to make it visible, accessible and usable for all strategic stakeholders \nSupport strategic People Business Partners in understanding and framing their business challenges, analyse relevant data, supervise with key insights and follow-up\nDesign and conduct internal surveys and ensure that we store them in an ethical and accessible way to follow our global survey strategy\nDrive change and be an ambassador for a data driven culture by visualising appealing studies and value for business\nCollaborate with HR Primary Data team (HR Data Management) and HR Privacy Officers\nContribute in the HR Transformation Programme where data and people analytics are key and highly prioritized\nCollaborate closely with internal stakeholders (e.g. Scania IT, People Services, Global P&C units, People Business Partners) as well as external stakeholders\n\nYour\u202fprofile:\u202f\n You are a passionate Data Analyst preferable with global HR experience. You are highly professional with a combination of analytical skills, an agile mindset, and excellent communication and influencing skills.\n\nWe believe you have a background in statistical and/or mathematical field and work experience from a similar role\nYou have great skills in development of sound survey questions and the whole process in gather data in a relevant survey system \nHigh ethical standards working with personal data is important to you\nExcellent data analysis and communication skills is a part of who you are\nYou also enjoy working in a global environment and supporting specialists across the globe with your expertise\nEnglish is our corporate language and we expect you to be proficient in both speaking and writing\n\nIf you recognize yourself in this you will be an excellent candidate for the role.\n We offer you a flexible workplace together with a both inclusive and motivated team. You will work in an interesting global environment in cooperation with highly experienced colleagues from many different countries and cultures. We invest in people\u2019s development and career together with us.\n\nFurther\u202finformation\u202f\n Please contact Camilla Didriksson, Head of People Analytics, camilla.didriksson@scania.com\n\nApplication\u202f\n A background check might be conducted for this position.\n Send\u202fin\u202fyour\u202fapplication\u202fas\u202fsoon\u202fas\u202fpossible, no later\u202fthan\u202f2022-09-04 .\u202fWe\u202fare looking\u202fforward to\u202fread\u202fyour\u202fapplication!\n Scania is a world-leading provider of transport solutions. Together with our partners and customers we are driving the shift towards a sustainable transport system. In 2020, we delivered 66,900 trucks, 5,200 buses as well as 11,000 industrial and marine power systems to\n our customers. Net sales totalled to over SEK 125 billion, of which over 20 percent were services-related. Founded in 1891, Scania now operates in more than 100 countries and employs some 50,000 people. Research and development are mainly concentrated in Sweden.\n Production takes place in Europe and Latin America with regional product centres in Africa, Asia and Eurasia. Scania is part of TRATON GROUP. For more information visit: www.scania.com"
    },
    {
        "position": "Data Analyst | Remote Friendly Policy",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Tamanna.com",
        "sector": "Technology, Information and\n                                                            Internet",
        "companySize": "51-200 employees",
        "location": "Lisboa, Lisbon, Portugal",
        "post": "About the job \n Are you ready for a real challenge? We're looking for an experienced Data Analyst | Remote Friendly Policy who will be part of the growing international technical team at Tamanna.\n If you're hands-on, with an entrepreneurial spirit, and driven by impact and ownership, keep reading!\n Tamanna is young but growing at high speed, which means you'll take ownership of your projects, work with great autonomy, and see your ideas and initiative being encouraged. Together our cross-disciplinary teams are iterating, experimenting and revolutionizing the retail industry, by building a fully fledged multi-brand marketplace for family fashion & beauty. Our mission is to become the number one destination for the latest shopping trends in the Middle-East with a unique customer-focused, shopping experience.\n\nSo, what will your day look like with us? You will:\n\n\nYou will live in the data. You will be primarily responsible for discovering opportunities to drive growth in user engagement and revenue. \nYou will unlock data for the organization, generating reports to enable discovery and understanding of performance throughout the organization\nYou will combine statistical analysis with business knowledge to help influencing decision-making at various levels. \nYou will work directly with stakeholders to gather requirements, share insights, and help drive the business. \nYou will help building and improving the Data ecosystem\n\n\nWhat we are looking for:\n\n\nStrong problem-solving and analytical skills and the ability to collect, organize, analyse and disseminate significant amounts of information with attention to detail and accuracy,\nPassion for driving business decisions through data-driven insights. \nYou have proven working experience as a Data Analyst or Business Data Analyst, preferably, in the E-commerce field. \nStrong communicative skills. The ability to prepare and present concise and clear results to stakeholders. \nExpertise in creating reports via Power BI and building optimized and robust DAX queries in addition to Power BI optimization (aggregated tables). \nExpertise with SQL and working with databases is necessary. \nExperience with Python is a nice-to-have especially within the Spark/Databricks ecosystem. \nExperience with the Azure Data Stack is a nice-to-have, Azure Synapse Analytics in particular. \n\n\nWhat our hiring process looks like?\n\n\nYou apply with your CV for the position\nWe will analyse it; if shortlisted, we will schedule a screening call with our recruiter. \nA screening call helps us understand your motivation, experience, and cultural fit with TAMANNA. \nTechnical Challenge. \nTechnical interview \nFinal interview \nJob offers. \n\n\n(These steps can be different according to your seniority)"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Fortum",
        "sector": "Utilities",
        "companySize": "5,001-10,000 employees",
        "location": "Stockholm City, Stockholm County, Sweden",
        "post": "About the job \n Business Technology drives digitalization at Fortum, enabling smart solutions for customers, improved asset and trading productivity, and new data driven business models. The organization brings together technical and digital competences and solutions to help optimize Fortum\u2019s entire value chain, create excellent customer experiences and drive new sources of revenue.\n\nAbout The Role\n\nWe are looking for a Data Engineer with experience on building big data solutions to join our Asset & Markets Data Platforms team in Espoo, Finland or Stockholm, Sweden. Data Platforms teams are a part of a larger Data Management team that helps our internal customers to develop and operate our data related services such as data lakes, warehouses, and visualization applications in modern cloud environment using the latest technology and methodology. As your first assignment you will be working in a team responsible of a data platform collecting, storing, processing, and sharing data from Fortum\u2019s energy production assets, mainly hydro power plants, wind parks, and district heating network.\n\nResponsibilities:\n\n\n\nDesign and implement data solutions, pipelines and infrastructure defined in the product backlogs\nIdentify, design and implement internal process improvements \nImprove team ways of working and the quality of our work\nTransform complicated business problems into data pipelines\nContribute to the development, operation and architectural design of complex data platforms\nReview the work of other data engineers and take an active role in supporting Junior Data Engineers in their career path\nActively find ways to learn from team members and stakeholders, and share knowledge beneficial to the team\n\n\nThis position reports to Manager, Asset & Markets Data Platforms.\n\nWhy Fortum?\n\nWith us, you can take an active role in driving the change for a cleaner world. To reach our goals, we embrace a culture of openness. With mutual trust, believing in people, and taking care of everyone's wellbeing, can we reach even better results. Flexibility is the new normal and we apply hybrid way of working wherever possible.\n For you, working at Fortum means exciting opportunities to develop your expertise and create a unique career path. We will support you on this journey. We believe diversity and inclusion inspire all of us to innovate and grow together. Therefore, we are committed to building teams where everyone feels included and is treated equally.\n\nWhat We Are Looking For\n\nEssential:\n\n\nSc. or M.Sc. degree in Computer Science, Engineering, Mathematics, or a related field, or comparable skills\nHands on experience with cloud platforms (AWS, Azure, or GCP), developing integrations and data processing pipelines\nUnderstanding agile software processes, data-driven development, and data security concepts\nHighly motivated and proactive mentality towards responsibilities\nWillingness and ability to learn more and grow in the role and beyond\nStrong communication and presentation skills in English (written and oral)\nWell-organized and structured working style\n\n\nNot required, but considered as your benefit:\n\n\nDatabricks and/or Snowflake experience\nHands on experience in IoT data (Kepware Server), streaming data (Kafka or AWS Kinesis) and Spark\nCreating and managing cloud infrastructure with Terraform\n\n\nInterested? \n\nPlease send your application via our online recruitment tool by August 15th 2022 at the latest, including your salary request. For further information, please contact Elina Saunam\u00e4ki, on Monday the 8th of August at 16:00-17:00 CET at +358 44 0912 859. You may also ask questions via email to elina.saunamaki(at)fortum.com. To be selected for the position, the applicant must go through background clearance and a health examination including drug testing.\n\nFortum and Uniper form a European energy group committed to enabling a successful transition to carbon neutrality for everyone. Our 50 gigawatts of power generating capacity, substantial gas import and storage operations, and our global energy trading business enable us to provide Europe and other regions with a reliable supply of low-carbon energy. We are already Europe\u2019s third largest producer of CO2-free electricity, and our growth businesses focus on clean power, low-carbon energy, and the infrastructure for tomorrow\u2019s hydrogen economy. In addition, we design solutions that help companies and cities reduce their environmental footprint. Our 20,000 professionals and operations in 40 countries give us the skills, resources, and reach to empower the energy evolution toward a cleaner world. fortum.com; uniper.energy"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Philip Morris International",
        "sector": "Tobacco Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Albarraque, Lisbon, Portugal",
        "post": "About the job \n Make History with us!\n Be part of the biggest transformation in the history of our company \u2013 towards a smoke-free future driven by data.\n The Team\n We are looking for Data Engineer to join our Data Management Engineering team based at our offices in Lisbon or Amsterdam. The team is building a brand-new platform which streamlines data management services and exposes them in a plug-and-play manner. The platform is meant to evolve through time with regular releases of new features, ranging from basic SQL monitoring to ML for data management (data quality, reference data, anomaly detection, standardization\u2026etc.).\n The Role\n As a Data Management Services engineer at PMI, you will join a newly created team which is meant to grow. You will be developing data services on PMI landscape using AWS services (glue, lambda, S3, sagemaker\u2026etc.), Python/Scala and Spark.\n You will also need good notions of data preparation and application management (Airflow orchestration, CICD with Git, Jenkins and JFrog).\n Additionally, we expect you to improve the current level of automation of our platform as well as do code reviews for your peers.\n We are looking for people with 5+ years of experience in Python, Scala (Java), SQL programming and code versioning (ideally GIT) as well as CICD management. We expect you to understand fundamentals of OOP and functional programing. You should also have hands on experience in ETL/ELT (data processing, preparation of automation of pipelines). Experience in AWS Glue, AWS S3, AWS Lambda, AWS Cloud Formation and Docker + Kubernetes will be an asset.\n\nResponsibilities\n\nResearch, evaluate and develop new Data Management Service to support PMI Enterprise Data Platform capabilities to solve new data problems and challenges.Continuously improve the performance of the platform and existing services by reassessing the technology and the architecture.Handle production support issues as they arise (problem solving, debugging).Work in one or more cross-functional teams to develop prototypes, proof of concepts and implementing data projects with a focus on collecting, parsing, managing, analyzing and visualizing large sets leveraging PMI Enterprise Data Platform. Extend and improve our internal frameworks, develop guidelines and best practices.Perform, in collaboration with PMI Enterprise Architecture team, technology and product research to better define requirements, resolve important issues and improve overall capability of PMI Enterprise Data Platform.Communicate with various teams, keeping everyone up-to-date on deployments, outages, issues, and solutions.\n\n\nSkills & Experience\n\nBachelor\u2019s degree in computer science or similarKnowledge and 5+ years of proven experience working withPython (advanced), Scala (Java)SparkSQL programmingBuilding ETL processesCode versioning (GIT/SVN)Data ingestion from APIsProblem solving skillsQuick learning of new technologiesGood communication skills,Good team-work spirit\n\nAs assets\nExperience in AWS Glue, AWS CloudFormation and AWS EMRExperience with AirflowExperience with Docker on KubernetesExperience in Big Data stack (Hadoop ecosystem)\n\nWhat can you expect from the company?\n Our success depends on the men and women who come to work every single day with a sense of purpose and an appetite for progress. Join PMI and you too can\nSeize the freedom to define your future and ours. We\u2019ll empower you to take risks, experiment and explore;Be part of an inclusive, diverse culture, where everyone\u2019s contribution is respected; collaborate with some of the world\u2019s best people and feel like you belong;Pursue your ambitions and develop your skills with a global business \u2013 our staggering size and scale provides endless opportunities to progress;Take pride in delivering our promise to society to deliver a smoke-free future.\n\nWhat we offer you?\nPrivate health insurance for you and your household;Life Insurance;Employee pension plan;Lunch card (Ticket);26 vacations days;Wide range of trainings."
    },
    {
        "position": "IoT Analytics Senior Engineer",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Vodafone",
        "sector": "Telecommunications",
        "companySize": "10,001+ employees",
        "location": "Lisboa, Lisbon, Portugal",
        "post": "About the job \n\nRole Purpose\n\nTo support Vodafone\u2019s key strategic growth areas in IoT, Group Enterprise Technology requires a highly capable and experienced Analytics Data Engineer. This role will be responsible for establishing an end to end deliveries in agile culture within the IoT Reporting, Analytics and BigData team You will develop, manage, execute & take full accountability for bringing Data Solutions for all the IoT systems enabling all required capabilities to all of the IoT project deliveries. You will work very closely with technical delivery leads, solution architects, integration engineers, external system integrators and software developers and ensure the IoT deliveries happen in time, on budget & effectively follows the agile best practices & principles.\nThis is a very central & exciting role to address the ever growing demands of the new Analytics Platform among other IoT systems as we are moving to the cloud. . You will help architect and deploy the tools required to enable ingestion and storage capabilities in the cloud in close cooperation with the Test, Applications & Enablement teams and will become a key part of major ongoing and upcoming projects for delivery. Your objective is to ensure that every IoT project gets delivered effectively in agile and as promised.\nIdeal Background\n\n\n\nBSc or MSc level degree in Software Engineering, Computer Science or Telecommunications\nAbility to understand architecture, network design & technical issues to drive effective agile delivery\nCreative and efficient in proposing solutions to complex, time-critical problems\nProven hands-on experience in developing and deploying Analytics solutions\nKnowledge on Analytics solutions and data engineering\nKnowledge on Redshift Data Modelling and SQL \nKnowledge on Data ETL (Spark)\nDeep Knowledge of DevOps tools and CI/CD\nExperience with AWS Service or Goggle Cloud Service\nExperience of scripting and coding languages (e.g.Java, Python, Ruby, Bash)\nAbility to maintain calm attitude during difficult situations and handle pressure situations\nAgile Metholopgy embrancement\nStrong team player with an ability to identify and remove impediments or conflicts that interfere with the ability of the team to deliver the sprint & project goals\nSelf-starter & self-motivated with a drive to identify opportunities for improvement across the agile delivery processes\nHighly independent, takes ownership, does not need to be told what to do and seeks feedback and execute actions\nEnglish (B2 or above)\nAny other non-native language an advantage"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "HEMA",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Amsterdam, North Holland, Netherlands",
        "post": "About the job \n\nDo you have experience in end-to-end design and deploy of data pipelines and analytics solutions?\n\n\nHEMA is looking for a Data Engineer for our Data & Analytics team\n\n\nyou have\n\nExperience in Design, Build, Test and Deploy data pipelines to process massive amount of data\nExperience in building data pipelines to collect, transform, and load data from various sources (e.g. REST, Kafka) into data lakes and/or databases\nAdvanced knowledge of data processing and analysis (e.g. with SQL, Pyspark)\nExtensive programming know-how (e.g. in Python, Scala, Java, NodeJs)\nExperience with some IaC framework (terraform, cloud formation) \nExtensive knowledge of software engineering best practices, tools and methods (e.g. TDD, CI/CD, GIT)\nExperience in using workflow orchestration tools (e.g., Apache Airflow)\nExperience working in self-organised, cross-functional teams \n\n\n\na day as Data Engineer\nHEMA is a data-driven company. Many decisions are made on data, which requires that this data is available, complete and correct. As a Data Engineer, you are responsible for end-to-end design and deploy of data pipelines and analytics solutions that all HEMA employees and partners can work with data by making it available via a state-of-the-art platform and tooling.\nTogether with the others Data Engineers, you have open space to discuss, test and implement new ideas and concepts related with new technologies. You help HEMA to have the most curated up to date dataset available in the AWS Analytics platform supporting business questions, machine learning models and stakeholders to improve internal process and support business decisions.\nYou work in a data platform team together with the data engineers. Together with Business intelligence, data science and analytics & insights, you form the Data & Analytics team at HEMA."
    },
    {
        "position": "Data Engineer - Economics & Experimentation (all genders)",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Zalando",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Berlin, Berlin, Germany",
        "post": "About the job \n\nTHE OPPORTUNITY\n\nYou will join a brand-new team in Economics and Experimentation to productionalize causal machine learning models developed by our Applied Scientists. Our team is highly visible. The causal models and experimentation platforms we develop are used for decision-making for both the senior management board and all Zalando product teams.\n As one of the very first hires in this new team, you are key to bridge the gap between research and production. You also have opportunities to shape ways of working in this new team. Your technical decisions will help people across the whole company benefit from our causal machine learning models reliably.\n\n\nWHERE YOUR EXPERTISE IS NEEDED\n\n\nCollaboratively design and implement a reliable and performant data infrastructure Continuously improve existing data systems with the aspiration of stress-free operations and a sustainable work pace Provide high-quality, performant datasets for machine learning and causal inference research. Provide guidance and supportive feedback for your colleagues\u2019 work to help them grow as professionals \n\nWHAT WE\u2019RE LOOKING FOR\n\n\nBachelor or higher in computer science, software engineering, mathematics, or closely related discipline Demonstrated real-world working experience in designing and setting up high volume, performant databases (experience with feature stores is a big plus) Strong understanding of data engineering tools (e.g. Spark, database, data format) Proficiency in programming skills in Python (Scala or other JVM language is a plus). Proficiency with professional software engineering practices (e.g. software design, data structure) Hands-on experience with cloud infrastructure, ideally AWS Experience working with Applied Scientists \n\nPERKS AT WORK\n\n\nA workplace run on trust, empowerment and feedback; positive, inspiring working atmosphere Competitive salary, employee share shop, 40% Zalando shopping discount, discounts from external partners, centrally located offices, public transport discounts, municipality services, great IT equipment, flexible working times, additional holidays and volunteering time off, free beverages and fruits, diverse sports and health offerings Mentoring and personal development opportunities and an international team of experts Relocation assistance for internationals, PME family service and parent & child rooms We celebrate diversity and are committed to building teams that represent a variety of backgrounds, perspectives and skills. All employment is decided on the basis of qualifications, merit and business need. \n\nABOUT ZALANDO\n\n\nZalando is Europe\u2019s leading online platform for fashion, connecting customers, brands and partners across 23 markets. We drive digital solutions for fashion, logistics, advertising and research, bringing head-to-toe fashion to more than 45 million active customers through diverse skill-sets, interests and languages our teams choose to use.\n\nPlease note that all applications must be completed using the online form - we do not accept applications via email."
    },
    {
        "position": "Data Engineer - Economics & Experimentation (all genders)",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Cabify",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Berlin, Berlin, Germany",
        "post": "About the job \n\n\n\nAbout the job\n\nDo you want to change the world? At Cabify, that's what we're doing. We aim to make cities better places to live by improving mobility for the people living in them, connecting riders to drivers at the touch of a button. Maybe one day cities will be places where nobody needs a private car. But we've still got a long way to go\u2026fancy joining us? \n\n\nAbout the position:\n\n\n\nAt Cabify we claim to be a data-driven company. Our team builds and maintains a robust warehouse where the Analytics team can find not only raw data, but also complex etls processes to provide the insights they need. \n\n\nBut where can I see all that data? We have a Tableau server instance that contains thousands of workbooks and is consulted by many users every day. We own that instance so we work hard to make sure everything works properly. We also created, and keep on creating, tooling around Tableau and our data warehouse, in order to keep on improving the way our users interact with data. \n\n\nAt Analytics Engineering we manage our own cloud infrastructure (AWS). Our in-house etls platform has more than 300 processes (Python, Airflow, Redshift, S3, Spectrum, Glue, RDS) that we visualize with our Tableau server instance (Tableau Server, Ec2, Python). \n\n\nYou will:\n\n\n\nWe are looking for new members, and this is how you will play an important part in helping us achieve our mission: \n\nMaintain & evolve our data warehouse, making sure the data is easily accessible, reliable & accurate. \nCreate data models, applying business logic to data. Evaluate all proposals and requests to improve the structure of the data warehouse. \nCoordinate with other data stakeholders to ensure overall health and performance of the data warehouse environment. \nDesign, develop, test, monitor, manage, and validate data warehouse activity. Including defining standards for the data warehouse as well as troubleshooting ETL processes and resolving issues effectively. \n\n\n\nOur Ideal candidate has:\n\n\nGreat alignment with our principles, we take this very seriously. \nAt least 5 years tenure in coding and delivering complex data projects. \nProven track record in Data Modeling. \nYou continuously find ways to derive more value in our raw data and lower the amount of effort our end users spend on getting answers. \nYou have proper DBA skills, with which you should ensure high standards in DWH data accessibility, integrity, security & performance monitoring. \nYou have intermediate level SQL skills, which allows you to understand subqueries, pivots, joins, and how indexes work. \nYou can take a complex concept and make it sound simple. You're accomplished at orienting business users within the data domain, understanding their needs, and translating them into technical requirements to ultimately design effective data solutions. \nYou have experience integrating data from multiple sources including DBs, product tracking, and APIs. You get excited by seeing your jobs run like clockwork. \nUnderstanding of Microsoft technologies (Azure, Data Factory and Microsoft SQL) is a plus. \n\n\n\nThe good stuff:\n\n\n\nWe're a company full of happy, motivated people and we never want that to change. Here are some more reasons why it rocks to be part of our family. \n\nExcellent Salary conditions: L3: 40000EUR - 48000EUR, L4: 45000EUR - 65000EUR \nWe also offer a very competitive stock options plan. \nRecharge day: Every 3rd Friday monthly off! \nRemote Position \nFlexible work environment & hours. \nRegular team events. \nCabify staff free rides. \nPersonal development programs based on our career paths. \nAnnual budget for training. \nFlexible compensation plan: Restaurant tickets, transport tickets, healthcare and childcare \nAll the equipment you need (you only have to bring your talent). \nA pet room ,so you don't have to leave your furry friend at home \nAnd last but not least...free coffee and fruit! \n\n\n\nSounds good? Joing us!!"
    },
    {
        "position": "Data Engineer - Economics & Experimentation (all genders)",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Stuart",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Berlin, Berlin, Germany",
        "post": "About the job \n\n\n\nStuart (DPD Group) is a sustainable \ud83c\udf31 last-mile logistics company that connects retailers and e-merchants to a fleet of geolocalised couriers across several countries in Europe. \n\n\nOur Mission \ud83d\ude80 \nWe are an impact-driven company that aims to build the future of logistics for a more sustainable world: shared, efficient and reliable. We are committed to creating a new standard for urban deliveries that meet today\u2019s environmental and social challenges while offering a premium delivery experience blending speed, flexibility and convenience. \n\n\nOur motto: \u201cMake every delivery a moment all of us can truly celebrate!\u201d More than 3000+ leading brands already partner with us across Restaurants, Grocery, Retail & Luxury, eCommerce and Professional Services to deliver all types of goods at the tap of a button. Stuart is a highly diverse and inclusive company of 600+ talents from 90+ countries working in Paris \ud83c\uddeb\ud83c\uddf7, London \ud83c\uddec\ud83c\udde7, Barcelona, Madrid \ud83c\uddea\ud83c\uddf8, Poland \ud83c\uddf5\ud83c\uddf1, Portugal \ud83c\uddf5\ud83c\uddf9 and remotely around the world \ud83c\udf0d \n\n\nIt\u2019s the right moment and the right place for us to make an impact on millions of people, as home delivery services hit a record high. And guess what? You can help us fulfil our vision \ud83d\ude4c \n\n\nWe are looking for a Data Engineer \ud83e\udd16 to take part in the scaling of our data platform and support the team\u2019s and company\u2019s growth. \n\n\nOur stack currently relies mostly on the Python & Scala languages and It includes technologies like Apache Airflow, Docker, Apache Kafka, Tensorflow, etc. and we extensively use AWS products like S3, Redshift, and Athena. \n\n\nWhat will I be doing? \ud83e\udd14\n\n\nDesigning, implementing and maintaining a solid Data Lake and Data Warehouse that collects, stores, and processes data, focusing on scalability and reliability. \nWorking closely with the Business Intelligence and Data Science teams to help them design and build machine-learning algorithms and tooling to explore and visualize data. \nGrowing with us and sharing: https://medium.com/stuart-engineering \ud83e\udd13 \n\n\n\nWhat do we need from you? \ud83d\ude0e\n\n\nFluency in English \n3+ years experience working with Python or Scala \n3+ years of experience design and implementing data platforms \nExperience with Apache Kafka or other streaming platforms \nExperience with query engines like AWS Athena, Hive, SparkSQL or similar technologies \n\nWant to put a smile on our face? \n\nExperience in designing data lakes in Amazon S3 \nExperience with Apache Airflow \nExperience with Hadoop, Apache Spark, Flink or similar technologies \nExperience with data quality processes \n\n\n\nThe stuff you wanna know \ud83d\ude09\n\n\nFamily-friendly work-life balance - work from home and flexible hours \ud83c\udfe1 \nOption to work remotely anywhere in Spain \ud83c\uddea\ud83c\uddf8 \nTicket Restaurant by Edenred (\u20ac11 daily) \ud83e\udd57 \nUnlimited access to Udemy for all your learning and development needs \ud83d\udcda \nPersonal Engineering Learning Budget of \u20ac1,000 per year \ud83e\uddd1\u200d\ud83d\udcbb \nStuart Academy with regular workshops, Stu-Classes, and Stu-Talks \ud83c\udf93 \nStuart is putting Mental Health Awareness first! Wellness Allowance (\u20ac40 monthly) to use in any gym or sport class \ud83e\uddd8 \nPrivate healthcare provided by Sanitas \ud83e\uddd1\u200d\u2695\ufe0f \nWork in an international, dynamic and passionate environment with a company culture focused on learning and development \ud83c\udf89 \n\n\n\nYou\u2019ve read all this way but you\u2019re missing a skill or two? No problem, it\u2019s our job to up-skill you to take your career to the next level. What we\u2019re trying to say is, don\u2019t be afraid to apply if you don\u2019t tick all the boxes \ud83d\udcaa \n\n\nAt Stuart, we believe that employees today want to evolve in collaborative, high-growth environments where they can demonstrate their abilities and thrive both professionally and personally. We are convinced that employees need to find alignment between their inner values and their company\u2019s culture and mission to unlock their full potential. We work to create a culture of empowerment, continuous learning and growth where everyone can bring expertise, own projects and easily measure their impact \ud83d\ude4c \n\n\nStuart is proud to be an equal opportunity workplace dedicated to promoting diversity. We don\u2019t discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status \ud83d\udc99 \n\n\nWant to learn more about us? Visit https://stuart.com/about-us/"
    },
    {
        "position": "Data Engineer - Economics & Experimentation (all genders)",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Flight                                                                                                                                                                                                                                            Centre                                                                                                                                                                                                                                            Travel                                                                                                                                                                                                                                            Group",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Berlin, Berlin, Germany",
        "post": "About the job \n\n\n\n\n\nAbout your opportunity...\n\n\n\nDo you enjoy untangling complex, enterprise information? \n\n\n\nWe are seeking a highly motivated Data Modeller with experience in logical/conceptual data design, semantic layer modelling, and data stewardship to take on the challenge of transforming how FCTG manages and shares critical information assets.\n\n\nIn this role you will provide graphical representations of the entities that interoperate within the organisation in support of business processes and the relationships among these entities. You will be responsible for developing the data models, by engaging with business users and soliciting their requirements and iteratively refine the conceptual, logical, and physical data models. \n\n\nLocated within the Data Science and Engineering (DSE) team, this role goes beyond the role of a typical application level \"data modeller\" in that it requires modelling not just from a single business perspective but from an organisational perspective with Global reach. \n\n\n\n\nWhat You\u2019ll Do...\n\n\n\n\nEngage the business users to assess their information needs \nReview the business process and conceptualize the entities that interoperate within the business process \nDetermine how the various entities are related and develop entity relationship diagrams that represent the connections among the entities \nIdentify each entity's characteristics and properties and ensure that the entities can be differentiated within the model \nDevelop a logical data model and validate the model to ensure that it serves the needs of the business application and its consumers \nTransform the logical representation of the model into a physical representation and work with data engineers to instantiate and manage the data \nCollaborate with the BI and Analytics teams on creating the optimized, reusable semantic models, complete with metadata and lineage information \n\n\n\nWho you are\u2026\n\n\n\n\nExperience with Business Intelligence products e.g., Power BI \nExcellent teaming and communication skills \nStrong consultative, facilitation and consensus building skills \nProven experience in an enterprise environment developing relational datasets \nProven experience developing models for Business Intelligence solutions \nStrong analytical, data profiling and problem-solving skills \nStrong verbal and written communication skills \nAdvanced SQL skills \nIn depth knowledge of Azure technologies \nIn depth knowledge of Databricks \n\n\n\nDesirable Competencies...\n\n\n\n\n3+ years of data modelling experience \nIn depth knowledge of the data modelling tools being proficient in at least one \nExperience with Microsoft\u2019s Purview \nMandatory: Bachelor's degree in management Information Systems, Computer Science, Computer Information Systems, or equivalent Information Technology discipline \n\n\n\nLet\u2019s skip to the good part\u2026\n\n\n\n\nGenerous remuneration structure \nTravel discounts, in-house financial and health services, access to internal 24/7 gym \nGlobal career opportunities in a network of brands and businesses \nOngoing training and professional development \nFun and flexible work environment \nProud Corporate Social Responsibility platform through the Flight Centre Foundation \n\n\n\nWho we are...\n\n\n\nAt Flight Centre, our vision is to open up the world for those who want to see.\n\n\n\nWe DREAM BIG through collaboration and innovation and are supported to make incredible ideas a reality. We deliver quality, innovative solutions to delight our customers and achieve our strategic priorities.\n\n\nWe work autonomously from anywhere and work collaboratively online or in the office to achieve our team goals.\n\n\nIrreverence. Ownership. Egalitarianism."
    },
    {
        "position": "Data Engineer - Economics & Experimentation (all genders)",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Mars",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Berlin, Berlin, Germany",
        "post": "About the job \n\n\n\nData and Analytics is foundational to Royal Canin and will drive our transformation to a business that is powered by data. To deliver on this ambition we are looking to recruit a Data Engineer who will work remotely from the Netherlands and be able to attend meetings in Amsterdam and travel to the Global HQ in South of France. \nThe role reports to the Royal Canin Global Data Engineering Lead. \n\n\nWhat are we looking for?\n\n\nDeep and rich experience in working with data (Python / Spark / Databricks) and delivering robust data transformation pipelines. \nPrevious experience working in a cloud environment would be a plus (Azure preferred). \nGreat at developing new relationships, driving positive change, and matching analytics opportunities to data acquisition strategy. \nExcellent planning and prioritization skills. \nGood understanding of Data Protection and Privacy principles and practices including GDRP. \nWork comfortably in an agile and fast paced environment. \n\n\n\n\nWhat will be your key responsibilities?\n\n\nEngineer and orchestrate data flows & pipelines using high quality, easily deployable, \nrepeatable and extensible codebases that ingest and integrate data from many disparate \ndata sources in a cloud environment using a progressive tech stack. \nDesign and build complex data models to support performant and accurate analytical insight, science research and marketing activation purposes removing excessive data preparation from the solution users to expedite their processes and reduce effort duplication and subsequent errors. \nSupporting the global data engineering lead to adapt data architectures, analytical data platforms & related processes (i.e. designing and specifying data structures and processing frameworks based on local functional and technical requirements. ) \nDeveloping local strategies for data acquisition and democratization \nManaging data transformation and troubleshooting data processing issues \nEU Platform Support, alerting and monitoring to ensure high platform reliability in compliance with Mars \nCyber Security Standards and Privacy Policies \nData Lifecycle Management through Global Metadata and Access Control Management \nPartner with functions and divisions to ensure RC data capabilities roadmap, operating model and governance principles are best serving the organization data strategy and are effectively activated across RC Europe \n\n\n\n\nWhat can you expect from Mars?\n\n\nAt Mars, we believe in a relationship of mutual trust, dignity and respect between our company and Associates that is more meaningful than the standard employer/employee relationship. \nAs Associates, we can expect to be respected, supported and valued as individuals, to be treated fairly and equitably. \nThe opportunity to learn and develop, taking charge of your own career across Mars. \nAn environment where you are empowered to be proactive and to take initiatives to make a difference. \nYou will work in a multicultural environment (more than 40 nationalities)"
    },
    {
        "position": "Software Engineer (Data) - Economics & Experimentation",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Zalando",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Berlin, Berlin, Germany",
        "post": "About the job \n\nTHE OPPORTUNITY\n\nYou will join a brand-new team in Economics and Experimentation to productionalize causal machine learning models developed by our Applied Scientists. Our team is highly visible. The causal models and experimentation platforms we develop are used for decision-making for both the senior management board and all Zalando product teams.\n As one of the very first hires in this new team, you are key to bridge the gap between research and production. You also have opportunities to shape ways of working in this new team. Your technical decisions will help people across the whole company benefit from our causal machine learning models reliably.\n\n\nWHERE YOUR EXPERTISE IS NEEDED\n\n\nCollaboratively design and implement a reliable and performant data infrastructure Continuously improve existing data systems with the aspiration of stress-free operations and a sustainable work pace Provide high-quality, performant datasets for machine learning and causal inference research. Provide guidance and supportive feedback for your colleagues\u2019 work to help them grow as professionals \n\nWHAT WE\u2019RE LOOKING FOR\n\n\nBachelor or higher in computer science, software engineering, mathematics, or closely related discipline Demonstrated real-world working experience in designing and setting up high volume, performant databases (experience with feature stores is a big plus) Strong understanding of data engineering tools (e.g. Spark, database, data format) Proficiency in programming skills in Python (Scala or other JVM language is a plus). Proficiency with professional software engineering practices (e.g. software design, data structure) Hands-on experience with cloud infrastructure, ideally AWS Experience working with Applied Scientists \n\nPERKS AT WORK\n\n\nA workplace run on trust, empowerment and feedback; positive, inspiring working atmosphere Competitive salary, employee share shop, 40% Zalando shopping discount, discounts from external partners, centrally located offices, public transport discounts, municipality services, great IT equipment, flexible working times, additional holidays and volunteering time off, free beverages and fruits, diverse sports and health offerings Mentoring and personal development opportunities and an international team of experts Relocation assistance for internationals, PME family service and parent & child rooms We celebrate diversity and are committed to building teams that represent a variety of backgrounds, perspectives and skills. All employment is decided on the basis of qualifications, merit and business need. \n\nABOUT ZALANDO\n\n\nZalando is Europe\u2019s leading online platform for fashion, connecting customers, brands and partners across 23 markets. We drive digital solutions for fashion, logistics, advertising and research, bringing head-to-toe fashion to more than 45 million active customers through diverse skill-sets, interests and languages our teams choose to use.\n\nPlease note that all applications must be completed using the online form - we do not accept applications via email."
    },
    {
        "position": "Data Science and Engineering Manager",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Music Tribe",
        "sector": "Musicians",
        "companySize": "1,001-5,000 employees",
        "location": "\u00c5rhus, Middle Jutland, Denmark",
        "post": "About the job \n\nWE EMPOWER, YOU CREATE\n\nWe at Music Tribe believe that our sole purpose is to empower you to become the most creative you can be. We believe in obsessively empowering through our Brand Tribes \u2013 Midas, Klark Teknik, Lab Gruppen, Lake, Tannoy, Turbosound, TC Electronic, TC Helicon, Behringer, Aston Microphones, Bugera, Oberheim, Auratone and Coolaudio. Empowering you to create and receive appreciation is the key to our happiness. That\u2019s why we exist.\n Music Tribe celebrates over 30 years as a provider of Music Products and Solutions and works across 12 counties employing 2,000 Customer Obsessed Tribers. We want you to be part of our ambitious growth journey, empowering your team or fellow Tribers to create the absolute best.\n\nOur People, Our Tribe\n\nTRIBE - Teamwork, Respect, Integrity, Bold & Engage are our cultural cornerstone. We respect all our people and aspire to supply inclusive working experiences and an environment that reflects the audience we serve.\n We are diverse, we come from different backgrounds and different countries. We are software engineers, designers, researchers, marketers, accountants, customer service, production operatives, technologists and more. We believe that a diverse organisation makes us stronger.\n\nOur Purpose\n\nWe at Research Data believe that delivering life-changing Data Services through self-service tools related to Data, Master Data and Analytics, will empower our Customers as well as Music Tribe.\n We further believe that relentlessly and consistently measuring and improving our services, will lead to appreciation and Customer Advocacy.\n\nRoles And Responsibilities\n\nStrategy\n\n\nResponsible of world class and passionate data scientists and engineers to develop innovative science products and reusable science modules. You\u2019ll translate complex requirements into detailed project plans and schedules \nResponsible for designing, implementing, and maintaining systems used to collect and analyse business intelligence data. \nResponsible for developing and executing a data integration & automation roadmap as well as delivering an architecture for collecting and storing data. Also, maintaining & testing of data pipeline during development proves (Reliability / Performance) \nOwning a roadmap to develop innovative science products and reusable science modules, ensuring they are productionised and available to the business. \nDevelop processes and tools to monitor and analyse model performance and data accuracy \nCreating and using advanced machine learning algorithms and statistics \nUsing statistical computer languages to manipulate data and draw insights from large data sets \nDevelop custom data models and algorithms to apply to data sets \n\n\nOperations\n\n\nDesign and implement the management, monitoring, security, and privacy of data using the full stack of Azure data services to satisfy business needs \nEnsuring non-functional system characteristics such as such as security, maintainability, quality, performance, and reliability are captured, prioritized, and incorporated into products \nDeveloping reusable software components and systems based on requirements, architecture and design specifications and organizational policies and standards. \nCollaborating with other data engineers, scientists, software architects, software engineers, quality engineers, and other team members to design and build solutions that best fit the requirements \nLeverage Agile, CI / CD and DevOps methodologies to deliver high quality product on-time \nExpose data to end users using Power BI which can be done by BI team, Azure API Apps or other modern visualization platforms like Rstudio, Panda \nMaintain data so that it remains available and usable e.g. SQL (Basic, Advanced modelling, Efficient, Big Data and Programmatic) \nData munging such as reshaping, aggregating, joining disparate sources, etc...small-scale ETL, API interaction, and automation e.g. Python \nData normalisation and modelling as part of the transform step of ETL/ELT pipelines \nCreate interfaces and mechanisms for the data flow and access of information \nClean the data, removing duplicates, and conforming data to specific data model. Store the normalised data in the data warehouse or in a relational database. \n\n\nQualifications, Minimum\n\n\nBachelor\u2019s degree or equivalent in an engineering/numerate subject e.g. Engineering, Stats, Maths, Computer Sciences \nExperience in hiring, mentoring and retaining a strong team of motivated data science engineers \nExperience in full-stack development and applying it to build science products. E.g. could include some or all of C/C++, Python/R, Linux scripting, SQL, Docker coupled with front ends such as HTML, Javascript, web front ends \nExperience with and passion for developing full-stack solutions using modern technologies, understanding and implementing science and machine learning algorithms such as regularised regression or tree-based ensembles, and ability to implement through libraries \nStrong understanding of Data Architecture & Modelling, and appreciation of impact on solution design decisions. \nStrong understanding of ETL/ELT concepts and execution \nDemonstrative ability to develop complex SQL queries and Stored Procedures \n\n\nQualifications, Preferred\n\n\nAbility to define and drive adoption of best practice in agile software development, quality assurance and testing, including automation \nGood understanding of machine learning techniques, with applications to classification, regression, and clustering. \nDemonstrated experience building data lakes and data warehouses in Azure \nFoundational knowledge of securing data access in a relational database \nHands-on experience using Synapse or related tool with cloud-based resources (e.g. Stored Procedures, ADF, NoSQL Databases, JSON/XML data formats) \nHands-on experience with Azure Functions, Azure Data Factory data integration techniques \nData Modelling concepts, monitoring, designs and techniques \nKnowledge of Data Warehouse project lifecycle, tools, technologies, best practices \nHands on with DWH, APIs (RESTful), Spark APIs, FTP protocols, SSL, SFTP, PKI (public Key Infrastructure) and Integration testing \n\n\nTools\n\n\nFull stack of Azure: Azure Datalake Gen-2, Azure Synapse, Azure Data Factory, Power BI, Power Automate, Azure Storage Explorer, Azure Cosmos DB, Azure Databricks, Azure Data Studio), Python/R, MDM Profisee (a plus), Azure D365, Apache Spark \n\n\nMetrics\n\n\nData Enrichment: Each modeler should ask themselves about \u201cis that all the relevant data? Are there, maybe outside of the organization, additional sources that could generate impactful features?\u201d \nSupport & Coverage: Support is defined as the percentage of keys found in a secondary dataset, out of all unique keys in the main dataset. Coverage is defined as the percentage of rows with a matching key in the main dataset, out of all rows in the main dataset. \nData Quality: can be measured by number of incidents triggered by data issues. Includes: Internal alerts, failed tests, issues raised by BI consumers. Will need to include scoring weighting for severity of incident and resolution time = additional complexity \nData On-time delivery (Data Uptime): Expected frequency (Daily, Hourly, RT) or SLA requirements (Frequency clause stipulated by an SLA agreement between a data producer and consumer for when data must by updated by e.g. every day at 7am or every 20 min. \nDevelopment Velocity: Number of user story points completed per iteration; Data research & exploration can be expressed in small, testable user stories and epics = efficiency of the team \nData Science: Data model\u2019s freshness / Data pipeline\u2019s speed / Machine learning model\u2019s accuracy\n\n\nWhy work for us?\n\n\nAnnual leave provision, plus public holidays\nPension / retirement fund contributions\nHealth Care\nHybrid & remote working options in some locations \nWe measure our People Engagement\nWe run quarterly team building events\nWe are invested in learning & development\nWe reward daily through digital recognition systems"
    },
    {
        "position": "Data Modeling Specialist",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "PepsiCo",
        "sector": "Food and Beverage Services",
        "companySize": "10,001+ employees",
        "location": "Barcelona, Catalonia, Spain",
        "post": "About the job \n\nAuto req ID: 284447BR\n\nJob Description\n\n#Locations: Barcelona, Spain; Vitoria-Gasteiz, Spain\n PepsiCo is using the power of data to transform the way our world-famous portfolio of brands are sold every day. Our Data Science & Analytics group influences every aspect of how we sell and move our products. In just a short period of time, they\u2019ve built new capabilities that have defined the data science roadmap across all of our brands. Members of our team solve complex problems facing our rapidly changing business and get to see their work come to life in the real world.\n Join PepsiCo\u2019s Enterprise Data Operations team which develops quality data collection processes, maintains the integrity of our data foundations and enables business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation.\n As a Data Modeling Specialist, your focus would be to partner with D&A Data Foundation team members to create data models for Global projects. This would include independently analyzing project data needs, identifying data storage and integration needs/issues, and driving opportunities for data model reuse, satisfying project requirements. The role will advocate Enterprise Architecture, Data Design, and D&A standards, and best practices. You will be a key technical expert performing all aspects of Data Modeling working closely with Data Governance, Data Engineering and Data Architects teams.\n As a member of the data modeling team, you will create data models for very large and complex data applications in public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. The primary responsibilities of this role are to work with data product owners, data management owners, and data engineering teams to create physical and logical data models with an extensible philosophy to support future, unknown use cases with minimal rework. You'll be working in a hybrid environment with in-house, on-premise data sources as well as cloud and remote systems. You will establish data design patterns that will drive flexible, scalable, and efficient data models to maximize value and reuse.\n Key Accountabilities:\n\nIndependently complete conceptual, logical and physical data models for any supported platform, including SQL Data Warehouse, EMR, Spark, DataBricks, Snowflake, Azure Synapse or other Cloud data warehousing technologies.\nGoverns data design/modeling \u2013 documentation of metadata (business definitions of entities and attributes) and constructions of database objects, for baseline and investment-funded projects, as assigned.\nProvides and/or supports data analysis, requirements gathering, solution development, and design reviews for enhancements to, or new, applications/reporting.\nSupports assigned project contractors (both on- & off-shore), orienting new contractors to standards, best practices, and tools.\nAdvocates existing Enterprise Data Design standards; assists in establishing and documenting new standards.\nContributes to project cost estimates, working with senior members of team to evaluate the size and complexity of the changes or new development.\nEnsure physical and logical data models are designed with an extensible philosophy to support future, unknown use cases with minimal rework.\nDevelop a deep understanding of the business domain and enterprise technology inventory to craft a solution roadmap that achieves business objectives, maximizes reuse.\nPartner with IT, data engineering and other teams to ensure the enterprise data model incorporates key dimensions needed for the proper management: business and financial policies, security, local-market regulatory rules, consumer privacy by design principles (PII management) and all linked across fundamental identity foundations.\nDrive collaborative reviews of design, code, data, security features implementation performed by data engineers to drive data product development.\nAssist with data planning, sourcing, collection, profiling, and transformation.\nCreate Source To Target Mappings for ETL and BI developers.\nShow expertise for data at all levels: low-latency, relational, and unstructured data stores; analytical and data lakes; data streaming (consumption/production), data in-transit.\nDevelop reusable data models based on cloud-centric, code-first approaches to data management and cleansing.\nPartner with the Data Governance team to standardize their classification of unstructured data into standard structures for data discovery and action by business customers and stakeholders.\nSupport data lineage and mapping of source system data to canonical data stores for research, analysis and productization.\n\n\nQualifications/Requirements\n\nQualifications:\n\n\n8+ years of overall technology experience that includes at least 6+ years of data modeling and systems architecture.\n3+ years of experience with Data Lake Infrastructure, Data Warehousing, and Data Analytics tools.\n6+ years of experience developing enterprise data models.\nExpertise in data modeling tools (ER/Studio, Erwin, IDM/ARDM models).\nExperience with integration of multi cloud services (Azure) with on-premises technologies.\nExperience with data profiling and data quality tools like Apache Griffin, Deequ, and Great Expectations.\nExperience with at least one MPP database technology such as Redshift, Synapse, Teradata or SnowFlake.\nExperience with version control systems like Github and deployment & CI tools.\nExperience with building solutions in the retail or in the supply chain space is a plus\nExperience of metadata management, data lineage, and data glossaries is a plus.\nWorking knowledge of agile development, including DevOps and DataOps concepts.\nBA/BS in Computer Science, Math, Physics, or other technical fields.\n\n\nSkills, Abilities, Knowledge:\n\n\nExcellent communication skills, both verbal and written, along with the ability to influence and demonstrate confidence in communications with senior level management.\nStrong change manager. Comfortable with change, especially that which arises through company growth.\nAbility to understand and translate business requirements into data and technical requirements.\nPositive and flexible attitude to enable adjusting to different needs in an ever-changing environment.\nStrong organizational and interpersonal skills; comfortable managing trade-offs.\nProactively drives impact and engagement while bringing others along.\nConsistently attain/exceed individual and team goals\nAbility to work with virtual teams (remote work locations); lead team of technical resources (employees and contractors) based in multiple locations across geographies\nLead technical discussions, driving clarity of complex issues/requirements to build robust solutions\n\n\nWhat makes us different?\n\n\nHybrid work model & collaborative office experience to enable innovation\nEntrepreneurial environment in leading international company \nProfessional growth possibilities & learning opportunities \nVariety of benefits to support your physical, emotional and financial wellbeing\nVolunteering opportunities to help external communities\nDiverse team from over 25 countries\nHave a stake in D&I strategy and Bring your whole self to work \n\n\nAbout PepsiCo\n\nWe believe that culture should be at the cornerstone of everything we do at PepsiCo. We operate with start-up mindset \u2013 agile, innovative and not afraid of failure. We want our team to come to work every day excited to explore new ways bring enjoyment, refreshment and fun to the world.\n PepsiCo Positive (pep+) is the future of our organization \u2013 a strategic end-to-end transformation, with sustainability at the center of how we will create growth and value by operating within planetary boundaries and inspiring positive change for the planet and people. https://www.youtube.com/watch?v=PO5CdBmWjUY\n So, if you\u2019re ready to be a part of a playground for those who think big, we\u2019d love to chat.\n\nWe encourage the diversity of applicants across gender, age, ethnicity, nationality, sexual orientation, social background, religion or belief and disability\nRelocation Eligible: Eligible for Standard Relocation\n\nJob Type: Regular"
    },
    {
        "position": "Data Warehouse Developer/Data Modeler",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Watercare Services Limited",
        "sector": "Utilities",
        "companySize": "501-1,000 employees",
        "location": "Auckland, New Zealand",
        "post": "About the job \n\nWatercare is the largest water and wastewater utility in New Zealand more than 400 million litres of water to Auckland every day. Now is an exciting time to join Watercare, we're planning to spend $18.5 billion over the next 20 years to ensure we can continue to support our growing city in a climate-resilient way. When you average that out, that's an investment of $2.5 million every day.\nIt doesn't just stop there; we ensure that sustainability lies at the heart of everything that we do to help protect our water resources for future generations. This means that we are continuously focused on how we can reduce our carbon footprint with initiatives likes solar panels, electric cars, revegetation programmes and much, much more. We really are a company that wants to make a positive difference.\n\n\nHe whakam\u0101rama m\u014d te t\u016branga mahi | About the role\n\n\n\nAs the provider of water to the majority of Auckland, Watercares data is critical to understanding the ins-and-outs of our services to Tamaki Makaurau. We thrive on the optimism and innocation of current systems and learning new technologies to provide better visibility, allow more informed decisions to improve out business processes and the end experience for our customers.\nAs our Date Warehouse Developer/Data Modeler, you will design, implement and document data modelling solutions which include the use of relational, dimensional and NoSQl databases. In this role you will be responsible for the development of conceptual, logical and physical data models, the implementation of RDBMS, operational data store, data marts and data lakes on target platforms. Additionally, you will define and govern data modelling and design standards, tools, best practices and related development methodologies. You will also oversee and govern the expansion of existing data architecture and the optimisation of data query performance based on best practices.\n\n\nYou will work closely with our Data Engineering team to create optimal physical data models of datasets, as well as creating and maintain data maps and system interrelationship diagrams. This is a key enabler role for Analytics at Watercare - you will open up a world of opportunities related to data for our internal and external customers.\n\n\n\n\nNg\u0101 p\u016bkenga e rapu nei m\u0101tou | About you\n\n\nWe are looking for passionate, analytical people who have a high attention to detail. In this role you will bring:\n\n\n\nTertiary level qualification in an appropriate discipline\n3+ years of hands-on relational, dimensional, and/or analytic experience (using RDBMS, dimensional, NoSQL data platform technologies, and ETL and data ingestion protocols)\nExperience in collecting and translating business rules into conceptual, logical & physical models for data platforms. \nExperience with building data models using Kimball methodology - alternatively, experience in data vault would also be considered.\nProven commercial experience working in an agile environment, as well as recognised and relevant technology industry qualifications\nExperience with data warehouse, data lake and enterprise big data platforms in multi-data-centre contexts required\nGood knowledge of metadata management, data modelling, and related tools (Erwin, ER Studio or others)\n\n\n\nNg\u0101 hua m\u014du | What's in it for you\n\n\nWe offer a competitive salary and staff benefits package including: \n\n\n\nTraining and development opportunities\nLife and income protection insurance plans\nGenerous parental leave\nEmployee discounts at a range of large retailers\nKiwisaver contribution\nFree on-site gym\nDiscounted parking options available\n\n\n\nMe p\u0113hea te tono mai | How to Apply\n\n\nCome and join our team! If you are looking for an exciting career opportunity with a fantastic team then please apply online today - www.careers.watercare.co.nz."
    },
    {
        "position": "Data Scientist - Senior Level",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Temple & Webster",
        "sector": "Retail",
        "companySize": "201-500 employees",
        "location": "Sydney, New South Wales, Australia",
        "post": "About the job \n\nSenior Data Scientist \n\n\n\nAustralia's #1 furniture and homewares online retailer\nGrowing business with a fantastic culture\nHybrid working arrangement - work from home and our St Peters Office\n\n\n\nTo lead and execute data science activities for Temple & Webster, empowering this business to make better decisions when it comes to designing and importing new product.\n\n\nWhat we\u2019re looking for\n\n\n\n\nMain responsibilities of this role include:\n\n\n\nDevelop scalable machine learning solutions to support forecasting, purchasing and pricing.\nUtilising modern NLP methods to derive additional features and insights from products and customer behaviour\nLead data projects that support business growth, e.g. drive increases in customer acquisition and retention, engagement, purchase frequency and average order value\nManage data projects end to end, including opportunity identification, data gathering, data cleansing and analysis, \nAnalyse customer behavioural data to develop insights and identify performance improvement and growth opportunities\nCollaborate with the data team (Data Science, Data Engineering, BI and Analytics), reviewing solutions, sharing knowledge, and improving coding standards\nCoach cross-functional teams to understand where and when different models or analyses should be used and can create value.\n\n\n\nWhat you already have\n\n\n\n5+ years of experience as a Data Scientist or related working experience, e.g. Machine Learning Engineer\nTertiary qualification in a quantitative discipline (e.g. Statistics, Engineering, Mathematics)\nBackground in statistical analysis techniques, including logistical regression, linear regression, K-Means clustering, random forest, factor analysis, and text analysis.\nExperience with Prediction/Forecasting economic growth from transactions and customer behaviour\nExperience extracting informations from images and text\nStrong technical experience using SQL, Python or R (GCP is a bonus)\nExperience developing machine learning algorithms\nCapable of working with high volumes of structured and unstructured data\n\n\n\nNice to have\u2026\n\neCommerce experience\nExperience in a high-growth digital business\nExcellent communication and presentation skills\nAble to work directly with a variety of internal and external stakeholders\nStrong planning and project management skills\nComfortable working in a fast-moving environment\nCurious mind and strong problem-solving skills\n\n\n\nIt is expected that you will also make a contribution to:\n\n\n\nCultural, social and behavioural standards within the business through leadership by example (i.e. Walk the Talk)\nManagement presentations as required\nAny other responsibilities/duties as required by the group\n\n\n\nNaturally, there's the expectation that you'll bring good humour, a strong sense of personal style!\n\n\nAdditional benefits\n\nAmazing culture\nCompetitive salary\nGenerous employee discounts across our entire range\nFlexible working arrangements\nPaid leave on your birthday\nPaid parental leave\nCatered lunch provided 3 days per week\nSubsidised breakfast daily\nFree mindfulness practice daily\nRegular celebrations and team socials\nOpportunities to volunteer with our charity partner"
    },
    {
        "position": "Data Scientist",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Symptoma",
        "sector": "Hospitals and Health Care",
        "companySize": "51-200 employees",
        "location": "Vienna, Vienna, Austria",
        "post": "About the job \n\nWE WANT TO SAVE LIVES. ARE YOU ON BOARD?\n\nWe are doers. Our amazing team joined forces for a bold mission worth fighting for: To give every patient access to the right diagnosis and treatment.\n We know that each and every one of us can make a difference with our unique skills, powers & passions. As a team, we are powerful and overcome even the biggest challenges. Take this chance to become part of Symptoma - read on!\n\nTHESE TASKS AWAIT YOU:\n\n\nDesign and implement models to improve the diagnostic capabilities of Symptoma\nCommunicate data-driven results to both key stakeholders and company-wide\nOwn projects from development to deployment, either working independently or as part of a team\n\nWHAT YOU BRING ALONG:\n\nMust-haves:\n\nDegree in a quantitative field (e.g., computer science, statistics, math, physics, informatics)\nWorking experience in data science\nAbility to work independently or as part of a team\nExperience in Python\nExperience with LINUX operating systems\nFluency in English, both written and spoken\n\nNice-to-haves:\n\nExperience with Java\nExperience in Natural Language Processing (NLP), especially when applied to medical data\nExperience in Deep Learning and neural nets\nExperience with ElasticSearch\nExperience in software engineering, including code versioning and test-driven development\nExperience with containerization (Docker) and cloud computing \nDomain knowledge in medical informatics and/or digital health\n\nWHY YOU SHOULD APPLY:\n\n\nImpact: Leave a dent in this universe and use your skills for a good cause.\nGrowth: Work at a fast-growing scale-up company with great opportunities for career progression.\nAppreciation: Your input and creative ideas are highly appreciated \u2013 we want YOU with all your abilities, talents and (soft) skills.\nResponsibility: You are responsible for what you do - you\u2019re not only able to implement what you envision but also to work without supervision. Don\u2019t hesitate to bring in all your strengths, knowledge and experience to reach your full potential.\nFlexibility: Being productive before the earliest early birds, taking an extra long coffee break or working in the dark, you can find your rhythm with us.\nHome Office: We have an output-orientated mindset and trust our team members to decide for themselves where they can work the best (amount of home office days may differ depending on the position).\nDiversity: Our team is anything but boring \u2013 Do you speak Arabic, Swedish or Chinese? We\u2019ll be able to understand you! \nEquipment: We offer state-of-the-art workstations (multiple monitors, powerful laptops, height-adjustable desks)\nAmazing office: in vibrant Vienna (excellent accessibility in the heart of the third district)\n\nGreat performers must be paid appropriately. We offer a monthly salary starting at 3.200 Euro gross per month following internal company agreements for this position. Your professional experience, qualifications, and industry standards will guide the actual remuneration package.\n\nWE MIGHT BE THE PERFECT FIT FOR YOU. LET'S FIND OUT!\n\n__Please send us the following file:\n\nonly your CV (Please include the code-word \"Better Diagnosis\" as text in your CV)\n\nApply now and help us take healthcare to the next level.__"
    },
    {
        "position": "Software Engineer",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "The Coca-Cola Company",
        "sector": "Food and Beverage Services",
        "companySize": "10,001+ employees",
        "location": "Sofia, Sofia City, Bulgaria",
        "post": "About the job \n\nPosition Overview\n\nCoca-Cola is one of the most recognizable brands in the world. We were the first company to ever utilize coupons and for decades our marketing practices have been cutting edge. Today we\u2019re using world class Marketing Technology (MarTech) to continue to market our brands to billions of consumers globally.\nThe Coca-Cola Company\u2019s IT organization is in the midst of a digital transformation that allows our employees to use world class technology to connect our products to our customers all over the world. This journey is a very exciting time for Coca-Cola and our employees are big contributors to our Success and Growth. Our large, scale and complex environment offers an incredible opportunity to address challenges, enable innovative solutions to make a difference for our customers, leveraging technology such as Adobe Experience Platform (AEP), AWS, MS Azure, and many more.\nTo continue this digitalization, we are looking for a software engineer to join our dynamic team to help build scalable, cutting-edge technologies for today and tomorrow. This position is part of a globally networked team that utilizes deep technical skills to create and improve software applications that empower the Coca-Cola Company to reach our growth objectives. If you enjoy a dynamic, innovative environment, are eager to learn and highly motivated, we\u2019d love to speak with you!\nWhat You\u2019ll Do For Us\n\n\n\nDevelop and implementation of new capabilities and enhancements within Coca-Cola\u2019s Adobe Experience Platform (AEP) and Cloud environments\nIntegrate AEP with Coca-Cola\u2019s internal Consumer Data Services (CDS) platform, Adobe\u2019s Experience Cloud ecosystem (Target, Magento, Campaign), and 3rd party destinations including: social, mobile, Google, Demand Side Platforms (DSPs), and other Ad Tech capabilities\nDesign and code the interfaces between TCCC\u2019s Consumer Data Services (CDS) platform and AEP, AEP to TCCC\u2019s enterprise data lake, identity graph, Google Big Query, and Adobe Web SDK JavaScript library\nCreate Customer Journey Analytics dashboards providing insights to business stakeholders\n\n\nQualifications And Requirements\n\n\n\nBachelor's degree in Computer Science, Computer or Electrical Engineering or related fields\n2 years as Full Stack Software Engineer with experience of creating elegant, efficient, and testable code\nBack-end programming experience with Java, JavaScript, Python, plus front-end JavaScript development frameworks such as ReactJS, NodeJS, AngularJS, SQL, etc.\nWorking knowledge of AWS and/or Azure serverless products (network, storage, compute, database)\nExperience using cloud database systems and services such as AWS Aurora/Dynamo DB/Redshift or Azure alternatives\nExperience implementing REST APIs and web services\nExperience in dev-ops delivery/support models as well as iterative software delivery methodologies \u2013 Agile, SCRUM, etc. \nSolid understanding of Git-based version control\n\n\nPreferred Experience \u2013 if you don\u2019t have it, we\u2019ll train you on it!\n\n\n\nAt least 1 year of experience with Adobe Experience Platform including managing Experience Data Model (XDM) schemas, AEP setup through API, REST & Postman\nMarketing Automation experience with Consumer Data Platforms (CDPs) including: audience segmentation & activation, multichannel campaign management, and real-time interaction management, and consumer database, work for diverse global companies preferred\nAmazon Web Services (AWS) and/or Microsoft Azure Certifications \nExperience with personal (PII) data privacy and security best practices\nExperience with Azure B2C and Consumer Data (Consumer Identity and Access Management) is a strong plus\nExperience working in a multinational, distributed team, with in-house and external delivery resources\nProficiency in Jira, or similar Agile life cycle management tools\n\n\nWhat We Can Do For You\n\n\n\nInnovation & Technology: The ability to work with an award-winning team that is on the cutting edge of innovation. \nLearning & Development:\u202fAt\u202fThe\u202fCoca-Cola Company we believe innovation can't happen without continuous learning and we provide our employees many ways to grow professional and personally.\nAgile Work Environment: We embrace agile with management that believes in removing barriers, so you are empowered to experiment, iterate and innovate.\n\n\nSkills\n\nAngularJS; Hyper Text Markup Language (HTML); React.js; Cascading Style Sheets (CSS); Customer Service; Chatbots; Algorithms; Agile Methodologies; Adobe Experience; Data Modeling; Natural Language Processing (NLP); Analytical Techniques; Oral Communications; Server Side Development; Azure Bot Service; JavaScript; Artificial Intelligence Technologies; Written Communication; Problem Solving; Data Mining; Teamwork; Adaptability; Adobe Experience Platform; Self-Starter; Machine Learning\nOur Purpose And Growth Culture\n\nWe are taking deliberate action to nurture an inclusive culture that is grounded in our company purpose, to refresh the world and make a difference. We act with a growth mindset, take an expansive approach to what\u2019s possible and believe in continuous learning to improve our business and ourselves. We focus on four key behaviors \u2013 curious, empowered, inclusive and agile \u2013 and value how we work as much as what we achieve. We believe that our culture is one of the reasons our company continues to thrive after 130+ years. Visit Our Purpose and Vision to learn more about these behaviors and how you can bring them to life in your next role at Coca-Cola.\nWe are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and/or expression, status as a veteran, and basis of disability or any other federal, state or local protected class. When we collect your personal information as part of a job application or offer of employment, we do so in accordance with industry standards and best practices and in compliance with applicable privacy laws.\nR-74898"
    },
    {
        "position": "Software Engineer",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Shopee",
        "sector": "Food and Beverage Services",
        "companySize": "10,001+ employees",
        "location": "Sofia, Sofia City, Bulgaria",
        "post": "About the job \n\nAbout The Team\n\nThe search algorithm team is responsible for Shopee\u2019s product and store search. Our main mission is to continuously build world class search algorithms and become a power engine for the company's sustainable growth. We welcome passionate and experienced talents to join us and serve our customers from all over the world.\n\nJob Description\n\n\nResponsible for the design and optimisation algorithms, including category prediction, entity matching, semantic models, etc. \nDesign and optimisation of the recall algorithm model, including query rewriting, vector retrieval, deep personalised retrieval model, multi-modal retrieval model, etc. \nConstruct and apply knowledge graphs and knowledge bases, data annotation and data mining and apply them to relevance, query rewrite and etc. \nEnhance user shopping experience through improving features such as prefill, suggestion and related search.\n\n\n\nRequirements\n\n\nMore than 4 years of relevant work experience \nMaster degree or above in computer science, computational linguistics and other related majors \nHave excellent coding skills, hands-on online code development experience, and proficiency in at least one language among C++/Golang/Python/Java"
    },
    {
        "position": "Software Engineer",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Intel                                                                                                                                                                            Corporation",
        "sector": "Food and Beverage Services",
        "companySize": "10,001+ employees",
        "location": "Sofia, Sofia City, Bulgaria",
        "post": "About the job \n\n\n\nJob Description\n\nCorporate Services (CS) touches the lives of every Intel employee every day. CS creates an environment where employees can prosper while creating the innovative technologies that make amazing possible. Our scope is vast and includes operating and maintaining all Intel sites, offices, labs and factories globally as well onsite services and experiences that help employees stay safe and productive. CS also helps to make Intel and our community a greener place by supporting Intel commitment to environmental sustainability, including investing in conservation projects, setting company-wide environmental targets and driving reductions in greenhouse emissions, energy use, water use and waste generation.\n CS Central Engineering (CSCE) owns the strategic and systematic development, standardization, implementation, and measurement of key central engineering functions to drive efficiency, reliability, and world class cost optimization to support our global facilities portfolio. The scope of the Central Engineering Organization within Corporate Serviced consists of asset management, cost engineering, enabling growth, and automation.\n Central Engineering - Automation team is looking for an innovative, creative, and intellectually curious Data Scientist with experience in developing Machine Learning software to join our CS Central Engineering Automation team. This is an exciting opportunity to work in one of the world's leading semiconductor manufacturers working with real-world analytics to help our clients maximize equipment uptime, reduce risk and make more informed decisions. We are at a unique point in our company's journey. As we scale to more manufacturing sites worldwide, we must be efficient in the way we monitor and maintain our systems. Only by striving for excellence in our maintenance strategy and remaining at the technological edge can we ensure that we achieve our mission of creating world-changing technology that improves the life of every person on the planet.\n\nAs a CSCE-A Data Scientist your responsibilities will include but are not limited to:\n\n\nWork alongside our multi-disciplinary Automation team and apply data science techniques to predict anomalies and faults in complex, large-scale time-series data. \nApply your data science skills and statistical knowledge to build an autonomous fault detection and root cause platform using Machine Learning methodologies. \nSupport consulting activities to identify data availability, quality, and modelling requirements and participate in our customers' engagement.\n\n\nWhat We Offer\n\n\nWe give you opportunities to transform technology and create a better future, by delivering products that touch the lives of every person on earth. As a global leader in innovation and new technology, we foster a collaborative, supportive, and exciting environment-where the brightest minds in the world come together to achieve exceptional results. \nWe offer a competitive salary and financial benefits such as bonuses, life and disability insurance, opportunities to buy Intel stock at a discounted rate, and Intel stock awards (eligibility at the discretion of Intel Corporation). \nWe provide benefits that promote a healthy, enjoyable life: excellent medical plans, wellness programs and amenities, flexible work hours, time off, recreational activities, discounts on various products and services, and many more creative perks that make Intel a Great Place to Work. \nWe're constantly working on making a more connected and intelligent future, and we need your help. Change tomorrow. Start today.\n\n\nMinimum Qualifications\n\nQualifications\n\n\nBachelors/Masters with 8 yrs experience in Computer Science or related field or a PhD in Computer Science or related field with 4 yrs experience in Statistical analysis, machine learning and deep learning methodologies.Large datasets and scaling ML models and information extraction. Computing fundamentals in algorithm design, data structures, complexity analysis, problem-solving and diagnosis. \nGood understanding of data science concepts, such as regression analysis, predictive modelling, and data visualization.\n\n\nPreferred Qualifications\n\n\nUnderstanding of what it takes to write clean code and experience with software development lifecycle. \nKnowledge of system identification of dynamic models and control systems. \nExperience with Vibration analysis, Fault Detection and Root Cause Diagnosis. \nPractical experience of predicting Remaining Useful Life. \nExtraction of conditional indicators using signal processing techniques and analyzing data from physical sensors.\n\n At Intel inclusion means we recognize and respect the worth and dignity of every employee. We promote and sustain a sense of belonging, valuing diverse talents, beliefs, backgrounds, and experiences to help Intel win. Our success depends on Intel\u2019s amazing employees. Make Intel your workplace of choice today. Intel provides equal employment opportunity for all applicants and employees in all areas of employment.\n Intel does not discriminate based on race, characteristics that are commonly or historically associated with race including hair, color, religion, religious creed, sex, national origin, ancestry, age, physical or mental disability, medical condition, genetic information, military and veteran status, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or ordinance.\n\nInside this Business Group\n\nAs the world's largest chip manufacturer, Intel strives to make every facet of semiconductor manufacturing state-of-the-art -- from semiconductor process development and manufacturing, through yield improvement to packaging, final test and optimization, and world class Supply Chain and facilities support. Employees in the Technology Development and Manufacturing Group are part of a worldwide network of design, development, manufacturing, and assembly/test facilities, all focused on utilizing the power of Moore\u2019s Law to bring smart, connected devices to every person on Earth.\n\nWork Model for this Role\n\nThis role will be eligible for our hybrid work model which allows employees to split their time between working on-site at their assigned Intel site and off-site."
    },
    {
        "position": "Software Engineer",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Sanofi",
        "sector": "Food and Beverage Services",
        "companySize": "10,001+ employees",
        "location": "Sofia, Sofia City, Bulgaria",
        "post": "About the job \n\n\n\nAbout Sanofi:\n\nWe are an innovative global healthcare company, driven by one purpose: we chase the miracles of science to improve people\u2019s lives. Our team, across some 100 countries, is dedicated to transforming the practice of medicine by working to turn the impossible into the possible. We provide potentially life-changing treatment options and life-saving vaccine protection to millions of people globally, while putting sustainability and social responsibility at the center of our ambitions.\n\nOur vision for digital, data analytics and AI\n\nSanofi has recently embarked into a vast and ambitious digital transformation program. A cornerstone of this roadmap is the acceleration of its data transformation and of the adoption of artificial intelligence (AI) and machine learning (ML) solutions. This has enabled us, to accelerate R&D, improve manufacturing and commercial performance, and bring novel drugs and vaccines to patients faster, all in order to improve health and save lives.\n The Digital Team at Sanofi is a unique data-driven team. We pride ourselves on being data obsessed and highly focused on using state of the art processes along with global technologies to drive impact to our solutions. We measure our insights and products based on how they preform across the globe and hold ourselves to the highest regard as our solutions can impact millions of lives. When tackling a problem, we do not just ask how we will create a solution, but how we will create a solution that reaches across the world with the best possible societal outcome.\n If you are passionate about improving the health and wellness of people across the globe using Data as your means, then you should look no farther than the Digital Team here at Sanofi.\n Join us on our journey in enabling Sanofi\u2019s Digital Transformation through becoming an AI first organization. This means:\n\n\nAI Factory - Versatile Teams Operating in Cross Functional Pods: Utilizing digital and data resources to develop AI products, bringing data management, AI and product development skills to products, programs and projects to create an agile, fulfilling and meaningful work environment. \nLeading Edge Tech Stack: Experience build products that will be deployed globally on a leading-edge tech stack. \nWorld Class Mentorship and Training: Working with renowned, published leaders and academics in machine learning to further develop your skillsets\n\n\n\nThere are multiple vacancies across our Digital organisation. Further assessments will be completed to determine specific function and level of hired candidates. \n\nJob Highlights: \n\n\n\nApply data science expertise in machine learning, statistics, text-mining/NLP, forecasting and optimization to multiple analytics projects. \nBuild models, algorithms, simulations, and experiments by writing highly optimized code and using state-of-the art machine learning technologies. \nWork on full-spectrum of activities, from conducting ML experiments to delivering production-ready models. \nUse data analysis, visualization, storytelling, and data technologies to scope, define and deliver AI-based data products. \nWork with developers, engineers, and MLOps to deliver AI/ML solutions. \n\n\n\nKey Functional Requirements & Qualifications:\n\n\n\nHands-on AI/ML modeling experience of complex datasets combined with strong understanding of theoretical foundations of AI/ML. \nExpertise within most of the following areas: supervised learning, unsupervised learning, deep learning, reinforcement learning, federated learning, time series forecasting, Bayesian statistics, optimization \nExperience developing deployable code and deploying models in product-focused development under an agile environment \nComfortable working in cloud and high-performance computing environments (e.g. AWS, GCP, Databricks, Apache Spark) \nExperience in production-ready software development \nExcellent written and verbal communication, business analysis, data visualization and data storytelling skills \nA demonstrated ability to work and collaborate in a team environment \nNice to have: Experience in life sciences and healthcare and experience in a complex global organization \n\n\n\nKey Technical Requirements & Qualifications:\n\n\n\nPhD in mathematics, computer science, engineering, physics, statistics, economics, or a related quantitative discipline with strong coding skills, OR Master\u2019s\u202fDegree in relevant domain with 4+ years of analytical experience \nExpertise with core data science languages (such as Python, R, Scala), and familiarity with different database systems (e.g. SQL, NoSQL) \nDisciplined AI/ML development (CI/CD, Orchestration) \nKnowledge of\u202fTableau, Power BI, Plotly or similar \nExperience with various enterprise-level Application Programming Interfaces (APIs) \n\n\n\nLocation: \n\nGlobal Innovation center - Barcelona - Spain\n At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all.\n Sanofi is committed to welcoming and integrating people with disabilities.\n\nNote:\n\nOnly those candidates selected for interviews will be contacted.\n Thank you in advance for your interest.\n You can learn more about our opportunities:\n www.sanofi.com\n www.linkedin.com/company/sanofi\n\nPursue Progress. Discover Extraordinary.\n\nOwn your future. Make your move!\n\n#DDBBCN \n\n#Hybrid\n At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all."
    },
    {
        "position": "Data Analyst (f/m/d) technical lead at Computed Tomography",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Siemens Healthineers",
        "sector": "Hospitals and Health Care",
        "companySize": "10,001+ employees",
        "location": "Forchheim, Bavaria, Germany",
        "post": "About the job \n Do you want to help create the future of healthcare? Our name, Siemens Healthineers, was selected to honor our people who dedicate their energy and passion to this cause. It reflects their pioneering spirit combined with our long history of engineering in the ever-evolving healthcare industry.\n We offer you a flexible and dynamic environment with opportunities to go beyond your comfort zone in order to grow personally and professionally. Sound interesting?\n\nThen come and join our global team as Data Analyst (f/m/d) technical lead at Computed Tomography (CT) to shape the future of CT by applying your technical skills, analytical mindset and product intuition.\n\nChoose the best place for your work - within the scope of this position, it is possible, in consultation with your manager, to work mobile (within Germany) up to an average volume of 60% of the respective working hours.\n\nThis position is limited to 24 months.\n\nYour tasks and responsibilities:\n\n\n\nYou will drive the mindset of data driven decisions and promote the benefits and value of our data analytics solutions\nAs a product owner of business-critical data analytics applications, you will support the analysis of stakeholder objectives, assess the problems needing to be solved using Data Analytics methods and communicate the requirements to other Data Analysts and Data Scientists\nYou will design, ideate, implement, validate, and deploy data analytics and data science projects in CT to analyze data, generate insights, create business value, and support decision-making\nAs a recognized Data Science expert, you will actively contribute to our Communities of Practice and knowledge sharing events and thereby shape our analytics methods, standards, and guidelines\nYou will provide a technical leadership to the team of data analysts and data scientists\n\n\nTo find out more about the specific business, have a look at Computed tomography\n\nYour qualifications and experience:\n\n\n\nYou hold a Master's degree in science, technology, engineering and mathamatics or a related field with a strong quantitative focus\nYou have several years of experience as a data analyst with successful execution of a variety of practical projects\nYou have strong understanding and experience in execution of data science workflows like CRISP-DM\nYou know the principles of agile development and have already worked as a member of an agile development team\nYou have solid understanding of Machine Learning (supervised and unsupervised learning, NLP, explainable AI) and you are strong in exploratory data analysis and feature engineering\nYou have a successful track record of running diverse data analytics / data science projects\nYou have experience in Visual Analytics, building data-driven applications for end users with BI tools (Qlik, Power BI)\n\n\nYour attributes and skills:\n\n\n\nYou have excellent professional communication skills (English, written and oral), German would be a plus\nYou are flexible and curious to learn new technologies and business areas fast\nYou confidently interact with developers and business stakeholders and can present your work to technical and non-technical audiences\nYou have an entrepreneurial and performance-driven mindset and a team player mentality with the ability to drive results under own initiative in an agile and fast driving environment\nYou have strong technical grasp on task prioritization and effort estimation\nYou are motivated to drive a range of data analytics projects and to lead strategic visions and benefit our team with your active, energetic mindset\nYou have experience / strong potential to functionally lead the team\n\n\nOur global team:\n\nSiemens Healthineers is a leading global medical technology company. 66,000 dedicated colleagues in over 70 countries are driven to shape the future of healthcare. An estimated 5 million patients across the globe benefit every day from our innovative technologies and services in the areas of diagnostic and therapeutic imaging, laboratory diagnostics and molecular medicine, as well as digital health and enterprise services.\n\nOur culture:\n\nOur culture embraces different perspectives, open debate, and the will to challenge convention. Change is a constant aspect of our work. We aspire to lead the change in our industry rather than just react to it. That\u2019s why we invite you to take on new challenges, test your ideas, and celebrate success.\n Check our Careers Site at https://www.siemens-healthineers.com/de/careers\n As an equal opportunity employer, we welcome applications from individuals with disabilities.\n Wish to find out more before applying? Contact us: +49 (9131) / 17 \u2013 1717, if you wish to discuss any initial questions with our recruitment team. The contact person handling this job ad is\n Laura Roos.\n We care about your data privacy and take compliance with GDPR as well as other data protection legislation seriously. For this reason, we ask you not to send us your CV or resume by email. We ask instead that you create a profile in our talent community where you can upload your CV. Setting up a profile lets us know you are interested in career opportunities with us and makes it easy for us to send you an alert when relevant positions become open. Click here to get started.\n Siemens Healthineers Germany was awarded the Great Place to Work\u00ae certificate.\n\nOrganization: Siemens Healthineers\n\nCompany: Siemens Healthcare GmbH\n\nExperience Level: Mid-level Professional\n\nJob Type: Full-time"
    },
    {
        "position": "Natural Language Processing Scientist",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Novo Nordisk",
        "sector": "Pharmaceutical Manufacturing",
        "companySize": "10,001+ employees",
        "location": "M\u00e5l\u00f8v, Capital Region, Denmark",
        "post": "About the job \n As part of the digitalisation of early research at Novo Nordisk we are looking for outstanding candidates with a strong background in computational science and natural language processing (NLP) who can bring value to the organisation by turning text into data for analysis and insights, via application of NLP and analytical methods.\nThis is an exciting position where you will help scientists in the early research organisation to transform their decision-making from a document-centric view of finding documents and reading them, to a data-centric view of uncovering new insights by the use of natural language processing-based text mining. This will help the researchers to overcome the limitations of unstructured data and uncover previously hidden relationships.\nThis is your chance to join forces with a competent information research department and help democratize external and internal scientific information and data. The position offers you a unique combination of science and information research.\nAbout The Department And Area\n\nYou will join 20 dedicated colleagues within the Novo Nordisk Global Information and Analysis department (GLIA), which offers a worldwide information service and scientific intelligence function to Research & Early Development (R&ED), at headquarter and affiliates.\n\nOur purpose is to provide modern digital solutions to the organisation and to ensure that internal customers have easy and global access to quality information sources and professional information research services supporting their needs.\nGLIA is part of a new area, Digital Research & Intelligence, which is being establised to provide a modern scientific intelligence unit, drive external collaborations and access to emerging technologies in the digital space of drug discovery, facilitate idea maturation and develop an educational framework to drive our digital jounney.\nDigital & Research Intelligence is part of Digital Science & Innovation (DSI), which was recently established to drive digitalisation across R&ED. DSI participates in drug development projects across the value chain, from early discovery to pre-clinical development.\n\nThe position\n\nYou will work as a NLP specialist and be a key expert within your field. By combining NLP text mining, artificial intelligence, mechanistic modelling and knowledge graphs you will help scientists in early research to extract key information from unstructured text, rapidly and effectively, to provide decision support. You will be working with textual documents of multiple format like scientific literature, patents, patient literature, internal safety reports, drug labels, clinical trial data, social media, electronic health records, Google slides, Electronic Lab Notebooks etc.\nKey Responsibilities\n\n\n\nDevelopment of algorithms for information extraction \nRelationship extraction/semantic similarities, summarization, Natural Language inference\nNeural network models for language understanding tasks like BERT, GTP-3 etc\nEvaluate the performance of neural models and validate the accuracy of extracted knowledge\nSupport GLIA and relevant part of DSI with knowledge enriching analysis results via natural language generation \nWork closely with relevant Digital Science & Innovation teams to translate best-performance techniques into production \nResponsible for presentation and reporting of scientific results \nParticipate in line/digital projects progression with strong NLP and knowledge graph expertise\nEncourage, propose and participate in projects boosting the use of advanced text mining and knowledge graphs\n\n\nQualifications\n\nWe are looking for a highly motived person preferable with a PhD in Computer Science, AI, Computational Linguistics, Applied Mathematics, Physics or similar. Further we expect you to have the skills and expertise listed below:\n\n\nProfound knowledge of Deep Learning methods applied to NLP\nStrong Experience with Natural Language Processing and Machine Learning technologies\nDemonstrated strong track record of developing and applying NLP solutions\nExcellent written, verbal presentation and graphical communication skills \nEffective communication skills with the desire to work with dispersed teams across multiple time zones\nAttention to detail, diligent and tenacious\nHigh degree of personal motivation and ability to self-manage \n\n\nTitle and conditions are evaluated based on the individual experience and contribution.\nContact\n\nFor further information, please contact Lilian Nilsson by email lznl@novonordisk.com\nDeadline\n\nAugust 31, 2022\nWe commit to an inclusive recruitment process and equality of opportunity for all our job applicants.\nAt Novo Nordisk we recognize that it is no longer good enough to aspire to be the best company in the world. We need to aspire to be the best company for the world and we know that this is only possible with talented employees with diverse perspectives, backgrounds and cultures. We are therefore committed to creating an inclusive culture that celebrates the diversity of our employees, the patients we serve and communities we operate in. Together, we\u2019re life changing."
    },
    {
        "position": "DATA SCIENTIST",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Ferrero",
        "sector": "Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Kirchberg, Luxembourg, Luxembourg",
        "post": "About the job \n Job Location: Luxembourg\n\nCompany Description\n\nFerrero is a family-owned company with a truly progressive and global outlook and iconic brands such as Nutella\u00ae, Tic Tac\u00ae, Ferrero Rocher\u00ae, Raffaello\u00ae, Kinder Bueno\u00ae and Kinder Surprise\u00ae. As the love for our brands continues to grow, so too does our global reach. Represented in 55 countries, with products sold in more than 170, the Ferrero Group is loved by generations around the world. The secret to our global success? Nearly 35,000 dedicated employees who celebrate care and quality to craft a business, careers and brands we are proud of. Join us, and you could be one of them.\n Diversity Statement\n Ferrero is committed to building a diverse and inclusive culture in which all employees feel welcomed and appreciated and have the same opportunities. We believe all of our people are equally talented in their own way. In nurturing the curiosity and natural abilities of our employees, we provide them, generation after generation, the means to succeed personally and professionally, enabling them to craft their journey at Ferrero. The diversity of our talents is what makes our work environment multicultural, innovative and highly rewarding.\n\nAbout the Role:\n\nFor our Ferrero Headquarter in Luxembourg we are currently looking for a talented DATA SCIENTIST supporting our Advanced Analytics pillar.\n Reporting to the Advanced Analytics Leader, the successful candidate will be focal point for:\n\nBusiness stakeholders across categories and geographies\nFerrero Luxembourg IT department\nColleagues in BI&A Unit working in Business Partnership pillar to support identification of potential solutions for business problems\nColleagues in BI&A Unit working in Data Governance pillar to identify current and new potential datasets for use in analysis \nPotentially work with external agencies and data brokers as needed.\n\n\nMain Responsibilities:\n\n\nDevelop, test and rollout statistical models to support analytics and business reporting functions\nCreate procedures to clean and classify data from disparate sources like retail sell-out, shopper behavior, consumer surveys, marketing and other 3rd party sources for use in modeling and reporting\nPractical experience of media measurement including digital to support business decision making\nScript automation procedures for analytical flows\nVisualizing analytic results for business stakeholders in PowerBI\nCreate dashboard templates and help BI colleagues to create and customize their own\nGuide and mentor junior data scientists on existing analyses and new capabilities creation.\n\n\nWho we are looking for:\n\nProfile\n\n\nBachelor\u2019s degree in quantitative area like Mathematics, Econometrics, Statistics, Engineering etc. Advanced degree preferred\nMinimum 3 \u2013 5 years of experience in applied work on Advanced Analytics, preferably at a FMCG manufacturer company\nExperience in modeling techniques and advanced statistical concepts: Regression, Classification, Text mining, Random Forest etc\nAnalytical creativity and desire to test & learn. Interpretation of analytic outputs from business standpoint\nExperience using external third-party data sources including Nielsen, IRI, consumer surveys\nStrong understanding of media data including traditional and digital\nRelevant communication skills.\n\n\nIT Skills\n\n\nExcellent knowledge and best practice analysis/programming of SQL, PowerBI, Azure, Spark, Scala, Power BI, Google Analytics, SAP HANA\nStrong knowledge of best practice analysis and programming techniques with R and Python.\n\n\nLanguages\n\n\nFluent in English is mandatory\nAny other language is a plus.\n\n\nHow to be successful in the role and at Ferrero:\n\nConsumers, quality and care are at the heart of everything we do. So, to be successful at Ferrero, you\u2019ll need to be just as consumer and product centric as we are - dedicated to crafting brilliant results for consumers around the world."
    },
    {
        "position": "DATA SCIENTIST",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "DEPT\u00ae",
        "sector": "Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Kirchberg, Luxembourg, Luxembourg",
        "post": "About the job \n Apply\n\nWanted: a Data Scientist who knows exactly how to work with algorithms, big data, machine learning and who can build predictive models. \n\nAs a data scientist, you know how to structure and clean up giant datasets meticulously, in order to apply your algorithms on them. You recognise patterns in data that no-one else would and this enables you to make campaigns better and smarter. From the output of a calculated dataset, you can start with the analysis for a client and eventually you are able to communicate your advice in a clear fashion to your team and your client.\n\nResponsibilities: \n\n\nPredicting customer propensity; \nForecasting supply and demand; \nSegmenting customer groups based on behavioural data;\nRecommending products and/or content. \n\n\nData at DEPT\u00ae: \n\n\nA group of data-hungry colleagues that will feel like friends in no-time;\nThe possibility to work with cutting-edge technologies in a continuously evolving environment;\nGood vibes: we\u2019re trusting and believe in creative freedom and autonomy;\nIf you grow, we grow. That\u2019s why we\u2019ll cheer you on [and support you] with personal coaching, a development plan and budget; \nProjects that work for you as well as the other way around. From short and snappy to more in-depth: whatever fits your ambition;\nClients that will make you feel like a proud ambassador, like Philips, Just Eat Takeaway and bol.com;\nBest of both worlds: the pros of an international leading agency with the energy of a local studio.\n\n\nWe strongly support diversity and are committed to create an inclusive environment for everyone at DEPT\u00ae. Ultimately, we are looking for a unique individual who wants to strengthen our work and community.\n\nYou:\n\n\nMUST HAVE at least 2 years of hands-on working experience in a data science role, preferably related to digital marketing data and/or working at a digital agency;\nAre an expert in Python (MUST), and experienced in SQL;\nStudied Business IT or similar (Computer Science, Data Science, Information Management);\nHave experience with Amazon Web Services, Azure or Google Cloud Platform;\nHave experience with Google Analytics and/or other Web Analytics software;\nAre familiar with NLP and MLOps; \nAre analytical, flexible, independent and a strong communicator.\n\n\nBenefits:\n\n\nDEPT\u00ae has been named A Great Place To Work in 2022 and certified B-Corp\u00ae since 2021 \u2013 award winning in the best way possible.\nAwesome clients. Whether big, small, local or global \u2014 at DEPT\u00ae you\u2019ll get the opportunity to work with all of them. And we celebrate all of our successes together!\nThe choice to work where you are most productive: whether that is in one of our offices, or abroad for 13 weeks a year. Rather work from home? No problem! We\u2019ll provide you with the best of class materials, such as a high-quality laptop, monitor, work phone and the necessary furniture.\nOpportunities to develop your skills even further through training and certifications. \nEverything to focus on your health: from free bootcamp to yoga lessons, mindfulness sessions, mental health services, serious discounts on sport memberships, healthy lunches at the office, and above all: a safe work environment. \nGreat fringe benefits; use of OV-bikes, an NS Business Card and many other goodies.\nYou can discover even more employee benefits here.\n\n\nDEPT\u00ae is a pioneering technology and marketing services company that creates integrated end-to-end digital experiences for brands such as Google, KFC, Philips, Audi, Twitch, Patagonia, eBay and more. Its team of 2,500+ digital specialists across 30+ locations on 5 continents delivers pioneering work on a global scale with a boutique culture. DEPT\u00ae is committed to making a positive impact on the planet and since 2021 has been Climate Neutral and B Corporation certified. Learn more about our diversity, equity, and inclusion efforts here or visit our careers page to find out more about culture and growth opportunities at DEPT\u00ae.\n\nRead more about our application process here and apply by clicking on the \u2018Apply\u2019 button."
    },
    {
        "position": "Remote | Data Scientist - Pricing and Valuation team",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "OLX Group",
        "sector": "Software Development",
        "companySize": "10,001+ employees",
        "location": "Pozna\u0144, Wielkopolskie, Poland",
        "post": "About the job \n WELCOME TO OLX GROUP\nOver 300 Million monthly active users; US $1.6 billion in revenue and 18% revenue growth (FY 2021; 36% growth in FY2020); Part of Naspers\u2019 Prosus, one of the biggest technology investors in the world (An early investor in Tencent and the owner of StackOverFlow). +30 countries. +20 Brands. Powered by +10,000 employees representing 81 nationalities. \nThat\u2019s what\u2019s on our plate at OLX Group.\nAnd that's why we need your help. Join Us. Shape your career with us.\nThe team\nThe Pricing and Valuation team at OLX Group is responsible for unlocking hidden value using data and artificial intelligence. We analyze the status quo, improve buyer & seller interactions, optimize the user experience and monetize on the delivered customer value. For us revenue growth is the good fruit of our work and not the goal itself. We invite you to join a team which works with OLX, Real Estate platforms (Otodom, Storia) and Automotive platforms (Otomoto, Standvirtual) across the entire EU region. A team that breaks through walls and builds cross-functional connections with everyone around. A team where a common mission and goals matter more than reporting lines. We build on each other, asking for help and support when needed, and we proactively support others. In your day to day routine you will have the opportunity to develop supervised models for behavioral classification, deep learning models for image classification, regression models for value estimation as well as NLP models for object and actor entity recognition. All in Python and the AWS cloud. You will be exposed to key stakeholders, having direct contact with internal customers. You will have the carte-blanche to experiment and test things. And most importantly, you will also witness how your work impacts the day to day business of OLX Group customer units. We have offices in Poznan and Warsaw, but this role can be based anywhere in Poland. \nWhat You Will Be Doing\n\n\nYour primary role will be to increase business value by finding opportunities where data science and machine learning can make an impact.\nYou will maintain strong relationships with stakeholders. This means asking a lot of questions to business people, translating their requirements into achievable projects. It also means collaborating with other teams, like infrastructure and data engineering to get things done in an elegant and timely manner. \nYou will build models, tinker around them to make them work, test them and eventually deploy to production. You will see your stuff in action and you will be able to measure the true impact of your models.\nYou will work in multi-functional teams, in a diverse, multinational environment, filled with people from Portugal, Bulgaria, Romania, Poland, Ukraine, Kazakhstan and Uzbekistan. \nMost importantly you will have fun working with us :)\n\nWhat Are We Looking For\n\n\nAnalytics and Modeling: \n\nVery strong analytical skills. Like really strong! So strong that truth and light are your two middle names. Solid background in statistics and modeling. Good knowledge of Python, which means having experience with at least one of the following: Scikit-Learn, TensorFlow, PyTorch, Pandas.\n\nMachine Learning Engineering: \n\nGood understanding of engineering best practices, that is: testing, CI/CD, monitoring, alerting, containers. Hands-on experience with SQL. Ability to work with big data at scale: experience with columnar storage clusters.\n\nStakeholder Management:\n\nProficient in English with excellent written and oral communication skills! Strong presentation skills. Able to work in multi-functional teams with people from different backgrounds.\nNice To Have\n\n\nDeploying models to production and serving models at scale.\nUsing AWS for deploying machine learning solutions.\nBuilding data pipelines using tools like Spark and Airflow.\nA/B testing.\nDocker.\n\nWhat We Offer\n\n\nStrengths-based personal career development.\nCompany mobile phone, MacBook Pro or Windows Dell along with necessary accessories to make your work comfortable.\nCompetitive compensation and benefits (medical care, sports package and others).\nTraining and conference budget.\nThe opportunity to learn from each other and become better every day.\nA passionate and diverse team of data scientists spanning across several tech hubs in Europe and around the world.\n\nWe look forward to receiving your application! OLX Group Talent Acquisition team\na Bit More About Us\nCheck our careers website here. Discover why you should join the OLX Group Now Check out our talent, product, engineering and design blogs here Follow us on Linkedin We encourage people of all races, ethnicities, disabilities, ages, gender identity or expression, backgrounds and experiences to consider applying for this role. We are committed to building an inclusive culture that seeks out the diverse perspectives and experiences of our people and becomes a company superpower and strategic competitive advantage. The OLX Group (OLX Group consists of OLX Global B.V. and its affiliated companies) will handle your personal data with care and will process your personal data to assess your fit for the position you are applying for. You can give your consent (optional) to allow us to store your data for up to 12 months after the application process. So that in case you are not fit for the role at stake we can consider you for other suitable roles. Please refer to our Privacy Statement to find out more about how your application data will be processed."
    },
    {
        "position": "Natural Language Processing Specialist (m/f/diverse)",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Continental",
        "sector": "Motor Vehicle Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Berlin, Berlin, Germany",
        "post": "About the job \n\nDescription\n\nWould you like to accelerate Continental's journey towards an AI-empowered company?\n As a Natural Language Processing Specialist in the Artificial Intelligence and Robotics Labs you will drive innovation projects with focus on artificial intelligence technologies for a broad range of application fields in industry 4.0 and automotive domains. This includes also the development of sophisticated solutions to improve our company's internal processes and operations.\n We look for a highly motivated and creative person with proven experience in NLP technologies. A profound knowledge of related methods, solution frameworks and a solid scientific background are of advantage. You will drive the development of novel concepts and the implementation of the technical solutions. Many challenging problems demand exploration of the latest achievements from the scientific community. You will work in collaboration with excellent Universities and Research Institutes in this field.\n In this position you will also support the definition of our strategy for Artificial Intelligence, consult business, innovation managers, product, and process owners about these technologies. Excellent communication and presentation skills are of advantage.\n\nDescription\n\n\n\nDrive innovation projects in the field of artificial intelligence and cognitive process automation, focusing natural language processing (NLP), machine learning based dialog systems, knowledge representation and semantic technologies, smart digital assistants\nDevelop novel application concepts using artificial intelligence to enhance company\u2019s internal processes (Sales, Marketing, HR, Engineering, Quality etc.)\nDevelop novel application concepts using artificial intelligence for mobility and industry 4.0 services\nPromote adoption of state-of-art and novel technologies in this field\nConsult business, innovation managers and product owners\nUnderstand and translate business and application specific needs into technical requirements\nElaborate solution concepts. Contribute hands-on to implementation of prototypes and technology demonstrators\nCollaborate close with other specialists: IT, System Engineers, Data Engineers, Software developers etc.\nEnsure hand-over from innovation to solution industrialization \nTechnical responsible for projects executed collaboration with Universities and Research Institutes\nMonitor technologies, open source frameworks, commercial tools and supplier offers in this field\nContribute to shaping Continental's Artificial Intelligence and Machine Learning strategy\n\n\nWorking in the AI Campus in Berlin means being part of a highly motivated and growing team of researchers working in the field of artificial intelligence. Being located in one of the German centers for AI, we strive to work on the frontier of research by having open exchange with experts and highly influential players in the community. Frequent talks, gatherings, and discussions as well as formal and informal team events ensure prompt spread of information. In our freshly established team of mostly Ph.D. students, we are maintaining an harmonious atmosphere of easy-going collaboration and exchange. Despite this inviting culture of togetherness, we will provide you with enough flexibility in terms of working time and location. Doing a Ph.D. in Continental is going to equip you with exceptional qualification, network, and industrial experience in the future field of autonomous driving. We are looking forward to meet you at the campus!\n\nQualifications\n\n\n\nStudied or did the Ph.D. in artificial intelligence, (business) computer science, mathematics, physics, robotics, computational neuroscience, or related fields\nWorked for several years with artificial-intelligence-related algorithms, neural language processing and related technologies like NLU or NLG, machine learning based chatbots, question-answering systems, and/or digital assistants\nKnow about machine learning frameworks like Tensorflow, Theano/Keras, Scikit-Learn, Spark/Mlib, R, etc.\nImplemented algorithms in object oriented programming languages \nDesirable to know about autonomous systems or to be interested in\nAble to professionally speak and write in English language\nSpeaking or eager to learn German\nIndependent, creative, and proactive working style\nCommunicate effectively with the ability to present technical concepts to all stakeholders\nAttitude towards driving customer and quality needs\n\n\nApplications from severely handicapped people are welcome.\n\nWhat We Offer\n\n\n\nIn addition to the interesting field of activity of the function, the city of Berlin offers a high recreational value and stands for quality of life\nYou will work in an innovative work environment, namely the \"co-working space AI Campus\"\nBecome part of our motivated team - we are looking forward to you"
    },
    {
        "position": "Data Scientist - Text Analytics and Natural Language Processing",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Merck Group",
        "sector": "Pharmaceutical Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Mollet del Vall\u00e8s, Catalonia, Spain",
        "post": "About the job \n Job description:\n\n\n\nA career at our company is an ongoing journey of discovery: our 60,300 people are shaping how the world lives, works and plays through next generation advancements in Healthcare, Life Science and Electronics. For more than 350 years and across the world we have passionately pursued our curiosity to find novel and vibrant ways of enhancing the lives of others.\n\n\n\n\n\n\nWho you are: As the Data Scientist, you will work in our global Reporting and Analytics team of the CFO Digital Strategy & Realization Organization. Our mission is to architect, design and refines analytics solutions supplying substantial and effective answers to business problems. We provide Digital Leadership for Analytics Initiatives across the Group Functions such as Finance, Procurement and HR. With our expertise, we support initiatives to produce practical and impactful analytic solutions for our customers. Operating in an agile environment, we closely work with internal and external partners like our Product Owners, Scrum Masters, Functional Experts, Data Architects, Data Scientists and IT Engineers to deliver sustainable analytical solutions and drive informed business decisions.\n\n\nYour focus will be on performing analytics in the area of Natural Language Processing (NLP), Machine Learning and Predictive Modelling, from gaining data and business understanding through data preparation and modeling, model evaluation to the result presentation and the solution deployment. In your role, you will apply a variety of models on large-scale datasets to address various business problems using advanced techniques. You will write high-quality production code, build and maintain robust, scalable project pipelines, document and validate the approach, set up processes to monitor, operate and continually improve the efficiency and performance of the implemented solutions.\n\n\nWith your passion for data and analytics, let\u2019s create new business insights from unstructured and structured data!\n\n\n\n\nYour Profile\n\n\n\u2022 Graduated with a higher degree in computer science, information technology, information science, or similar fields\n\n\n\u2022 5+ years of working experience in designing, developing and implementing machine learning/deep learning models (supervised or unsupervised), preferably applied to the text data\n\n\n\u2022 Strong programming skills in Python\n\n\n\u2022 Excellent knowledge of commonly used NLP, machine learning, and deep learning libraries such as PyTorch, Keras, Transformers, SKLearn, Gensim, SpaCy, or NLTK.\n\n\n\u2022 Experience in preprocessing and parsing text data stored in various formats such as PPT, DOC, PDF, and especially scanned documents using OCR technology\n\n\n\u2022 Good understanding of document indexing systems such as Elastic search or Solr\n\n\n\u2022 Expertise in agile software development, version control (git), continuous integration/deployment (CI/CD)\n\n\n\u2022 Experience with distributed computing with Apache Spark (pyspark)\n\n\n\u2022 Knowledge of microservices, RESTful APIs, Dockers and AWS Container Services is a plus\n\n\n\u2022 Experience in services offered by cloud technologies, preferably AWS.\n\n\n\u2022 Proficient in English in written and verbal communication\n\n\n\nProfile description:\n\nPlease see Job Description\n\n\n\nWe offer:\n\nWhat we offer: We are curious minds that come from a broad range of backgrounds, perspectives, and life experiences. We celebrate all dimensions of diversity. Applications from individuals are encouraged regardless of age, disability, sex, gender reassignment, sexual orientation, pregnancy and maternity, race, religion or belief and marriage and civil partnerships. We believe that it drives excellence, innovation, and human progress. We care about our customers, patients, and our rich mix of people. This diversity strengthens our ability to lead in science and technology. We are committed to creating access and opportunities for all and empower you to fulfil your ambitions. Our diverse businesses offer various career moves to seek new horizons. Join us in building a culture of inclusion and belonging that impacts millions and empowers everyone to bring their curiosity to life!\n\n\n\n\nCurious? Chat with one of our curious minds on our interactive Q&A platform and catch a glimpse of our people, values, and culture. You can also apply and find more information at https://jobs.vibrantm.com\n\n\n\n\nIf you would like to know more about what diversity, equity, and inclusion means to us, please visit https://www.merckgroup.com/en/company/press-positions.html"
    },
    {
        "position": "Senior IT Professional - Natural Language Processing",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Roche",
        "sector": "Biotechnology Research",
        "companySize": "10,001+ employees",
        "location": "Pozna\u0144, Wielkopolskie, Poland",
        "post": "About the job \n The Position\n\nSenior IT Pro - Natural Language Processing\n\nIT INNOVATORS IN HEALTHCARE\n\nWe do #Code4lLife creating innovative software that helps doctors, patients, and scientists around the world.\n\nWho We Seek\nA person who has:\nUnderstanding of basic concepts from area of Text Mining, NLP \nExperience with modern deep learning architectures for NLP (encoder-decoder, transformers, attention), including:\nhands-on experience with using Huggingface Transformers, SBert, GPT-2/GPT-3 (one of) capability to build ML/DL pipeline for training/tuning model\n\nAt least 3 years of experience with our typical NLP tools used in daily work:\nscikit learn, numpy, pandaspytorch or tensorflowspaCy, NLTK\n\n3+ years of general experience in NLP/AI software engineering, especially\n\nproficiency with Python\nexperience with Git\nCI/CD tools is nice to have\nunderstanding of software testing (unit tests)\nbash/shell scripting\nexperience with Docker, API development\nexperience with cloud platforms (preferred AWS) and ready to use tools (SageMaker)\n\nAbility to deliver fully working products (deployment activities):\nGeneral understanding of SCRUM and its principles (PSM I or PSD certificate is nice to have)\n\n\nEXAMPLE PROJECTS ACTIVITIES YOU MAY WORK ON\n\n\nDesigning and developing pipelines for solving NLP tasks (predictions, clustering, deviations detection) for generating insights and extracting knowledge from millions of internal documents\nImplementing fully working AI/NLP powered applications for supporting our colleagues from all the departments, for instance: pharma, molecules development, clinical trials, sales, marketing, people & culture or IT\nBuilding toolset and re-usable components for our future projects and ideas\n\n\nWhat We Appreciate\n\n\nAbility to learn new technologies (we can teach you them as well!)\nAnalytical mindset and critical thinking\nGood communication skills\nOpenness for knowledge sharing\n\n\nWhat You Get\n\n\nSalary range 13 000 - 17 500 PLN gross\nAnnual bonus payment based on your performanceContract of employment \nEmphasis on continuous personal and professional self-development supported by dedicated training budget (training, certifications, conferences, diversified career paths etc.)\nExperienced and professional colleagues and workplace that supports innovation and new ideas\nHighly flexible working hours (starting your day at 7-11) and workplace according to employee\u2019s needs and preferences* (regular office/home office)\nA chance to work on solutions which can improve patients\u2019 lives\n\n\nAdditional Benefits\n\n\nRelocation package\nPrivate healthcare and insurance\nHealth, well-being and sport promotion\nSupport for parents and families\nStock share purchase additions\nYearly sales of company laptops and cars\nAdditional vacation time for long-term employees and more\n\n\nAPPLY DIRECTLY\n\nApply directly via Workday, pressing the blue button at the top.\n If you feel this offer suits a friend of yours, we\u2019ll appreciate you letting them know! Simply copy and share the link from the browser.\n If you have any questions regarding the offer and would like to contact us directly, please write to us at katarzyna.wisniewska@roche.com\n\nWANT TO KNOW MORE?\n\nCheck our website for more details, e.g. the career path, recruitment process, etc.\n https://it.roche.pl/work-with-us\n Want to know what it\u2019s like to be a part of Roche IT first-hand? Check out our blog! You will meet the community members there, sharing their experience and impressions from diverse perspectives, not only about their job but also their lives.\n https://www.roche.com/careers/weareroche.htm\n Please note that during the pandemic we are working and recruiting 100% remotely.\n \u2026..\n\nRoche is an equal opportunity employer. We care about inclusion in terms of gender, age, race, skin colour, nationality, religion, marital status, sexual orientation, background, physical or mental disabilities and on every other grounds. Applying for our position, we assure you that we will assess your application solely on the basis of your competencies.\n\nAdministratorem Pani/Pana danych osobowych jest sp\u00f3\u0142ka Roche Polska Sp. z o.o., ul. Domaniewska 39 B, 02-672 Warszawa. Dane przetwarzane s\u0105 w celu prowadzenia rekrutacji. Przys\u0142uguje Pani/Panu prawo dost\u0119pu do tre\u015bci swoich danych, ich sprostowania, usuni\u0119cia, ograniczenia przetwarzania, przenoszenia oraz \u2013 w sytuacji, gdy s\u0105 one przetwarzane na podstawie udzielonej zgody \u2013 cofni\u0119cia tej\u017ce zgody w dowolnym momencie. Kontakt do Inspektora Ochrony Danych:ochrona.danych@roche.com. Wi\u0119cej informacji o zasadach przetwarzania przez Roche Pani/Pana danych osobowych pod linkiem: \n\n https://www.roche.pl/pl/content/klauzula-informacyjna-rekrutacja-pl.html\n\nThe controller of your personal data is Roche Polska Sp. z o.o., ul. Domaniewska 39 B, 02-672 Warsaw. The data is processed for the purpose of recruitment. You have the right to access your data, rectify it, delete it, limit processing, transfer it and - if processing is based on your consent - withdraw this consent at any time. Contact the Data Protection Officer at: Ochrona.danych@roche.com. More information on the principles of processing your personal data by Roche at the link: \n\n https://www.roche.pl/pl/content/klauzula-informacyjna-rekrutacja-en.html\n Who we are\n At Roche, more than 100,000 people across 100 countries are pushing back the frontiers of healthcare. Working together, we\u2019ve become one of the world\u2019s leading research-focused healthcare groups. Our success is built on innovation, curiosity and diversity.\n At Roche Poland, we are more than 800 professionals working together on one mission. We are proud of who we are, what we do and how we do it. Join us in the area of Clinical Research, Medical, Marketing, IT or business departments.\n Roche is an Equal Opportunity Employer."
    },
    {
        "position": "Senior IT Professional - Natural Language Processing",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Brenntag",
        "sector": "Biotechnology Research",
        "companySize": "10,001+ employees",
        "location": "Pozna\u0144, Wielkopolskie, Poland",
        "post": "About the job \n Our team in Amsterdam currently has an opening for a Director Data & ML Engineering\n\nBrenntag is undergoing a group-wide transformation to deliver profitable organic growth and sustained group efficiencies. Data & Analytics is a key pillar which will allow us to \u2018liberate\u2019 our data and thus improve our decision-making at speed.\nAs part of the Data & Analytics leadership team, this role has accountability for the creation of Data Products to enable decision-making throughout Brenntag. You will serve as an evangelist for the power of analytics, engaging key stakeholders to illustrate proven successes.\nYou will lead Brenntag Data & ML Engineering function who is responsible for:\n\nLiberating our data from source system, making them fit for consumption by analytics and other systems across the organization.\n\nWorking with data scientist to create machine learning models and embed them in our systems and processes.\nYOUR ROLE & RESPONSIBILITIES\n\n\n\nEstablish and drive organization\u2019s strategic direction for enterprise, end-to-end data analytics solutions in alignment with Brenntag\u2019s strategic priorities. \nSet strategy, roadmap, plans and priorities to ensure reliable, high quality development operations to support speedy deployment and improved performance of data solutions. \nPromote the development of innovative products in collaboration across D&A, Digital, Core IT and Architecture. \nLead engineering and delivery of data lineage capabilities intended to trace data usage across Brenntag\u2019s Analytics Platforms. \nCollaborate with Data Governance team to create data management capabilities that enhance data quality data and prevent bad data propagation to downstream processes. \nContribute to organizational wide initiatives around Machine Learning and Automation. \nActs as a business owner and manages long-term and short-term strategic initiatives for analytics products within analytics platforms and analytics APIs to operational systems. \nThe role will work with cross-functional at a global and market to ensure successful design, development, and delivery of unified analytics data platform. \nDevelop and lead DevOps professionals responsible for supporting data and analytics solutions deployment and maintenance. \nPartner across D&A teams to accelerate and leverage data capabilities and insights as part of the Brenntag\u2019s integrated data offense. \nBuild, manage, mentor, and inspire team(s); managing performance, goals and development potential. \n\n\nYOUR PROFILE\n\n\n\nBachelor\u2019s degree in computer science, engineering or related field, or relevant equivalent. \n10 years of experience specializing in advanced data analytics, BI, and/or data products . \nStrong experience in DevOps, DataOps or systems administration. \nStrong understanding of data structures and algorithms. \nStrong understanding of solution and technical design.\nStrong problem solving and analytical mindset. \nExperience with cloud environments such as Microsoft Azure, Google Cloud, and AWS. Experience with Big Data and NoSQL technologies like Hadoop, HBase, Spark, Impala, Cassandra, Storm, Flume, Pig, or Hive. \nAble to influence and communicate effectively, both verbally and written, with team members and business stakeholders. \nAble to quickly pick up new programming languages, technologies, and frameworks. \nProven ability to influence critical business outcomes in a matrix based, global environment. \nExcellent critical thinking skills.\nExpert understanding of and proven ability to deliver complex data systems. \nExperience leading or working with DevOps / DataOps / MLOps engineers. \nSolid understanding of software development life cycle, test driven development, Agile methodologies, continuous integration, continuous delivery. \nAbility to educate, inform, persuade, and achieve understanding and buy-in on technical and business needs across different functions, levels and customers. \nGood understanding of key topics in data science and applied analytics. \nUnique greenfield environment to drive change in a global business \nOpen space in a vibrant start-up corporate incubator \nLots of possibilities for professional development \nInternational team\nFriendly and supportive colleagues \nCompetitive compensation package\n\n\n\nINTERESTED?\n\nWe look forward receiving your application."
    },
    {
        "position": "Senior IT Professional - Natural Language Processing",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Hemnet",
        "sector": "Biotechnology Research",
        "companySize": "10,001+ employees",
        "location": "Pozna\u0144, Wielkopolskie, Poland",
        "post": "About the job \n\n\n\nHemnet has more than 60 million visits every month. People come to us to find joy, inspiration and - most important - their new homes. We are now looking for a Data Engineer to join us as we are strengthening our platform team. \n\n\nThe Platform Team\n\nOur team's mission is to enable the product development teams to release and maintain their products by providing a powerful, approachable and stable application platform. The team consists of six developers and a development manager with different focus areas such as Data and Devops/Infrastructure. We work closely together to develop and evolve our platform. \n\n\nSome of the team\u2019s main responsibilities:\n\n\nApplication and data infrastructure \nServing analytics and product teams with high integrity data \nTools for CI/CD, release pipeline and monitoring \nSystem security, performance, stability and data integrity \nExternal integrations \n\n\n\nA peek at our tech stack\n\n\nAWS \nRedshift \nPostgres \nDatadog \nDocker \nRuby & Python \nBash/Shellscript \nSnowplow \nCircleCI \nTerraform \n\n\n\nWhat you\u2019ll do:\n\nAs part of the platform team at Hemnet you\u2019ll be working with core functionality in an area that is being highly prioritized in the company. We see great opportunities ahead leveraging from our vast data sources to both broaden and deepen our analytics department and build new data driven products to serve our customers. This will put increasing demands on both infrastructure and data engineering to keep data fresh and accessible with a high integrity. You\u2019ll be part of a team that puts great emphasis on using the right tool for the right task and keeping our data stack modern and up to date. This includes among other things: \n\n\n\nBuilding and managing ELT data pipelines (Extract, Load & Transform). \nEnsuring data integrity and observability. \nDeploying machine learning models \n\n\n\nWho are you?\n\nWe believe you are an experienced Data Engineer or an Developer who recently started your journey within Data Engineering. You have previously worked with data pipelines and infrastructure, and have good knowledge of best practices. Personal qualities are important for us, and you should be someone who thrives in a very collaborative environment, and who continuously strives to get the best solution in place. \n\n\nBackground/Skills:\n\n\nSkilled in at least one programming language (e.g. Ruby, Python, Java or C#) \nExperience working with SQL \nExperience with working with Git \nKnows your way around databases (relational & non-relational) \n\n\n\nBonus points:\n\n\nAWS \nsnowplow \ndbt \nPostgreSQL \nredshift \nstatistics/machine learning \ndynamoDB \nRuby \ngraphQL \n\n\n\nWay of working after the pandemic:\n\nAll employees at Hemnet will have the possibility to work from the office in the central parts of Stockholm. We will also have the opportunity to work the majority of time (but not 100%) remotely from home. \n\n\nDoes this sound intriguing? We look forward to reading your application and learning more about what makes you tick!"
    },
    {
        "position": "Senior IT Professional - Natural Language Processing",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Airbus",
        "sector": "Biotechnology Research",
        "companySize": "10,001+ employees",
        "location": "Pozna\u0144, Wielkopolskie, Poland",
        "post": "About the job \n\n\n\nJob Description\n\nAirbus Defence and Space is looking for a\n\nBig Data Engineer for the Services Analytics Plateau (d/f/m)\n\nThe successful applicant will join the department TASSI6 Data Diagnostics & Analysis Systems.\n The project you will be working on introduces Airbus Defence and Space's Analytics capabilities to our largest customers. The project is the cornerstone of data consolidation and analytics for the Eurofighter programme. It delivers improved performance and customer experience and enables a rapid understanding of the potential of digitalisation for our customers.\n You will be at the forefront of further developing our Data Analytics solutions. The main task will be to find new ways to address challenges with data and digital technologies and support the creation of new services.\n We are in production and already have a large pool of data.\n\nYour location\n\nLocated about an hour\u2019s drive north of Munich, Manching is an up-and-coming market town that offers a wide range of leisure and cultural activities. Here, you can enjoy the quality of life in the countryside while the pleasures of near-by cities are still within easy reach.\n\nYour Benefits\n\n\n\nAttractive salary including holiday pay, Christmas bonus and profit sharing \n30 days holidays and extra days-off for special occasions \nExcellent upskilling opportunities and great development prospects \nSpecial benefits: employer-funded pension, employee stock options, discounted car leasing, special conditions for insurances, public transport subsidy, discounts at local businesses \nOn-site-facilities: Medical officer for check-ups and other health-related services, canteen and cafeteria, kindergarten nearby\n\n\n At Airbus, we support you to work, connect and collaborate more easily and flexibly. Wherever possible, we foster flexible working arrangements to stimulate innovative thinking.\n\nYour Tasks And Responsibilities\n\n\n\nCollecting data and \"data wrangling\", i.e. transforming, cleansing and linking with other data \nProvide data sets for (machine learning) data models; determine relationships between data source attributes \nApply data mining techniques and perform statistical analysis \nDevelopment and implementation of prototypes, e.g. in Python and Bash, Java or similar \nSupport in the implementation of proof-of-concept and projects within the Military Air Systems Community \nPromote new working methods and new data governance models\n\n\n\nDesired Skills And Qualifications\n\n\n\nM.Sc. or equivalent in Computer Science or a similar field \nExpertise in data integration and management, in particular in the automated integration of a variety of data sources as well as a Secure handling of the usual software engineering practices: continuous integration (Jenkins, etc.), DevOps (Ambari, etc.), version control (git, etc.), code quality (pylint, etc.), design reviews, ETL (Airflow, etc.), testing (DocTest, pyTest, etc.) \nExpertise in automated data pre-processing \nKnowledge of HDFS or other file systems \nDeep knowledge of programming in Python (in particular: pySpark, pandas, matplolib, sci-kit learn, etc.); ideally also working knowledge of C# and/or R \nBeing fluent in English; knowledge of German is not strictly necessary but recommended\n\n\n Not a 100% match? No worries! Airbus supports your personal growth with customized development solutions.\n You have a question regarding this job offer? Please do not hesitate to get in touch by writing to questions@airbus.com.\n Take your career to a new level and apply online now!\n This job requires an awareness of any potential compliance risks and a commitment to act with integrity, as the foundation for the Company\u2019s success, reputation and sustainable growth.\n\nCompany\n\nAirbus Defence and Space GmbH\n\nContract Type\n\nPermanent Contract / CDI / Unbefristet / Contrato indefinido\n\nExperience Level\n\nProfessional / Exp\u00e9riment\u00e9(e) / Professionell / Profesional\n\nJob Family\n\nCustomer Eng.&Technical Support&Services\n By submitting your CV or application you are consenting to Airbus using and storing information about you for monitoring purposes relating to your application or future employment. This information will only be used by Airbus.\n Airbus is committed to achieving workforce diversity and creating an inclusive working environment. We welcome all applications irrespective of social and cultural background, age, gender, disability, sexual orientation or religious belief.\n Airbus is, and always has been, committed to equal opportunities for all. As such, we will never ask for any type of monetary exchange in the frame of a recruitment process. Any impersonation of Airbus to do so should be reported to emsom@airbus.com.\n At Airbus, we support you to work, connect and collaborate more easily and flexibly. Wherever possible, we foster flexible working arrangements to stimulate innovative thinking."
    },
    {
        "position": "Senior IT Professional - Natural Language Processing",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Toptal",
        "sector": "Biotechnology Research",
        "companySize": "10,001+ employees",
        "location": "Pozna\u0144, Wielkopolskie, Poland",
        "post": "About the job \n\n\n\nAbout Toptal\n\nToptal is a global network of top freelance talent in business, design, and technology that enables companies to scale their teams, on-demand. With $200+ million in annual revenue and over 40% year-over-year growth, Toptal is the world\u2019s largest fully remote company.\n We take the best elements of virtual teams and combine them with a support structure that encourages innovation, social interaction, and fun. We see no borders, move at a fast pace, and are never afraid to break the mold.\n Position Description\n As an Engineering Manager for the Data Engineering team, you will be leading and growing a team of data engineers to scale our data warehouse and pipelines. You will work with Business Analysts on improving and adding more sources to our data lake. The team will look to you for advice on data and operational issues facing the team, you will mentor your team across stakeholder management, project management, and overall technical architecture.\n Data Engineering Team is responsible for delivering a top-notch data warehousing experience for Toptal, making sure data is correct and accessible on demand. Data Engineers are working closely with Business Analysts and Data Scientists and they are responsible for building and maintaining data processing infrastructure and building new data and automation tools.\n This is a remote position that can be done from anywhere. Due to the remote nature of this role, we are unable to provide visa sponsorship. Resumes and communication must be submitted in English.\n\nResponsibilities\n\nYou will be leading a team of highly skilled professionals to create and maintain world-class data products used by our Business Analysts, Data Scientists, and engineering teams across the company.\n\nIn The First Week, Expect To\n\n\nStart at the team by being introduced to Toptal and its culture, meeting colleagues, and get access to documentation and repositories.\n\n\nIn The First Month, Expect To\n\n\nComplete onboarding, understand the team\u2019s immediate roadmap and become acquainted with your team and processes. \nConduct regular 1:1s with your teammates, and begin to understand their strengths and aspirations.\n\n\nIn The First Three Months, Expect To\n\n\nShip impactful initiatives that significantly changes the way in which clients interact with us \nBe working with your team and understand its mission and domain. \nBe leading your team\u2019s efforts from planning to delivery.\n\n\nIn The First Six Months, Expect To\n\n\nSet and follow through at least one full quarter of OKRs. \nBuild a deep understanding of the mission, constraints, and capabilities of your team and squad. \nDevelop relationships with engineers, engineering managers, and other colleagues to maximize cross-collaboration whenever beneficial. \nContribute improvement suggestions at an Engineering-wide and even Company-wide level.\n\n\nIn The First Year, Expect To\n\n\nMake a big impact on the product. \nOrganize at least one team gathering. \nDefine yearly OKRs with and for your team.\n\n\nRequirements\n\n\nHave 2+ years of previous experience leading a data engineering or a product development team. \nHave 5+ years of data engineering experience. \nHave a track record of making an impact as an engineer and as an engineering manager. \nHave a solid understanding of development and quality assurance methodologies and concepts. \nHave experience guiding the continuous improvement of processes and technology. \nThrive on providing and receiving honest but always constructive feedback. \nOutstanding communication and interpersonal skills. \nBe eager to help your teammates, share your knowledge with them, and learn from them. \nBe first and foremost a leader, not a developer. However, you are able to code and you stay up to date with programming-related topics and work shoulder-to-shoulder with your team when required. \nYou must be a world-class individual contributor to thrive at Toptal. You will not be here just to tell other people what to do.\n\n For Toptal Use Only: #individualcontributoreurope #individualcontributorSA"
    },
    {
        "position": "Senior IT Professional - Natural Language Processing",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Toptal",
        "sector": "Biotechnology Research",
        "companySize": "10,001+ employees",
        "location": "Pozna\u0144, Wielkopolskie, Poland",
        "post": "About the job \n\n\n\nAbout Toptal\n\nToptal is a global network of top freelance talent in business, design, and technology that enables companies to scale their teams, on-demand. With $200+ million in annual revenue and over 40% year-over-year growth, Toptal is the world\u2019s largest fully remote company.\n We take the best elements of virtual teams and combine them with a support structure that encourages innovation, social interaction, and fun. We see no borders, move at a fast pace, and are never afraid to break the mold.\n Position Description\n As an Engineering Manager for the Data Engineering team, you will be leading and growing a team of data engineers to scale our data warehouse and pipelines. You will work with Business Analysts on improving and adding more sources to our data lake. The team will look to you for advice on data and operational issues facing the team, you will mentor your team across stakeholder management, project management, and overall technical architecture.\n Data Engineering Team is responsible for delivering a top-notch data warehousing experience for Toptal, making sure data is correct and accessible on demand. Data Engineers are working closely with Business Analysts and Data Scientists and they are responsible for building and maintaining data processing infrastructure and building new data and automation tools.\n This is a remote position that can be done from anywhere. Due to the remote nature of this role, we are unable to provide visa sponsorship. Resumes and communication must be submitted in English.\n\nResponsibilities\n\nYou will be leading a team of highly skilled professionals to create and maintain world-class data products used by our Business Analysts, Data Scientists, and engineering teams across the company.\n\nIn The First Week, Expect To\n\n\nStart at the team by being introduced to Toptal and its culture, meeting colleagues, and get access to documentation and repositories.\n\n\nIn The First Month, Expect To\n\n\nComplete onboarding, understand the team\u2019s immediate roadmap and become acquainted with your team and processes. \nConduct regular 1:1s with your teammates, and begin to understand their strengths and aspirations.\n\n\nIn The First Three Months, Expect To\n\n\nShip impactful initiatives that significantly changes the way in which clients interact with us \nBe working with your team and understand its mission and domain. \nBe leading your team\u2019s efforts from planning to delivery.\n\n\nIn The First Six Months, Expect To\n\n\nSet and follow through at least one full quarter of OKRs. \nBuild a deep understanding of the mission, constraints, and capabilities of your team and squad. \nDevelop relationships with engineers, engineering managers, and other colleagues to maximize cross-collaboration whenever beneficial. \nContribute improvement suggestions at an Engineering-wide and even Company-wide level.\n\n\nIn The First Year, Expect To\n\n\nMake a big impact on the product. \nOrganize at least one team gathering. \nDefine yearly OKRs with and for your team.\n\n\nRequirements\n\n\nHave 2+ years of previous experience leading a data engineering or a product development team. \nHave 5+ years of data engineering experience. \nHave a track record of making an impact as an engineer and as an engineering manager. \nHave a solid understanding of development and quality assurance methodologies and concepts. \nHave experience guiding the continuous improvement of processes and technology. \nThrive on providing and receiving honest but always constructive feedback. \nOutstanding communication and interpersonal skills. \nBe eager to help your teammates, share your knowledge with them, and learn from them. \nBe first and foremost a leader, not a developer. However, you are able to code and you stay up to date with programming-related topics and work shoulder-to-shoulder with your team when required. \nYou must be a world-class individual contributor to thrive at Toptal. You will not be here just to tell other people what to do.\n\n For Toptal Use Only: #individualcontributoreurope #individualcontributorSA"
    },
    {
        "position": "Senior IT Professional - Natural Language Processing",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Flying                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Tiger                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Copenhagen",
        "sector": "Biotechnology Research",
        "companySize": "10,001+ employees",
        "location": "Pozna\u0144, Wielkopolskie, Poland",
        "post": "About the job \n\n\n\nFlying Tiger Copenhagen is looking for a Data Engineer with ambitions and a strong desire to learn\n\n\n\nDo you have a desire to work with Data Platform development and engineering? Do you thrive in an environment where you can develop your skills and do you want to be part of developing and deploying leapfrog technologies in global company? Then you are exactly the person we are looking for at Flying Tiger Copenhagen. \n\n\nThe position:\n\nYou will become part of an international and highly competent team that is responsible for the further development of our Data Platform architecture. In your work, you will play a key role in ensuring that the current solution is further developed in accordance with applicable requirements and the interest of stakeholders in the business as well as ensuring that the required documentation is in place. \n\n\nThe task portfolio is broad - you will, among other things, help us implement BI, AA, ML and Insights solutions that are among the finest in Retail here in Denmark. \n\n\nAs Data Engineer, you will help bring our data platform solutions to a level where we can really benefit from all the data we have available. You are excellent in delivering effective and innovative solutions that will support our Advanced Analytics mindset. You are able to keep track of your tasks and ensure they are implemented while remaining focused on business needs. \n\n\nYour profile:\n\nYou are ambitious and take proactively responsibility for the development and implementation of the individual solutions. We expect you to be able to always challenge our current practice for the better. Additionally, we except that you are familiar with various cloud platforms such as Microsoft Azure, AWS and Google Cloud technologies that can be utilized in our Data Platform solutions and leapfrog technology to achieve innovative and state-of-the-art setup. \n\n\nIt is important that you have an eye for the details as well as having the ability to comply with deadlines. As a person, you are open and curious about all kinds of tasks and you want to help to contribute to a good climate in the team. You would also enjoy working together across the entire organization. You must be professional, analytically strong and be able to focus on multiple tasks without losing sight in a busy day with many working streams. \n\n\nWe expect you to have a good knowledge of the following: \n\nMS Azure product portfolio \nOn hands knowledge of Azure Data Lake and Azure Data Factory \nSQL skills and experience with stored procedures on MS SQL Server \nMicrosoft SQL Server \n\n\n\nIn addition, it would an advantage to be familiar with: \n\nAmazon Web Services \nGoogle Cloud technology \n\n\n\nYour success at work is measured in your ability to achieve high stability in relation to business-specific solutions developed through various platforms. \n\n\nAs Data Engineer you will report directly to the Head of BI, Insights & Digital Solutions. \n\n\n\n\nAbout us:\n\nAt Flying Tiger Copenhagen, we are undergoing a digital transformation where we are moving our services into new technologies and platforms. We offer a business-oriented and ambitious environment, where your professional and personal development are in outmost focus. \n\n\nYou will be part of a committed department with experienced and competent employees who work with the latest BI, AA, ML and insights principles on various platforms. We have a strong focus on supporting the business with data-driven solutions. \n\n\nFurthermore, you will be part of a highly engaged team where we work together and support each other. Along the way we make sure we also have fun and are very socially well-functioning team. \n\n\nApplication:\n\nWe are looking forward to hearing from you. \nSubmit your application and CV via the link below as soon as possible. \nWe are continuously calling in for conversations."
    },
    {
        "position": "Lead Data Engineering",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "miDiagnostics",
        "sector": "Medical Equipment Manufacturing",
        "companySize": "51-200 employees",
        "location": "Leuven, Flemish Region, Belgium",
        "post": "About the job \n\nAbout miDIAGNOSTICS \nSpun out of the world-leading R&D and innovation hub in nanoelectronics and digital technologies, Imec, and a research collaboration with Johns Hopkins University, the leading US research and medical centre, miDiagnostics\u2019 goal is to enable fast, comprehensive and cost-effective health analysis, regardless of location. Based in Leuven, Belgium, miDiagnostics is a privately held company created in 2015.\nmiDiagnostics is using silicon chip technology which will bring miniaturized, rapid, easy-to-use, lab-quality PCR tests with built-in connectivity direct to the patient and clinician. Combining a nanofluidic processor on a chip and a compact reader, miDiagnostics can measure virtually any biomarker from an easily accessed sample such as drops of finger prick blood. The Company is developing an extensive portfolio of tests for screening, diagnosis and monitoring of a wide range of health conditions, including infectious diseases.\n\n\n\n\nThe Job\nmiDiagnostics is releasing its first product, an ultra-fast PCR test, into the market. This market introduction means rapid organization scaling and supporting the international growth ambitions of the company. For the further development of the Software team, miDiagnostics is looking for a Lead Data Engineering, who will report to the Director Software Engineering.\n\n\nJoin us on our exciting journey to enable the next generation of lab-on-a-chip diagnostics.\n\n\nAs our Lead Data Engineering, your responsibilities will include:\n\nLeads the Data Engineering team (small team of 3 in total) and has the ability to lead teams working in an agile set-up;\nDevelops, constructs, tests and maintains the data pipeline architectures;\nAligns data architecture with business requirements;\nSupports data acquisition from the lab all the way to cloud infrastructure and connected data visualization tools;\nUses structured tools, environments and coding languages to support and further develop sophisticated analytics programs, machine learning and statistical methods;\nIdentifies ways to improve data reliability, efficiency and quality;\nConducts research for industry and business questions;\nUses large data sets to address business issues;\nPrepares data for predictive and prescriptive modelling;\nData cleaning;\nData visualization;\nCascades the company priorities to the Data Engineering team and defines clear objectives and key results;\nEnsures the right talent is hired and supports hiring via his/her network;\nActs as an inspirational leader and promotes a growth mindset across the company;\n\n\n\n\n\nYour profile and competencies\n\nPhD or masters in a scientific field or equivalent through experience;\nExperience within the medical device industry, or other heavily regulated industries is considered a strong plus;\nExperience in IEC62304 and 13485 are considered a strong plus; \nSolid experience in cybersecurity aspects of data engineering; \nA solid experience in data cleaning, data mining, data analysis, data visualization, and shares our passion for accurate, accessible and transparent data;\nExperience with data visualization tools (experience in Tableau is a plus);\nExperience with the python and javascript (knowledge of additional programming languages is a plus);\nDeep understanding of databases and SQL (experience with mySql is a plus);\nFamiliarity with software for data cleanup (experience with OpenRefine is a plus);\nFamiliarity with Amazon Web Services (AWS) and REST API;\nFluent in English (written and verbal);\nStrong communication skills;\nService-minded, detail-oriented, result-focused and quality driven;\nStrong analytical and planning skills;\nAbility to build a high-performing team;\nTrue team-player;\nOur offices are located in Leuven (Belgium). Relocation to Belgium is needed. It is essential that you hold entitlement to work and live in Belgium.\n\n\nThe offer\n\nA job in a fast-growing and ambitious start-up in the medical diagnostics industry.\nmiDiagnostics is an international-oriented company with close connections to two world-class research institutions (imec and Johns Hopkins University).\nOpportunity to grow in a new and exciting cutting-edge field in point-of-care diagnostics.\n\n\n\nInterested? Please apply via our career website https://jobs.midiagnostics.com/"
    },
    {
        "position": "Data Engineering Manager, Database Migration Accelerator",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Amazon",
        "sector": "Technology, Information and\n                                                            Internet",
        "companySize": "10,001+ employees",
        "location": "Gda\u0144sk, Pomorskie, Poland",
        "post": "About the job \n\nJob Summary\n\nDESCRIPTION\n\nAmazon\u2019s mission is to be the most customer centric company in the world. Database Migration Accelerator team helps our customers to migrate their solutions from legacy on-premise and cloud enterprise workloads into modern AWS native application architectures. This is accomplished through a variety of cutting edge tools, sophisticated engineering systems and database expertise. We provide fixed price and high speed migrations to the cloud. Database Migration Accelerator is combining various AWS cloud platform services into one product which would serve our customers.\n We are a team of professionals that are forward-looking and using latest technology offerings to build new capability to operationalise and automate migration methodologies. Databases Services at AWS cover a range of data platforms including: Amazon Aurora, DynamoDB, Redshift, Athena, QuickSight as well as AWS Database Migration Service, Data Pipeline, Glue and more. As each service grows, so does adoption by customers world-wide.\n We are looking for Data Engineer Managers to apply their talents on modernizing ETL/BI/DWH solutions, migrating them into AWS cloud. And also developing strong working relationships with other teams to analyze business demands and create automated solutions to accelerate migrations.\n Joining the AWS Database Migration Accelerator team as a Data Engineering Manager gives you the opportunity to:\nWork for a company that\u2019s at the forefront of the cloud computing space.Be involved in the fast growing managed services space \u2013 help build new service offering from scratch.\n\nMentorship & Career Growth\n Our team is dedicated to supporting new team members in an environment that celebrates knowledge sharing and mentorship. Our senior engineers mentor more junior engineers through one-on-one mentoring and collaborative code reviews.\n Projects and tasks are assigned in a way that leverages your strengths and helps you further develop your skillset.\n Inclusive Team Culture\n We get to build a really cool service and the mains contributing factor to our success is the inclusive and welcoming culture that we embody every day.\n We welcome teammates who are enthusiastic, empathetic, curious, motivated, reliable, and able to collaborate with a diverse team of peers\n As a Data Engineering Manager you will manage a team of Data and Database Engineers, which perform the following tasks:\nAnalyze ETL, ELT flows to determine the most appropriate migration strategies.Leverage the latest technologies and products to convert legacy ETL, ELT tools into modern AWS Glue and AWS Lambda solutions. Identify and remediate technical obstacles to migrations.Research and identify new opportunities for AWS to innovate on behalf of our customers.Operate test and development environments in the cloud, run and analyze test results, perform diagnostics and troubleshooting, open, prioritize, and help triage defects, track and report test status and results.Design solutions and tooling to execute automated deployments, upgrades and migrations.\n\nWhat makes this role different than all the others out there? Simple: scope. You get the opportunity to work with every product in AWS Services plus external customers ranging from the very small to the very large \u2013 everyone has data. You be working on a large number of complex migration projects and be given a lot of independence. This is a new focus area for AWS so you have the opportunity to put your stamp on it. Andy\u2019s tweets on DB Freedom have been frequent \u2013 here\u2019s your chance for visibility while delivering some results!\n Key job responsibilities\n Manage a team of Data and Database Engineers (career development, ongoing operational issues resolution, mentoring, team events). Team long-term strategy and tactical activities creation.\n\n\nBasic Qualifications\n\n\n3+ years of experience as Technical Manager or Data Engineer, or the similar role\nExperience with data modeling, data warehousing, and building ETL pipelines\nSkilled with writing, tuning, and troubleshooting SQL queries \nExperience with Big Data technologies such as Hive, Spark, Hadoop, NoSQL, AWS EMR, Glue, Lambda, Kinesis\nProficiency with Python, Java, or Scala\nGood grasp of software development life cycle and/or agile development environment\nStrong organizational and planning skills with attention to detail\nExperience in understanding system limitations, scaling factors, boundary conditions, and the reasons for architectural decisions \nExperience in Designing and building scalable data pipelines\n\nPreferred Qualifications\n\n\n5+ years of industry experience as Technical Manager or Data Engineer, or the similar role (e.g. Software Engineer, Business Intelligence Engineer, Data Scientist, ETL Developer) with a track record of manipulating, processing, and extracting value from large datasets\nExperience with orchestration tools such as AWS Step Functions. \nDeep knowledge of data warehouses, architecture, infrastructure components, ETL and reporting tools and environments\nNice to have experience with some enterprise ETL tool (IBM Datastage, Informatica, Talend or MS SSIS)\nExperience with orchestration tools such as AWS Step Functions\n\nExperience with Massively Parallel Processing (MPP) databases - Redshift, Teradata etc.\nExperience directing medium to large-scale data warehousing and BI projects, including using AWS technologies \u2013 Redshift, S3, EC2, Data-pipeline and other big data technologies\nGood communication skills and able to work with business owners to develop and define key business questions and to build data sets that answer those questions\nExperience providing technical direction and mentorship of engineers and scientists on best practices in the data engineering space\nComfort working with the Linux command line and shell scripting \nBe self-motivated and show ability to deliver on ambiguous situations and projects\n\nAmazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We make recruiting decisions based on your experience and skills. We value your passion to discover, invent, simplify and build. Protecting your privacy and the security of your data is a longstanding top priority for Amazon. Please consult our Privacy Notice (https://www.amazon.jobs/en/privacy_page) to know more about how we collect, use and transfer the personal data of our candidates.\n\n\nCompany - AMZN Dev Cntr Poland sp. z.o.o\n Job ID: A2193620"
    },
    {
        "position": "Machine Vision System Engineer",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Boston Scientific",
        "sector": "Medical Equipment Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Galway, County Galway, Ireland",
        "post": "About the job \n More than the opportunity of a lifetime...the chance to improve lives\n Boston Scientific is one of the world\u2019s largest medical device companies, employing over 36,000 employees. It develops, manufactures and markets more than 13,000 products in over 120 countries, treating approximately 30 million patients annually. The medical devices are used in various interventional medical specialities, including interventional cardiology, peripheral interventions, neuromodulation, neurovascular intervention, electrophysiology, cardiac surgery, vascular surgery, endoscopy, oncology, urology and gynaecology.\n We are excited to add a new Machine Vision System Engineer to our Equipment Engineering Group here at our Galway site.\n As our successful candidate, you will work with our manufacturing partners to develop new and innovative vision solutions in line with our Industry 4.0-Smart Factory strategies. Innovative vision solutions offer the opportunity to deliver intelligent manufacturing machines and optimise production systems while working in a purpose-built technology innovation laboratory. You will also have the chance to assist R&D and Operations on New Product Development Programs and Sustaining Programs by participating in the Prototyping, Design, Build, Commissioning and Qualification of New Equipment as well as Equipment Upgrades.\n The role is primarily based in Galway, a world-class facility, although travelling abroad may be required from time to time for short periods. Working times are usually Monday to Friday, although some periodic weekend work may be needed per production schedules.\n\nKey Activities Of The Role\n\nDefine, implement and maintain architectures to retrieve, archive and analyse production image data. Develop, test, validate and deploy computer vision systems using open-source and proprietary tools such as VisionPro, Insight and MVTech. Provide strong leadership and problem solving to enable equipment technology innovation. Work closely with the customer to understand product visual inspection requirements and propose creative and cost-effective solutions to automate inspections. Generate quotations, concepts and business cases for new and upgraded business systems. Ensure equipment and business requests are processed promptly and effectively and manage the execution of results. Determine project schedules and work with the team and other departments across the plant to ensure adherence. Manage projects and portions of projects as part of a larger team. Lead and participate in cross-functional Design Reviews. Draft and Review Design and Compliance Quality System documentation. Write detailed functional design requirements. Contribute to all phases of software development, including design, implementation, unit test, integration, release and validation support. \n\n\nQualifications & Experienced\n\nEngineering qualification equivalent to or above NFQ Level 8 Three plus years of experience developing Vision Systems is essential. Proprietary Machine Vision / Image Processing tools (e.g. Cognex VisionPro and Insight, MVTec, LabVIEW). Optics, sensors and lighting applied to industrial machine vision. C#.NETor similar. Digital Image Processing techniques and dataflows applied to industrial machine vision. Advance Statistical analysis knowledge. Proprietary Machine Learning software (e.g. Cognex VIDi, MVTec, Matlab) is preferred. Basic knowledge of deep learning theory and techniques is desirable. TensorFlow 2+, OpenCV, and Pandas in Python environments are desirable. Knowledge of Robotics and Controls. GAMP / Documentation life cycle for regulated industries Imaginative and creative approach to problem-solving and continuous improvement. \n\n\nAt Boston Scientific, we recognise that nurturing a diverse and inclusive workplace helps us be more innovative. It is essential in advancing science for life and improving patient health. We stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific is proud to be an equal opportunity and affirmative action employer. #IJ"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "GreenVolt - Energias Renov\u00e1veis",
        "sector": "Renewable Energy Semiconductor\n                                                            Manufacturing",
        "companySize": "201-500 employees",
        "location": "Lisbon, Portugal",
        "post": "About the job \n\nGreenVolt is looking for a Data Engineer to integrate our international IT Development team, with the following main responsibilities:\n\nWorking with project team to clarify the requirements and then implement them;\nResearch, Design, Plan and Develop Azure Cloud-based Data Acquisition and Data Engineering solutions for developed Use Cases;\nDesigning and develop functionality and solution data pipelines as a data engineer developer and data architect;\nDevelop data transformation functions and database processing mechanism (SQL Server)\nDesigning, testing and implementing application - C#, ASP.NET, Blazor, Azure;\nDesign data pipeline test cases, Conducting performance test; \nTroubleshoot and resolve technical problems in timely and accurate manner to improve application performance and functionality;\nPlanning and reporting project work progress.\n\nProfile:\n\nBSc/MSc degree in Computer Science, Information Systems or equivalent;\n3-5 years of experience in development team, with strong competences in the following areas:\n\n-Software Programming Languages (SQL, Scala, PySpark, Python, Java) \n-Data Collection / Transformation Tools (Azure EventHub, Azure Functions, Azure Data Factory)\n-Azure Platform (Compute component, Containers component, Networking component, Storage component, Analytics component, Azure Data Explorer (ADX), Azure tools CLI)\n-Analytics Engine (e.g. Azure Synapse)\n-Agile and continuous Delivery and methodologies\n\nAbility to identify problems, analyze key information and propose the best solution;\nLearn quickly and want to expand your knowledge;\nFluent English (work 100% in international environment).\n\n\n\nWhat do we have to offer?\n\nCompetitive salary aligned with experience;\nAttractive benefits package including health insurance, pension plan and meal card;\nFlexible work environment and work-life balance;\n25 days of holidays;\n75 days per year of flexible work;\nFree birthday day;\nBeing part of an international environment.\n\n\n\n\n\nWe want an energy transition for everyone from everyone!"
    },
    {
        "position": "Data Scientist / Data Engineer (m/f/d)",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Siemens",
        "sector": "Automation Machinery\n                                                            Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Lisbon, Lisbon, Portugal",
        "post": "About the job \n\nThe time to change is now! \n\nIt's time to build a sustainable future and define how we evolve through technology with purpose.\n At Lisbon Tech Hub we create value in the business digital transition, from Portugal to the world, and IT solutions with purpose. Our team has more than 1300 experts working in areas such as Analytics & Business Intelligence, Application Lifecycle Management, Cybersecurity, IT Infrastructure Management, IT Project & Service Management and IT Strategy & User Experience.\n Lisbon Tech Hub innovates, designs, transforms the information technology solutions and services for Siemens through our delivery units.\n Transforming our future starts with every day!\n Lisbon Tech Hub is the home of the new technologists - Dream Builders, Impact Creators & Future Makers.\n Are you one of them? Join us!\n\nWhat role will you play?\n\n\n\nPerform strategic data analysis to support business processes and strategy and discuss results with team leads and customers. \nProcess large amounts of data from multiple sources and extract relevant insights.\nBuild and operationalize predictive models.\nArchitect and build cloud infrastructure for both the data engineering and the analytics pipelines\nBe part of an international team of data scientists and machine learning engineer with diverse backgrounds, utilizing AI and data analytics methods to accelerate Siemens internal digitalization\n\nWe are looking for:\n\n\n\nA degree in Mathematics, Physics, Statistics, Computer Science, Engineering, a similar quantitative field, or equivalent practical experience.\nExperience with statistical software and scripting languages (e.g., R, Python, SAS).\nFirst experience with cloud technology (AWS, Azure, GCP) and infrastructure as code (e.g., Terraform)\nProficiency in SQL.\nExperience analyzing and modeling data sets.\nExperience with statistical and machine learning methods.\nThe ability to communicate technical concepts into simple terms to present to non-technical audiences.\nEffective written and verbal communication skills\n\nWhat we have to offer: \n\nA flexible home office and schedule policy, virtual budget to improve your home office setup, health insurance, a Pension Plan and a Siemens Share Program time and financial support to your studies, medical center in the facilities, sport groups, 2 days for volunteering initiatives and a cool and relaxed environment.\n Access to e-learning platforms (Learnlight, Linkedin Learning and more), discounts with partners.\n\n#Siemens #LXTechHub #ITMakesUsMove \n\nWe recognize that building a diverse workforce is crucial to the success of our business. Therefore, Siemens provides equal employment opportunities to all qualified individuals without regard to race, creed, color, religion, national origin, age, gender, marital status, sexual orientation, or non-disqualifying physical or mental handicap or disability.\n We strongly encourage applications from a diverse talent pool and welcome the opportunity to discuss workplace adjustments with all our applicants to develop agile working and innovation.\n\nOrganization: Smart Infrastructure\n\nCompany: Siemens S.A.\n\nExperience Level: Experienced Professional\n\nJob Type: Full-time"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Amgen",
        "sector": "Biotechnology Research",
        "companySize": "10,001+ employees",
        "location": "Lisboa, Lisbon, Portugal",
        "post": "About the job \n\nHOW MIGHT YOU DEFY IMAGINATION?\n\nTHE AMGEN CAPABILITY CENTER IN LISBON, PORTUGAL (ACCP) will be home to over 300 multi-national and multi-cultural employees, representing a broad range of cross functional capabilities, including Commercial, General and Administrative, Research and Development and more. The ACCP will offer rich career growth and development opportunities, regional and global exposure and the opportunity to LIVE, WIN and THRIVE in one of Europe\u2019s most attractive cities.\n Our ACCP offices will be temporarily located at the Maleo \u2013 Saldanha, Av. da Rep\u00fablica 18, 1050-191 Lisbon, while we work toward finding a permanent office in the vibrant city center of Lisbon.\n\nData Engineer\n\nLive\n\nWhat You Will Do\n\nLet\u2019s do this. Let\u2019s change the world. Global Commercial Operational IS is looking for a talented Data Engineer, who is curious to learn and able to develop data engineering and data analytics solution in a fast-moving environment. Candidate will work closely with senior data engineer and product owner/business analyst to understand the requirement. This role will be part of the newly established technical/engineering team, develop data flow pipelines to extract, transform, and load data from various data sources in various data format to enterprise data lake and data warehouse system in three regions in AWS. Provide data analytics and predictive analysis to business users.\n The Data Engineer will be based out of Amgen\u2019s Capability Center in Lisbon. At Amgen, our mission is simple: to serve patients. Our Capability Center provides essential services that enable us to better pursue this mission. This state-of-the-art center serves as a base for finance, information systems, and human resources professionals to make a meaningful impact at one of the world\u2019s leading biotechnology companies.\n\n\nBe a key team member assisting in design and development of the data pipeline for Global Data and Analytics team\nCollaborate with Data Architects, Business SME\u2019s, and Data Scientists to design and develop end-to-end data pipeline to meet fast paced business need across geographic regions\nServe as system admin to manage AWS and Databricks platform; \nAdhere to best practices for coding, testing and designing reusable code/component\nAble to explore new tools, technologies that will help to improve ETL platform performance\nParticipate in sprint planning meetings and provide estimations on technical implementation; Collaborate and communicate effectively with the product teams\n\n\nWin\n\nWhat We Expect Of You\n\nWe seek a self-starter with these qualifications:\n\nBasic Qualifications\n\nMaster\u2019s Degree\n OR\n Bachelor\u2019s degree with 2 years Data Engineering and/or and Software Engineering experience\n OR\n Associate\u2019s degree 6 years of Data Engineering and/or Software Engineering experience\n OR\n High school diploma and 8 years of Data Engineering and/or Software Engineering experience\n\nPreferred Qualifications\n\n\n\nExperience with software development (Java, Python preferred), end-to-end system design\nExperience with data modeling for both OLAP and OLTP databases, hands-on experience with SQL, preferred Oracle, PostgreSQL, and Hive SQL; SQL performance tuning\nExperience with web development, java script, html, CSS, any web framework or microservice architecture\nExperience with software DevOps CI/CD tools, such Git, Jenkins \nExperience on AWS, familiar with EC2, S3, Redshift/Spectrum, Glue, Athena, RDS, Lambda, DynamoDB, and API gateway\nExperience with docker container, Kubernetes container orchestration\nExperience with Apache Airflow and Apache Spark; Spark performance turning\nExperience with Tableau Dashboard and Tableau Server\nSupport the creation of customizations and integrations required to solution delivery\nDevelop technical designs for new features and capabilities\nAccountability of technical implementation aspects of new features including planning, architecture, design, development, and testing\nAbility to learn quickly, be organized and detail oriented\nAgile/SAFe experience and/or understanding\n\n\nThrive\n\nSome of the vast rewards of working here\n\nAs we work to develop treatments that take care of others, so we work to care for our teammates\u2019 professional and personal growth and well-being.\n\n\nFull support and career-development resources to expand your skills, enhance your expertise, and maximize your potential along your career journey\nA diverse and inclusive community of belonging, where teammates are empowered to bring ideas to the table and act\nGenerous Total Rewards Plan\u2014comprising health, finance and wealth, work/life balance, and career benefits\u2014with compensation and benefits rated above 4 stars (out of 5) on Glassdoor\n\n\nApply now\n\nfor a career that defies imagination\n\nObjects in your future are closer than they appear. Join us.\n\ncareers.amgen.com\n\nReady to Apply for the Job?\n\nJoin Us\n If you're seeking a career where you can truly make a difference in the lives of others, a career where you can work at the absolute forefront of biotechnology with the top minds in the field, you'll find it at Amgen.\n Amgen, a biotechnology pioneer, discovers, develops and delivers innovative human therapeutics. Our medicines have helped millions of patients in the fight against cancer, kidney disease, rheumatoid arthritis and other serious illnesses.\n As an organization dedicated to improving the quality of life for people around the world, Amgen fosters an inclusive environment of diverse, ethical, committed and highly accomplished people who respect each other but compete intensely to win. Together, we live the Amgen values as we continue advancing science to serve patients."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Roche",
        "sector": "Biotechnology Research",
        "companySize": "10,001+ employees",
        "location": "Lisboa, Lisbon, Portugal",
        "post": "About the job \n\n\n The Position\n\nNLP Data Scientist/Engineer\n\nIT INNOVATORS IN HEALTHCARE\n\nWe do #Code4lLife creating innovative software that helps doctors, patients, and scientists around the world.\n\nWho We Seek\nIdeal candidate for this position has:\n\nUnderstanding of basic concepts from area of Text Mining, NLP and NLU, hands-on experience with regular expressions \nKnowledge from area of embedding representations and deep learning based solutions for NLP (word2vec, Gensim) \nExperience with our typical NLP tools used in daily work: \nscikit learn, numpy, pandas pytorch or tensorflow spaCy, NLTK \n\n\n\nExperience in NLP/AI software engineering, especially \n\nproficiency with Python \nexperience with Git, Gitlab \nknowing Jira, CI/CD tools is nice to have \nunderstanding of software testing (unit tests, integration tests, smoke tests) \nbash/shell scripting\n\n\n\nEXAMPLE PROJECTS ACTIVITIES YOU MAY WORK ON\n\n\nDeveloping pipelines for solving NLP tasks (predictions, clustering, deviations detection) for generating insights and extracting knowledge from millions of internal documents \nImplementing fully working AI/NLP powered applications for supporting our colleagues from all the departments, for instance: pharma, molecules development, clinical trials, sales, marketing, people & culture or IT \nBuilding toolset and re-usable components for our future projects and ideas\n\n\n\nWhat We Appreciate\n\n\nAbility to learn new technologies (we can teach you them as well!) \nAnalytical mindset and critical thinking \nGood communication skills \nOpenness for knowledge sharing\n\n\n\nWhat You Get\n\n\nSalary range 10 000 - 14 000 PLN gross \nAnnual bonus payment based on your performance Contract of employment \nEmphasis on continuous personal and professional self-development supported by a dedicated training budget (training, certifications, conferences, diversified career paths etc.) \nExperienced and professional colleagues and workplace that supports innovation and new ideas \nHighly flexible working hours (starting your day at 7-11) and workplace according to employee\u2019s needs and preferences* (regular office/home office) \nA chance to work on solutions which can improve patients\u2019 lives\n\n\n\nAdditional Benefits\n\n\nRelocation package \nPrivate healthcare and insurance \nHealth, well-being and sport promotion \nSupport for parents and families \nStock share purchase additions \nYearly sales of company laptops and cars \nAdditional vacation time for long-term employees and more\n\n\n\nAPPLY DIRECTLY\n\nApply directly via Workday, pressing the blue button at the top.\n If you feel this offer suits a friend of yours, we\u2019ll appreciate you letting them know! Simply copy and share the link from the browser.\n If you have any questions regarding the offer and would like to contact us directly, please write to us at <\n katarzyna.wisniewska@roche.com>\n WANT TO KNOW MORE?\n Check our website for more details, e.g. the career path, recruitment process, etc.\n https://it.roche.pl/work-with-us\n Want to know what it\u2019s like to be a part of Roche IT first-hand? Check out our blog! You will meet the community members there, sharing their experience and impressions from diverse perspectives, not only about their job but also their lives.\n https://www.roche.com/careers/weareroche.htm\n Please note that during the pandemic we are working and recruiting 100% remotely.\n \u2026..\n\nRoche is an equal opportunity employer. We care about inclusion in terms of gender, age, race, skin colour, nationality, religion, marital status, sexual orientation, background, physical or mental disabilities and on every other grounds. Applying for our position, we assure you that we will assess your application solely on the basis of your competencies.\n\nAdministratorem Pani/Pana danych osobowych jest sp\u00f3\u0142ka Roche Polska Sp. z o.o., ul. Domaniewska 39 B, 02-672 Warszawa. Dane przetwarzane s\u0105 w celu prowadzenia rekrutacji. Przys\u0142uguje Pani/Panu prawo dost\u0119pu do tre\u015bci swoich danych, ich sprostowania, usuni\u0119cia, ograniczenia przetwarzania, przenoszenia oraz \u2013 w sytuacji, gdy s\u0105 one przetwarzane na podstawie udzielonej zgody \u2013 cofni\u0119cia tej\u017ce zgody w dowolnym momencie. Kontakt do Inspektora Ochrony Danych:  ochrona.danych@roche.com. Wi\u0119cej informacji o zasadach przetwarzania przez Roche Pani/Pana danych osobowych pod linkiem: \n\n https://www.roche.pl/pl/content/klauzula-informacyjna-rekrutacja-pl.html\n\nThe controller of your personal data is Roche Polska Sp. z o.o., ul. Domaniewska 39 B, 02-672 Warsaw. The data is processed for the purpose of recruitment. You have the right to access your data, rectify it, delete it, limit processing, transfer it and - if processing is based on your consent - withdraw this consent at any time. Contact the Data Protection Officer at: Ochrona.danych@roche.com. More information on the principles of processing your personal data by Roche at the link: \n\n https://www.roche.pl/pl/content/klauzula-informacyjna-rekrutacja-en.html\n Who we are\n At Roche, more than 100,000 people across 100 countries are pushing back the frontiers of healthcare. Working together, we\u2019ve become one of the world\u2019s leading research-focused healthcare groups. Our success is built on innovation, curiosity and diversity.\n At Roche Poland, we are more than 800 professionals working together on one mission. We are proud of who we are, what we do and how we do it. Join us in the area of Clinical Research, Medical, Marketing, IT or business departments.\n Roche is an Equal Opportunity Employer."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Tyson                                                                                                                                                                                                                                Foods",
        "sector": "Biotechnology Research",
        "companySize": "10,001+ employees",
        "location": "Lisboa, Lisbon, Portugal",
        "post": "About the job \n\n\n\nTechnical qualifications\n\nRequired Skills: \n\u00b7 Experience building analytics solutions in cloud-based platforms such as GCP (Big Query, Dataflow, Cloud Storage) & AWS (Redshift, S3, AWS Glue, Greengrass). \n\u00b7 Hands on experience with SQL and Query Optimization. \n\u00b7 Java/Apache Beam. \n\u00b7 Python. \n\u00b7 The ideal candidate would have 3 years of data ingestion and integration experience. \nPreferred Skills: \n\u00b7 CI/CD & DevOps Principles. \n\u00b7 Kubernetes. \n\u00b7 Terraform. \n\u00b7 Metadata management, data quality, data visualization, and agile methodologies. \n\n\nAbout the job\n\nTyson Foods Core+ Development team is seeking a Senior Data Engineer who will build Analytics solutions on cloud platforms like GCP & AWS. The primary focus is to design and build data pipelines using open-source technologies to bring in data from IoT devices, external data sources, and internal data sources. This role will translate requirements to build integrated solutions with automated deployments and monitoring following cloud platform best practices. \nYou can be part of a team that is constantly fostering the innovation and the implementation of cutting-edge technologies while building high-performance and scalable solutions. This team is primarily responsible for data integration across Tyson\u2019s applications and will be collaborating with most areas within IT. If you enjoy working in a rapidly changing environment and influencing the strategic direction of a large global organization, this position will provide you with that opportunity. \n\n\nCheck out Tyson Technology!\n\n\n\nTyson Foods\u2019 Equal Opportunity Employer Statement:\n\nTyson Foods is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will be considered without regard to race, national origin, color, religion, age, genetics, sex, sexual orientation, gender identity, disability or veteran status. \n\n\n*** In case we do not contact you within three weeks of your application please consider this a negative response. Thank you for understanding ***"
    },
    {
        "position": "Data Engineer with focus on Data Governance & Strategy - Safe Vehicle Automation",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Volvo Cars",
        "sector": "Motor Vehicle Manufacturing",
        "companySize": "10,001+ employees",
        "location": "G\u00f6teborg, Vastra Gotaland County, Sweden",
        "post": "About the job \n\nLet's create change together.\n\nNothing beats being part of positive change. We\u2019re on a truly exciting journey, working together in a fast-paced global environment to break new ground in almost every aspect of our operations.\n Our organisation Safe Vehicle Automation gives the driver of the vehicle a safe ride using active and intelligent systems and will give free time to the driver using autonomous systems. To make this happen we need talented people that are passionate about using data and likes to be part of creating a data driven culture!\n\nWho You Are\n\nYou are a self-driven team player with high ambitions. As a person, you are curious, innovative, and entrepreneurial. You care about the people around you, and get things done. Being an entrepreneur includes finding your way through the unexplored landscape of our new business and accepting to not have all the answers given to you.\n You have education plus some years\u2019 experience from working with data engineering and have a basic understanding of the problem space of Data governance. Your passion takes you to learn new areas and keeps you updated on latest trends and technologies. You have a base in Data systems and technical architectures, both theoretical and practical.\n You have great communication and presentation skills and are open to share and collaborate. You probably have a M.Sc or similar experience. Good knowledge in English language, both spoken and written, is required for the role.\n Having knowledge of GDPR and data privacy and how to apply them in the context of data engineering is a merit.\n\nWhat will you do?\n\nBe part of a growing team that is dedicated to set and execute data strategy and architecture across Safe Vehicle Automation solution at Volvo Cars.\n Introduce policies and solutions for using data so that developers of functions and components in the vehicle can become more innovative, productive and recourse efficiencies. Listen and guide the teams and managers of the organization to understand the challenges and suggest solutions that best matches the need defined by the product owner in the backlog and roadmap.\n\nWhat do we offer? \n\nHaving among the largest data sets in Sweden and Europe you will explore all the aspects of big-data. Working with us you will create real value, both for your colleagues and for the customers driving a car from Volvo. The fast phase and uncharted domain will allow you to gain experience in many domains and we offer opportunities (if you chose to accept) to build a very strong competence.\n We will support you to reach your full potential. Join us in creating the future!\n\nHow To Learn More And Apply\n\nPlease submit your application no later than Sunday 18th of September 2022 via out career site. Applications per email cannot be accepted due to GDPR.\n For questions about the position, please contact hiring manager Stefan at sflink@volvocars.com or +46721777682, and for questions about the recruitment process, please contact recruiter Dalila at dkendic@volvocars.com.\n\nWho are we?\n\nEverything we do starts with people. Our purpose is to provide freedom to move, in a personal, sustainable and safe way. We are committed to simplifying our customers\u2019 lives by offering better technology solutions that improve their impact on the world and bringing the most advanced mobility innovations to protect them, their loved ones and the people around them.\n Volvo Cars\u2019 continued success is the result of a collaborative, diverse, and inclusive working environment. The people of Volvo Cars are committed to making a difference in our world. Today, we are one of the most well-known and respected car brands, with over 40,000 employees across the globe. We believe in bringing out the best in each other and harnessing the true power of people. At Volvo Cars your career is designed around your talents and aspirations so you can reach your full potential. Join us on a journey of a lifetime as we create safety, autonomous driving and electrification technologies of tomorrow."
    },
    {
        "position": "Data Engineer to Finance & Loans to SEB in Stockholm",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "SEB",
        "sector": "Banking",
        "companySize": "10,001+ employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nData Engineer, Finance & Loans to SEB in Stockholm\n\nSEB has started an exciting transformational journey to become the most data-driven bank in the world. Are you ambitious, driven, and curious, and want to continually develop your knowledge and skills? Then here you have an opportunity to take an important role as a data engineer as we establish a team that will work to develop and maintain the pricing model for Financing & Loans.\nWhat You Will Be Doing\n\nAs a Data Engineer you will be part of totally new team where you will build the Pricing platform from scratch. You will work in an international environment with multiple agile teams located in Stockholm and Vilnius. Together with your colleagues you will:\n\nDevelop, test and maintain new technical capabilities within the Pricing platform and create data pipelines to make data available for various business users and applications.Work with new technologies within Big Data\n\n\nOur technical environment consists of Java, Python, Hadoop, Kafka, Spark Streaming and Elastic Search. If you don\u00b4t have experience of all of these, you are curious to learn. We encourage you to be creative and contribute with your own ideas, as this is a totally new team you will be get a change to design and implement the whole solution. You will also be given the tools you need to develop further within your profession.\nWho are you?\n\nTo thrive here you should be interested in engineering problems and like finding creative solutions to complex problems. You will be working closely with your colleagues and therefor you should feel comfortable working in a team and sharing your knowledge with others. If you are analytical, curious and have a passion for discovering new ways of working, you will enjoy it here!\nRequired skills:\n\nYou have previous experience of Java.Experience from working with big data tools like NiFi, Kafka, Hive, Airflow etc.Excellent programming skills in languages such as Java, Python with Spark framework.Collaboration skills and high sense of responsibility. We are working team based, and the ability to share knowledge and experience is fundamental.Version control systems (e.g. Git)Experience from working with distributed computing (e.g. Hadoop)Database knowledge (e.g. SQL, NoSQL, graph databases)A burning curiosity and interest in data, big data, data governance, data models, data warehouse, data insights.\n\n\nNice-to-have\n\nAdditional big data technologiesIT securityGoogle CloudCI/CDContainerized development (e.g. Docker)\n\n\nWhat We Offer\n\n\nWe offer you the opportunity to build up an expertise that goes within the whole bank, where the advantages of working at SEB is getting to try and use new technologies and be able to be more independent in certain tasksOpportunity of a career path both as a generalist and specialistGreat work-life balance, and you quickly become part of the teamExtensive training and learning opportunities through own digital university SEB Campus. We also offer mentorship programs, voluntary work, work shadowing and gigs where employees receive the opportunity to work in another part of the bank for a short period\n\n\nLearn More About Working At SEB Www.sebgroup.com/career\n\nIt is our fundamental belief that inclusion and diversity is crucial for our future success. We strive to have an inclusive, value-driven culture where employees feel valued, respected and involved irrespective of who they are, what they believe or where they come from.\nReady to join?\n\nSince we select candidates continuously, feel free to send in your application today but no later than 2022-09-20. If you have questions about the position please contact Katarina Pihl, Talent Acquisition Partner at Katarina.pihl @seb.se.\nWelcome to a community of tech-savvy and passionate employees from all corners of the world. SEB is in fact one of the largest IT employers in the Nordics. Together we future proof a world of financial flows by exploring and implementing modern digital architecture and state-of-the-art technology. We are driven by collaboration, insight, and friendship. But also, a desire to change and improve. All in all, it creates a balance - where life and a stable yet exciting job can co-exist. If you want to shape tomorrow's bank - continue reading and apply today.\n\nRead more:sebgroup.com/techcareers"
    },
    {
        "position": "Data Engineer to the Information Platform team at SEB",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "SEB",
        "sector": "Banking",
        "companySize": "10,001+ employees",
        "location": "Solna, Stockholm County, Sweden",
        "post": "About the job \n SEB has started an exciting transformational journey to become the most data-driven bank in the world and you will get the opportunity to take an important role where you will help accelerate the data driven journey by providing the data engineering community with established components and experience working in Cloud.\nOur tribe Data and Analytics lead all parts of SEB in becoming a data driven company.\nOur architectural vision is Data Mesh and we are in the centre of it, providing tooling, processes and people.\nWhat you will be doing\nAs Cloud Data Engineer in the Data and Analytics tribe (department) you will work in an international environment with multiple agile teams located in Stockholm and Vilnius, consisting of experts in various Big Data technologies, on-prem and cloud (GCP). This recruiting team also have some data products to be built together with new \u201cSEB-wrapped\u201d GCP components which we also will take care of and improve in terms of performance, security and scalability.\nThis area in the bank is a supporting tribe meaning we support others with their journeys and initiatives. You will be positively exposed to a broader audience in the bank instead of only owning one dataset or system you will come in contact with all customers using GCP and who wants to work with established solutions within data engineering in cloud provided by our tribe.\nIn short, you will get exposed to real customer data from day one and build reusable components at the same time.\nTogether with your colleagues you will:\n\nDevelop, test and maintain new components to be used on GCP and on prem when needed.Collaborate within the Data and Analytics tribe and help support other teams to create data pipelines to make data available for various business users and applications in cloud. Provide innovative solutions for complex problems.Work with modern technologies within data engineering and all its different layers of complexity.Create a customer data product to be available in cloud for our colleagues. Firs time in cloud!Work with R&D and provide documentation and conclusions to share in the tribe and outside the tribe.Our technical environment consists of but is not limited to Python, Java, Scala, Kafka, Spark, Warehousing, SQL plus the GCP stack! CI/CD and automation are crucial in cloud, so we expect that you are well versed in this area as well. Infrastructure as code is our mantra.If you do not have experience of all of these, you will get the opportunity to learn them here. We encourage you to be creative and contribute with your own ideas. You will also be given the tools you need to develop further within your profession.\n\n\nWho we are looking for\n\nIn order to thrive here you should have proven experience within data engineering.You are interested in learning all levels of data engineering and you like to find and adapt new technologies that fits into our mission.You are proficient in Python or Java, knowledgeable in Kafka, Spark and warehousing.You have deployed a flow into production in a cloud such as GCP or AWS.You will be working closely with your colleagues and therefor you should feel comfortable in sharing your knowledge with other teams and building your network.Agile ceremonies are fundamental in our tribe so continuous agile improvement is expected from you and your team.If you are analytical, curious and have a passion for discovering new ways of working, you will enjoy it here!\n\n\nWhat we offer\nWe offer many experiences and benefits to our employees, and there is nuance to every individual\u2019s career experience, but the elements that define the core of our offering are:\n\nFriendly and welcoming cultureStart up mindsetAccess to SEB staff banking with exclusive benefitsInnovative company in forefront of technologyExtensive training and learning opportunitiesInteresting, cutting-edge workAgile and modern ways of workingOpportunities to help transform an industry\n\n\nReady to join?\nAttach your CV and a personal letter describing yourself and how you can contribute. Since we select candidates continuously, feel free to send in your application today, but no later than 2022-09-01. Due to summer vacation we initiate selection process in full after mid-August. \nIf you have questions about the position, please contact Mervan Yildiz via mervan.yildiz@seb.se\nSEB Sweden has a redeployment responsibility, why this position might be covered by internal redeployment.\nWelcome to a community of tech-savvy and passionate employees from all corners of the world. SEB is in fact one of the largest IT employers in the Nordics. Together we future proof a world of financial flows by exploring and implementing modern digital architecture and state-of-the-art technology. We are driven by collaboration, insight, and friendship. But also, a desire to change and improve. All in all, it creates a balance - where life and a stable yet exciting job can co-exist. If you want to shape tomorrow's bank - continue reading and apply today.\n\nRead more:sebgroup.com/techcareers"
    },
    {
        "position": "Data Engineer to Analytics and Reporting at SEB in Stockholm",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "SEB",
        "sector": "Banking",
        "companySize": "10,001+ employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n SEB is a leading northern European financial services group, and at the same time, one of the largest IT employers in the Nordics. Banking is changing rapidly, and we are proud of our reputation for being entrepreneurial and innovative in the face of change. Our brilliant techies work hard to future proof SEB\u2019s digital architecture and customer products because it genuinely makes a huge impact for our customers and colleagues. Does that sound like a fit for you?\nTake a driving role in enabling data accessibility throughout one of the Nordic\u2019s biggest banks as Data Engineer at SEB.\nWhat you will be doing\nTake the next step in your career and elevate our Big Data solutions! As Data Engineer at SEB in Stockholm, you build large-scale Big Data solutions, streaming and processing data to our Data Lake. Making data accessible is central to our business and solutions, and our work enables the delivery of our digital services to our customers. With us you make this possible, working with our modern tech stack and the Accounts and Payments data that is at the core of our business.\nAs Data Engineer you will:\n\nDevelop and maintain complex Big Data solutions and data pipelinesEnabling efficient and qualitative analyses and reporting of large-scale transactional dataSolve complex problems, processing and streaming data from various sources into our Data Lake.\n\n\nWho we are looking for\nWe believe that you are a person who understand complex issues and challenges. You like to solve problems with a systematic but still innovative approach. This role includes close contact with your team and other stakeholders; therefore we believe that you are a person with great communication skills who likes to cooperate with others.\nYou are an experienced Data Engineer with experience in: \n\n\nHaving worked with developing Spark applications and solutions from scratchYou have worked in a Hadoop environment and are experienced in programming with Java and ScalaYou have a passion for expanding your knowledge and new ways of workingYour deep knowledge within Big Data tech and tools is something you enjoy sharing with others, and you have an interest in taking on larger responsibilities within agile developmentWe at SEB work agile with SAFe and it is a plus if you have experience of working within the SAFe framework\n\n\nIn this role you will be building Big Data solutions from scratch with modern techniques and tools and get a role where you contribute to our important work with Accounts and Payments data, being highly involved in decision-making and our technical road map.\nWhat we offer\nWe offer many experiences and benefits to our employees, and there is nuance to every individual\u2019s career experience, but the elements that define the core of our offering are\n\nAccess to SEB staff banking with exclusive benefitsInnovative company in forefront of technologyChallenging, cutting-edge workTop class client network and projects\n\n\nLearn more about working at SEB www.sebgroup.com/career is our fundamental belief that inclusion and diversity is crucial for our future success. We strive to have an inclusive, value-driven culture where employees feel valued, respected and involved irrespective of who they are, what they believe or where they come from. Ready to join?Since we select candidates continuously, feel free to send in your application today, but no later than 2022-03-31. If you have questions about the position please contact Delila Mauritzon, Team Manager Analytics & Reporting 2 at phone no 070-772 3039 or by mail delila.mauritzon @seb.se \nWelcome to a community of tech-savvy and passionate employees from all corners of the world. SEB is in fact one of the largest IT employers in the Nordics. Together we future proof a world of financial flows by exploring and implementing modern digital architecture and state-of-the-art technology. We are driven by collaboration, insight, and friendship. But also, a desire to change and improve. All in all, it creates a balance - where life and a stable yet exciting job can co-exist. If you want to shape tomorrow's bank - continue reading and apply today.\n\nRead more:sebgroup.com/techcareers"
    },
    {
        "position": "Senior Data Scientist to Advanced Analytics and AI Team",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Handelsbanken",
        "sector": "Banking",
        "companySize": "10,001+ employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nJoin the Advanced Analytics and AI Team within Handelsbanken, in Stockholm, as we provide our business with highly accurate insights and models that drive us forward in a data-driven way and help create the best possible experience for our customers.\n\n\nOur Team\nWe are on a mission to make Handelsbanken a leader in using advanced analytics and AI to deliver superior products, service and experience to our customers. This involves applying statistics, machine learning and other technologies in a wide range of areas such as content personalization, product development and business strategy.\n\n\nWe work with other teams throughout the bank in an environment characterized by initiative, collaboration and innovation to tackle business challenges by predicting outcomes, understanding complex data relationships and constructing models that contribute to a better experience for our customers.\n\n\nYour Role\nAs a Data Scientist you will collaborate with other data scientists, data engineers and business analysts to define business problems and implement solutions. You will take part in driving complex data science projects from ideation through to completion and communicating findings to ensure solutions are well understood and incorporated into business processes.\n\n\nThe role involves applying data science tools and techniques to provide insights, models and actionable recommendations for the business. You will enjoy the freedom to explore new projects, the support to think outside the box and the opportunity to expand your data science skillset through development opportunities and researching innovative tools and techniques to level up our capabilities.\n\n\nThe team is expanding quickly so we are looking for people who are able to take ownership, establish best practices and contribute in defining how this field will be applied in the bank. Your role can evolve over time and for the right candidate there are tremendous growth opportunities.\n\n\nAbout You\n\nYou have a master\u2019s degree, PhD or similar in a quantitative field with good academic results\nMinimum 3 years\u2019 experience as Data Scientist\nYou have excellent problem solving skills and enjoy solving problems with code\nAdvanced knowledge of at least one programming language for data science with good knowledge of supporting libraries, preferably Python\nExtensive experience in applied statistics and/or mathematics (preferably with a focus on machine learning)\nThe ability to communicate advanced technical concepts to a non-analytical audience\nAbility to understand business operations and translate them into well-defined analytical deliverables\nYou are willing to learn, or already know, basic Swedish\nYou constantly want to learn new skills and are proactive with your own development\n\n\n\nWe are looking for a person who fits the positive, friendly and supportive culture of Handelsbanken. The ideal candidate is curious, inventive, strives for improvement every single day and shares our aim to be smart, humble and, above all, collaborative.\n\n\nWe Offer\n\nThe chance to develop fast, make a big impact and cut out new paths in an expanding team at the core of Handelsbanken\u2019s ambitious focus on digitalization.\nAn abundance of interesting data science opportunities and a focus on building new capabilities, not just maintaining what others have already created\nA friendly and collaborative work environment where colleagues learn and achieve together\nCompetitive compensation and pension plan\nExtensive benefit package (subsidized banking services, health care, lunch and more)\nFlexibility to work from home part of the time\nOffice at prime location in central Stockholm\n\n\n\nYour Application\nWe look forward to receiving your CV and academic records. Furthermore, we are particularly interested in previous team work experience, what motivates you and achievements that you are proud of.\n\n\nPlease submit your CV and academic records merged in the same file. \nThe promotion of gender equality, diversity and an inclusive corporate culture is a fundamental part of our values. We encourage candidates from all backgrounds to submit their applications."
    },
    {
        "position": "Machine Learning Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Formulate by RELEX",
        "sector": "Retail",
        "companySize": "11-50 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nDo you want to be part of our exciting growth journey and help our customers optimise their promotion campaigns through our world class retail analytics platform?\n\n\nWe are currently hiring a Machine Learning Engineer to join our growing team in our office in central Stockholm.\n\n\nAbout Formulate\nOur mission is to help retailers make better, data-enabled decisions that save time, drive sustainable revenues, and (perhaps most importantly) reduce waste. We help campaign planners at bricks-and-mortar retailers (like Coop and 7-ELEVEN) and online retailers (like Mathem), to optimize their promotions. To do this most effectively, we\u2019ve developed a solution that\u2019s part analytics suite, part planning tool. We provide insights; we also make sure they\u2019re actionable.\n\n\nAs you\u2019ve probably grasped, Formulate is a rich solution, with multiple functions and user stories. We need someone who thrives on this complexity; who relishes large, complex challenges, and is ready to tackle them as part of a smart, supportive team. Work with us and you\u2019ll learn a lot, quickly, in an environment where everyone is rooting for you to succeed. Read more about Formulate and our values here.\n\n\nIn May 2022 Formulate joined RELEX Solutions, a hyper-growth Finnish supply chain scaleup with a $5bn valuation. Together we\u2019re building the next generation of unified retail solutions. So join us! Get all the benefits of an agile startup plus the muscle and resources of a global scaleup.\n\n\nAbout the position\nAs Machine Learning Engineer you'll join the Product Team, working together with a group of people dedicated to ensuring a rapid client system integration, robust data management, and an analytics engine that scales. Together we make sure that the product is user friendly, fast, powerful and intuitive.\n\n\nSome of your tasks will be to:\n\nDesign and deploy new models to iteratively improve Formulates business-critical models and systems\nSupport and improve our existing model operations with deployment tools and pipelines\nImagine new feature ideas and design data pipelines to incorporate them into our models\nImprove the way we evaluate and monitor our model and system performance\n\n\n\nWe would like to get in touch if you have\n\nAn advanced degree in a quantitative field (e.g. computer science, stats, physics, engineering)\nSolid experience in software engineering in a production environment\nExperience designing and training machine learning models to solve critical business problems\nExperience with the design and implementation of applications and tooling for consolidating and processing of big volumes of data\nKnowledge about how to manipulate data to perform analysis, including querying data, defining metrics, or slicing and dicing data to evaluate a hypothesis\n\n\n\nTech we use\n\nAnalytical techniques ranging from complicated to \"simple\": neural networks to Bayesian inference, state-space models and linear regression\nPython, R, Go\nBigquery\nCadence and Google Platform products for orchestration and data analysis\nKubernetes, ClickHouse\n\n\n\nWhat you can expect from us\n\nCompetitive salary\nBenefits including pension, wellness allowance, health insurance, home internet and more\nAn opportunity to work with great engineers\nFlexible remote; work set up\nModern office in central Stockholm\n\n\n\nIf you join us, you'll work with a colourful mix of people from across the world, with bundles of creativity, drive, empathy, and humour!\n\n\nsounds interesting? drop us a line, we would definitely like to get in touch with you!"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Netlight",
        "sector": "IT Services and IT Consulting",
        "companySize": "1,001-5,000 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nWHO WE ARE\nNetlight is the leading, and award-winning, IT consultancy in providing premium quality consulting services at the forefront of the digital industry. To unleash the potential of the world\u2019s most prominent digital companies, we take responsibility for world-class knowledge sharing to make sure each Netlighter has all of Netlight\u2019s combined knowledge available (close to 2000 Netlighters across Europe). To achieve this, we have a highly engaged network organization, where every employee gets a mentor, delivery coach and personal communities. The key to our continued success is trust and personal responsibility, diverse experiences, equality, challenging opportunities and developing from personal values. Every Netlighter is an active part of building and shaping this culture, which leads to a clear correlation between personal growth and the growth of Netlight.\n\n\nWhat does it mean to be a Data Engineer Consultant at Netlight?\nIt will vary a lot between Netlighters as we, around the right person, will design a role together with you. You will be starting somewhere familiar with your experience, and from there it is your call how your career at Netlight will look, ranging from which clients you will work with, what role you want to take (based on your personal experience, strengths, your personal interest) and how your relationship with your mentor/coach/EDGE networks/social networks will look like.As a consultant at Netlight, you will build the products, systems, and technical solutions of today and tomorrow. This means that our consultants get the opportunity to help build and scale existing and new products and companies and also continuously learn and master a variety of technical tools. At Netlight, we will challenge you. Our clients will challenge you. You will challenge our clients. You will challenge us. We will grow together and unleash the potential in each other.\n\n\nAs a Data Engineer Consultant, you will help our clients in projects with roles in Data Engineering. It can be working within Data Engineering, Data Architecture, or project management in terms of working with data or utilizing data to make product decisions to mention a few examples.\n\n\nMinimum Qualifications\n\nMaster Degree in Engineering or Technology\nVerbal and written fluency in English\n0,5-5 years of work experience within the data engineering field related to IT and software products in agile teams\n\n\n\nApplication\nWe are always looking for new Netlighters, so feel free to apply if you meet the qualifications.We will get in touch within two weeks if we find that your profile and experiences are a match beyond the qualifications at this time."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Hemnet",
        "sector": "Real Estate",
        "companySize": "51-200 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nHemnet has more than 60 million visits every month. People come to us to find joy, inspiration and - most important - their new homes. We are now looking for a Data Engineer to join us as we are strengthening our platform team.\nThe Platform Team\nOur team's mission is to enable the product development teams to release and maintain their products by providing a powerful, approachable and stable application platform. The team consists of six developers and a development manager with different focus areas such as Data and Devops/Infrastructure. We work closely together to develop and evolve our platform.\n\n\nSome of the team\u2019s main responsibilities:\n\nApplication and data infrastructure\nServing analytics and product teams with high integrity data \nTools for CI/CD, release pipeline and monitoring\nSystem security, performance, stability and data integrity\nExternal integrations\n\n\n\nA peek at our tech stack\n\nAWS\nRedshift\nPostgres\nDatadog\nDocker\nRuby & Python\nBash/Shellscript\nSnowplow\nCircleCI\nTerraform\n\n\n\nWhat you\u2019ll do:\nAs part of the platform team at Hemnet you\u2019ll be working with core functionality in an area that is being highly prioritized in the company. We see great opportunities ahead leveraging from our vast data sources to both broaden and deepen our analytics department and build new data driven products to serve our customers. This will put increasing demands on both infrastructure and data engineering to keep data fresh and accessible with a high integrity. You\u2019ll be part of a team that puts great emphasis on using the right tool for the right task and keeping our data stack modern and up to date. This includes among other things:\n\n\n\nBuilding and managing ELT data pipelines (Extract, Load & Transform).\nEnsuring data integrity and observability.\nDeploying machine learning models\n\n\n\nWho are you?\nWe believe you are an experienced Data Engineer or an Developer who recently started your journey within Data Engineering. You have previously worked with data pipelines and infrastructure, and have good knowledge of best practices. Personal qualities are important for us, and you should be someone who thrives in a very collaborative environment, and who continuously strives to get the best solution in place.\n\n\nBackground/Skills:\n\nSkilled in at least one programming language (e.g. Ruby, Python, Java or C#)\nExperience working with SQL\nExperience with working with Git\nKnows your way around databases (relational & non-relational)\n\n\n\nBonus points:\n\nAWS\nsnowplow\ndbt\nPostgreSQL\nredshift\nstatistics/machine learning\ndynamoDB\nRuby\ngraphQL\n\n\n\nWay of working after the pandemic:\nAll employees at Hemnet will have the possibility to work from the office in the central parts of Stockholm. We will also have the opportunity to work the majority of time (but not 100%) remotely from home.\n\n\nDoes this sound intriguing? We look forward to reading your application and learning more about what makes you tick!"
    },
    {
        "position": "Associate Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Volvo Cars",
        "sector": "Motor Vehicle Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nWe\u2019re creating our own future \n\nAt Volvo Cars, we are making bold digital visions come true. We aim to be the leader in the automotive world by creating a digital ecosystem built around making our customers' lives less complicated. What we all have in common at Volvo Cars is our passion for protecting lives, our endless curiosity, and our dedication to create a new future for the automotive industry. Our human centric focus is what separates us from all other car companies.\n Would you like to influence and craft the technical strategy that helps Volvo Cars to grow and reach our goal of being an electric car company by 2030? Excellent, then we would like you to join our Cluster as Data Engineer!\n The Data & Identity Cluster is a part of the Global Online Experience (GOX) area and our mission is to ensure we know our customers well and keep this information safe and secure. We support the rest of the organization in using this knowledge to serve the customers in the best possible way. We\u2019re looking for someone that will help us craft a world class data ecosystem that spans across multiple product teams and clusters. We have only just begun this journey in earnest, and you\u2019ll be joining us at a time where you can really have a great impact and help us set the tone for the next chapter in our company's history!\n\nWhat You\u2019ll Do\n\n\nAs an early joiner in a new team within a highly prioritized area you will collaborate with senior data engineers to build data tools and systems that scale\nDeliver high quality solutions using modern data engineering principles\nImplement subcomponents and data pipelines, and understand their bigger role in the system\nBuild domain knowledge and leverage our large and diverse datasets to enable use cases with direct impact on the end-customer's digital experience\nWork with state-of-the-art data processing frameworks, technologies, and cloud platforms\nDevelop in different technologies and languages ranging from Java and Scala to Python and SQL\nHelp implementing optimization, testing, and tooling to improve data quality\nAdvocate and advance modern, agile software development and help develop and foster good engineering practices\nDemonstrate and champion an appetite for knowledge and never stop developing as a Data Engineer\n\nWho You Are\n\n\nYou have worked with data pipelines (1-2 years experience) and have some knowledge about data modeling, data access, and data storage techniques\nYou have worked with cloud technologies (we use AWS and Azure) \nYou can independently execute smaller well-defined data engineering tasks\nYou have an interest to improve engineering practices like continuous delivery, defensive programming, and automated testing\nYou are comfortable working both independently and collaboratively (pairing and mobbing)\nYou care about and have experience with agile software processes, data-driven development, reliability, and responsible experimentation\nYou are passionate about crafting clean code and comfortable using at least one of the following programming languages (Python, Java, C++, or Scala)\nYou are well versed in the SQL language and databases\nYou understand the value of collaboration and partnership within a team\nYou like to have fun at work and take great care in making sure everyone always feels welcome and included!\nYou fully embrace a growth mindset, and encourage others to do the same\nYou are a self-motivated individual contributor and a great teammate with the ability to multitask, prioritize and communicate progress in a rapidly changing environment\n\nWe Offer Our Employees Excellent Benefits Such As\n\n\nPlenty of leave to let you take time off for what's most important in life\nCollective Agreement and ITP pensions\nAn annual allowance to spend on your health and wellbeing\n\nApplication\n\nWe are continuously screening applications and will fill the position as soon as we find a good match. We encourage you to apply as early as possible and to reach out to hiring manager Jacqueline Eriksson jacqueline.eriksson@volvocars.com for questions about the position and Senior Recruiter Sophie Esphagen sophie.esphagen@volvocars.com if you have any questions regarding the process.\n\nWho are we?\n\nEverything we do starts with people. Our purpose is to provide freedom to move, in a personal, sustainable and safe way. We are committed to simplifying our customers\u2019 lives by offering better technology solutions that improve their impact on the world and bringing the most advanced mobility innovations to protect them, their loved ones and the people around them.\n Volvo Cars\u2019 continued success is the result of a collaborative, diverse, and inclusive working environment. The people of Volvo Cars are committed to making a difference in our world. Today, we are one of the most well-known and respected car brands, with over 40,000 employees across the globe. We believe in bringing out the best in each other and harnessing the true power of people. At Volvo Cars your career is designed around your talents and aspirations so you can reach your full potential. Join us on a journey of a lifetime as we create safety, autonomous driving and electrification technologies of tomorrow."
    },
    {
        "position": "Data Engineer - Platform Foundations",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Spotify",
        "sector": "Musicians",
        "companySize": "5,001-10,000 employees",
        "location": "Sweden",
        "post": "About the job \n The Freemium R&D team oversees the entire user journey on Spotify and ensures we engage with people in innovative ways, every step of the way. Our team grows Spotify\u2019s audience by finding future listeners around the world and delivering the right value to them, at the right time. With research, product development, product design, engineering, and marketing all collaborating in one organization, we\u2019re able to quickly create meaningful features and services for millions of people around the world, resulting in joyful, long-lasting relationships with Spotify.\nWe are looking for a Data Engineer to join a team of versatile engineers that craft libraries, tooling and the infrastructure supporting data processing at Spotify. We research and develop state of the art solutions, collaborating with other teams within the Commerce Tribe to evolve a robust and reliable platform. Our platform is built to enable data practitioners to solve complex technical challenges, while providing an awesome developer experience, enforcing standards and making sure data workflows run reliably and efficiently.\nWhat You'll Do:\n\n\nResearch, prototype, implement and drive improvements and solutions, focused on solving complex data processing problems across the commerce organization.\nYou will create and update and evangelize standards and documentation that improve the experience for people working with data at Spotify.\n\n\nWho You Are:\n\n\nYou love Data Engineering.\nYou are Data centric (able to morph between a Data Engineer and Data Scientist).\nYou have a strong understanding of data systems.\nYou are knowledgeable and passionate about improving and building data platforms.\nYou are familiar with current engineering practices such as distributed architecture.\nYou are curious about new technologies and finding uses and insights for all types of data.\nYou will have experience working on and building distributed data pipelines that ingest huge amounts of data across multiple sources and brands.\nYou will have experience working with Scala and Python, Scio & Luigi would be an encouraged bonus.\n\n\nWhere You'll Be:\n\n\nWe are a distributed workforce enabling our band members to find a work mode that is best for them!\nWhere in the world? For this role, it can be within the EMEA region in which we have a work location\nPrefer an office to work from home instead? Not a problem! We have plenty of options for your working preferences. Find more information about our Work From Anywhere options here.\nWorking hours? We operate within the Central European time zone for collaboration\nWe ask that our team members be located within Greenwich Mean time zone, Central European time zone, or Eastern European standard time zone for the purposes of our collaboration hours. \n\n\nSpotify is an equal opportunity employer. You are welcome at Spotify for who you are, no matter where you come from, what you look like, or what\u2019s playing in your headphones. Our platform is for everyone, and so is our workplace. The more voices we have represented and amplified in our business, the more we will all thrive, contribute, and be forward-thinking! So bring us your personal experience, your perspectives, and your background. It\u2019s in our differences that we will find the power to keep revolutionizing the way the world listens.\nSpotify transformed music listening forever when we launched in 2008. Our mission is to unlock the potential of human creativity by giving a million creative artists the opportunity to live off their art and billions of fans the chance to enjoy and be passionate about these creators. Everything we do is driven by our love for music and podcasting. Today, we are the world\u2019s most popular audio streaming subscription service."
    },
    {
        "position": "Machine Learning Engineer to SEB in Stockholm",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "SEB",
        "sector": "Banking",
        "companySize": "10,001+ employees",
        "location": "Solna, Stockholm County, Sweden",
        "post": "About the job \n SEB is a leading northern European financial services group, and at the same time, one of the largest IT employers in the Nordics. Banking is changing rapidly, and we are proud of our reputation for being entrepreneurial and innovative in the face of change. Our brilliant techies work hard to future proof SEB\u2019s digital architecture and customer products because it genuinely makes a huge impact for our customers and colleagues. Does that sound like a fit for you?\nWe are working together with our customers to provide advanced analytics to SEB. This is the tooling for building and managing data science and machine learning models in order to enable and scale machine learning usage in SEB.\nTogether, we will increase the frequency of finding valuable insights within our data in the bank waiting to be found. Our team is dedicated to making data science and machine learning accessible by creating user friendly, secure and governed tools that standardize the ways of working.\nWe belong to the SEB Data & Analytics tribe, an international environment with multiple agile development teams located in Stockholm and Vilnius, consisting of experts in various Big Data and Advanced Analytics technologies.\nWhat you will be doing\nWe are looking for an engineer with system operations experience and an interest in system development and machine learning.\nYou and your fellow team members will create and maintain products in the Advanced Analytics team, together with data scientists and other internal customers.\nWho we are looking for\nIf you are analytical, curious and have a passion for problem solving and discovering new ways of working, you will enjoy it here. Especially if you also like Swedish fika!\nRequired Skills\n\n\nA degree in engineering or science, or equivalent work experience.Experience from working in Linux environments.An automation, DevSecOps and/or Site reliability engineer mindset.Programming and scripting skills (e.g. Python, Java and Scala) Collaboration skills and high sense of responsibility. We always work and deliver as a team, and the ability to share knowledge and experience is fundamental.Well versed in matters of IT securityAgile methodologies mindset.\n\n\nNice-to-have:\n\nExperience from working with container orchestration (e.g. Docker, Kubernetes, OpenShift)Machine Learning experience.Experience in developing services (e.g. REST APIs).Data engineering experience, e.g. Apache SparkDatabase knowledge (RDBMS and/or NoSQL)Knowledge of authentication and authorization services (e.g. Kerberos, LDAP, OAuth 2.0)Automation and configuration management systems (e.g. Ansible, Terraform, Chef)Cloud technologies, such as GCP.CI/CD, such as GitHub Actions\n\n\nWhat we offer\nWe offer many experiences and benefits to our employees, and there is nuance to every individual\u2019s career experience, but the elements that define the core of our offering are:\n\nExtensive training and learning opportunitiesWork-life balanceFriendly and welcoming cultureAttractive compensation and benefitsAccess to SEB staff banking with exclusive benefitsLong-term stabilityInnovative company in forefront of technologyOpportunities to help transform an industryChances to make an impact on social or environmental issues Excellent office environmentAgile and modern ways of workingEmpowering environment\n\n\nReady to join?\nAttach your CV and a personal letter describing yourself and how you can contribute. Since we select candidates continuously, feel free to send in your application today, but no later than 2022-09-29. Due to summer vacation we initiate selection process in full after mid-August. \nIf you have questions about the position, please contact team manager Mervan Yildiz on mervan.yildiz@seb.se.\nSEB Sweden has a redeployment responsibility, why this position might be covered by internal redeployment.\nWelcome to a community of tech-savvy and passionate employees from all corners of the world. SEB is in fact one of the largest IT employers in the Nordics. Together we future proof a world of financial flows by exploring and implementing modern digital architecture and state-of-the-art technology. We are driven by collaboration, insight, and friendship. But also, a desire to change and improve. All in all, it creates a balance - where life and a stable yet exciting job can co-exist. If you want to shape tomorrow's bank - continue reading and apply today.\n\nRead more:sebgroup.com/techcareers"
    },
    {
        "position": "Senior Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Cognizant",
        "sector": "IT Services and IT Consulting",
        "companySize": "10,001+ employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n What makes Cognizant a unique place to work? The combination of rapid growth and an international and innovative environment! This is creating a lot of opportunities for people like YOU \u2014 people with an entrepreneurial spirit who want to make a difference in this world.\n At Cognizant, together with your colleagues from all around the world, you will collaborate on creating solutions for the world's leading companies and help them become more flexible, more innovative and successful. And this is your chance to be part of the success story: we are looking for a Big Data Engineer to join out Artificial Intelligence & Analytics team.\n\nAbout Cognizant Artificial Intelligence & Analytics Practise\n\nCognizant\u2019s Artificial Intelligence & Analytics (AIA) is one of the world\u2019s biggest BI practices (20.000+ colleagues) and well-known for its ability to execute and client focus. We have a broad range of experience in different functions like Customer Analytics, Visualization, Big Data, Data Warehouse design, Data modelling and others. Although we are a big organization we value proximity and toward our employees we act in small communities where everybody knows each other.\n As Data Engineer you will be part of our exciting European team. We offer an international, result driven -but at the same time fun -environment to grow in, learn and build your own professional network.\n You will be part of the AIA team, which provides a full range of data and analytic services to clients across multiple sectors. You will work alongside other experts to deliver BI solutions to our clients, many of whom are well-known brands.\n\nAbout The Role\n\nWe are looking for candidates focusing on big data analytics space. In this job, you will need to function as big data engineer who masters multiple roles such as solution designer, developer, maintenance personnel, meaning a full stack Dev-Ops engineer.\n You should be passionate about tackling complex problems, especially tuning, scaling and multi-tenancy. You should be a good team player who knows how to work with agile Dev-Ops setup.\n You should be proficient enough to realize and translate business requirements into data products catering to use cases. You should also help business users to understand and realize their need of data-driven analytics.\n\nRequirements\n\n\nBachelors or Master Degree in Computer Science or similar technical degree.\nStrong experience with Big Data technologies and experience with Hadoop ecosystem technologies like HDFS, Hive, Spark, Kafka, Airflow.\nStrong development/automation skills. Must be very comfortable with reading and writing SCALA and Python code.\nExperience with data manipulation languages and technologies such as Spark-SQL, Hive HQL, Shell-Scripts.\nExperience with big data use cases around pipelines, data lakes, reporting, and other data-driven functionalities\nStrong problem solving and analytical skills, with permanent-maintainable-reusable solution approach.\nSound knowledge of security protocols and systems such as Kerberos, LDAP, AD servers\nExperience with multi-tenant data lake implementation, with performance tuning, scaling and reusability aspects of complex applications.\nKnowledge and experience with Bitbucket, Git, Jenkins, Jira\n\nNice To Have Skills\n\n\nExperience in working with AWS is a bonus.\nTelecom/Media and Entertainment Domain Knowledge\nFluency in Swedish is added advantage.\n\nWhat You Can Expect\n\n\nBecome part of a the \u2018flag ship\u2019 success story - We go through enormous growth!\nBased in the Benelux \u2013 we have offices in Amsterdam, Eindhoven and Brussels within an European and Global network\nOrganization driven by technology \u2013 We have a tremendous technology backbone\nOpen, \u2018can do\u2019 team spirit\nEnvironment where you can make your own ideas reality\nDrive your own career\nMarket conform benefits\n\nAbout Cognizant\n\nCognizant is one of the world\u2019s leading professional services companies, transforming clients\u2019 business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant, a member of the NASDAQ-100, is ranked 205 on the Fortune 500 and is consistently listed among the most admired companies in the world.\n Employee Status : Full Time Employee\n Shift : Day Job\n Travel : No\n Job Posting : Sep 16 2022\n\nAbout Cognizant\n\nCognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @Cognizant."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Meta",
        "sector": "Software Development",
        "companySize": "10,001+ employees",
        "location": "Sweden",
        "post": "About the job \n Every month, billions of people leverage Meta products to connect with friends and loved ones from across the world, and the Meta Business Group (MBG) helps small-to-large businesses, organizations, developers, creators, and other partners engage those people.MBG is looking for exceptionally talented and experienced Data Engineers to join the Business Products Engineering (BPE) team. Our team provides analytics and workflow tools for MBG, engaging with Sales, Marketing, Partnerships, Measurement, support, and operations teams. We also work with leading content creators, publishers, and businesses in entertainment, sports, news, and many other domains.As a highly collaborative organization, our data engineers work cross-functionally with software engineering, data science, and product management to optimize growth, strategy, and experience for over three billion users, as well as our internal employee communities.In this role, you will see a direct correlation between your work, company growth, and our partners\u2019 satisfaction. Beyond this, you will work with some of the brightest minds in the industry, and you'll have a unique opportunity to solve some of the most interesting data challenges with efficiency and integrity, at a scale few companies can match. As we continue to expand and create, we have a lot of exciting work ahead of us!\nData Engineer Responsibilities:\n\n\nArchitect build and launch new data models that provide intuitive analytics\nBuild data expertise and own data quality for allocated areas of ownership\nDefine and manage SLA for data sets within your domain\nDesign, build and launch extremely efficient and reliable data pipelines (ETL) to move data across a number of platforms including the data warehouse, online caches and real-time systems\nEducate your partners: Use your data and analytics experience to \u2018see what\u2019s missing,\u2019 identifying and addressing gaps in their existing systems and processes\nIdentify the data needed for a business problem and implement logging required to ensure availability of data, while working with data infrastructure to triage issues and resolve\nLead, influence and set direction on domain areas as a subject matter expert to drive solutions on complex and strategic problems\nManage the delivery of high impact dashboards, tools and data visualizations\nPartner with internal stakeholders to understand business requirements, work with cross-functional data and products teams and build efficient and scalable data solutions\n\n\nMinimum Qualifications:\n\n\n2+ years of experience in the data warehouse space, custom ETL design, implementation and maintenance\nExperience in leading data driven projects from definition through interpretation and execution\nExperience analyzing data to discover opportunities and address gaps\nExperience with data architecture, data modeling, schema design and software development\nExperience working with cloud or on-prem Big Data/MPP analytics platform (i.e., Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar)\n2+ years of experience in SQL or similar languages, and development experience in at least one language (Python, PHP etc.)\n\n\nPreferred Qualifications:\n\n\nExperience with data quality and validation\nExperience with Airflow\nExperience querying massive datasets using Spark, Presto, Hive, Impala, etc.\nExperience with more than one coding language\nExperience with SQL performance tuning and E2E process optimization\nExperience with designing and implementing real-time pipelines"
    },
    {
        "position": "Senior Data Analyst",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Telia",
        "sector": "Telecommunications",
        "companySize": "10,001+ employees",
        "location": "Solna, Stockholm County, Sweden",
        "post": "About the job \n Right now, we are looking for a talented Senior Data Analyst in our common analytics team with in Telia Company to boost our team capacity in delivering analytical insights to our Product areas & Business units. We have a passion to make Telia Company a truly data driven organization and to achieve that goal we have secured state of the art big data and advanced analytics capabilities both on Cloud and On prem. Our mission is to work closely with our internal stakeholders to explore new opportunities to optimize investments and operations based on Data and insights.\n\nIs this your next opportunity?\n\nAs a Senior data analyst, you will have a key role in the team being the bridge between business and analytics, helping the stakeholders with valuable insights from our vast amount of data.\n You will be part of a highly skilled and passionate cross-cultural team focused on delivering actionable insights for different product areas and business units across six different countries. You will get an opportunity to work in Scaled Agile environment and use the latest analytics tools & capabilities to explore, visualize and bring the data to life.\n We are working in cross-functional teams tightly integrated with our stakeholders. We are focusing on making our product areas such as Mobile and Broadband, TV & Media, Connectivity & Communication services more data driven, We are also continuously exploring new areas within Telia company to enable them to become data driven. Your contribution will be central, and you will have a wonderful opportunity to influence the work that your team is doing.\n\nIs this you?\n\nYou are independent with a strong passion to drive organizations to become data driven. Still, you are a team player that appreciates an inclusive team environment. You have a proven track-record from working with data analysis using programmatical methods and/or have used popular tools for data analysis and visualization. You have used your unique blend of analytical, technical, and business skills to create value by solving key business problems. You see data analysis and visualization as an art. It could be great if you understand our Telco & Media industry and how we work and our products.\n\nYour personality:\n\n\nCommunicative and good presentation skills\nEmpathetic and a team player in a cross-cultural competent team \nEngaged and proactive\nCreative and innovative\nAnalytical and insights driven\nProblem solving attitude\n\nYour Experience:\n\n\nPreviously worked as Data Analyst for at least 6 to 7 years with several success stories to share\nComfortable in applying data transformation and statistical programming using Python or any other programing languages like R\nSkilled in developing and presenting impressive insights using modern visualization tools like Qlik sense or python visualization capabilities\nExtensive experience of working with Dimensional modeling\nProficient in writing complex queries with SQL\nExperience in agile ways of working\nGood in stakeholder management\nGreat presentation skills along with the ability to explain complex concepts in a simplified manner\nExperience from a consultant position within the Telco industry is a bonus\nConceptual knowledge of applying Machine learning is a bonus \nBasic functional understanding of AWS Cloud or GCP Cloud, Hadoop Stack and Snowflake is a bonus\n\nIt\u2019s more than just a job!\n\nRegardless of the position you are looking for, we will give you the tools and support you need to grow both as a professional and as a person, with us. We can offer you your next big opportunity in a creative, motivating, and welcoming company where everyone can be themselves, with equal access to opportunities. We respect and value the diversity of people. In addition to an attractive and inclusive work environment, we also enable flexibility and offer a wide variety of employee benefits.\n\nInterested?\n\nIf this sounds like your next career move, apply for the job! Selection is ongoing, so do not hesitate to get in touch. Last day to apply is 2022-09-30.\n\nWelcome to Telia \u2013 Home to your next big opportunity!"
    },
    {
        "position": "Data Analyst / Engineer to Nordax Bank",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Nordax Bank",
        "sector": "Banking",
        "companySize": "201-500 employees",
        "location": "Stockholm City, Stockholm County, Sweden",
        "post": "About the job \n Nordax Bank is a leading Nordic specialist bank that offers consumers private loans, savings, mortgages and mortgages for those aged 60+, capital release loans. Nordax has about 300,000 customers, mainly in Sweden, Norway and Finland.\n Ever since Nordax was founded in 2003, the company has grown and formed an organization based on great know-how and commitment. Through responsible lending, we help people make well-thought-out choices for a life they can afford. Since January 2019, Nordax owns Svensk Hypotekspension AB and then added capital release credits to the product portfolio and during November 2021, the acquisition of Bank Norwegian was also completed. With the acquisition of Bank Norwegian, Nordax has doubled its size regarding its loan portfolio and will receive another product in the form of a credit card.\n\nAbout The Role\n\nOur Data Engineering team is currently expanding, and we are currently looking for a Data Analyst / Engineer! You will be a part of IT and your stakeholders will be all over the organization. The team is currently in an expansion phase with new architecture under design. This is a great career opportunity for a data analyst or engineer to grow in front end, backend and design matters. You will also have possibility to influence new end to end data architecture and flows and designing data solutions from the start (On prem, Cloud and hybrid).\n\nSpecific responsibilities include but are not limited to:\n\n\nImplementing traditional database & DWH concepts to provide self-service reporting solutions in Power BI\nCreating power BI reports \nCreating and maintaining data pipelines\nIdentifying data quality gaps and improve data quality\nDesign and build ETL/ELT processes\nSupport in creating and improving functional and technical design of current and existing solutions\n\n\nYour Profile\n\nTo thrive and succeed in the role you should be passionate about data, technical solutions, modern software development methodologies and learning new things related to data. You have an eye for details and are a driven person that has demonstrated \u201cpulling up the sleeves\u201d to reach your goals.\n\nWe believe you have:\n\n\nRelevant academic degree e.g., civil or industrial engineering, computer sciences, math, statistics etc. \nOverall experience with Analytics & BI tools and services (we use the Microsoft stack MS SQL, SSIS, Power BI)\nExperience with on premise DW and Cloud solutions \nPractical experience in setting up data warehouses and/or data lakes\nExperience in planning for implementation of big data systems \nHands on ETL implementation \n\n\nAs a person you are result-orientated and you are an inclusive team player with a willingness to grow and develop. You have an ability to mentor other developers in all aspects of their engineering skillset. You are fluent in English and have excellent communication and presentation skills.\n\nOther qualifications that it is good to have:\n\n\nFinance industry, or other regulated industry\nDeveloping and maintaining CI/CD pipelines \nWorking with data on cloud (e.g., Azure SQL, ADF, Data bricks, Snowflake etc.)\nOther programming skills such as Python, Scala etc. \nCreate and maintain technical design and data architecture \nOverall experience with Analytics & BI tools and services, (we use the Microsoft stack MS SQL, SSIS, Power BI)\n\n\nOur offer\n\nFreedom with responsibilityCareer DevelopmentFeedback CultureCoaching Leadership\nA strong caring company culture \u2013 we really care about each other!\n\n\nIf you want to know more\n\nPlease feel free to contact hiring manager Nina Alias at nina.alias@nordax.se if you have any specific questions about the role. If you have any question about the application or recruitment process, please contact recruiter Maria Moberg at maria.moberg@nordax.se. Due to GDPR, we are unable to handle applications sent to us by e-mail.\n\nNext step\n\nWe will review applications continuously and the position may be filled before the application deadline, so make sure not to wait until the last day! The applications should include your CV, written in English or Swedish.\n We believe in evidence-based tests in order to eliminate unconscious bias and increase hiring precision - the right person for the right position. For this reason, we use Alva Labs assessment methods for our recruitment processes to help us identify candidates with the greatest probability to succeed in this role.\n We also want to inform you that we take UC (check payment remarks) and ask for an excerpt from the police criminal record for all positions at Nordax.\n\nWe look forward to your application!\n\nAbout Nordax\n\nNordax is one of the leading niche digital banks in Northern Europe that helps people make informed financial decisions for their well-being by acting as a strong alternative to traditional banks. We are proud of our sound and data-driven competence that allows us to lend responsibly and earn our customers\u2019 trust based on transparent and clear pricing models. We are experts in mortgages, savings accounts, private loans and equity release products."
    },
    {
        "position": "Data Warehouse Developer - Scania",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Scania Group",
        "sector": "Motor Vehicle Manufacturing",
        "companySize": "10,001+ employees",
        "location": "S\u00f6dert\u00e4lje, Stockholm County, Sweden",
        "post": "About the job \n Scania is currently undergoing an exciting transformation from a traditional truck manufacturer to a provider of complete sustainable transport solutions. IT is a crucial part of this transformation as Scania\u2019s success is depending on flexible and efficient IT solutions that support current and future business requirements.\nBI department at Scania - Drive the shift with Data as fuel\nOur department plays a big role in Scanias data strategy to deliver top analytical solutions. We enable and enhance data to enforce our employees to perform at their best by providing excellent solutions that increase and secure the right decisions to reach and exceed the business goals. We work in Teams and Squads close with business to be Business & It as One.\nWhat We Offer\n\nWe offer a competitive salary, flexible working hours, and an educational establishment with courses and programs to develop your skills. As a Scania employee, we also offer you benefits such as a company car, performance bonuses, parental benefits, and wide range of sports clubs and a free Health Centre with a gym, classes, and much more. If you live in Stockholm we offer a direct bus between Stockholm and S\u00f6dert\u00e4lje with Scania Job express.\nPlease click here to read more about Scania, our core values, benefits, and much more.\nWhat You Get To Do\n\nData management is a central component in making the vision real - to prepare data that can be consumed by our BI applications and users. You will work with Scania's stakeholders to describe/implement information models in DW solutions and will be involved in both development of new solutions as well maintaining the existing portfolio. We work with data pipelines in data warehouse and Hadoop environments. \nYour contacts will be both with business users of the applications as well as internally at Scania IT.\nSkills And Experience\n\n\n\nAt least 3 years experience with DW development and support \nDimensional modeling\nAdvanced working SQL knowledge and experience working with relational databases\nETL toolset - Oracle Data Integrator is highly meriting\nBSc or MSc in Computer Science or related field (or equivalent experience)\nStrong English language skills \n\n\nYour Profile\n\nIn addition to the technical requirements we believe that the right candidate has the following characteristics:\n\n\nAnalytical - Analyses data, all other sources of information and demonstrates an understanding of how one issue may be a part of a much larger system\nCurious and want to learn - Rapidly learns new tasks and quickly commits information to memory and learns from successes and failures and seeks staff and customer feedback\nOrganized - Sets clearly defined objectives and plans activities while taking into account possible changing circumstances\nGoal-oriented - You set high goals for yourself and works hard and persistently to achieve those goals\n\n\nLocation: S\u00f6dert\u00e4lje\nInformation and Application \n\nIf you have specific questions regarding the position! Please contact Claes Stille, Manager, at +46 8 553 51 449\nInterviews will be scheduled continuously, We are looking forward to reading your application, the last day to apply is 2022-04-24\n\nFor more information about the recruitment process, contact Zanko Dasko, Senior Talent Acquisition Specialist tel. +46 855 351 621\nIf the position requires it, a background check will be conducted.\n\nScania is a part of Traton Group and one of the world\u00b4s leading manufacturers of trucks and buses for heavy transport applications. Scania is also leading provider of industrial and marine engines. Service-related products account for a growing proportion of the company\u00b4s operations, assuring Scania customers of cost-effective transport solutions and maximum uptime. Scania also offers financial services. Scania\u2019s IT organisation is an integrated part of the company providing products and services to all business units worldwide. Based on deep Scania business knowledge and internal relations we balance in-house core competences and service production with services externally sourced and governed by us. We are around 1500 people and the majority is located in Sodertalje."
    },
    {
        "position": "Data Analyst",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "foodora",
        "sector": "Food and Beverage Services",
        "companySize": "1,001-5,000 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nfoodora is in constant growth and is always focusing on developing our business and industry alike. We are now looking for someone who loves to deep dive into large sets of data and create tangible analysis and actionable insights out of them. You most probably have a strong business acumen and have the ability to see the bigger picture. You are strong at visualizing how your day-by-day analytics can contribute and benefit the business and move us forward as a company. You will be a big part in fortifying us as a future-proof business. If you see yourself as a part of this journey, come join the quick commerce revolution at foodora as our next Data Analyst! \n\nWhat You Will (but Not Only) Do\n\n\nExtract, analyze and visualize complex data to understand customer behavior. \nDeliver actionable insights to improve the customer/partner experience and to identify commercial opportunities. \nPerform cluster analysis of customer data to identify patterns, build cohorts and develop market segments.\nBuild action-oriented dashboards that enable different teams to make data-driven decisions.\nKnowledgeable about the latest analytics methods and trends. \nEffectively communicate insights and recommendations to stakeholders.\n\n\nWho You Are\n\n\nStructured - You can create structure even in the most un-structured environment\nAnalytical - You base your decisions on data and is used to back your arguments with strong analyses\nIndependent - You take full ownership for your work by taking your own initiatives and making sure they move forward, forward and forward!\nCommunicative - Your communication skills will be key in this role\nPrioritization ability - A lot is happening at foodora all the time, this will challenge your ability to prioritize, which we hope that you really enjoy!\n\n\nQualifications\n\n\nYou have a university degree where the education has included some quantitative elements like economics, engineering or mathematics. \nYou have a few years of experience working as an analyst or in a similar role. \nYou have previous experience with relational databases (e.g. SQL) and it is meritorious if you have worked with BigQuery\nYou have the skills and experience of visualizing large quantities of data and it is meritorious if you have experience with Tableau and/or Power BI. \nYou communicate fluently in English both verbally and in writing. It will be considered a plus if you speak Swedish as well. \n\n\nOur selection process is continuous and the ad may close before the recruitment process is completed, if we\u2019ve moved forward to the screening or interview phase.\n Our recruitment process will include the following:\n \ud83d\udca1 Psychometric tests via Alva Labs - We use science-based methodology.\n \ud83d\udcbb Digital HR interview - Let\u2019s get to know each other a bit better!\n \ud83d\udcbc Case interview - Do your magic and meet us face to face.\n \ud83d\udc8c Reference check - Almost there!\n \u2714\ufe0f Background check - Final step before we\u2019ll become colleagues.\n\nWho We Are\n\nWe\u2019re foodorians, a driven and happy gang of food lovers eager to create the LMD* service of the future! Our core values help concretize what we\u2019re aiming for: We dare, We get it done & We\u2019re equally pink. We\u2019re people from all backgrounds, with different experiences, opinions and ideas. This is something we value highly, since we fully believe that diversity is what builds our culture and success.\n Success is fun, but let\u2019s be clear: it cannot happen at the expense of sustainability. Since January 2020 we\u2019re a carbon neutral business and we hope to lead the way for sustainability within our industry - from supplying 100% electrical transportation to promoting more environmentally friendly food choices. Please check out our Instagram, foodorapeople.se, to see what\u2019s going on right now.\n\nLMD = Last Mile Delivery. That, and many other nerdy abbreviations, is something you\u2019ll learn when you start. ;)\n\n\nBenefits\n\n\nWellness allowance.\nEmployee discount at foodora (woho!).\nOccupational pension, incl. premium exemption insurance, accident insurance and life insurance.\nGreat deals at Benify.\nAwesome AW\u2019s and (pink) parties."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Media.Monks",
        "sector": "Advertising Services",
        "companySize": "5,001-10,000 employees",
        "location": "Stockholm City, Stockholm County, Sweden",
        "post": "About the job \n A Data Engineer at Media.Monks, with a thorough understanding of cloud technologies, will help to deploy Big Data solutions, build and manage data pipelines, ETL processes, and cloud data migrations in a production, secure and scalable manner. The data engineer should be a data specialist with strong experience in the deployment and automation of data pipelines, data development, data cleansing, data warehousing, monitoring data processing systems, and dealing with large and various sets of structured and unstructured data. The data engineer will have experience ingesting real-time data from various data sources and designing new data platforms.\n\nWhat You'll Be Doing\n\n\n\nDesign and build data pipelines using a cloud platform.\nManage and provision the cloud solution infrastructure.\nDesign for data security and compliance.\nManage and automate ETL and cloud deployment implementations. \nEnsure solution and operations reliability.\nDesign and implement Big Data and Data Warehousing solutions with their corresponding Data Governance processes.\nAble to manage Cloud databases.\nProvide domain expertise around public cloud and enterprise technology.\n\n\nWhat You'll Bring\n\n\n\nDemonstrable deep knowledge and experience in cloud migration, cloud strategy and transformation, cloud architecture and engineering.\nBroad knowledge of the major cloud vendors with deep knowledge in GCP.\nA set of certifications in (GCP): Cloud Architect, Data Engineer or Cloud Engineer.\nUnderstanding of the high-level levers for cost-effective cloud delivery.\nDeep hands-on experience with cloud orchestration tooling, infrastructure-as-a-code (Terraform, Chef, Ansible or Puppet). \nDeep hands-on experience building scalable ETL pipelines (Apache Beam, Airflow).\nProgramming experience in Python and Javascript.\nTechnical depth and experience with SQL.\nStrong problem solving or analytics experience.\nPreferred qualifications\nFamiliarity with digital marketing context.\nKnowledge of/exposure to Adobe Marketing Cloud or Adobe Analytics.\nA set of certifications or work experience in another cloud vendor (AWS or Azure).\nTechnical depth and experience with: Linux/Unix administration. \nKnowledge of enterprise computer networks and VPC networks.\nKnowledge of IT and cloud security solutions.\n\n\nWhat We Offer\n\nUpon meeting the Company's eligibility requirements mentioned above, you will/may also be entitled to the following benefits at the discretion of the Board: \n25 days paid annual leave & Paid bank holidays for your region\nHealth Insurance (Euroaccident) & reimbursement scheme for medical, optical or dental expenses not covered by the plan (Annual limits apply)\nFlexible working with no set days to be present in the office as well as options to \u2018Work from Abroad\u2019 in other European offices for up to 12 weeks a year.\n\nWe provide an Internet & Home Office Reimbursement for all employees to ensure that working from home is as effective as possible.\n\nGenerous Parental Leave\nWorkplace Pension Plan (Avanza)\nCorporate Mobile Phone plan\nRegular Team Events & generous Social Budgets to help develop team morale.\nAnnual Personal Training budget to be used towards training & development courses to help you learn and grow your skill set.\nAccess to LinkedIn Learning training course on a huge range of topics\nReasonable usage of company Uber account.\n\n\nAbout Media.Monks\n\nMedia.Monks is on a mission to create a new future for this industry. Our vision? Build everything with a belief that changing for good comes from changing who does the work. Yep, that means you. Welcome to the party\u2014one global, cross-cultural collective with a passion for using our skills to create better and a better world. That\u2019s how we\u2019re able to connect the dots between data, content, digital media, and technology from everywhere we are\u2014a true end-to-end model. Joining the Media.Monks collective means having the opportunity to create award-winning work with some of the most gifted, focused, joyful, talents from all over the world.\n At Media.Monks, you\u2019ll be joining a highly ambitious company on a global mission to win the decade by changing the industry for good. Partner to 8 of the 10 most innovative companies in the world, Media.Monks works with established as well as up-and-coming global, regional, DTC and B2B brands, helping them own their data and build out customer ecosystems to elicit smart, efficient, high-impact engines for growth. We deliver table stakes quickly, creating cost efficiencies from day one to push up the creative effectiveness of our work with every cycle.\n We are an equal-opportunity employer committed to building a respectful and empowering work environment for all people to freely express themselves amongst colleagues who embrace diversity in all respects. Including fresh voices and unique points of view in all aspects of our business not only creates an environment where we can all grow and thrive but also increases our potential to produce work that better represents\u2014and resonates with\u2014the world around us."
    },
    {
        "position": "Staff Database Engineer (Redshift)",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Zendesk",
        "sector": "Software Development",
        "companySize": "1,001-5,000 employees",
        "location": "Sweden",
        "post": "About the job \n\nJob Description\n\nAt Zendesk, we get excited about building software that delivers the ultimate customer experience. Your favourite brands (like Airbnb, Uber, Slack, and Disney) use our products to engage you as a customer, and we lead the industry with beautifully simple software. And we\u2019re constantly innovating - no, really, we can\u2019t wait to outdo ourselves in the near future.\n Zendesk Explore (https://www.zendesk.com/explore/) is our latest analytics product. It is a complex business intelligence application, serving 100,000 customers and utilising data from over 500 million Zendesk users and 40+ external data source connectors. Explore is responsible for ingesting millions of records from the Zendesk product family and allowing them to be queried and visualised at low latency - and all that at scale!\n We\u2019re looking for a Staff Software Engineer to help take Zendesk products to the next level. You\u2019ll join a team that works on our Explore analytics data engine and datastores. Explore is a complex reporting application that provides analytics for Zendesk data. You\u2019ll have the skills, experience, wisdom, patience, and determination to work with the team to meet our customer's needs.\n\nWhat You Get To Do Every Day\n\n\nWork with Redshift and Postgres databases, analysing customer usage patterns and identifying bottlenecks in their database schemas and/or queries.\nDesign and document data-related changes to improve database performance.\nWork with stakeholders, including the Engineering, Product, Data and Design teams, to assist with data-related technical issues and support their data infrastructure needs.\nWork with Data and Analytics experts to strive for better performance in our data systems.\n\nWhat You Bring To The Role\n\n\nAt least 5 years of proven experience working on data-related services, big data environments and/or analytics.\n\n\nAn advanced working knowledge of Redshift.\nA familiarity with PostgreSQL.\n\nDo you know when and when not to apply a B-TREE index?\nDo you know what AUTOVACUUM is?\n\nExperience with AWS cloud services: EC2, ECS, Redshift, RDS\nExperience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.\nExperience supporting and working with cross-functional teams in a dynamic environment.\n\nNice-to-haves\n\n\nExperience working with Scala or any strongly typed language (Java, Kotlin, C#).\nExperience developing ETL/ELT pipelines and knowing best practices for maintaining them.\n\nDon\u2019t meet every single requirement? Studies have shown that women and people of colour are less likely to apply to jobs unless they meet every single qualification. At Zendesk, we are dedicated to building a diverse, inclusive and authentic workplace, so if you\u2019re excited about this role, but your past experience doesn\u2019t align perfectly with every qualification in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles\n\nAbout Zendesk - Champions Of Customer Service\n\nZendesk software was built to bring a sense of calm to the chaotic world of customer service. Today we power billions of conversations with brands you know and love. We advocate for digital first customer experiences \u2014 and we stick with it in our workplace. Over 6,000 employees worldwide have the flexibility and trust to choose where they work. The fact is, we know great work happens anywhere. Whether you\u2019re collaborating from your home office, a Zendesk workspace, or the kitchen table, you\u2019re part of one team at Zendesk.\n Zendesk is an equal opportunity employer, and we\u2019re proud of our ongoing efforts to foster global diversity, equity, & inclusion in the workplace. Individuals seeking employment and employees at Zendesk are considered without regard to race, color, religion, national origin, age, sex, gender, gender identity, gender expression, sexual orientation, marital status, medical condition, ancestry, disability, military or veteran status, or any other characteristic protected by applicable law. We are an AA/EEO/Veterans/Disabled employer. If you are based in the United States and would like more information about your EEO rights under the law, please click here.\n\nFor jobs in the US only: If hired, you will be required to provide proof of full vaccination against COVID-19 and will be provided with an opportunity to request an accommodation for reasons recognized by applicable law. This is a requirement of employment for jobs based in the United States.\n\nFor jobs in Australia, Brazil, Canada, the Philippines and Singapore: If hired and required to work in office or in person with others as part of your job, you will be required to provide proof of full vaccination against COVID-19. Zendesk will consider exceptions for reasons recognized by applicable law. This is a requirement of employment for jobs based in Australia, Brazil, Canada, the Philippines and Singapore.\n Zendesk endeavors to make reasonable accommodations for applicants with disabilities and disabled veterans pursuant to applicable federal and state law. If you are an individual with a disability and require a reasonable accommodation to submit this application, complete any pre-employment testing, or otherwise participate in the employee selection process, please send an e-mail to benefits@zendesk.com with your specific accommodation request.\n By submitting your application, you agree that Zendesk may collect your personal data for recruiting, global organization planning, and related purposes. Zendesk's Candidate Privacy Notice explains what personal information Zendesk may process, where Zendesk may process your personal information, its purposes for processing your personal information, and the rights you can exercise over Zendesk\u2019s use of your personal information."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Prezi",
        "sector": "Software Development",
        "companySize": "201-500 employees",
        "location": "European Union",
        "post": "About the job \n\nRole Description\n\nPrezi is the zooming presentation software that uses an open canvas instead of traditional slides to help people explore ideas, collaborate more effectively, and create visually dynamic presentations. Founded in 2009, and with offices in San Francisco, Budapest and Riga, Prezi provides its users a visually engaging, personalized way to express their ideas anytime, anywhere.\nThe company\u2019s vision extends well beyond authoring software alone into becoming the inspiration and enabler of world-changing ideas for people, organizations, and businesses. Prezi has enjoyed explosive growth and developed a rapid following of passionate users. More than 85 million people from over 190 countries use Prezi from their desktops, browsers and mobile devices. Prezi is rapidly adding new users each month, and more than 1 Prezi is created every second. The company has over 300 employees and is backed by premier investors, including Accel Partners, Sunstone Capital (based in Copenhagen), and TED. We are looking for a talented software engineer to join our Data Infrastructure Team.Data @ Prezi \n\nWe believe that data analytics should be easy for both technical and non-technical people. We aim to create the tools, build the data platform and train our users to make this possible.\nTo better understand our users we collect data from all parts of our product and push it to a Kafka cluster and ingest data to Amazon distributed storage S3. We then use open source tools like Apache Gobblin to further process and analyze our data. We collect around 1TB data/day. Analysts who are interested in the data can crunch the data using Zeppelin or can schedule jobs with our ETL system to process the data with Spark/Trino. Data is then exposed through Hive tables for further analyses and reporting.\nSee more from our talk at Big Things .\nResponsibilities\n\n\nKeep petabyte-scale data flowing through our pipeline. We have hundreds of data-analytics jobs running every day. \nDefine best practices. \nWork closely together with our Data Team Design and build data architecture and related tooling including: \nLogging framework ETL and batch processing infrastructure Realtime data systems, data pipelines, pub/sub interfaces Data warehouse modeling and design BI tooling, OLAP Future proof our system to enable new business opportunities e.g. through machine learning Partner with Data Analysts, provide tools and guidance on schema modeling, query optimization Oversee data lifecycle, understand it\u2019s current and future use cases and build a scalable, maintainable solution Automate data quality assurance and provide best practices to teams. Work together with Product Teams and provide them simple APIs to push and pull data \nYou have \n\n\nExperience with k8s (at scale) Bachelor\u2019s Degree in Computer Sciences or related field Minimum 3 years of experience in software engineering Fluency in a scripting language (e.g. Python, Ruby) Familiarity with *nix environment and tooling (e.g. bash, ssh, git) Up-to-date knowledge about big data tools and techniques Experience developing and working with ETL pipelines SQL knowledge Strong interpersonal and communications skills; ability to consult, partner and work effectively with business partners and technical partners across functions Enthusiasm for DevOps: we write it, we run it! Excitement for building on open sourced tools as well as contributing to existing products Get it done behaviour: you are smart and quick with a focus on delivery Bravery to try, pilot and eventually productise new technologies You might also have \n\n\nExperience with Amazon Web Services or similar cloud provider Experience with continuous integration, configuration management Experience with data warehouse design and maintenance Background in statistics, data analysis, data science, and machine learning What we offer you \n\n\nDeploy to production from day one A working environment that supports career and skill growth People who listen to your opinions and value them Remote-first attitude (but we also have a centrally located office in downtown Budapest) Receive stock options to become your own employer Be yourself - we are proud to be colorful!"
    },
    {
        "position": "Data Engineer to Advanced Analytics and AI Team",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Handelsbanken",
        "sector": "Banking",
        "companySize": "10,001+ employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nJoin the Advanced Analytics and AI Team within Handelsbanken, in Stockholm, as we provide our business with highly accurate insights and models that drive us forward in a data-driven way and help create the best possible experience for our customers.\n\n\nOur team\nWe are on a mission to make Handelsbanken a leader in using advanced analytics and AI to deliver superior products, service and experience to our customers. This involves applying statistics, machine learning and other technologies in a wide range of areas such as content personalization, product development and business strategy. As a key part of delivering on this mission we have set out to build a state-of-the-art analytics platform in the Microsoft Azure cloud environment.\n\n\nWe work with other teams throughout the bank in an environment characterized by initiative, collaboration and innovation to tackle business challenges by predicting outcomes, understanding complex data relationships and constructing models that contribute to a better experience for our customers.\n\n\nYour Role\nAs a Data Engineer you will be part of building and improving our data and analytics platform. This includes a journey to build, and migrate to, a new analytics platform in Azure by creating solutions for everything from data ingestion and orchestration to machine learning pipelines. You will be involved in solving complex data processing problems, building large-scale batch and real-time data pipelines and designing high quality data sets. The role also includes collaborating with other data engineers, data scientists, software engineers and business analysts in specific data science projects to generate insights and models that inform and automate decision making.\n\n\nYou will enjoy the freedom to explore new projects and solutions, the support to think outside the box and the opportunity to expand your data engineering skillset through development opportunities and researching innovative tools and techniques to level up our capabilities.\n\n\nThe team is expanding so we are looking for people who are able to take ownership, establish best practices and contribute in defining how this field will be applied in the bank. Your role can evolve over time and for the right candidate there are tremendous growth opportunities.\n\n\nAbout You\n\nYou have a master\u2019s degree or equivalent in a technical field with above average academic results\nYou have excellent problem solving skills and enjoy solving problems with code\nExtensive experience in software development with a deep understanding of system design and data structures\nExperience working with data and building data pipelines with respect to data modeling, orchestration and validation\nProficient in cloud technologies from at least one of the major providers\nUnderstand modern data concepts such as data lakehouse and data mesh and the impact it will have on traditional data architectures.\nHave a good understanding of distributed computing for large scale data processing\nYou are willing to learn, or already know, basic Swedish\nYou constantly want to learn new skills and are proactive with your own development\n\n\n\nWe are looking for a person who fits the positive, friendly and supportive culture of Handelsbanken. The ideal candidate is curious, inventive, strives for improvement every single day and shares our aim to be smart, humble and, above all, collaborative.\n\n\nWe Offer \n\nThe chance to develop fast, make a big impact and cut out new paths in an expanding team at the core of Handelsbanken\u2019s ambitious focus on digitalization.\nAn abundance of interesting opportunities and a focus on building new capabilities, not just maintaining what others have already created\nA friendly and collaborative work environment where colleagues learn and achieve together\nCompetitive compensation and pension plan\nExtensive benefit package (subsidized banking services, health care, lunch and more)\nFlexibility to work from home part of the time\nOffice at prime location in central Stockholm\n\n\n\nYour Application\nWe look forward to receiving your CV and academic records. Furthermore, we are particularly interested in previous team work experience, what motivates you and achievements that you are proud of.\n\n\nPlease submit your CV and academic records merged in the same file. \nThe promotion of gender equality, diversity and an inclusive corporate culture is a fundamental part of our values. We encourage candidates from all backgrounds to submit their applications."
    },
    {
        "position": "Senior Data Engineer \u2013 Apache Spark (Java/Scala) (Bangkok based, relocation provided)",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Agoda",
        "sector": "Technology, Information and\n                                                            Internet",
        "companySize": "5,001-10,000 employees",
        "location": "Stockholm City, Stockholm County, Sweden",
        "post": "About the job \n\nAbout Agoda\n\nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 4,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u202fenhancing the ability for our customers to experience the world.\nAbout Agoda\n\nAgoda is an online travel booking platform for accommodation, flights, and more. We build and deploy cutting edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 4,000+ talents coming from 90+ different nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enabling our customers to experience the world\nGet to Know Our Team\n\nThe Data department oversees all of Agoda\u2019s data-related requirements. Our ultimate goal is to enable and increase the use of data in the company through creative approaches and the implementation of powerful resources such as operational and analytical databases, queue systems, BI tools, and data science technology. We hire the brightest minds from around the world to take on this challenge and equip them with the knowledge and tools that contribute to their personal growth and success while supporting our company\u2019s culture of diversity and experimentation. The role the Data team plays at Agoda is critical as business users, product managers, engineers, and many others rely on us to empower their decision making. We are equally dedicated to our customers by improving their search experience with faster results and protecting them from any fraudulent activities. Data is interesting only when you have enough of it, and we have plenty. This is what drives up the challenge as part of the Data department, but also the reward.\n\nWhy Agoda Data Applications Team?\n\nOur Data Engineering teams are at the intersection of business analytics, data warehousing and software engineering. Our job involves dealing with distributed systems, stream processing, computation and data governance at tens of PB Scale.\nWe focus on software engineering related to data replication, storage, centralized computation, and Data API\u2019s. By providing our users with data products/tools, shared frameworks and data services, we enable our company to validate strategic decisions, make smarter choices, and react to the fast-changing world.\nWe are a small but passionate team with people from different nationalities working together on a single goal J\nIn this Role, you will get to\n\n\n\nLead the team technically in improving scalability, stability, accuracy, speed and efficiency of our existing Data systems\nBuild, administer and scale data processing pipelines\nBe comfortable navigating the following technology stack: Scala, Spark, java, Golang, Python3, scripting (Bash/Python), Hadoop, SQL, S3 etc\nImprove scalability, stability, accuracy, speed and efficiency of our existing data systems\nDesign, build, test and deploy new libraries, frameworks or full systems for our core systems while keeping to the highest standards of testing and code quality\nWork with experienced engineers and product owners to identify and build tools to automate many large-scale data management / analysis tasks \n\n\nWhat You\u2019ll Need To Succeed\n\n\n\nBachelor\u2019s degree in Computer Science /Information Systems/Engineering/related field\n5+ years of experience in Data engineering\nGood experience in Apache Spark\nExpert level understanding of JVM and either Java or Scala\nExperience debugging and reasoning about production issues is desirable\nA good understanding of data architecture principles preferred \nAny other experience with Big Data technologies / tools\nSQL experience\nAnalytical problem-solving capabilities & experience\nSystems administration skills in Linux\n\n\nIt\u2019s great if you have\n\n\n\nGood understanding of Hadoop ecosystems\nExperience working with Open-source products\nPython/Shell scripting skills\nWorking in an agile environment using test driven methodologies \n\n\n#sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #mexico #sydney #melbourne #toronto #vancouver #shanghai #beijing #shenzhen#estonia #paris #hongkong #budapest #jakarta #bali #kualalumpur #dublin #berlin #telaviv #milan #rome #tokyo #osaka #amsterdam #oslo #manila #warsaw #krakow #moscow #saintpetersburg #seoul #barcelona #madrid #stockholm #zurich #taipei #bangkok #chiangmai #phuket #istanbul #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #hochimin #dhaka #islamabad #newdelhi #Bangalore #Pune #Hyderabad #Bangalore #Mumbai #Bengaluru #Chennai #Kolkata #Lucknow #IT #ENG #4\nEqual Opportunity Employer \n\nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u2019s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy .\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes."
    },
    {
        "position": "Data Engineer - Experience Mission",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Spotify",
        "sector": "Musicians",
        "companySize": "5,001-10,000 employees",
        "location": "Sweden",
        "post": "About the job \n Delivering the best Spotify experience possible. To as many people as possible. In as many moments as possible. That\u2019s what the Experience team is all about. We use our deep understanding of consumer expectations to enrich the lives of millions of our users all over the world, bringing the music and audio they love to the devices, apps and platforms they use every day. Know what our users want? Join us and help Spotify give it to them.\nWe are looking for an engaged and enthusiastic Data Engineer to join one of our Experience Mission departments! Our teams within the Experience Mission are responsible for all of Spotify\u2019s consumer experiences across our mobile apps as well as platforms like desktop, web, TVs, smart-speakers, cars, wearables, and partner application integrations to make Spotify available wherever our users are. We are hiring data engineers who are passionate about building structured, high-quality data solutions. These solutions will be used to evolve our products, bringing better experiences to Spotify users and the global artist community alike. We process petabytes of data using tools such as GCP and its products suite such as BigQuery, Dataflow and Pub/sub. We are also known to write our own open source software to cater for our needs, such as Scio, a Scala API wrapper for Apache Beam.\nWhat you'll do\n\n\nBuild large-scale batch and real-time data processing systems with Scala, and cloud platforms.\nFacilitate and drive collaboration with other software engineers, data scientists, and decision-makers, such as product managers, to build exceptional data powered products.\nEvolving our data pipelines towards technical excellence by improving data quality through testing, tooling and continuously evaluating performance at scale.\nPerform root cause analysis on data and processes in order to answer business questions and find opportunities for improvement.\nContinuously improving our code bases by working with innovative data processing frameworks, technologies, and platforms.\nWork in multi-functional teams with end-to-end responsibility for product development and delivery within the mission.\n\n\nWho you are\n\n\nYou are knowledgeable and driven about software engineering. We use languages such as Python, Java, Scala and SQL combined with various cloud solutions. Although you might not have a background in our field, bringing knowledge and experience from other fields is merited.\nYou have experience working with high volume heterogeneous data, preferably with data processing frameworks like Apache Beam, Apache Spark, Apache Flink.\nYou have strong analytical skills and love to visualize your data findings in a clear and easy to understand way and to collect corner cases of implementations.\nYou care deeply about agile software processes, reliability, and responsible experimentation as well as being a strong advocate for engineering best practices such as continuous integration and delivery.\n\n\nWhere you'll be\n\n\nWe are a distributed workforce enabling our band members to find a work mode that is best for them.\nWhere in the world? For this role, it can be within the EMEA region in which we have a work location and is within working hours.\nWorking hours? We operate within the Central European and GMT time zones for collaboration and ask that all be located that time zone.\nPrefer an office to work from home instead? Not a problem! We have plenty of options for your working preferences. Find more information about our Work From Anywhere options here.\n\n\nSpotify is an equal opportunity employer. You are welcome at Spotify for who you are, no matter where you come from, what you look like, or what\u2019s playing in your headphones. Our platform is for everyone, and so is our workplace. The more voices we have represented and amplified in our business, the more we will all thrive, contribute, and be forward-thinking! So bring us your personal experience, your perspectives, and your background. It\u2019s in our differences that we will find the power to keep revolutionizing the way the world listens.\nSpotify transformed music listening forever when we launched in 2008. Our mission is to unlock the potential of human creativity by giving a million creative artists the opportunity to live off their art and billions of fans the chance to enjoy and be passionate about these creators. Everything we do is driven by our love for music and podcasting. Today, we are the world\u2019s most popular audio streaming subscription service."
    },
    {
        "position": "Data Engineer (Analytics)",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Kambi",
        "sector": "IT Services and IT Consulting",
        "companySize": "1,001-5,000 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nThe Role\n\nThis position offers a great opportunity for a motivated, creative individual to deliver reporting solutions in a vibrant and growing company. The mission of the Reporting Services team is to optimize Kambi\u2019s Analytics applications and to enable internal and external stakeholders to improve decision-making through access to high quality data and allow Kambi to be on top of all regulatory requirements within sports betting industry. We have several large data assets and are a critical function within Kambi\u2019s mature Data and Analytics departments.\n Our ambition is that you will become an expert in Kambi\u2019s sports betting business, our data assets, the tools and methods we apply for reporting and provide a gateway for stakeholders to make the most out of our data.\n\nResponsibilities\n\n\n\nConvert specifications into business intelligence models and associated reports\nCreate and maintain reporting solutions while documenting the flows\nDesign report layouts and determine the best ways to present them to stakeholders\nWork closely with stakeholders to support their goals and make sure their needs are accurately translated into reporting solutions\nPerform reporting ad-hoc duties in accordance with business needs\n\n\nSkills and Experience:\n\n\n\nMinimum 3 years of work experience in a reporting environment \nVery good knowledge of SQL, Python and working with large data sets\nExperience with at least one BI reporting framework (we use DBT/Looker, but anything relevant will be a good fit: Tableau, Cognos, Micro-strategy, Qlik, SSRS, Power BI, Spotfire, etc.) \nExperience with cloud services and containerized architecture (similar with AWS EKS) and orchestration tools\nCommunication skills and detailed oriented\nConfident communication skills in English\n\n\nThe successful candidate has:\n\n\n\nCreative and experimental mind-set to data technology\nExcellent interpersonal skills and the ability to communicate with both business and technical minded colleagues\nAbility to quickly grasp new concepts and tools\nExcellent attention to details\n\n\nYou'll like Kambi if you:\n\n\n\nThrive in a relaxed and high paced work environment\nDo not need supervision\nAren't afraid to speak your mind\nTake pride in being good at what you do and doing it well\nHave high expectations of yourself and your peers\nThinks business value delivered is what defines great development\n\n\nAll applications will be acknowledged and treated in the strictest of confidence. If you are interested, we'd like you to meet us for a fika! :)\n\nAbout Kambi\n\nKambi Group plc is a leading B2B provider of premium sports betting services to licensed gaming operators. Our services provide an end-to-end solution for operators wanting to launch a standalone Sportsbook or bolster their existing offering with an innovative sports betting product. From front-end user interface to customer intelligence, risk management and odds compiling, all built on our in-house developed software, we strive to deliver the ultimate service and solution to our partners.\n Our vision is to create the world\u2019s leading sports betting experiences, together with our partners.\n With offices in Malta (HQ), Bucharest, London, Manila, Sydney, Uppsala and Stockholm and together with over 1000 passionate and highly skilled people; Kambi live and breathe sports betting. It is in everything we do. From delivering a premium service to our operators, to creating an entertaining experience for the end user; we are unwavering in our mission to create the worlds\u2019 leading sports betting experience."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Etraveli Group",
        "sector": "Technology, Information and\n                                                            Internet",
        "companySize": "1,001-5,000 employees",
        "location": "Gothenburg, Vastra Gotaland County, Sweden",
        "post": "About the job \n\nThe team Data Science and Research (DSR) at Etraveli Group consists of Data Scientists, Machine Learning Engineers, ML Ops Engineers and Data Engineers. The DSR teams get their feet into more business domains and at the same time, they need to maintain, enhance and grow our data architecture together with the increase of traffic. To implement new state-of-the-art data pipelines and consolidate our existing solutions, the team needs an additional member.\n\n\nMain tasks\n\nInterpret and analyse data from various source systems to support machine learning, data integration and data reporting needs.\nDesign, develop and maintain ETL and streaming pipelines according to business and ML solution needs for pricing, conversion and revenue optimization.\nDefine and ensure data quality standards and assist in implementing relevant monitoring solutions.\nAssist in selecting, evaluating and integrating industry leading solutions and tooling that are required within our DE platform, ensuring scalability, performance, maintainability and associated documentation.\nOptimize and create new data pipelines together with Machine Learning Engineers and core engine backend developers.\nWork with internal and external stakeholders to prioritize business and information needs.\nOpportunity to assist in ML Ops engineering and machine learning engineering.\nPlan, communicate and share status updates together with your fellow colleagues and IT Dev developers creating synergies and using best practice.\n\n\n\nLearning curve\nIn this role you will be using the best selection of tools and processes in the DE domain. The role enables you to learn even more about creating, developing and implementing standards for DE applications, and get deep knowledge about DE concepts and frameworks. You will also have the possibility to learn more about (and get hands-on experience of) adjacent fields like Data Science, ML Pipeline Architecture and Platform Engineering.\n\n\nRequirements\nMinimum 2 years of relevant experience in these areas:\n\nDeveloping with Scala or Python and respective build tools\nDeveloping in distributed computing frameworks and massive parallel processing (Spark, Impala)\nData stream transfer and aggregation technologies (Nifi, Sqoop, Flume, Kafka)\nWorking with databases (MySQL, Singlestore or Hive)\nOptimising at SQL queries, report writing and presenting findings\nUsing distributed storage and data layer tools (HDFS, S3).\n\nPlease note that for this position we are not sponsoring relocation. \n\n\nBenefits\nSince we are growing as a company and expecting to treat more customers with a broader range of ML applications in the future we offer an exciting but demanding position to grow in.\nWith us you become part of a tight-knit team of about 110 people in Gothenburg, all of us with different skills and personalities and we believe that it is precisely this that makes us a great team. The ambition however is shared \u2013 we strive for the same goals, are passionate about what we do and work hard at a high pace.\n\nHybrid work environment (3 days working at the office and 2 days working from home) enabling you flexibility.\nOffice in the City \u2013 We are located on Kungsgatan in central Gothenburg, a stone's throw from public transport and lunch restaurants.\nConferences and training \u2013 We believe in personal development and continuous education. As an employee, you receive a generous budget each year to spend at conferences, online courses or other means to learn new things. In addition to this, we continuously organise internal and external training and workshops so that we can learn from each other.\nHealthcare allowance \u2013 Each employee receives a maximum allowable amount each year according to the Swedish Tax Agency to spend on health-promoting activities such as a gym card, massage etc.\nPension and health insurance \u2013 Through partners we offer a comprehensive pension and health insurance so that you can get help quickly in case of an accident.\nHackathon and Dev week \u2013 We believe in fostering creativity and testing new things. Therefore, we have recurring Hacker Fridays, Hackathons and Dev weeks where the teams decide what they want to work on.\n\nIn addition to this we serve you breakfast every morning. Welcome to Etraveli Group!\n\n\nAbout Etraveli Group\nEtraveli Group is a leading global technology provider for Flights focused on offering the best possible flight content delivered through flexible tech solutions. We are the preferred partner of some of the world\u2019s most prominent travel technology companies such as Booking.com & Google Flights. In this context, to deliver on the company's overall mission to make it easier for everyone to experience the world, Booking Holdings recently entered into an agreement to acquire our company. Completion of the acquisition is subject to certain closing conditions, including regulatory approval.\nExciting times ahead, so join us in Gothenburg and become part of the ETG diverse team of 1000+ talented professionals!"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Computer Futures",
        "sector": "IT Services and IT Consulting",
        "companySize": "501-1,000 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nData Engineer \n\n\nOur Stockholm-based client is looking to hire a Data Engineer to be part of their exciting growth journey. \n\n\nThe mission? Help retailers to make better, data-driven decisions in order to save time, become more sustainable and reduce waste! Our client is dedicated to helping organisations with their promotion campaigns by offering them a world class retail analytics platform. Both traditional and online retailers are optimizing their promotions through a solution that is part analytics suite, part planning tool. \n\n\nJoin a Scale-Up company able to offer all the agility and forward thinking of a start-up, with the financial backing and resources of an established organisation. You are someone who thrives on complexity and is not afraid to take on large challenges. You will have the opportunity learn quickly in a smart and supportive team! \n\n\nThe Role\nYou will join the Data Science and Engineering team centred at the core of the organisation. You responsibilities will include: \n\nDesigning, building and testing data models\nContributing to building and enhancing data infrastructure\nTesting ideas and hypotheses\nSupporting and collaborating with the team in order to optimise processes for collecting, testing, and governing data across the data stack.\n\n\n\nIdeally you have\n\nB.Sc. or higher within engineering, statistics or similar.\nProfessional experience in a Data Engineering Role\nYou are comfortable in either Go or Python\nA deep understand of how to maintain a modern data stack\nA deep understanding of advanced data processing pipelines and repositories\nExperience with modern data engineering techniques\nUnderstanding of data modelling techniques and how to use them. \n\n\n\nWhat to expect\n\nCompetitive Salary\nBenefits including pension, wellness allowance, health insurance and more\nFlexible remote work set up\nModern Office in central Stockholm\n\n\n\nInterviews are ongoing so apply today!"
    },
    {
        "position": "Senior Data Engineer - Remote",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Schibsted",
        "sector": "Media Production",
        "companySize": "5,001-10,000 employees",
        "location": "Stockholm City, Stockholm County, Sweden",
        "post": "About the job \n Schibsted is a growing and diverse family of over 50 brands whose mission is to empower people in their daily lives and each brand contributes to it in its own way. Amongst our brands you can find leading Nordic marketplaces like Finn and Blocket, world-class media houses like VG and Aftonbladet (we are the largest media group in Scandinavia) and other rapidly developing digital companies like Prisjakt, Lendo and many others.\n Data Foundations is a central department within Schibsted that is responsible for the data platform and is working on data fueled products with emphasis on volume, velocity and privacy. We are building products at scale, serving the whole of Schibsted and its brands.\n Our team within Data Foundations is responsible for development and maintenance of the segmentation platform, which supports online advertising, personalization and analytics use-cases across the whole company.\n\nWhom are we looking for?\n\nWe are looking for an experienced Data Engineer, who is independent, goal oriented and loves working with Big Data. We practice a product-oriented mindset, so engineers work together with the product management team to find the best solutions to meet our customers' needs. You also will be responsible for designing and building platform functionality as a part of a team within Data Foundations.\n\nGood examples of such functionality would be:\n\n\n\nImplementation of new segmentation criteria\nEnsure compliance with data governance, security policies and privacy laws in all parts of the processing pipeline\nMonitoring and optimisation of processing pipelines\nAdding new ways to integrate with consumers and carrying out a migration\n\n\nWhat is our technology stack?\n\n\n\nPython and Spark for data processing, Luigi for data orchestration\nScala and Finatra for backend services\nDocker and Kubernetes as a main platform for both processing and services\nAWS for storage and other infrastructure (S3, RDS, SQS, Cloudformation,\u2026)\n\n\nRequirements\n\n\n\nA Bachelor\u2019s degree in Computer Science, Informatics or relevant work experience\nKnowledge and hands-on experience with Python and Spark\nExperience with Scala or other JVM languages , ability to get up to speed with Scala is expected\nFamiliarity with Kubernetes, orchestration frameworks (Airflow / Luigi), DevOps, CI/CD, cloud solutions (AWS / Azure / Google Cloud), container-based workflows or distributed systems are all regarded as positive.\n\n\nAs a part of Schibsted, you will also have the opportunity to share knowledge and learn from other data engineers across the organisation. We encourage a diverse, collaborative and creative work environment, where you will develop and push for state-of-the-art solutions in big data processing as well as building reliable and highly scalable services.\n\nA little peek at what we offer\n\n\n\nOpportunity to work remotely from Europe (the team is based in Norway, Sweden, and Poland)\nInternal career growth opportunities\nFlexibility of working from home\nExcellent work equipment of choice at home and at the office \nCentral office locations\nOpportunity for development of competencies, conferences and various knowledge sharing events such as hackathons, innovation days, etc.\n2 lab days every month to explore new technologies and development ideas connected to our work\nOpportunity to take on various learning courses and classes through our Schibsted Learning Lab and LinkedIn Learning\nPension scheme\nSchibsted share saving and matching plans\nWellness programs (e.g. running, yoga, classes with a coach...etc.)\n\n\nOur Interview process\n\n\n\nRecruiter screening (30 min) : An initial call with a talent acquisition partner. We\u2019ll tell you a bit about us, answer any questions you may have, learn about your background and what you\u2019re looking to do\nHome assessment and code review OR live coding interview (60 min) : Done in Python/Java/Scala a take-home exercise with follow-up discussion where you meet two of our engineers or a live refactoring coding interview\nSystem design interview (60 min): System Design interview and potentially some computer science fundamentals discussions with two engineers\nValues interview (30 min): meeting the Engineering Manager and Product Manager of the team for a short discussion\nOffer extended! If you are interested in talking to more potential coworkers or have additional questions, we will also arrange any additional chats for you\n\n\ntag:"
    },
    {
        "position": "Data Architect",
        "jobType": "Contract",
        "jobLevel": "",
        "company": "LTI - Larsen & Toubro Infotech",
        "sector": "IT Services and IT Consulting",
        "companySize": "10,001+ employees",
        "location": "S\u00f6dert\u00e4lje, Stockholm County, Sweden",
        "post": "About the job \n\nA little about us ...\n\n\nL&T Infotech is one of the largest global technology consulting and digital solutions company - holding an annual revenue of $ 1.4 bn. We were founded 20 years ago as the information technology arm of the Larsen & Toubro group. We are currently partnered with more than 350 clients (66 of which are Fortune 500 companies). We operate in 30 countries - employing over 50,000 employees world-wide!\n\n\n\u00b7 We lead in providing the best experiences for our clients and their customers.\n\u00b7 We provide our employees with a learning environment that promotes growth and creativity.\n\n\nTo learn more please visit us at www.lntinfotech.com and or follow us on Twitter @LTI_Global.\n\n\nWe are looking for a Data Architect having a good experience in the following technology areas. \n\n\n\n8+ years of enterprise data architecture experience\nMust have very strong SQL experience\nData modelling skills on relational databases especially for data warehousing.\nMust have implemented at least 3 end to end data warehouses. Must have strong ETL tool working experience.\nGood to have experience in working within the AWS ecosystem & Snowflake\nStrong project management, communication, and data analysis skills\n\n\n\nWhat we have to Offer:\n\n\n\nA challenging function with possibilities to grow in a leading organization who has proved themselves in process optimization and information technology.\nPrivate Insurance\nGood secondary benefits & Online trainings to expand your knowledge.\nCompetitive market salary based on professional experience and skills"
    },
    {
        "position": "Growth Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Epidemic Sound",
        "sector": "Musicians",
        "companySize": "201-500 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nAt Epidemic Sound we are reinventing the music industry. Our carefully curated catalog, with over 35,000 tracks, is tailored for storytellers, streaming services, and in-store soundtracks. Countless clients around the world, from broadcasters, production companies, DSPs, and YouTubers rely on our tracks to help them tell their stories. Epidemic Sound\u2019s music is heard in hundreds of millions of online videos daily, across millions of playlist streams, and in thousands of in-store locations. Headquartered in Stockholm, we\u2019re spread across offices in New York City, Los Angeles, Seoul, Hamburg, and Amsterdam. We\u2019re growing fast, have lots of fun, and are taking the music industry with us.\n\n\nAre you an experienced data engineer with entrepreneurial ambitions? Do you listen to startup podcasts like Indie Hackers, a16z or Acquired? If so, this may be the perfect opportunity for you, because we are looking for Python, JavaScript, and full-stack engineers who are passionate about technology and business to help us accelerate Epidemic Sound\u2019s growth.\n\n\nThe Marketing Technology team is focused on building the best-in-class platform to enable marketing at Epidemic Sound. We build marketing automation tools and systems that are used by our stakeholders in Marketing (Performance and Email Marketing). We\u2019re looking for an experienced engineer who can lead efforts to build a scalable marketing platform that enables delivering personalized content to Epidemic Sound users off-site such as SEM, display and video ads automation, email and push notifications. The team also covers areas such as privacy law compliance, email marketing infrastructure, tracking and analytics, and more.\n\n\nHow you will make an impact;\n\n\n\nYou will be joining an organization with passionate data engineers, data analysts and software engineers. This is a chance to be part of architecting, designing and building a marketing technology and data platform and toolbox that scales worldwide.\nYou will be setting up and/or building analytics tools, both through internally developed software and on Google Cloud Platform.\nYou will be working with business stakeholders, marketing experts and data analysts to design data models to quantitatively support everything from corporate strategy to user acquisition.\nYou will be partnering with the data engineering team as well as product development teams to build the infrastructure and tracking needed to provide data analysis and insights tools. \nBuild next gen marketing technology tools and services\nDesign and drive new integrations across other Epidemic Sound teams\nYou will have the opportunity to work on the mission critical marketing and technology initiatives behind Epidemic Sound traffic, conversion and analytics efforts.\n\n\n\nWho you are;\n\n\nWe think you are a Data Engineer or a Backend Engineer with a passion for data and analytics. You love collaboration and teamwork in agile environments. You are curious and eager to learn and you thrive when you get to share your knowledge with others. Inclusion is key to us, and you share that notion and actively work towards building and nurturing an inclusive culture.\n\n\nSome of the abilities and skills which will help you in this role are;\n\n\n\nExperience working as a data engineer, building data flows and data pipelines\nExperience working with the Google Cloud Platform, dbt, Airflow, etc\nKnowledge of at least one programming language, ideally Python \nHave worked with REST APIs, and you're strong on standard methodologies for security and performance.\nStrong interpersonal and communication skills. You are highly collaborative, you love participating in code reviews, and you enjoy upbeat discussions about architecture, design, and user experience. You're also comfortable working with others who are not engineers.\nExperience from agile methodologies and environments\nInterest in actively contributing to the team\u2019s technical strategy and roadmap\nYou know how to break big problems down into smaller pieces. You thrive on moving items to the Done column at a healthy pace\nLove to experiment and tackle problems. You\u2019re product-minded and growth-focused. You\u2019re happy to question assumptions and back your recommendations with data.\nInterest in supporting and mentoring other team members, for example by sharing your knowledge\nPrior marketing and business experience is not required, but you should be excited to learn the art and science of growing the business.\n\n\n\nCurious to learn more about who we are and what we do? Check out our brand new \"About us\" page \u2192 https://www.epidemicsound.com/about-us/ \n\n\nWe have lots of fun soundtracking the world and our annual Spring Bash is an event that captures this perfectly. Take a look at our most recent one, a virtual celebration!\nApplication\nDo you want to be a part of our fantastic team? Please apply, in English, by clicking the link.\n\n\nWe believe that bringing people together from different backgrounds, experiences and perspectives makes for a healthy workplace, a more successful business and a better world. We value diversity and encourage everyone to come and soundtrack the world with us."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Volvo Cars",
        "sector": "Motor Vehicle Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nWe\u2019re creating our own future \n\nAt Volvo Cars, we are making bold digital visions come true. We aim to be the leader in the automotive world by creating a digital ecosystem built around making our customers' lives less complicated. What we all have in common at Volvo Cars is our passion for protecting lives, our endless curiosity, and our dedication to create a new future for the automotive industry. Our human centric focus is what separates us from all other car companies.\n Would you like to influence and craft the technical strategy that helps Volvo Cars to grow and reach our goal of being an electric car company by 2030? Excellent, then we would like you to join our Cluster as Data Engineer!\n The Data & Identity Cluster is a part of the Global Online Experience (GOX) area and our mission is to ensure we know our customers well and keep this information safe and secure. We support the rest of the organisation in using this knowledge to serve the customers in the best possible way. We\u2019re looking for someone that will help us craft a world class data ecosystem that spans across multiple product teams and clusters. We have only just begun this journey in earnest, and you\u2019ll be joining us at a time where you can really have a great impact and help us set the tone for the next chapter in our company's history!\n\nWhat you\u2019ll do: \n\nAs an early joiner in a new team within a highly prioritized area you will play a key role in setting technical direction and building a world-class data architecture based on Data Mesh principlesWork in a multi-functional agile team to continuously experiment, iterate and deliver on product objectivesLeverage our large and diverse datasets to enable use cases with direct impact on the end-customer's digital experienceWork with state-of-the-art data processing frameworks, technologies, and cloud platformsDevelop in different technologies and languages ranging from Java and Scala to Python and SQLHelp drive optimization, testing, and tooling to improve data qualityIncrease developer productivity by building innovative tools that reduce maintenance overhead of working with data pipelines and help increase platform reliabilityBe an active member of the Engineering community and collaborate with other Engineers across the clusterAdvocate and advance modern, agile software development and help develop and foster good engineering practicesHelp ensure the solutions are scalable, sustainable, architecturally sound, and technical debt is both incurred consciously and repaid in a reasonable timeDemonstrate and champion an appetite for knowledge and never stop developing as a Data Engineer\n\nWho you are: \n\nYou are deeply knowledgeable and passionate about modern data architecture principlesYou have extensive experience working hands-on as a Data Engineer developing large scale data solutions in an agile environmentYou know and care about sound engineering practices like continuous delivery, defensive programming, and automated testingYou are comfortable working both independently and collaboratively (pairing and mobbing)You are pragmatic and understand the trade-offs between the perfect solution and a working solutionYou care about and have experience with agile software processes, data-driven development, reliability, and responsible experimentationYou are passionate about crafting clean code and have a steady foundation in coding and building data pipelinesYou are knowledgeable about data modelling, data access, and data storage techniquesYou have worked with cloud technologies (we use AWS and Azure) You are well versed in the SQL language and databasesYou know how to write distributed, high-volume services in Java or ScalaYou understand the value of collaboration and partnership within a teamYou like to have fun at work and take great care in making sure everyone always feels welcome and included!You fully embrace a growth mindset, and encourage others to do the sameYou are a self-motivated individual contributor and great teammate with the ability to multitask, prioritize and communicate progress in a rapidly changing environment\n\nWe offer our employees excellent benefits such as: \n\nPlenty of leave to let you take time off for what's most important in lifeCollective Agreement and ITP pensionsAn annual allowance to spend on your health and wellbeing\n\nWho are we?\n\nEverything we do starts with people. Our purpose is to provide freedom to move, in a personal, sustainable and safe way. We are committed to simplifying our customers\u2019 lives by offering better technology solutions that improve their impact on the world and bringing the most advanced mobility innovations to protect them, their loved ones and the people around them.\n Volvo Cars\u2019 continued success is the result of a collaborative, diverse, and inclusive working environment. The people of Volvo Cars are committed to making a difference in our world. Today, we are one of the most well-known and respected car brands, with over 40,000 employees across the globe. We believe in bringing out the best in each other and harnessing the true power of people. At Volvo Cars your career is designed around your talents and aspirations so you can reach your full potential. Join us on a journey of a lifetime as we create safety, autonomous driving and electrification technologies of tomorrow."
    },
    {
        "position": "ML Ops Engineer",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Tele2",
        "sector": "Telecommunications",
        "companySize": "5,001-10,000 employees",
        "location": "Stockholm City, Stockholm County, Sweden",
        "post": "About the job \n\nWe are looking for a passionate, self-reliant and skilled ML Ops Engineer with an open can-do attitude to join us on our journey to automate and personalize Tele2\u2019s customer interactions. We are working in Tele2\u2019s social and collaborative workspace in Kista \u2013 when not working from home\u2026\n\nJob description:\n\nAs an ML Ops Engineer you will be working closely with our data scientists in operationalizing predictive models and building a robust environment for development, serving, retraining and model management. Our final deliveries are AI products generating scores daily, consumed by third-party systems (such as marketing automation systems, call center systems etc.)\n We run on the belief that decisions are best made by the team members holding the most information, rather than managers or individual solution architects. As such we aim to maximize transparency across all hierarchy levels and in turn expect team members to assume high levels of responsibility for our shared deliveries and architecture.\n You would join a team with seriously talented, experienced, and fun individuals, diverse both in terms of gender, culture, and background. All with their own perspectives and valuable input. Now we want yours as well.\n\nKey responsibilities include:\n\n\nDevelop and maintain our production framework, utilizing and developing tools handling massive data volumes on AWS\nImprove and support the data science development environment \nKeep improving our model monitoring solution\nSupport productionization of new ML products\nAny other potential improvements to the team\u2019s products, tools and ways of working\n\nRequirements:\n\n\nStrong team player\nCurious to learn what you don\u2019t know and eager to share what you do know\n5+ years in practical software development outside of academia \n1+ year of experience of data software development/data engineering\nEmbracing Agile\nBig Data principles\nDevOps\nCI/CD and IaC\nExperience of working with cloud-based infrastructure\nProficient in at least one object-oriented programming language, e.g. Python\nSQL\n\nConsidered as merits:\n\n\nExposure to ML development, MLOps and any work alongside data scientists\nComfortable with both structured and unstructured data\nAWS stack\nExperience of or certificates in agile specific roles, e.g. Scrum master\nDW and Data Lake experience\nDocker & Kubernetes\nAirflow or other orchestration tool\n\nCome join us if you are interested in working in a diverse team where focus lies on the team effort, and with deliveries that truly have an impact on business and our customers.\n\nCome join us if you want to work in a fast-paced environment, in a department that values both professional and personal development and performance, while at the same time cherishes a fun and stimulating work environment and work-life balance.\n\nWhat Tele2 can give you:\n\nWorking at Tele2 you will work in a creative and flexible work environment. You will be a part of culture where teamwork and inclusion are leading the way forward. Every employee is important for the company\u2019s success and you will always have an impact of your work. We provide you with the opportunity to grow and develop through internal paths within the organization.\n\nThe position is located in our headquarter in Kista, Stockholm. We want to create an inclusive culture where all forms of diversity are seen. At Tele2, we aim to build an inclusive company in a diverse world"
    },
    {
        "position": "Machine Learning Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "AB Trav och Galopp",
        "sector": "Gambling Facilities and Casinos",
        "companySize": "201-500 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nF\u00f6r ATG \u00e4r medarbetarna v\u00e5r allra viktigaste tillg\u00e5ng. V\u00e5r ambition \u00e4r att vara en av Sveriges mest attraktiva arbetsgivare. Vi arbetar aktivt med v\u00e5r f\u00f6retagskultur och v\u00e4rdegrund i en inspirerande och engagerande arbetsmilj\u00f6. Vi tror p\u00e5 h\u00e5llbara och friska medarbetare och har en heltidsanst\u00e4lld H\u00e4lsocoach, eget modernt gym med m\u00f6jlighet att tr\u00e4na under arbetsdagen. Vi har flexibel arbetsplats och molnbaserade arbetsverktyg som m\u00f6jligg\u00f6r b\u00e4ttre samarbeten mellan avdelningar.\n\n\nMachine Learning Engineer\n\n\nHar du ett brinnande intresse f\u00f6r matematik och AI och vill du h\u00e4nga med p\u00e5 resan mot att leverera v\u00e4rldens b\u00e4sta spelupplevelse? S\u00f6k d\u00e5 denna tj\u00e4nst!\n\n\nOm rollen\nSom Machine Learning Engineer kommer du att ing\u00e5 i ett team best\u00e5ende av fem mycket talangfulla, rutinerade och engagerade medarbetare f\u00f6r att l\u00f6sa utmanande problem inom v\u00e5r avdelning Commercial och jobba med den kommersiella aff\u00e4ren. Du kommer arbeta i n\u00e4ra samarbete med v\u00e5r Digitals Technical Manager, Data Scientist, Head of Digital, Horse Betting- och Sportteamet samt delar av Analysis-avdelningen och delar av IT-avdelningen. Du ska vilja bidra med din spetskompetens inom maskininl\u00e4rning och AI genom att bland annat programmera maskininl\u00e4rningsmodeller, ta fram beslutsunderlag och programmera prototyper. Du kommer \u00e4ven att delta i olika utvecklingsprojekt och arbetsgrupper och driva projekten p\u00e5 uppdrag av v\u00e5ra aff\u00e4rsomr\u00e5den inom h\u00e4st, sport och casino.\n\n\nVem \u00e4r du?\nVi tror att du \u00e4r en nyfiken person och har koll p\u00e5 vad som h\u00e4nder i Big Data-v\u00e4rlden. Du \u00e4r inte r\u00e4dd f\u00f6r f\u00f6r\u00e4ndringar utan snarare ser du det som inspirerande och en drivkraft i ditt arbete. Du har en relevant eftergymnasial utbildning med fokus p\u00e5 matematik, exempelvis inom till\u00e4mpad matematik eller teknisk fysik, och har n\u00e5gra \u00e5rs erfarenhet av att jobba som Data scientist eller med en liknande roll inom maskininl\u00e4rning. F\u00f6r att lyckas i denna roll b\u00f6r du ha goda kunskaper inom matematik, programmering och erfarenhet av AI/neutrala n\u00e4tverk samt programmering med Python och/eller Java. \n\n\nSom person \u00e4r du positiv, driven, initiativtagande och probleml\u00f6sande. Du har en ambition att utvecklas liksom ett m\u00e5l- och resultatinriktat arbetss\u00e4tt. Arbetet st\u00e4ller h\u00f6ga krav p\u00e5 din f\u00f6rm\u00e5ga att samarbeta men ocks\u00e5 att kunna arbeta sj\u00e4lvst\u00e4ndigt. Eftersom du kommer arbeta verksamhetsn\u00e4ra- \u00e4r det viktigt att du har en f\u00f6rm\u00e5ga att skapa l\u00e5ngsiktiga relationer och \u00e4r lyh\u00f6rd. Du tycker om att ta en ledande roll att styra teamet fram\u00e5t f\u00f6r att l\u00f6sa problem, och \u00e4r en sann teamplayer med god kommunikationsf\u00f6rm\u00e5ga som tycker om att samarbeta samtidigt som att du har en f\u00f6rm\u00e5ga att ta ett starkt \u00e4garskap \u00f6ver dina arbetsuppgifter.\n\n\nOm mig \u2013 rekryterande chef Jesper Komstadius, Manager Product & Business Development\nJag brinner f\u00f6r att utveckla produkter och skapa tillv\u00e4xt. F\u00f6r att lyckas med det beh\u00f6ver vi starka team med tydligt \u00e4garskap. Vi har ett grymt g\u00e4ng med stort engagemang och massor av kompetens. Och vi har bara b\u00f6rjat!\n\n\n\u00d6vrigt:\nTj\u00e4nsten \u00e4r p\u00e5 heltid och utg\u00e5r fr\u00e5n v\u00e5rt kontor vid Solvalla. ATG har en fortsatt flexibel arbetsplats d\u00e4r du beroende p\u00e5 roll har m\u00f6jlighet att kombinera hemarbete med arbete fr\u00e5n kontoret. Vi till\u00e4mpar sex m\u00e5naders provanst\u00e4llning f\u00f6r alla tj\u00e4nster. Har du n\u00e5gra fr\u00e5gor kontakta ansvarig rekryterare Maja Brodin, maja.brodin@atg.se. \n\n\nVi jobbar med l\u00f6pande urval i rekryteringen och behandlar ans\u00f6kningar l\u00f6pande efter ans\u00f6kningsdatum, v\u00e4nta d\u00e4rf\u00f6r inte med din ans\u00f6kan. Vi tar inte emot ans\u00f6kningar via mejl utan ber dig att s\u00f6ka via v\u00e5r rekryteringsportal.\n\n\nOm ATGI \u00f6ver 45 \u00e5r har ATG verkat i h\u00e4stsportens tj\u00e4nst, d\u00e4r hela v\u00e5rt \u00f6verskott g\u00e5tt tillbaka till v\u00e5ra \u00e4gare, den svenska trav- och galoppsporten \u2013 det t\u00e4nker vi forts\u00e4tta med. P\u00e5 den nya spelmarknaden ska ATG fortsatt vara h\u00e4stn\u00e4ringens motor och verka f\u00f6r en spelbransch som m\u00e5r b\u00e4ttre imorgon \u00e4n idag. Spelansvaret \u00e4r, och f\u00f6rblir, v\u00e5r absolut viktigaste h\u00e5llbarhetsfr\u00e5ga. V\u00e5rt kundl\u00f6fte \u00e4r att erbjuda v\u00e5ra kunder sp\u00e4nnande spelupplevelser p\u00e5 ett schysst och smidigt s\u00e4tt. I dag \u00e4r vi n\u00e4rmare 450 personer som arbetar p\u00e5 ATG och vi beh\u00f6ver bli fler. F\u00f6rutom en inspirerande och engagerande arbetsmilj\u00f6 erbjuder vi en heltidsanst\u00e4lld f\u00f6retagstr\u00e4nare, eget modernt gym med m\u00f6jlighet att tr\u00e4na under arbetsdagen, och flexibla arbetstider."
    },
    {
        "position": "Data Analyst - Healthtech",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Platform24",
        "sector": "Hospitals and Health Care",
        "companySize": "51-200 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\n\n\n\n\n This job is sourced from a job board. Learn more\n\n About Platform24 Platform24 is a leading B2B health tech company in Europe, yet just at the beginning of our journey. By combining intelligent automation with deep medical knowledge, we build a platform that radically improves how healthcare is accessed and delivered. We are revolutionizing how healthcare is done in public and private healthcare with strong growth and presence across several European markets. We have an uncompromising focus on making every day better for both patients and clinicians and together create healthcare 2.0. Joining our team as a Data Analyst means\u2026 That you will have a key role in one of the most interesting health-tech startups. You will also have a significant impact and be part of shaping what tomorrow's healthcare looks like. The core part of our product is produced by our doctors in the Medical Content team. With medical expertise and the technology created by our engineers, we are able to improve the quality and efficiency of healthcare significantly on a large scale. You will work closely with our Medical Content team to draw insights from the data generated within the platform and create insights the team can act upon. The role also includes educational initiatives to make the team more self-sufficient in analysis. Your first mission will be connected to the Medical Content team, but we see great possibilities to develop and work together with other product teams. This is a significant opportunity to have a big impact on our product. Besides being part of product teams, you will also be part of the data team that stretches throughout the company. We see this team as the main driving force for data democratization and for creating informative ways of working at the company. The team consists of individuals with different areas of expertise, such as Data Analysts, Data Engineers, and Data Scientists. To succeed in this role, we believe you have:\n\n\nProfessional experience in analyzing large datasets to extract valuable insights that drive decision-making.\nStrong communication skills. You will interact with stakeholders within the organization to understand their needs, communicate the insights you create and also enable users to do their own analysis.\nExperience creating visualizations in BI-Tools such as Metabase, QlikView, Tableau, Looker, Superset, or similar. We currently use Metabase.\nStrong skills with relational databases and SQL.\nExperience with programming for analysis and creating data pipelines, e.g. with Python.\nComfortable working with version control and CI/CD.\nIt is a plus if you know statistics, at the very least you are comfortable with correlation vs causation conversions and good at thinking about which \"lurking variables\" could explain strange results.\nFluent communication in Swedish & English, written and spoken. What's in it for you At Platform24 we recognize that we all have different needs for planning our lives. That is why we believe in flexible working hours to ensure work-life balance for everyone. Every other week we have Demo & Beers, where we share our accomplishments (beers optional :). We offer personal growth and knowledge-sharing sessions regularly, and on top of lots of other nice benefits such as office snacks and parties, we provide you the opportunity to use five work days a year to do voluntary work helping others. Besides this, you will get the chance to work with intelligent, friendly, and skilled colleagues from all over the world.\nThis position is located in our Stockholm office.\nAs we interview candidates continuously, we kindly ask you to apply as soon as possible."
    },
    {
        "position": "Data Engineer to Financial Crime Prevention",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "SEB",
        "sector": "Banking",
        "companySize": "10,001+ employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n SEB is a leading northern European financial services group, and at the same time, one of the largest IT employers in the Nordics. Banking is changing rapidly, and we are proud of our reputation for being entrepreneurial and innovative in the face of change. Our brilliant techies work hard to future proof SEB\u2019s digital architecture and customer products because it genuinely makes a huge impact for our customers and colleagues. Would you like to work in a team of data engineering experts responsible for delivering large-scale Big Data solution for SEB? We are a now looking for a skilled Data Engineer to join our team working with our growing area Financial Crime Prevention (FCP).\nWhat You Will Be Doing\n\nAs Data Engineer in the Financial Crime Prevention team you will combat fraud against our customers and protecting the bank from money laundering, this is central not only to SEB but for society as such. You will work in an environment with multiple Agile teams located in both Stockholm and Riga.\nYou will be responsible for developing and maintaining new technical capabilities in a smart way to allow us to detect bad actors. Our technical environment consists of but is not limited to Java, Scala, Python, Hadoop, Kafka, NiFi, Spark, Grafana and Elastic Search. Here you will have a chance to make a difference and work with challenging tasks. You will have great opportunities to both develop and take further steps in your career working within a highly collaborative environment.\nWho We Are Looking For\n\nTo succeed in your role with us you should really love solving engineering problems and have the following experiences/ mindset.\n\nExtensive experience in Java programming languageExperience with Scala, Hadoop, Kafka, SparkExperience in Jenkins, Tekton, OpenShift and Kubernetes is considered an advantage.Analytical mindset and ability to solve complex technical problemsPassion for challenges that drive your personal development and professional growthBeing a team player open for growth and learning is crucially important for the role\n\n\nWhat We Offer\n\nWe offer many experiences and benefits to our employees, and there is nuance to every individual\u2019s career experience, but the elements that define the core of our offering are:\n\nExtensive training and learning opportunitiesWork-life balanceInternational opportunities and working environmentAccess to SEB staff banking with exclusive benefitsInnovative company in forefront of technologyChallenging, cutting-edge workOpportunities to help transform an industryExcellent office environment\n\n\nLearn more about working at SEB www.sebgroup.com/career \n\nI t is our fundamental belief that inclusion and diversity is crucial for our future success. We strive to have an inclusive, value-driven culture where employees feel valued, respected and involved irrespective of who they are, what they believe or where they come from. \nReady to join?\n\nFeel free to send in your application today, but no later than 2022-09-29. If you have questions about the position please contact Katarina Pihl, Talent Acquisition partner by mail katarina.pihl@seb.se. \nWelcome to a community of tech-savvy and passionate employees from all corners of the world. SEB is in fact one of the largest IT employers in the Nordics. Together we future proof a world of financial flows by exploring and implementing modern digital architecture and state-of-the-art technology. We are driven by collaboration, insight, and friendship. But also, a desire to change and improve. All in all, it creates a balance - where life and a stable yet exciting job can co-exist. If you want to shape tomorrow's bank - continue reading and apply today.\n\nRead more:sebgroup.com/techcareers"
    },
    {
        "position": "Data Scientist - QuantumBlack",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "QuantumBlack, AI by McKinsey",
        "sector": "IT Services and IT Consulting",
        "companySize": "1,001-5,000 employees",
        "location": "Stockholm City, Stockholm County, Sweden",
        "post": "About the job \n\nQualifications\n\n\nDegree in a computer science, machine learning, applied statistics, mathematics or engineering\nBusiness level fluency in the local language and English (verbal and written) mandatory\nAbility to write clean, maintainable, and robust code in Python \nAdvanced knowledge of SQL required\nGood presentation and communication skills with the ability to explain complex analytical concepts to people from other fields \nMethodical yet creative problem solver \nExperience in applying data science and machine learning methods to real world problems\n\nWhat You'll Do\n\nAs a data scientist at QuantumBlack, you will work in multi-disciplinary environments harnessing data to provide real-world impact for organisations globally. You will influence many of the recommendations our clients need to positively change their businesses and enhance performance.\n\nRole Responsibilities\n\n\nWork on complex and extremely varied data sets from some of the world\u2019s largest organisations to solve real world problems\nDevelop data science products and solutions for clients as well as for our data science team\nWrite highly optimized code to advance our internal Data Science Toolbox\nWork in a multi-disciplinary environment with specialists in machine learning, engineering and design\nFocus on modelling by working alongside the Data Engineering team\nAdd real-world impact to your academic expertise, as you are encouraged to write papers and present at meetings and conferences should you wish\n\nOur tech stack\n\nWhile we advocate for using the right tech for the right task, we often leverage the following technologies Python, PySpark, SQL, Airflow, Databricks, Kedro (an OSS developed by QuantumBlack), container technologies such as Docker and Kubernetes, cloud solutions such as AWS, GCP or Azure, and more!\n\nWho You'll Work With\n\nYou will join our Copenhagen, Oslo or Stockholm office. As a data scientist at QuantumBlack, you will work with other data scientists, data engineers, designers and strategy consultants on interdisciplinary projects, using maths, statistics and machine learning to derive structure and knowledge from raw data across various industry sectors.\n You'll work hands in hands with our clients, from data owners and users to C-level executives."
    },
    {
        "position": "Junior Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "BITEQ Denmark A/S",
        "sector": "IT Services and IT Consulting",
        "companySize": "11-50 employees",
        "location": "Gothenburg, Vastra Gotaland County, Sweden",
        "post": "About the job \n\nYour new company\nBITEQ is a subsidiary of Pedab Group and aims to deliver the best and most relevant Data & Analytics solutions, offering both consulting and managed services. The services are based on a subscription model, targeting companies with about 100-1000 employees. The company instills trust in their customers in order to cooperate with BITEQ, rather than them \u201cjust\u201d delivering a solution. To be trusted to take over the client\u2019s analytics services \u201cas a service\u201d, BITEQ expects that solid consulting services will be the way through. As an analytics pure player within Data & Analytics, they offer one of the market's best competencies, advising on how to build and modernize platforms and give security and insight. Their managed service concept \u201cBITEQ Data & Analytics\u201d has two components: 1. BITEQ Team \u2013 The customer gets a 100% tailor-made team, where they get access to BITEQ's full competence profile; 2. BITEQ Platform \u2013 The customer gets a full Data & Analytics platform, up to 100% hands-off, so they can focus all their efforts on developing business. Currently, BITEQ is initially focusing on business in Denmark and will expand their business to the Nordic countries, the Baltics and France.\n\n\nYour new role\nAs Junior Data Engineer, you will help shape the new Azure cloud and Analytics platform, since BITEQ is planning to grow exponentially already within this and next year. You will be responsible for helping build, develop, and implement the data platform for and at customers. In doing so, the following falls under your responsibility:\n\nDeveloping client data platforms (Data Warehouse, Data Lakes etc.)\nMaking sure that master data and data quality is of necessary standard\nDesigning, modeling and integrating data from various sources \u2013 both structured and unstructured\nWorking with ETL, ELT, optimization, and real time processes \nSupporting and enabling the analytics department\nEngaging with \u201cexternal\u201d data and IoT\nSupporting the go-to-market, sales, and proposal activities\n\n\n\nWhat you\u2019ll need to succeed\nThe position requires a person that might have a relevant degree within IT, Data Science, Computer Science or any related field. Alternatively, you are knowledgeable and passionate about data and analytics within a professional service firm, and you have an understanding of the importance of the elements of the Data Platforms for business stakeholders. You have an understanding of working with solutions based on Microsoft Azure data stack or on-prem platforms (but with the desire to learn about the cloud implementations of these). Furthermore, you are familiar with SQL, data storage (Data Lake, Data Warehouse, etc.) and data modelling tools & techniques (conceptual, logical and physical). Additionally, it would be beneficial to have knowledge of or experience with:\n\nAWS, Google etc.\nAzure DevOps (Or Jira or similar systems) & CI/ CD\nPowerShell\nC#, Python, R\n\n\n\nThe right candidate for this position has the ability to build trust in relations to clients and to build strong relationships on a cross-functional basis at all levels within the business, as well as with customers and other external stakeholders. You have a business minded attitude towards work and excellent communication and team-working skills. As a person, you are a self-starter who is comfortable working with little direction or oversight \u2013 thus, having the ability to prioritize your own workload and responsibilities. You set high personal goals and pursue them with tenacity. Furthermore, you are enthusiastic, proactive, and outgoing as well as committed.\n\n\nWhat you\u2019ll get in return\nThis is a unique opportunity to join a new company which is growing out of Pedab Group\u2019s unique network of clients. Here you will truly have the opportunity to add your personal touch, influence the development and growth of the business and shape the future of BITEQ. You will have the opportunity to develop personally and professionally with the plan of developing towards managing your own clients and offerings. You will be part of a flat organization with little hierarchy and bureaucratic rules. A strong entrepreneurial spirit and empathy is visible between colleagues and towards customers, including a decent and honest tone. At BITEQ, they truly believe their people are the heartbeat of their success. BITEQ considers their employees as family that is taking care of each other. The motto is working as a team, being better together. The culture allows one to be oneself, adding a great emotional value. Next to the efforts towards successful business without pressure and the proximity to clients and projects, the focus is on fun and work-life balance.\n\n\nWhat you need to do now\nIf you are interested in this role, please apply with your CV and cover letter. In case you have any questions, you can contact Researcher Joachim Harders (joachim.harders@hays.dk)."
    },
    {
        "position": "Data Engineer",
        "jobType": "Contract",
        "jobLevel": "Mid-Senior level",
        "company": "BlueLabs",
        "sector": "IT Services and IT Consulting",
        "companySize": "11-50 employees",
        "location": "European Union",
        "post": "About the job \n\nWe're now looking for a Data Engineer to join our Data Team. The team covers a wide range of skills to drive data-related initiatives and impact different parts of the organization. Our aim is to provide a solid data platform, discover insights, promote data-driven decisions, and collaborate with other teams to optimize, innovate, and enhance our services. The team's mission is to provide an ecosystem where data is transmitted, stored, processed, and analyzed in a fast, stable, reliable, and secure way. By applying data science on top of the gathered data and with ML-powered applications we want to give our company a competitive advantage.\n\n\nResponsibilities\n\nIdentifying problems, designing solutions, implementing them, performing code reviews, and maintaining services in the production environment \nCareful modeling of the data storage layer, ensuring reliable and swift message transfer, building high-performance data pipelines, and supporting Analytics and Data Science flows \nApplying simple and effective solutions, and a \u201cgetting things done\u201d mentality\n\nHowever, that's not all! At BlueLabs, we encourage you to contribute wherever your interests take you \u2014 and shape your role and our product accordingly.\n\n\n\n\nCompensation\n\n\nThe compensation range for this role is \u20ac50,000 to \u20ac80,000 annually, depending on your skills and experience. We encourage you to read our Recruitment FAQs for further details. In addition to the monetary compensation, we provide several perks, including a shiny new MacBook 16\" M1 Pro or Linux laptop.\n\n\nJob requirements\n\nBS degree in Computer Science or similar technical field\n2+ years of professional software engineering experience\n1+ years of experience working with relational databases (Postgres, MariaDB, Oracle) and writing complex SQL queries\nDeep understanding of modern back-end systems, microservices, message-driven architecture, distributed systems, and replication\nBackground in building data transformation pipelines - knowledge of DBT is highly appreciated\nUnderstanding of data streaming concepts and technologies such as Kafka, Pulsar, and RabbitMQ\nFamiliarity with Agile methodology, containerization, continuous integration/deployment, cloud environment, and monitoring\nAbility to write clean, efficient, maintainable, and well-tested code; Golang/Java/Python skills are a big plus\nAnalytical thinking, troubleshooting skills, and attention to detail\nGood communication skills in verbal and written English.\n\n\n\nNice to have\n\nExperience with Data Warehouses (BigQuery, Snowflake, SingleStore), Data Lakes, NoSQL, Stream Processing (Apache Beam, Flink), Workflow Management Tools (Prefect, Airflow, Argo), BI Tools (Looker), or other Big Data solutions are highly appreciated\nKnowledge of Terraform/IaC and Kubernetes\nExperience setting up dashboards and alerting in Grafana/DataDog \n\n\n\nAt BlueLabs we're combining the buzzing world of sports betting with modern tech and great engineering culture. We own our multi-tenant sports betting platform end-to-end. It consists of tens of microservices in a handful of decoupled domains, orchestrated by a terraform-provisioned Kubernetes cluster, achieving high scalability thanks to an event-driven architecture based on Apache Pulsar. We follow modern CI/CD and agile methodologies to deploy into production multiple times per day and use Datadog to monitor our infrastructure and applications."
    },
    {
        "position": "Software Engineer \u2013 data, infrastructure & tools",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Axis Communications",
        "sector": "Computer Networking Products",
        "companySize": "1,001-5,000 employees",
        "location": "Lund, Sk\u00e5ne County, Sweden",
        "post": "About the job \n\nJob Title\nSoftware Engineer \u2013 data, infrastructure & tools\n\nJob Description\nNow you have the chance to work as a Software Engineer in a workplace with friendly and high-skilled people and a culture that values work-life-balance and encourage you to put all of your great ideas into reality.\nYour future team\nWe are looking for an additional member to our team that will work with development of framework and tools to secure AXIS OS (FW) performance. Also working with collecting and from time to time analyzing internal measurement data to evaluate the FW performance. The team you\u00b4ll be working with consists of experienced SW engineers and the area is strategically important for Axis with great development potential moving forward. The company is in an expansive market, and it is important to be innovative as well as being able to select and later validate the selected strategy, at the same time taking fact-based decisions on all levels. Therefore, the deliverables are essential for various organizations within SW organization as well as Product management organization to secure performance of our FW deliverables.\nYour role\nAs SW Engineer, you will be part of a skilled team where you will play an important role. The exact tasks can vary from developing new framework, dedicated tools and/or creating scenarios to secure FW performance. You will have a high influence on your own role as well as how the team works with various exciting challenges.\n\nWho You Are\nYou like programming and are a self-going person that likes to take responsibility for your own tasks as well as seeing the big picture. Furthermore, you are curious and want to learn new things all the time as well as recognizing the importance of networking with others inside and outside your own team to achieve an efficient way of working. You are open to learn new things as well as sharing knowledge with others. Additionally, we prefer that you have the following background and skills:\n\nBachelor or Master of Engineering in Computer Science or equivalent \nExperience with Python as well as working in Linux development environment \nExperience working with various databases and GIT \n\n\nAdditional skills that can give plus points during recruitment:\n\nPrevious experience working with Docker \nKnowledge of building architecture for performance measurements using data \n\n\nReady to act?\nAre you ready to join us on our journey to innovate for a smarter, safer world - submit your application to us as soon as possible. To find out more contact the recruiting manager Tory Li at +46 70 246 7198\n Type of Employment \n Permanent Employment\n\n Posting End Date \n 2022-09-30\n\n\n About Axis Communications\nWe enable a smarter, safer world by creating innovative solutions for improving security and business performance. As a network technology company and industry leader, we offer solutions in video surveillance, access control, intercom, and audio systems, enhanced by intelligent analytics applications. With around 4000 committed employees in over 50 countries, we collaborate with partners worldwide. Together, we thrive in our friendly, open, and collaborative culture and inspire each other to think beyond the expected. United by our commitment to inclusion, diversity, and sustainability, we consistently seek to develop our skills and way of working.\nLet\u00b4s create a smarter, safer world \nFor more information about Axis, please visit our website www.axis.com. Listen to Get To Know Axis \u2013 Podcast"
    },
    {
        "position": "Data Scientist",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Kambi",
        "sector": "IT Services and IT Consulting",
        "companySize": "1,001-5,000 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n Kambi is searching for a motivated self-starter to join our Data Science Team. For the right candidate, the position will provide the opportunity to research and develop the best-of-breed solution supporting our B2B Sportsbook operations. The candidate will join a team based in central Stockholm, working as an agile software engineer and quantitative researcher, to build and refine Kambi's BI solutions.\n\nResponsibilities:\n\n\n\nCollaborate with stakeholders throughout the organization to identify opportunities for leveraging the company\u2019s data to deliver business solutions.\nResearch and develop machine learning models.\nKeep up to date with the latest technological trends.\nCommunicate results and ideas to key stakeholders.\nMonitor performance and continuously improve already deployed models.\nFluency in English is essential.\nInterest in, and experience of, sports betting is meritorious. \nWe work in a Linux environment.\n\n\nThe position reports to the Data Science Manager.\n\nRequirements:\n\n\n\nAn academic degree in quantitative discipline (computer science, mathematics, physics, etc.).\nMinimum two years of experience in similar role applying statistical, machine learning, or algorithmic solutions to business problems.\nCreative and experimental mind-set to data mining.\nStrong problem-solving skills with an emphasis on product development.\nAdvanced knowledge of SQL and Python.\nExperience using statistical computer languages to manipulate data and draw insights from large and complex data sets.\nExperience with distributed data/computing tools: map reduce, Hadoop, Hive, and Spark.\nA drive to promote innovative algorithmic solutions and data focused problem-solving.\nExcellent interpersonal skills and ability to communicate with both business and technical minded colleagues.\nAbility to work on multiple tasks and prioritize your own time. \nFamiliarity with workflows based on version control.\n\n\nNice to have, but not required:\n\n\n\nPrevious exposure to cloud native solutions.\nDevOps mindset\n\n\nIf you want to be part of a very dedicated team in central Stockholm please apply below. Since we will be interviewing candidates continuously send your application as soon as possible.\n #wearekambi\n\nAbout Kambi\n\nKambi Group plc is a leading B2B provider of premium sports betting services to licensed gaming operators. Our services provide an end-to-end solution for operators wanting to launch a standalone Sportsbook or bolster their existing offering with an innovative sports betting product. From front-end user interface to customer intelligence, risk management and odds compiling, all built on our in-house developed software, we strive to deliver the ultimate service and solution to our partners.\n Our vision is to create the world\u2019s leading sports betting experiences, together with our partners.\n With offices in Malta (HQ), Bucharest, London, Manila, Sydney, Uppsala and Stockholm and together with over 1000 passionate and highly skilled people; Kambi live and breathe sports betting. It is in everything we do. From delivering a premium service to our operators, to creating an entertaining experience for the end user; we are unwavering in our mission to create the worlds\u2019 leading sports betting experience."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Star Stable Entertainment AB",
        "sector": "Entertainment Providers",
        "companySize": "51-200 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nThe mission\nOver the past 10 years Star Stable Entertainment has grown to become a multi-channel entertainment company; the home of the 1# fastest-growing horse adventure in the world - Star Stable Online, an independent record label, short-form animations, book series, comics and mobile apps. We have over 21 million registered users across our games and apps, that are supported in 14 languages across 180 countries and we are on an adventure where we continue to scale our unique impact in the world with several new games and product lines in development across desktop/mobile.\n\n\nDo you have a passion for data? An irresistible urge to collect, gather, store and harness its power, turning it into information that can be understood and acted on across the business? Then Star Stable needs you! We are now on the lookout for a Data Engineer who will have the passion to build, manage & develop the next generation data environment to support Star Stable Entertainments vision as a multi-product and data-informed business. If you are a light-hearted, structured and passionate data nerd that knows the ins and outs of what works in today\u2019s cloud data platforms, look no further!\n\n\nWhat will you be doing?\n\nDevelop and maintain the underlying data structure and pipelines to support the AAI team and the organisation.\n\n-Make sure that the data is current, accurate and structured.\n-Handle, manage & structure data based on business needs.\n\nWork with stakeholders such as Product, Tech and Marketing and assist with data-related technical issues and support their data infrastructure needs.\nParticipate in building our next generation Data Warehouse using analytical data modelling theories from DataVault2.0, Inmon & Kimball.\nBe the link between the analysts and tech from a deep data perspective.\nWork with Ops to keep our data secure across national boundaries through multiple data centres and AWS regions.\nTaking compliance into consideration.Manage ad-hoc tasks as well as recurring tasks to maintain and develop our analytics environment.\nBuild the infrastructure required for optimal extraction, transformation and loading off data from a variety of data sources, using for example SQL and GCP/AWS.\nDevelop new data flows and storages based on business needs. \nBuild automated data pipelines and infrastructure that requires no or minimal manual intervention.\n\n\n\nWe believe that you:\n\nHave been a part of a similar journey before and have a vision for how to build Star Stable Entertainments future analytics data infrastructure, analytical data model and pipeline.\n\n-May be you have been a \u201cBusiness Intelligence Data Warehouse consultant, employee or similar\u201d in your past, and have built or participated in building or maintaining analytical data models.\n\nHave experience with GCP (BigQuery) and/or AWS data infrastructure/tools.\nHave a solid foundation in SQL and Python (Pandas+PySpark).\nHave a great knowledge of ETL/ELT tools such as Airflow and dbt, which is a merit.\nValues input from others and understands that collaboration is what creates magic for our users.\nAre located in Sweden.\nExcellent communicator with the ability to build relationships with different stakeholders.\nAbility to take ownership with a proactive mindset.\nAre curious about new technologies and ways of working.\nHave a good sense of humour and enjoy working in a friendly and open-minded team with a positive attitude, which values every member and is built for a long lasting perspective.\nPrefer test driven development.\nLike agile methodologies, like Scrum and DevOps.\n\n\n\nWhat can we offer you?\n\nA growing journey where you will have a lot of freedom in exploring new technology and ways of working as we expand into new product lines.\nYou will be a driver in the shift into new ways of working in regard to data for the overall business.\nA team that experiments and learns. If you like sharing ideas and learnings with colleagues both within- and outside of your field, this is the role for you.\nA pretty sweet mission. We want to build quality games for girls and we take that vision very seriously.\nWe strive to hit that mark every single day.We may be a big group, but we\u2019re a tight-knit team! A diverse team of friendly, fun, and supportive co-workers from 20 different countries!\nWe\u2019re more than 50% female-identifying! #YES to #WomenInTech! \nFlexible working opportunities.\n30 Vacation Days.ITP1 Insurance plan.\nParental pay top up to 90%.\n5,000 SEK per year Health allowance.\nHybrid working model, which allows you to combine the best of \u201cworking from home\u201d, and being together with the team at our cozy office, which has the best ever location for everyday commuters (be it T-bana, pendelt\u00e5g, train or a bike). Yes, we have a locked bike room with shower facilities!\n\n\n\nEager to revolutionise Star Stable Entertainment into a world-class data-driven organisation? Reach out and apply! We would love to hear from you!"
    },
    {
        "position": "Cloud Solution Architect - Data & Analytics",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Microsoft",
        "sector": "Software Development",
        "companySize": "10,001+ employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nCloud Solution Architecture, Data & Analytics\n\nWith over 17,000 employees worldwide, the Microsoft Customer Experience & Success (CE&S) organization is responsible for the strategy, design, and implementation of Microsoft\u2019s end-to-end customer experience. Come join CE&S and help us build a future where customers come to us not only because we provide industry-leading products and services, but also because we provide a differentiated and connected customer experience.\n As a Cloud Solution Architect, you will enable customers to achieve their outcomes, based on their investments in Microsoft technology. Leveraging your Microsoft Azure and Data & Analytics technical subject matter expertise you will lead technical conversations with customers to drive value from their MS investments, including identifying resolutions to issues blocking customer success projects. This opportunity will allow you to accelerate your career growth, honing your technical and collaboration skills, and deepening your cloud expertise. This role is flexible in that you can work up to [50% / up to 100% from home / This role is Microsoft onsite only].\n Microsoft\u2019s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.\n\nResponsibilities\n\nKey Responsibilities:\n\nUnderstand customers\u2019 overall data estate Business and IT priorities and success measures to design Data & Analytics solutions that drive business value. \nApply technical knowledge to architect and design solutions that meet business and IT needs, create Data & Analytics roadmaps, drive POCs and MVPs, and ensure long term technical viability of new deployments, infusing key AI technologies where appropriate.\nEnsure that solution exhibits high levels of performance, security, scalability, maintainability, repeatability, appropriate reusability, and reliability upon deployment\nBe the Voice of Customer to share insights and best practices, connect with Engineering team to remove key blockers and drive product improvements\nMaintain technical skills and knowledge, keeping up to date with market trends and competitive insights; collaborate and share with the Data & Analytics technical community while educating customers on Azure platform\n\nQualifications\n\nRequired/Minimum Qualifications:\n\nBachelor's Degree in Computer Science, Information Technology, Engineering, Business, or related field AND 6+ years of experience in cloud technologies, database solution, architecture and design.\n 6+ years of experience working in a customer-facing role.\n 6+ years of experience working on technical projects.\n\nTechnicalQualification\n\n\nDeep domain expertise in one of the Data-specific areas, such as Azure SQL Data (IaaS/PaaS), deployments and migrations to the cloud, Open-source database deployments and migrations, Cloud Scale Analytics, Data Governance, etc. OR hands-on experience working with the respective products at the expert level.\nExperience creating Data & Analytics Proof\u202fof Concepts (PoC), Minimum\u202fViable Products\u202f(MVPs)\u202ffor customersthat lead to production deployments\nThe technical aptitude and experience to learn new technologies and understand market and relevant cloud trends .\nCompetitive Landscape: Knowledge of key Data & Analytics platforms such as AWS, GCP, Snowflake, etc.\nPartners: Understanding of partner ecosystems and the ability to leverage partner solutions to solve customer needs\nSoftware development practices like DevOps and CI/CD tool chains. \n\nProfessional Qualification\n\nCommunication:\u202f\n\nRelationship Building: Proven track record of building deep technical relationships with executives. The ability to influence and build relationships across technical and business teams.\nGood understanding of key Data & Analytics scenarios that are driving digital transformation in key industries such as financial services, Retail, Healthcare etc.\nProblem Solving: Ability to solve customer\u2019s Analytics problems through various cloud technologies\nCollaboration and Communication: Acknowledged for driving decisions collaboratively, ability to communicate Analytics concepts effectively with business, data engineers/analysts and technical audiences, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT Management, Data Analysts, Engineers)\n\nMicrosoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances.\n Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work."
    },
    {
        "position": "Data Engineers and Senior Data Engineers to Data Arena",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Volvo Group",
        "sector": "Motor Vehicle Manufacturing",
        "companySize": "10,001+ employees",
        "location": "G\u00f6teborg, Vastra Gotaland County, Sweden",
        "post": "About the job \n\nPosition Description\n\nWelcome to the Data Arena of autonomous development\n\nAt Volvo Autonomous Solutions our purpose is to create safe automation solutions helping our customers reach sustainability- and productivity goals. We are guided by the vision that our innovations will contribute to a society that we want to live in, as well as meet and exceed expectations from customers.\nThe Global Technology Area Infrastructure provides tools, environments, and methodology to enable development, verification, and validation of world-class heavy-duty autonomous functionality. Sub domains include CI, CD, simulation environments, a broad variety of structured data, analytics and the data privacy office. Data driven software development with shorter and faster feedback loops are key in reaching our vision.\nWe\u2019re now recruiting Data Engineers and senior Data Engineers to our new Data Arena group, to be part of building and leading the scale-up of structured data availability. This is a unique opportunity to join an technology area with disruptive technology, scale-up momentum, and the global business leading Volvo Group.\nThe Data Arena operates in the technology domain, and is responsible for the structured data, data preparation, and advanced analytics. This includes the actual data and analytical products, and also the tools, methodology and interfaces with other parts of the Volvo group. The Data Privacy Office belongs to the same department, ensuring immediate legal compliance- and best practice expertise.\nHow You Will Make An Impact\n\nAs Data Engineer or senior Data Engineer at Data Arena, your main responsibilities include making data available by pre-processing, cleaning and structuring data to facilitate data exploration and advanced analytics/Machine Learning activities. You will also build large-scale batch and real-time data pipelines with data processing frameworks in cloud platforms or on premise, as well as create and manage environments.\nAnother aspect is to collaborate closely with data scientists and data architects to implement and deploy scalable solutions. This can include to conducts data discovery, and to guide others in how data is organized and accessible for an efficient analytical setup.\nTo succeed, you have a community of specialists, domain architects, partner companies and suppliers around you. You also have full access to immense resources from the Volvo Group.\nWho are you?\n\nWe believe it is the right mindset and attitude that will make a difference within our organization. We expect you to have documented education and experience in Data Engineering and/or SW development. We believe you are curious and have the ability to understand new contexts quickly and efficiently.\nAs success in the role is all about collaboration, we believe you are a good listener, skilled communicator, and that it is easy for you to connect with others. Our working environment is highly international, and hence you need to be proficient in English, both written and spoken. \nAre we a perfect match? \n\nIf you are as eager to embark on this exciting journey as we are to get to work with you then do not hesitate to reach out and send in your application! Please note that all applications will be reviewed and processed continuously.\nIf you have questions, please contact the recruiting manager \n\nPeter H\u00e4rsl\u00e4tt, Global Technology Manager Infrastructure, peter.harslatt@volvo.com. We kindly but firmly decline all offers of recruitment services.\nKindly note that due to GDPR, we will not accept applications via mail. Please use our career site.\nAbout Us\n\nThe Volvo Group drives prosperity through transport solutions, offering trucks, buses, construction equipment, power solutions for marine and industrial applications, financing and services that increase our customers\u2019 uptime and productivity. Founded in 1927, the Volvo Group is committed to shaping the future landscape of sustainable transport and infrastructure solutions. Countless career opportunities are offered across the group\u2019s leading brands and entities that share a culture of Trust, Passion, High Performance, Change and Customer Success.\nwww.volvogroup.com/career.Volvo Autonomous Solutionsconstitute a new business area as of January 1, 2020, entering new and exciting territories for Volvo Group. We accelerate the development, commercialization and sales of autonomous transport solutions, focusing on defined segments for the on- and off-road space. The combination of strong tech expertise and skilled customer solutions creates innovative transport offers never seen before. We are constantly pushing our own skills and ability to drive change in a traditional industry to meet a growing customer demand. We are now looking for innovative, committed individuals to join us in our endeavor to create customer solutions that enhance safety, flexibility and productivity.\nAuto req ID\n\n133516BR\nOrganization\n\nVolvo Autonomous Solutions\nState / Province\n\nV\u00e4stra G\u00f6taland\nCity/Town\n\nG\u00f6teborg\nEmployment/Assignment Type\n\nRegular\nTravel Required (maximum)\n\nOccasional Travel\nFunctional Area\n\nTechnology\nLast application date\n\n23-Oct-2022"
    },
    {
        "position": "Data Engineer to Analytics and Data Platforms",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "H&M Group",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nCompany Description\n\nAre you a creative and experienced Data Engineer, passionate about solving problems, building new stuff and always have something new to learn? We are looking for you to join our AI, Analytics and Data domain. \n\nShaping the future of fashion with people, data, and tech - the fashion and retail industries are going through a transformation, driven by customers technology and sustainability expectations. At H&M Group, we want to shape the future of retail by harnessing the power of smart tech and data. With our 74-year history of innovation, we understand the need to collaborate and co-create with engineers and tech specialists around the world to achieve our vision.\n\nWhat we offer!\n\nBesides the obvious perks such as staff discount card, flexible work life, learning communities, wellness benefits, parental benefits etc. you are joining a unique value driven culture, a large tech network and community where you can be yourself. There are endless opportunities to experiment and grow in any direction that you want and when you grow, we grow. Being a major player gives us countless opportunities to make a real impact and shape the future. \n\nJob Description\n\nWe love design, and we love technology! Our diversity makes us strong and creates an inclusive and welcoming workplace where everyone\u2019s individuality is highly valued. We are looking for Data Engineers who want to work in a modern organization, where agility, automation and cloud are non-negotiables.\n Our product area is called Analytics and Data Platforms and our teams are responsible for all data processing, reporting and advanced analytics capabilities across the whole value chain. This means tons of data and unlimited learning opportunities. We welcome applications from varied backgrounds in data and analytics.\n\nAbout The Position\n\nYou will work with one of our Analytics team. You and the team leverage modern software engineering principles and techniques to build robust data solutions for a varied spectrum of analysts. You appreciate working in autonomous teams, have a hands-on attitude and believe that no challenge is too big if we have the right support and tools in place.\n We appreciate a multitude of technical backgrounds, but we believe you will enjoy working here if you\u2019re passionate about data and have worked hands-on with data warehousing and analytics in the past with modern open-source data processing frameworks and Azure/GCP-based data integration services. We appreciate your solid foundations in database principles and/or software engineering, as these go hand-in-hand when building robust BI and advanced analytics solutions.\n We believe that you are a true team player, solution-driven and open-minded, with a passion for continuous improvement and automation. You are collaborative and you have the ability to build relations with different types of people and roles.\n\nWe Are Looking For You Who\n\n\nAre triggered by developing and designing the next generation data- and analytics-solution with focus on enabling smart self-service capabilities\nhave a DevOps mindset and embrace Engineering Principles, which emphasizes automation, continuous integration, and end-to-end ownership of solutions\nWant to work in a small, smart, agile team \u2013 designing, developing and owning the full solution\nAre motivated by analyzing and understanding the business needs, translating it to technical solutions, assuring that both business and technical needs are met\n\n\nQualifications\n\n\nExperience in Google Cloud Platform \nExperience of designing, development and testing in the field of Data & Analytics\nExperience in PowerShell scripting\nExperience in SQL\nExperience in object-oriented programming languages (Python) \nExperience in Big Data technologies (e.g. Spark)\nExperience in Big Data file formats (e.g. Parquet)\nSolid understanding of Data Modeling. Experience in modeling and developing tabular cubes, SSAS. Experience also in composite models is a plus.\nExperiences in working with Power BI\nExperience in agile methodologies\nExperience from successful delivery of high-quality outcomes \nFluent in English both written and verbal\nPassion for people and technology\n\n\nAdditional Information\n\nSounds interesting? Great! Please apply with your CV. Due to GDPR, we don't accept applications through email.\n\nDo you think we are a match? We hope so!\n\nThis position is placed in Stockholm, Sweden."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Readly",
        "sector": "Online Audio and Video Media",
        "companySize": "51-200 employees",
        "location": "V\u00e4xj\u00f6, Kronoberg County, Sweden",
        "post": "About the job \n\nThis is Readly\nReadly is a digital subscription service that lets customers have unlimited, \u201call-you-can-read\u201d access to thousands of national and international magazines - all in one app. Readly has partnered with 800+ publishers around the world to drive the digital transformation of the magazine industry. We see ourselves as an ecosystem where all our stakeholders share the value of digitized quality content. By bringing the magic of magazines into the future - trusted content anytime, anywhere, our passionate team of 100+ people in Sweden, Germany and UK hope to make the enjoyment of magazines and the power of trusted journalism more accessible than ever before. Since September 2020 Readly is listed at Nasdaq Stockholm.\n\n\nAbout the role\nWe are looking for more data-focused engineers to support our journey towards building more personalized and data-driven products. We currently have two teams who work on ingesting, curating, and preparing data for analytical and operational use. The teams are expected to take ownership of the over full lifecycle of data and support existing data products like recommendation- and search engines. Which team you fit in will depend on your profile and interests. Our cross-functional teams, consisting of data scientists, data engineers and software developers, also work closely with the Analytics- and CRM-teams to create a personal Readly experience in all touchpoints with our users.\n\n\nAt the company we work with the following technologies:\n\nAWS as our cloud service provider\nSnowflake (and Redshift) as a data warehouse solution\ndbt for data transformation and dependency management\nRuby/Go/Python as mainly used programming languages\nTerraform as IaC tool\nStep functions for data job orchestration\nGitlab for code versioning and deployment pipelines\n\n\n\nWhat is expected from you\nIt is expected of you to have a great understanding of the data engineering area as well as basic understanding of the data science area. While it\u2019s not important which service provider, experience working with modern Data Engineering in a cloud environment is essential for the job. Having hands-on experience working with the exact technologies we use is not a requirement although working with similar products within the same area is a must. We have, however, made a bet on Snowflake as our primary data warehouse, so Snowflake experience is a big plus. As we are building a lot of new and exciting services and products, your input on a lot of critical and long-lasting decisions will be greatly appreciated. Therefore, it is important that you have a good level of knowledge about what it means to develop a data product, from data modelling to robust deployment strategies for data pipelines. Good communication skills and ability to work in a team with a culture of knowledge sharing is of course a must as well.\n\n\nApplication\nDo you feel this is a perfect match? Please apply by clicking the link below!"
    },
    {
        "position": "Software Developer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "VECTOR Sweden",
        "sector": "Motor Vehicle Manufacturing",
        "companySize": "51-200 employees",
        "location": "Link\u00f6ping, Ostergotland County, Sweden",
        "post": "About the job \n\nDO YOU WANT TO MAKE THE NEXT SELF DRIVING CAR A REALITY?\nDo you want to be part of a team that makes it possible for customers to develop and deploy software for the next generation of vehicles such as highly automated driving, cloud connectivity and more? We are an international team with co-workers, customers, and projects all over the world \u2013 join us!\n\n\nJob Description\nYou will be part of an agile team developing solutions for Adaptive AUTOSAR - the standardized platform for high performance computers in vehicles. You will work with product development in modern C++ create components for a state-of-the-art software platform. The development environment is Linux, and the software can be deployed on a POSIX based operating system.\n\n\nWhat we are looking for\nThe person we are looking for has a very good knowledge and great interest of programming in object oriented languages especially in modern C ++ as well as experience of working in Linux (both as target platform and as development environment). You want to work in an international agile team using leading-edge technology with different aspects of software development (design, test, implementation and documentation etc.). We apply a structured testing approach using GoogleTest, GoogleMock and JUnit Testing, so such experience is requested.\n\n\nWe believe that the agile way of working is natural to you and thus the importance of collaboration, curiosity, and ability to respond to change. You have a degree in computer science or equivalent experience.\n\n\nThis position is located in Link\u00f6ping and business travels may occur. \n\n\nAbout Vector\nWe are a global, continuously growing engineering company. For over a quarter of a century, we have been at the forefront of electronic innovations within the automotive industry and related sectors. We support manufacturers and suppliers with a professional platform of software and hardware tools, embedded software components, and services for developing embedded systems. All with one mission: Simplifying the development of automotive electronics and software! \nIn Sweden we have a fast growing Product Development Center in Gothenburg and Link\u00f6ping.\n\n\nWhy Vector Sweden?\n\nWe provide a fun, attractive, and high-tech working environment! \nWe have the atmosphere of a small company with the resources of a global organization\nOur work climate is characterized by helpfulness, trust and appreciation\nWe embrace diversity and are proud to have co-workers work from all over the world!\nCompetence development\nFlexibility for a good work-life-balance\nNew and fresh offices\nOpportunity to work part time remotely\nWellness allowance, insurance, pension and other great benefits! \n\n\n\nAre you interested?\nInterviews will be held continuously. Therefore we encourage you to apply as soon as possible via the apply button below. \nWe are looking forward to your application!"
    },
    {
        "position": "Software Developer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "FlexLink",
        "sector": "Automation Machinery\n                                                            Manufacturing",
        "companySize": "1,001-5,000 employees",
        "location": "Gothenburg, Vastra Gotaland County, Sweden",
        "post": "About the job \n\nDo you like finding new solutions to challenging software problems? Are you ready to ignite your potential and become part of tomorrow\u2019s smart factory makers? We always seek the next step to widen the horizon for both the individual and the company. Take the opportunity to be part of a stimulating and international environment! \n\n\nAs a part of the dynamic and inspiring work environment at FlexLink, you have every opportunity to grow \u2013 in all aspects. You will be a member of a prosperous and innovative company with collaborative teams that will inspire you to ignite your potential and expand your horizons. We apply a hybrid remote working policy and flexible working hours.\n\n\nMain activities and responsibilities\n\nDevelop high-quality software and web applications\nAnalyze and maintain existing applications\nWrite testable, efficient code by using best software development practices\nParticipate in projects and product changes\nAssisting first-line support with analysis and problem-solving in support cases\n\n\n\nAs part of our Software Development team, you will improve and adapt the software tools that our engineers and customers use to create the automated factories of tomorrow. Our customers are the Global producers of all kinds of consumer goods, electronics and pharmaceutical products such as food, beverages, medicine, toilet paper, diapers, electric car batteries, and much more. These are the kind of products that you will help to bring to people all around the world. You would be based at our Global HQ in Gothenburg, Sweden.\n\n\nDevelopment stack\n\nGo, Python, Docker, frontend in Svelte.js / Vue.js, Nginx, Microservice architecture, Git / GitLab, SQL, MongoDB, Rabbit MQ, MQTT\nLinux servers\n\n\n\nRequired skills\n\nCoding experience\nPrefer to work in a team\nLike coding and problem-solving\nSkilled in one or more languages of Go, Java, C#\nFluent in English\n\n\n\nNice to have\n\nExperience in Internet security flow \u2013 authentication/firewalls, etc\nFront-end development, Docker, CI/CD\n\n\n\nAbout FlexLink \nFlexLink is an industry leader in automated production flow solutions. Working closely with global customers, we provide innovative, optimized solutions to produce goods smarter, safer, and at lower operating costs. Headquartered in Gothenburg, Sweden, FlexLink has operating units in 26 countries and is represented in more than 60. In 2021, FlexLink had about 1,100 employees and a turnover of 244 MEUR.\n\n\nFlexLink is part of Coesia, a group of 21 companies specializing in highly innovative industrial and packaging solutions based in Bologna, Italy. The Group, whose sole Shareholder and President is Isabella Ser\u00e0gnoli, is present in 35 countries with 84 production plants in 136 operating units and has over 8,000 employees.\n\n\nJoin the team! We are looking forward to receiving your application through our job portal. \n\n\nThis is a permanent position, full-time. If you have any questions, feel free to reach out to eliza.erlandsson@flexlink.com. As selection and interviews take place on an ongoing basis, we ask you to send your application as soon as possible. Kindly note that due to GDPR we will not accept applications via mail. Please use the link to apply via our career site.\n\n\nExternal agencies are kindly requested not to contact the company regarding this position."
    },
    {
        "position": "IOT Solutions Architect, PTC \u2013 Kalypso",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Rockwell Automation",
        "sector": "Automation Machinery\n                                                            Manufacturing",
        "companySize": "10,001+ employees",
        "location": "G\u00f6teborg, Vastra Gotaland County, Sweden",
        "post": "About the job \n\nJob Description\n\nIoT Technical Delivery Leader and/or Solution Architect\n\nLocation Anywhere, Europe\nKalypso, A Rockwell Automation Company, is a professional services firm dedicated to helping clients discover, create, make and sell better products with digital. We believe that innovation across the value chain is the single most important factor for long-term growth and success.\n\nWe are passionate about our work and committed to helping clients become more innovative, competitive, and productive.\nThe Kalypso team consists of diverse industry and technical experts with proven experience delivering results.\nOur people are recognized business, industry, and technical thought leaders with a passion for innovation.\nAs a provider of professional services, our people are the key to success. We are looking for the absolute best to join our world-class team.\nWe want balanced individuals who are willing to go the extra mile to provide the sustainable results our clients expect.\nAt the same time, we are looking for real, multidimensional people \u2013 Characters with Character \u2013 who complement their expertise and intelligence with personality and integrity.\nWe are seeking exceptional candidates who are passionate about the exciting world of digital technologies, including the Internet of Things, Big Data, Advanced Analytics, Artificial Intelligence and Machine Learning.\nThe candidate will assume the role of a Technical Delivery Leader / Solution Architect in our Enterprise Technology Practice and oversee technical strategy and delivery for our IoT advisory and implementation projects across their lifecycles.\nThe candidate\u2019s scope will include supporting\n\n\nSales/pre-sales activities (understanding client/customer goals and requirements, conceptual solution development, demos, proposal development, work planning, and project approach and work estimates)\nClient delivery (defining solutions and architecture that meet client requirements, coaching and management of technical personnel, management of technical tasks and work threads, incorporation of DevOps and other firm and industry standard methods and practices, interfacing and coordinating with client team members, delivering on time and on budget solutions that exceed client expectations)\nFirm technical capability development (assisting with hiring and mentoring junior technical resources, contributing to DevOps and technical standards and methods).\n\n\nThis person can be located anywhere in Europe and will provide solution development and technical delivery leadership to client initiatives in Europe as needed.\nYou will work in a client-facing role for established global clientele, helping them apply leading ThingWorx IoT, Advanced Analytics and Augmented Reality capabilities to challenging business problems. Our work is fast-paced, demanding, and provides unparalleled exposure to unique opportunities. The learning curve can be quite steep, but our team will help you build confidence and enable you to explore areas that are of interest to you. Our focus is on helping clients extract business value from cutting edge IoT capabilities, not just on making the technology work. In this role you will help design, develop, and test solutions for a diverse set of clients in industries such as Manufacturing, Life Sciences, High Tech, Consumer Goods and Retail.\n\nThe successful candidate will be a member of Kalypso\u2019s Enterprise Technology capability and work with and receive coaching and oversight from Senior Regional and Global technology leaders to successfully develop and implement IoT and Digital solutions that meet client needs. In turn, the candidate will also be expected to provide direction, guidance, coaching and training to technical specialists (developers, software engineers, etc.) who are assigned to their client engagements, many of whom will be based in one of Kalypso\u2019s Innovation Centers in Pune, IN, Bucharest, RO or Monterrey, MX.\nTo qualify for our Technical Delivery Lead / Solution Architect position, you should possess the following\n\n\nExperience leading the implementation, validation and deployment of scalable, commercial IoT/IIoT, AR/VR and analytics solutions in a client-facing setting.\nExperience supporting sales and pre-sales activities in these domains\nUndergraduate degree (preferably in Computer Science or Information Systems with supplementary experience in Data Science and/or Statistics)\nExcellent communication skills in English, both written and verbal\nStrong academic performance required\nRelevant work experience is highly preferred\nSuperior analytical, technical and problem-solving skills\nEffective interpersonal, organizational, and time management skills\nCreativity, self-confidence and flexibility\nWillingness to travel (required) up to 75%\n\n\nSolution Architects should possess the following technical and consulting skills\nExperience with the PTC ThingWorx technology stack\n\ndevelopment of IoT applications and solutions including building scalable data model, services, orchestration, system integrations\ndevelopment of IoT connectivity components utilizing ThingWorx edge SDKs or industrial protocols (OPC, MQTT, MTConnect, ModBus and similar)\n\nExperience in working within manufacturing domain \u2013 understanding typical OT and IT components of manufacturing operations, their architectures and data structures MES, CMMS, PLC, DCS, SCADA, HMI, ERP, Asset Management and similar.\nExperience with advanced analytics and machine learning disciplines like model development, training, validation and deployment\nExperience integrating ThingWorx with \u2018Big Data\u2019 platforms\nCompetency in Graph/NoSQL database techniques, and RDBS platforms like Oracle,MS SQL Server, Postgres, InfluxDB\nCompetency in mathematical disciplines including linear algebra, calculus, probabilistic models and statistics\nData manipulation techniques, including ETL/ETLV\nCompetency in object-oriented development patterns in Java and .NET\nCompetency in data analysis applications built in R, Python, Scala\nCompetency in data visualization platforms like D3.js and Tableau\nCompetency in modern web development techniques like Angular, Node.js, React, Bootstrap, HTML5 and CSS, Javascript\nCompetency in modern integration standards like RESTful and OData, message-oriented-middleware (MQ)\nStrong UML skills and ability to document structural and behavioral elements of solution architecture\nCompetency in one of the major cloud platforms such as AWS, Microsoft Azure, GCP, etc.\nExperience leading remote development teams, performance testing, unit test, etc. \nStrong knowledge and experience in Agile and SDLC software development practices and technical documentation (requirements, functional specifications, test plans, DevOps, test automation etc.)\nUnderstanding of business requirements and the process of translating them into well-engineered and integrated technical solutions; attention to detail\nClient-focused to understand and appropriately respond to our clients\u2019 business needs\nDemonstrated ability to interface effectively and collaborate with clients, peers and management to help develop solutions and ensure stakeholder buy-in\nVersatility, flexibility and proactivity when resolving technical issues and dealing with ambiguity\nCommitment to quality and on-schedule/on-budget delivery; proven ability to establish and meet milestones and deadlines with solutions that meet or exceed client expectations and requirements."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Once Upon Publishing AB",
        "sector": "Consumer Services",
        "companySize": "11-50 employees",
        "location": "Skellefte\u00e5, V\u00e4sterbotten, Sweden",
        "post": "About the job \n\n\n\n\n\n This job is sourced from a job board. Learn more\n\n\nSome Of The Things You\u2019ll Do\n\nOnce Upon is on an exciting growth journey and we are developing fast. So are the requirements on our data being made available for analytics, data science, reporting and BI. That is why we are now in the search for a data engineer to take ownership of our data management. We offer a flexible, open and innovative work environment. You will be surrounded by many other tech-savvy colleagues, serving lots of opportunities to share knowledge and expertise but also gaining new skills and bouncing out-of-the-box ideas. About the role You will work crossfuntional and in close collaboration with colleagues from Finance, Performance Marketing and Product Development, but also other teams.\n\n\n\nAlign data from various sources and ensure they are stored efficiently, creating API connections and data pipelines.\nImprove collection, storage and work with data.\nExplore new ways of producing and processing data.\nLead documentation of data pipelines.\nHelp drive optimisation, testing and tooling to improve data quality.\nSupport data consumers within the company to build, tone and visualize KPI:s, reports and graphs in BI-tool. If you want to read more about our current tech-stack, welcome to have a look here. Your background\nDegree in Engineering, Computer Science or equivalent.\nAt least 2-3 years experience from a Developer role within the field of Data (Data- or Backend/Database Engineer).\nExperience from building cloud data solutions (Prio1: AWS, Prio2: GCP).\nGood coding skills in Python.\nExperience from working with big data in relational databases. \nStrong understanding of GDPR guidelines.\nBasic experience in data visualization in Tableau/PowerBI or similar is a plus. Who you are We are looking for a collaborative colleague who enjoys partnering across teams and departments. An ability to coordinate at multiple levels as well as great communication skills are talents that will serve you (and us) very well in this role. You are a self starter and problem solver who sees possibilities where others see obstacles. If you are also an innovative thinker and open minded about trying new ideas, you will like working at Once Upon!\n\n\nWorking at Once Upon Our app was created to help people save their favorite moments in an easy and fun way, a little at a time, making everyone\u2019s memories shine. And that\u2019s how we want our workplace to be too \u2013 life (and work) at Once Upon should definitely be filled with happiness. Because happiness is the key to success, not the other way around. Right? We strive for a safe, caring environment that gives everyone space to be their whole self, all the time. If you feel free and have fun at your job, it is easier to feel passion and responsibility for what you do. We always dare to do what we believe in \u2013 failing at something is not the opposite of succeeding in the long run. And we always strive to make things better, for our Once Uponers, for our planet and for each other. Through innovation, co-creation, transparency and our collective knowledge as a team we always aim to bring value to our Once Uponers. And that collective brain grows with every new colleague that we welcome to the team, enriching us with new perspectives, experiences and views on life. If you\u2019re looking for a little more happiness in your life and feel like working at Once Upon would be fun, well, that new colleague might just be you! At Once Upon, we commit to being an anti-racist company that leads by example. This means doing the work to be inclusive and equitable, across all aspects of our business. Location Our headquarters are located in Skellefte\u00e5, in the North of Sweden. We also have offices in Pite\u00e5, \u00d6rnsk\u00f6ldsvik and Stockholm, maybe that's closer to home for you? We are remote flexible, but we also value the creativity and sense of community that follows from meeting face to face with colleagues. Let\u00b4s connect Are you the perfect fit? Then we can't wait to hear from you! Please help us get to know you by submitting your resume or LinkedIn-profile on our website. Applications in Swedish or English work equally fine!\nWe conduct a competence based recruitment, meaning that every person who applies to join Once Upon receives equal employment opportunities. We value a welcoming environment where everyone feels included, respected and empowered, regardless of their race, colour, religion, gender, gender identity or expression, sexual orientation, civil status, national origin, disability or age. If you have any questions about the job or work at Once Upon, don\u2019t hesitate to contact Talent Partner Matilda \u00d6kvist at matilda.okvist@onceupon.se. Last day of application is October 23rd. At Once Upon you have the chance to be part of something that truly makes people happy. We want to help people save their favourite moments in an easy and fun way, a little at a time, making everyone\u2019s memories shine. Today, there are just over 50 of us working at Once Upon. The app is translated into 12 languages, has been downloaded over 3 million times, with books delivered to over 109 countries, and we\u2019re still growing!\nTo be the best we can possibly be, we need all kinds of people that are able to look at things from all kinds of perspectives. That\u2019s why we need you, with your unique background, experiences and view on life. Want to be part of our story? Get in touch!"
    },
    {
        "position": "Data Engineer with Development Skills",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "H&M Group",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nCompany Description\n\nAt H&M, we are on an exciting journey where fashion and tech make magic together. As rapid technological development and new customer behaviors are transforming the fashion retail industry, our mission is to meet and exceed our customers' expectations. All while keeping in mind sustainable practices. We know that the best ideas evolve when great minds with different backgrounds and perspectives get together.\n At H&M, we are all on the same team in a global environment where we learn from each other and grow together. We live our values and know that sharing knowledge is the best way to continuously improve our ways of working and creating.\n We are proud to foster a workplace free from discrimination. We strongly believe that diversity of experience, perspectives, and background will lead to a better environment for our employees and a better product for our users. H&M Group \u2013 Business Tech.\n There are countless reasons for you to consider joining H&M, but here is a list we think summarizes the most important ones:\n\nThere are tremendous amounts of growth opportunities: we have many courses and workshops running so that you can become your best-self;\nYou will be surrounded by incredible colleagues from all around the globe;\nYou will experience what being part of a large organization means;\nThe opportunity to always be on the forefront of tech and fashion\n\nAre you a Data Engineer with development skills. Do you have a passion for large scale cutting edge analytics and data platforms? Do you think Kubernetes is the way forward in a multi cloud world? Do you think that everything could be automated with pipelines? Do you want to work in an enablement team building cool stuff that empowers a multitude of product teams? Then this is the opportunity for you!\n\nJob Description\n\nIn Common Tools and Services we empower all product teams by building the tools and services that makes sure H&M Group\u2019s data and analytic platforms are awesome. You will build self-service data platforms and integrations solutions at enterprise level. You will join a team of amazing professionals with great opportunity to contribute with your own creative ideas. As a team we have innovation sprints and lab days so we can evolve and develop new ideas.\n\nSome of your daily tasks include:\n\n\nDesign and develop our large scale Apache Kafka platform in Kubernetes. You will work both on a strategic level and with hands-on implementation and also support other teams in data platform and integration advisory including advanced troubleshooting.\nDesign and develop our test automation framework that is an important tool for our data engineers.\nDesign and develop our deployment pipelines used by many product teams.\nTranslate strategies and requirements into modern, innovative and scalable solutions\n\nQualifications\n\nWe are looking for someone that is smart, humble and hungry in helping us build our next modern data platform, you will play a key role in our data transformation journey. We believe you have the ability to understand and\u202fanalyze\u202fcomplex information as well as being able to communicate with others regardless of their IT knowledge.\n You work proactively and with continuous improvements in a fast transforming environment. You enjoy working with implementation and taking operational aspects into account.\n\nTo do this, we think you have a curious mindset, excellent communication skills as well as:\n\n\nExperience in Cloud (Azure, GCP)\nExperience in Kubernetes, Docker and containerization.\nExperience in Python and/or Java\nMeritorious with experience in Devops\nMeritorious with experience in Apache Kafka\n\nLeadership? In this role you will act as a thought leader towards other product team. You should be in the frontline on both new technology and H&M strategies.\n\nAdditional Information\n\nThis is a full-time position with a placement in Stockholm.\n Please apply with CV and cover letter as soon as possible, as a part of the process you may be asked to complete a test connected to engineering. Interviews will be held continuously. And We love code! So If you have contributed to Github project(s), also send those to us together with the CV. We are more than happy to take a look!"
    },
    {
        "position": "Site Reliability Engineer - Observability",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "King",
        "sector": "Entertainment Providers",
        "companySize": "1,001-5,000 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nCraft:\n\nTechnology & Development\n\nJob Description:\n\nAt King millions of players connect to our games every day and expect to continue playing from where they left off. All this user and game progression data is stored in our infrastructure. We are looking to find someone eager to help us engineer and manage the monitoring and observability environments at the heart of this ecosystem.\n We believe that you share our passion for learning new things, coding (primarily in Python), quality, automation, continuous improvements, and actively building and upholding a great culture. Above all, we would like to see that you have a genuine interest in high performance observability.\n Your role within our Kingdom\n Our job is to build effective, stable and reliable large-scale infrastructure tools and services for our platform, games, and product teams. We strive to empower developers to be autonomous and flexible. We continuously work to create self-service models for our tech in close collaboration with development teams.\n We care deeply about our culture and believe in:\n\nAn inclusive and diverse workplace\nContinuous improvement of everything we do\nAutomation and coding as much as possible\nCollaboration and blame-free respectful problem solving\nAsking for help and sharing ideas openly\n\n\nWe engineer and provide the shared infrastructure platform serving all of our games, as well as environments for developers and supporting tech like observability, log management, and event transport. This includes everything from working in our data centers, writing code for full stack orchestration and automation, troubleshooting distributed systems and resolving production incidents.\n For this role you will join the our Applications engineering team to work on observability. You will engineer and provide the systems that are the eyes and ears of the infrastructure that processes over 100 billion events per day.\n Example of what you will work on:\nOur monitoring pipeline for platform and infrastructure meters (kafka, collectors, adapters, influxdb, stackdriver, OpenTSDB), Alerting and notification (Nagios, PagerDuty, Monitoring in the )Troubleshooting and instrumentation solutions (NetData, atop, or other such solutions)Log management (Elk, Graylog, StackDriver)\n\n\nSkills to create thrills\n\nMonitoring Pipelines built with Kafka, Collectors, Adapters\nAlerting and notifications (Nagios, PagerDuty, Incident response)\nTroubleshooting and instrumentation solutions (Netdata, Pixie) \nKnowledge of monitoring systems like OpenTSDB, InfluxDB, Graphite, log management systems like Graylog or ELK\nOrchestration frameworks like SaltStack, Ansible, Puppet, Terraform etc\nComfortable with the Linux command line & its performance tools\nAble to communicate proficiently in written and spoken English\n\n\nWe think that you are a curious, humble, driven, collaborative, and responsible person who loves to work with infrastructure as code.\n\nAbout King\n\nKing is the game developer behind the world-famous Candy Crush franchise, as well as mobile game hits including Farm Heroes, Bubble Witch and Pet Rescue. Candy Crush is the top-grossing franchise in US app stores, a position it has held for the last two years, and King\u2019s games are being played by 245 million monthly active users as of Q3 2021. King, which is part of the Activision Blizzard group since its acquisition in 2016, employs nearly 2,000 people in game studios in Stockholm, Malm\u00f6, London, Barcelona and Berlin, and offices in San Francisco, New York, and Malta.\n\nA Great Saga Needs All Sorts of Heroes\n\nMaking games is fun. Especially when you do it with people who share the same idea of what makes a good workplace great. We design games for everyone, no matter where they are or who they are, and we employ all sorts of people from all kinds of backgrounds to bring them to life. Truth is, we simply cannot expect diversity in our players and originality in our games without first nurturing it in our people. A great saga needs all sorts of heroes.\n\nMaking the World Playful\n\nMaking the World Playful is what inspires us to create new experiences and raise the bar. It\u2019s what makes King a place where we can all dream bigger, continue to add innovation to our games, broadening the portfolio and exploring new territories in mid-core and casual. We take the art and science of gaming to the next level through our curiosity for the unexplored, passion for games, respect for each other and love for our players - and we\u2019re not afraid to have fun along the way. In fact, together with our parent company Activision Blizzard and experts around the world, we believe having fun is good for you. There has never been a better time to join us. We're dreaming bigger and see a world of possibilities ahead. If you share our passion, our values, and our hunger to shape the future, join us in Making the World Playful!\n Applications needs to be in English.\n Discover King at careers.king.com"
    },
    {
        "position": "Cloud Data Warehouse Architect, Siemens Financial Services",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Siemens",
        "sector": "Automation Machinery\n                                                            Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Solna, Stockholm County, Sweden",
        "post": "About the job \n Working for Siemens Financial Services Information Technology (SFS IT), you will assume end-to-end responsibility for one or more of our business-critical finance IT applications. You will secure reliable operations and continuous enhancement while ensuring that regulatory and security requirements as well as agreed service levels are met. You will achieve this, working hand in hand with our interdisciplinary and international team of IT experts.\nThere are more than 1200 professionals working in Cybersecurity, Analytics Business Intelligence, Application Lifecycle Management, IT Project & Service Management and IT Infrastructure Management.\n\nWe are a global powerhouse focusing on the areas of electrification, automation, and digitalization. One of the world\u2019s largest producers of energy-efficient, resource-saving technologies, Siemens is a leading supplier of systems for power generation and transmission as well as medical diagnosis. In infrastructure and industry solutions the company plays a groundbreaking role.\nLooking for a chance to create a positive impact on our society? Join us!\n\nWhat role will you play?\n\nData is at the heart of our business and one of our greatest assets. And we treat it like this. Who we are? - We are the Chapter Data Management at Siemens Financial Service\u2019s Information Technology & Cybersecurity Function. We are a global team of experts accountable for Data Warehouse Architectures & Development Principles shaping Data Management of Today and Tomorrow.\n\n\nIn Collaboration with all relevant stakeholders (e.g., Chapter & Delivery Lead, Business) and based on predefined business requirements, you design the Intra-Architecture of our Data Warehouse and Data Lake of Today and Tomorrow.\nThis includes end-2-end responsibility form taking over the business requirements for a specific use case/ user story, translating them into technical solution designs and ensuring that your technical concepts are developed by your data engineering colleagues as requested.\nWe work use case and project oriented, meaning that you take a leading role within the squad(s) you are assigned to as Technical Lead (e.g., for an upcoming migration a/o data integration project).\nIn close collaboration with the Lead Data Architect, you develop further, govern, and communicate our Data Warehouse Architecture & Data Modelling Guidelines & Principles and thus ensure a standardized Data Warehouse Delivery and build of new features.\nYou advise and support your data engineering colleagues in all their activities, proactively include the requirements of other colleagues (e.g., DWH Automation, Compliance & Governance/ GDPR/ Finance Regulatory) and always keep an eye on the needs of your squads and customers.\nYou support your key management stakeholders, e.g., via well-targeted technical consultancy, effort estimation for the implementation of new features and preparation of senior and C-Level management meetings.\nYou identify knowledge gaps in the squads and develop recommendations for action to close them eventually (e.g., through suggestions for training, coaching, workshops, etc.). \nAs you also are familiar with at least one programming language (e.g., SQL, Python) you take over smaller software programming tasks if necessary.\n\n\nWe are looking for:\n\n\n\nThe basis of your success is a degree in Information Technology, Mathematics, Physics, Business Administration or equivalent with at least +3 years\u2019 experience - Gained Knowledge in Finance and Banking Industry is a big plus.\nYou are an enthusiast on data, data warehousing and engineering and you have gain several years of experience as a Data Warehouse Architect/ DWH Solution Design Expert in your current a/o previous positions or you are a Data Warehouse Developer with the willingness to make the next big move in her/ his/ its carrier.\nYou have worked and gained practical knowledge with Cloud Data Warehouse Technologies (ideally Snowflake on Azure).\nYou are familiar with innovative technologies and concepts of the Azure Eco-System (Azure Data Lake Gen2, Azure Data Factory, Kafka/ CDC, Docker/ Containerization, AKS/ Kubernetes, Azure Directory (AD), Data Warehouse Automation and API).\nYou are familiar and you have a proven track record in Data Modelling with Data Vault 2.0.\nYou have a proven track within the diverse fields of Data Warehouse Architecture (Data Vault 2.0, Multiple Layer-, Lamda-, Kappa-), Data Processing (Load Design Patterns, CDC, Stream, Batch, etc.) a/o in the setup and roll-out of complex rights-role concepts.\nAt least, advanced programming experience in SQL.\nFamiliarity with Design Patterns and Object-Oriented thinking. \nHigh motivation to meet deadlines, hands-on mentality, flexibility, and proactive support.\nHigh agile mindset, as well as particularly effective communication and presentation skills.\nEnglish is necessary, German would be a plus.\nA proven project experience in migrating on-premises data warehouses such as SAP BW / SAP HANA, Oracle, Microsoft SQL Server to the Cloud (ideally Snowflake on Azure) would be a great plus.\nA further programming Languages (e.g., SQL, Python, Java, C++) would be a plus.\n\n\nWhat we have to offer:\n\nA flexible home office and schedule policy, virtual budget to improve your home office setup, health insurance, a Pension Plan and a Siemens Share Program time and financial support to your studies, medical center in the facilities, sport groups, 2 days for volunteering initiatives and a cool and relaxed environment.\nAccess to e-learning platforms (Learnlight, Bookboon, Linkedin Learning and more), discounts with partners.\n#Siemens #LXTechHub #ITMakesUsMove\n\nWe recognize that building a diverse workforce is crucial to the success of our business. Therefore, Siemens provides equal employment opportunities to all qualified individuals without regard to race, creed, color, religion, national origin, age, gender, marital status, sexual orientation, or non-disqualifying physical or mental handicap or disability.\nWe strongly encourage applications from a diverse talent pool and welcome the opportunity to discuss workplace adjustments with all our applicants to develop agile working and innovation.\nOrganization: Siemens Financial Services\nCompany: Siemens Financial Services AB\nExperience Level: Mid-level Professional\nFull / Part time: Full-time"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Ericsson",
        "sector": "IT Services and IT Consulting",
        "companySize": "10,001+ employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nAbout This Opportunity\n\nData is a key theme for Group Supply to become data driven. We in Digital Acceleration are on a mission to accelerate digital transformation to strengthen the resilience of the Ericsson Supply Chain. Our focus is to build up outstanding competence in data used by Supply organization, democratize and build the digital capabilities that will help us to automate our business processes, provide intelligent decision support through AI/ML and make data more easily accessible for exploration and analysis. The Digital Acceleration is a truly global team with team members spread across the world helping Group Supply in the next phase of the digitalization journey.\n\nWhat You Will Do\n\n\nWork closely with our Supply Digitalisation team, data engineers, data analysts, data scientist, SW developers, and operations teams\nDesign, and development of the Supply data foundation and platform\nCoach data engineering DevOps teams on CI/CD process\nBuild solutions on the Supply data platform, which currently includes Azure, Databricks, SAP, and other technologies\nStandardize deploy data pipelines to production across the Supply data foundation\nBe instrumental in implementing data mesh across the Supply engineering community\nuse a range of different programming languages to accomplish your tasks \u2013 our main language today is Python and SQL (teams around you will use R, Scala, Python, and JavaScript)\n\nYou will bring\n\n\nMinimum 4 years of experience in Data Engineer\nAble to develop Power BI or Qlik dashboards\nBe self-directed and comfortable supporting the data needs of multiple teams, systems, and products - the right candidate will be excited by the prospect of optimizing or even re-designing the data architecture to support our next generation of products and data initiatives\nBe methodical and goal oriented\nManage a volatile, uncertain, complex, and ambiguous environment \nHave an experience from working in/with:\nModeling of systems, data, and interfaces\nAll phases of development, from gathering requirements, through systemization, development, quality assurance, release & delivery, and operations & maintenance\nOne or preferably more open source components, including but not limited to Azure ADLS, Synapse, AWS ecosystem, Databricks, SAP \nDevOps, Continuous Integration (CI), and Continuous Delivery & Deployment (CD&D)\nAn architectural framework, e.g., TOGAF\n\nApplication\n\nAs the selection process and interviews are ongoing, we encourage you to send your application in English as soon as you can.\n Location:- Stockholm, Sweden.\n If you have any questions, you are welcome to contact Recruiter Asmita Kumari at asmita.a.kumari@ericsson.com\n Note that we cannot process applications sent via email.\n Encouraging a diverse and inclusive organization is core to our values at Ericsson, that's why we nurture it in everything we do. We truly believe that by collaborating with people with different experiences we drive innovation, which is essential for our future growth. We encourage people from all backgrounds to apply and realize their full potential as part of our Ericsson team.\n Ericsson is proud to be an Equal Opportunity and Affirmative Action employer, https://www.ericsson.com/en/careers\n Primary country and city: Sweden (SE) || Sweden : Stockholm : Stockholm\n Req ID: 699216"
    },
    {
        "position": "Senior Data Engineer, Siemens Financial Services",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Siemens",
        "sector": "Automation Machinery\n                                                            Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Solna, Stockholm County, Sweden",
        "post": "About the job \n\nWhat role will you play?\n\nData is at the heart of our business and one of our greatest assets. And we treat it like this.\nWho we are? \n\nWe are the Chapter Data Management at Siemens Financial Service\u2019s Information Technology & Cybersecurity Function. We are a global team of experts accountable for Data Management Architectures & Development Principles shaping Data Management of Today and Tomorrow.\n\nHow will you help shape the future with us?\n\n\n\nIn Collaboration with all relevant stakeholders (e.g., Chapter & Delivery Lead, Business, Data Architects) and based on predefined business & technical requirements, you develop our Data Warehouse and Data Lake of today and tomorrow.\nTherefore, you take end-2-end responsibility from taking over the business requirements for a specific use case/ user story, translating them into technical solution designs (together with the Data Architects) and developing the technical end-2-end solution (incl. ETL-Jobs, if necessary, technical coding, testing, deployment & release).\nIf necessary, you can help yourself in solving technical topics by programming well-fitting technical modules with e.g., Python, Scala a/o C#, e.g. for user defined functions etc.\nYou develop, update and take accountability on our development guidelines (e.g., Data Lake, ADF, DWH) not only for SQL Data Warehouse Developers but also for Low Code DWH Developers and align these guidelines with all stakeholders (e.g., Data Governor, Data & BI Engineers in Business & IT).\nYou take a guiding role for other data engineers (internal & external) by being first contact e.g., for the usage of the data warehouse automation tool, for data modelling topics (Data Vault 2.0) and thus ensure high quality outcome of the data engineering community overall.\nYou build up and moderate communities of practice for (citizen) data engineers and thus train them on our Cloud DWH technologies, automation tools & modelling techniques.\n\n\nWhat You Need to Make Real What Matters:\n\n\n\nThe basis of your success is a degree in Information Technology, Mathematics, Physics, Business Administration or equivalent with at least +5 years\u2019 experience - Gained Knowledge in Finance and Banking Industry is a big plus.\nYou are an enthusiast on data, data warehousing and engineering and you have gained +3 years of experience as a Data Warehousing Developer and/or Data Engineer .\nYou have a proven track record in Cloud Data Warehouse Technologies (ideally Snowflake on Azure), and you are familiar with the Azure Eco-System, such as Azure Data Lake Gen2, Delta Lake, Azure Data Factory and Azure Functions.\nYou are an expert in Data Modelling with Data Vault 2.0 and have worked at least with one of the following Data Warehouse Automation Tools, such as dbt/ dbt cloud, WhereScape, vaultspeed a/o datavault builder.\nYou are familiar with different Data Warehouse Architectures (Multiple Layer-, Lamda-, Kappa-) and Data Processing Techniques (Load Design Patterns, CDC, Stream, Batch, etc.).\nYou have expert programming expertise in SQL.\nYou have expert knowledge in one of the following programming languages such as Python, Scala, Java, C++, C# and you are familiar with design patterns and object-oriented thinking.\nYou have deep knowledge in CI/CD Pipelines, Azure DevOps, Git, Github a/o GitBash.\nYou are highly motivated and convince through your hands-on & can-do mentality, your flexibility, and proactive support. Besides that, you believe in agility and you like to work with KANBAN, SCRUM a/o SaFe.\nFurther, you can communicate technical complex problems easily to technical and non-technical listeners and are not afraid of presenting from time to time in front of a group.\nYou see functional leadership as one possible next step in your carrier.\nEnglish is necessary, German would be a plus.\nExperiences with Low Code/ Citizen DWH Developers would be a plus.\nA proven project experience in migrating on-premises data warehouses such as SAP BW / SAP HANA, Oracle, Microsoft SQL Server to the Cloud (ideally Snowflake on Azure) would be a great plus.\n\n\nWhat we have to offer:\n\nA flexible home office and schedule policy, virtual budget to improve your home office setup, health insurance, a Pension Plan and a Siemens Share Program time and financial support to your studies, medical center in the facilities, sport groups, 2 days for volunteering initiatives and a cool and relaxed environment.\nAccess to e-learning platforms (Learnlight, Bookboon, Linkedin Learning and more), discounts with partners.\nWe recognize that building a diverse workforce is crucial to the success of our business. Therefore, Siemens provides equal employment opportunities to all qualified individuals without regard to race, creed, color, religion, national origin, age, gender, marital status, sexual orientation, or non-disqualifying physical or mental handicap or disability.\n\nWe strongly encourage applications from a diverse talent pool and welcome the opportunity to discuss workplace adjustments with all our applicants to develop agile working and innovation.\n\nOrganization: Siemens Financial Services\nCompany: Siemens Financial Services AB\nExperience Level: Mid-level Professional\nFull / Part time: Full-time"
    },
    {
        "position": "Senior Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Volvo Cars",
        "sector": "Motor Vehicle Manufacturing",
        "companySize": "10,001+ employees",
        "location": "G\u00f6teborg, Vastra Gotaland County, Sweden",
        "post": "About the job \n\nWe Are People Who Want To Make a Difference.\n\nEverything we do starts with people. It\u2019s what makes us different from all other car companies. If you share our belief in the power of people and our passion for human-centric innovation, you will thrive together with brilliant, like-minded colleagues who are committed to making a true difference?\nWe\u2019re creating our own future \n\nAt Volvo Cars, we are making bold digital visions come true. We aim to be the leader in the automotive world by creating a digital ecosystem built around making our customers' lives less complicated. What we all have in common at Volvo Cars is our passion for protecting lives, our endless curiosity, and our dedication to create a new future for the automotive industry. Our human centric focus is what separates us from all other car companies.\nWould you like to influence and craft the technical strategy that helps Volvo Cars to grow and reach our goal of being an electric car company by 2030?\nExcellent, then we would like you to join our Cluster as Senior Data Engineer!\nThe Data & Identity Cluster is a part of the Global Online Experience (GOX) area and our mission is to ensure we know our customers well and keep this information safe and secure. We support the rest of the organisation in using this knowledge to serve the customers in the best possible way. We\u2019re looking for someone that will help us craft a world class data ecosystem that spans across multiple product teams and clusters. We have only just begun this journey in earnest, and you\u2019ll be joining us at a time where you can really have a great impact and help us set the tone for the next chapter in our company's history!\nWhat you\u2019ll do: \n\nAs an early joiner in a new team within a highly prioritized area you will play a key role in setting technical direction and building a world-class data architecture based on Data Mesh principles\nWork in a multi-functional agile team to continuously experiment, iterate and deliver on product objectives\nLeverage our large and diverse datasets to enable use cases with direct impact on the end-customer's digital experience\nWork with state-of-the-art data processing frameworks, technologies, and cloud platforms\nDevelop in different technologies and languages ranging from Java and Scala to Python and SQL\nHelp drive optimization, testing, and tooling to improve data quality\nIncrease developer productivity by building innovative tools that reduce maintenance overhead of working with data pipelines and help increase platform reliability\nAdvocate and advance modern, agile software development and help develop and foster good engineering practices\nDemonstrate and champion an appetite for knowledge and never stop developing as a Data Engineer\nWho you are: \n\nYou are deeply knowledgeable and passionate about modern data architecture principles specialized in either the Data Lake or Data Warehouse tech stack\nYou know and care about sound engineering practices like continuous delivery, defensive programming, and automated testing\nYou care about and have experience with agile software processes, data-driven development, reliability, and responsible experimentation\n\nYou are passionate about crafting clean code and have a steady foundation in coding and building data pipelines in a cloud-based environment\nYou are knowledgeable about data modelling, data access, and data storage techniques\nYou know how to write distributed, high-volume services in Java, Scala or Python and are well versed in the SQL language and databases\n\nYou understand the value of collaboration and partnership within a team\nYou like to have fun at work and take great care in making sure everyone always feels welcome and included!\nYou fully embrace a growth mindset, and encourage others to do the same\nWe offer our employees excellent benefits such as: \n\nPlenty of leave to let you take time off for what's most important in life\nCollective Agreement and ITP pensions\nAn annual allowance to spend on your health and wellbeing\nHow to learn more and apply:\n\nFor questions regarding the recruitment process, please contact Senior Tech Recruiter, Noopur Thatte at noopur.thatte@volvocars.com . Please note that applications via email will not be accepted. Please note that this position is open for several of our locations.\nWho are we?\n\nEverything we do starts with people. Our purpose is to provide freedom to move, in a personal, sustainable and safe way. We are committed to simplifying our customers\u2019 lives by offering better technology solutions that improve their impact on the world and bringing the most advanced mobility innovations to protect them, their loved ones and the people around them.\nVolvo Cars\u2019 continued success is the result of a collaborative, diverse, and inclusive working environment. The people of Volvo Cars are committed to making a difference in our world. Today, we are one of the most well-known and respected car brands, with over 40,000 employees across the globe. We believe in bringing out the best in each other and harnessing the true power of people. At Volvo Cars your career is designed around your talents and aspirations so you can reach your full potential. Join us on a journey of a lifetime as we create safety, autonomous driving and electrification technologies of tomorrow."
    },
    {
        "position": "QA Engineer - Data",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Frontiers",
        "sector": "Research Services",
        "companySize": "1,001-5,000 employees",
        "location": "European Economic Area",
        "post": "About the job \n\nWe are on a mission to make science open so everyone can live healthy lives on a healthy planet\n\nWho We Are\n\nFrontiers is an award-winning open science platform and leading open access scholarly publisher.\n We are one of the largest and most cited publishers globally. To date, our 200,000 freely available research articles have received more than 1 billion views and downloads and 2 million citations. Our journals span science, health, humanities and social sciences, engineering, and sustainability. And we continue to expand into new academic disciplines so more researchers can publish open access.\n Be part of the publishing revolution and help us transform the way research is published, evaluated, and communicated to the world.\n\nThe Role\n\nWe are looking for an enthusiastic QA Engineer to work on testing our data products and data processes that serve efficient and AI-supported article review. We believe that Data is one of our key assets at Frontiers and is one of the main deliverables across the IT teams and depending on the application, we can manage a multitude of things including stream data, batch data, bulk data, processed data, data lake, data pipelines, ETLs and machine learning models.\n While working for us you will be on guard of the quality of data solutions by projecting tests, analyzing data, writing Python scripts or introducing various types of automated tests and quality gates. Moreover, you might also be involved in some cross-team backend validations requiring API or background processes testing.\n By working at Frontiers you will play a key role in shaping the future of science and academic publishing. You will join a thriving company where your contribution will have an immediate effect on the way science is evolving.\n\nWe are offering positions remotely based in the UK, Ireland, Spain, Italy, Poland, Portugal, The Netherlands and Germany. \n\nResponsibilities\n\n\nMapping business and technical requirements into test suites, test cases, automated tests together with quality control processes.\nExecuting tests, reporting and analyzing results in a timely manner.\nDriving the quality mindset of the Development Team together with other QAs.\nMonitoring all stages of the software development lifecycle to identify and resolve bugs or report potential risks.\nWorking closely with the Product Owner to define and verify the Acceptance Criteria of our Backlog items.\nTesting new functionalities by analyzing data in Databricks Notebook and coding Python scripts.\nTesting activities in different stages of our big data ETL pipeline, also by implementing new quality gates.\nCooperating with Machine Learning Engineers, Data Analysts and Scientists to ensure quality and visibility across different data-related teams.\nTesting backend services.\nPreparing test data, monitoring background processes and the data flow.\nSuggesting and introducing improvements in our QA process, also by coding some POCs.\n\n\nRequired Qualifications\n\n\n3+ years of experience as a QA Engineer in the Agile environment.\nExperience working closely with business teams to understand business requirements and anticipate issues.\nStrong knowledge of QA methodology and tools.\nExperience with Data Testing.\nWorking with ETL pipelines.\nCoding skills.\nAnalytical mind and strong organization and problem-solving skills.\nGreat interpersonal and communication skills.\nGood English skills, we are an international company and English is our working language.\n\n\nPreferred Qualifications\n\n\nExperience working with Big Data and Data Lakes.\nExperience with Databricks.\nExperience with Azure DevOps pipelines or Azure Data Factory. \nCoding skills in Spark.\nExperience working with background processes.\nExperience with .Net stack.\nExperience with MongoDB and Elasticsearch or other NoSQL databases.\nExperience with Xray Test Management for JIRA\n\n\nBenefits\n\nWith more than 50 nationalities represented in our global team, you will work regularly with teammates in other countries, and with our community of researchers, editors, and authors from around the globe.\n Our mission to create solutions for healthy lives also extends to the working environment we provide for our employees.\n\nThis includes:\n\n100% remote working\n\nEmployees now have the flexibility to choose where they want to work, with remote working available on a part- or full-time basis (not applicable to some Workplace/IT jobs due to nature of role requiring presence onsite, in the office).\n\nLearning and development\n\nAll employees have access to LinkedIn Learning (and Pluralsight for our technology team), an annual personal learning budget, and dedicated L&D time.\n\nWellbeing\n\nWe offer free online yoga classes, an employee assistance plan, access to the Headspace app, and four wellbeing days on top of your annual leave allowance.\n\nVolunteering opportunities\n\nEmployees can dedicate three days each year to volunteer for a personal cause or through our volunteering partner platform, Alaya.\n\nFrontiers actively embraces diversity and is a safe and welcoming workplace. Recruitment is free from discrimination \u2013 including based on race, national or ethnic origin, age, religion, disability, sex, gender identity or sexual orientation. With over 600 employees from more than 50 different nations, our diversity creates vibrant teams and constantly challenges us to appreciate multiple perspectives."
    },
    {
        "position": "Data Engineering - Experienced Software Engineer",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Zenseact",
        "sector": "Software Development",
        "companySize": "501-1,000 employees",
        "location": "G\u00f6teborg, Vastra Gotaland County, Sweden",
        "post": "About the job \n\nAre you an experienced Python developer with experience in big data management systems? Do you want to work in a cutting edge company where deep learning and neural networks are core to our success to make self driving cars a reality? Do you want to work with really bright people in a warm inclusive culture where it's safe to fail? Would you like to contribute to making traffic accidents a thing of the past and help save millions of lives? Then this role is for you! Read on and apply today - no CV needed at first stage, only contact info and we'll take it from there! \n\nInsights from the Team\nZenseact is flooded with sensor data from our collection fleet. Our data team's objective is to build the tools and pipelines which can manage this data for Zenseact's perception stack development.\nAs a member of our team, you will be responsible for expanding our modular codebase to support annotation pipelines and data curation. In doing so, you will be helping Zenseact in building the first fully autonomous car.\nWe are looking for a passionate individual with a strong background in Python programming, as well as experience in big data management systems, to join our team and make it real.\nYour mission and illustrative day-to-day tasks\n\n\nWork with our modern stack for processing multi-sensor vehicle data and the way in which data is processed and fetched from our collection fleet.\nIntegrate neural networks into our data selection and annotation pipelines.\nImprove our deep learning training data management to enable rapid experimentation and improvement of the perception stack. \n\n\nWhat's in it for you?\nYou have the possibility to influence the direction of our product and the way we work, and the chance to help fulfill our mission of saving lives and shaping the future. Based on your competences and interests you will have the possibility to shape your own role and develop professionally. All this at a global workplace with people from all over the world (we have colleagues from over 50 countries). Zenseact offers a flexible work approach and good work/life balance.\nQualifications & Experiences\n\nPreferred profile:\n\n\n\nSeveral years of professional experience with software engineering.\nSeveral years of professional software development in Python. \nCollaborative coding, testing and continuous integration\nFamiliarity with modern modular architectural patterns\nFamiliarity with database management systems\nAgile mindset and wanting to improve processes with new ideas \nPh.D., M.Sc. or B.Sc. in a related field such as: Computer Science, Machine Learning, Computer Vision, Engineering Physics, Robotics, etc.\n\n\nNice To Have\n\n\n\nExperience working with industrial sensory data (image, LiDAR, CAN, FlexRay, GPS/IMU, sensor calibration, or similar)\nExperience in developing large scale annotation/labeling pipeline development and management\nFamiliarity with machine learning (computer vision)\nFamiliarity with Kubernetes and cloud technologies (Microsoft Azure)\nFamiliarity with distributed data engineering solutions (Spark, Hadoop, Presto and similar)\n\n\nHow do we work?\nFlexible-remote way of working: Zenseact has a flexible and modern approach, thus is happy to offer to its employees the possibility for a combination of work at the office and from home. This doesn't include fully remote work from outside Sweden/China.\nMore About Zenseact\n\nAt Zenseact we want to make safe and intelligent mobility real, for everyone, everywhere. We develop the complete software stack for ADAS and AD, from pixel to torque. Our focus is to build a single cutting-edge software platform in order to serve various levels of autonomy and offer unequaled scalability at the same time. We operate out of Gothenburg, Sweden and Shanghai, China. Zenseact\u2019s first self-driving deployment will be launched on the next-generation vehicle platform from Volvo Cars and Polestar.\nEvery year, 1.350.000 people are killed in traffic accidents, another 55.000.000 people are injured. With the push of our technology and the use of our software, we can move towards zero, faster. That's our purpose and that's why we get up in the morning. We feel that is a goal worth pursuing.\nBut technology, software, tools and datasets would not mean much without the best people behind the wheel to drive them. At Zenseact, some five hundred of the best engineering minds globally, stationed across two continents, are collaborating with the same passion: to bring autonomous driving to the streets for real and create a safer journey for everyone. This is part of our culture and how we work, develop and grow together.\nZenseact works proactively to create a culture of diversity and inclusion, where individual differences are appreciated and respected. To drive innovation we see diversity as an asset, which means we value and respect differences in gender, race, ethnicity, religion or other belief, disability, sexual orientation or age etc.\n\nInterviews are held on a continuous basis, so we highly recommend that you submit your application at your earliest convenience.\n\nWe develop the complete software stack for ADAS and AD, from sensing to actuation. Our focus is to build a single cutting-edge software platform in order to serve various levels of autonomy and offer unequaled scalability at the same time. We operate in Sweden and China."
    },
    {
        "position": "Senior Data Engineer to Bosch",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Nexer Recruit",
        "sector": "Staffing and Recruiting",
        "companySize": "11-50 employees",
        "location": "Lund, Sk\u00e5ne County, Sweden",
        "post": "About the job \n Come join us at Bosch in this new role as Data Engineer! This is an interesting opportunity where you will join an AI & Cloud team and shape the future with a leading global supplier of technology and services. If you enjoy working with the latest technologies within your area, and with colleagues around the globe, then this is the right challenge for you. Welcome to a world, where your ideas lead to something big. Welcome to Bosch!\n\nYOU WILL\n\nAs a Data Engineer At Bosch There Is An Opportunity To Take On Challenges In Many Different Areas And Projects, With Topics Like\n\nYou will be part of a team that deliver comprehensive big data and cloud infrastructure and software tools to support Bosch data and AI projects. We are a new and growing team at the R&D-center in Lund that has skilled and innovative colleagues within cloud, data and machine learning engineering. You will also have close co-operation with international teams within Bosch, such as Bosch center for AI.\n\nBuild reliable and scalable data pipelines.\nTake part in the architecture and design process of new use cases.\nWork together with customers, e.g. Data Scientists, to realize data- and AI products.\nBuild solutions both in cloud and on-premise \u2013 as well as hybrid setups.\nTake ownership of pipelines and tools.\n\nYOU ARE\n\nExamples Of Meriting Topics Are\n\nWe are looking for you who have several years of experience as a data engineer or similar role. In order to be successful in this role, we see that a broad range of knowledge is required.\n\nsoftware development of production quality code in one or more programming languages, e.g. Scala, Python and Java etc.\nBig Data technologies and distributed computing, e.g. data processing with Spark and Scala.\nData management, e.g. APIs, accessibility, security, metadata, schemas etc.\nDatabase technologies \u2013 both SQL and NoSQL\nData processing methodologies, tools and orchestration, e.g. ETL, Batch/Streaming, Kafka, Airflow, etc.\n\nYou have a bachelor\u2019s or master\u2019s degree in Computer Science or a related technical field, or equivalent practical experience. We expect you to have excellent verbal and written communication skills in English. As a person you are a self- motivated team player who brings a positive, co-operative and knowledge-sharing attitude. You are communicative, responsive and like to work with a customer and goal focus. You also have good critical thinking skills, a continuous learning mindset and a strong sense of quality.\n\nWANT TO LEARN MORE?\n\nWe are collaborating with Nexer Recruit regarding this recruitment. If you want to learn more about the position please contact recruitment consultant Jenny Nilsson at jenny.nilsson@nexergroup.com / +46 703 01 82 79 or Johanna V\u00e4rmfors at johanna.varmfors@nexergroup.com / +46 730 82 12 30. We are looking forward to hearing from you!\n\nBOSCH AS AN EMPLOYER\n\nThe development site in Lund focuses on software for the automotive industry, electric bikes and the internet of things with excellence in connectivity, open source, agile development, security software and software update over-the-air. Whether in the areas of mobility solutions, consumer goods, industrial technology or energy and building technology \u2013 with us, you will have the chance to improve quality of life all across the globe. At Bosch you will have the opportunity to work in a modern agile software organization.\n We offer you flexible worktime options, benefits and services, medical services, employee discounts, various sports and health opportunities, catering facilities, access to local public transport, room for creativity, urban infrastructures, rural surroundings. Diversity is our strength! At Bosch we look at diversity in gender, generation, nationalities and culture as our advantage. For more information visit www.bosch.se ."
    },
    {
        "position": "Data Engineer to Financial Crime Prevention",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "SEB",
        "sector": "Banking",
        "companySize": "10,001+ employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n SEB is a leading northern European financial services group, and at the same time, one of the largest IT employers in the Nordics. Banking is changing rapidly, and we are proud of our reputation for being entrepreneurial and innovative in the face of change. Our brilliant techies work hard to future proof SEB\u2019s digital architecture and customer products because it genuinely makes a huge impact for our customers and colleagues. Would you like to work in a team of data engineering experts responsible for delivering large-scale Big Data solution for SEB? We are a now looking for a skilled Data Engineer to join our team working with our growing area Financial Crime Prevention (FCP).\nWhat You Will Be Doing\n\nAs Data Engineer in the Financial Crime Prevention team you will combat fraud against our customers and protecting the bank from money laundering, this is central not only to SEB but for society as such. You will work in an environment with multiple Agile teams located in both Stockholm and Riga.\nYou will be responsible for developing and maintaining new technical capabilities in a smart way to allow us to detect bad actors. Our technical environment consists of but is not limited to Java, Scala, Python, Hadoop, Kafka, NiFi, Spark, Grafana and Elastic Search. Here you will have a chance to make a difference and work with challenging tasks. You will have great opportunities to both develop and take further steps in your career working within a highly collaborative environment.\nWho We Are Looking For\n\nTo succeed in your role with us you should really love solving engineering problems and have the following experiences/ mindset.\n\nExtensive experience in Java programming languageExperience with Scala, Hadoop, Kafka, SparkExperience in Jenkins, Tekton, OpenShift and Kubernetes is considered an advantage.Analytical mindset and ability to solve complex technical problemsPassion for challenges that drive your personal development and professional growthBeing a team player open for growth and learning is crucially important for the role\n\n\nWhat We Offer\n\nWe offer many experiences and benefits to our employees, and there is nuance to every individual\u2019s career experience, but the elements that define the core of our offering are:\n\nExtensive training and learning opportunitiesWork-life balanceInternational opportunities and working environmentAccess to SEB staff banking with exclusive benefitsInnovative company in forefront of technologyChallenging, cutting-edge workOpportunities to help transform an industryExcellent office environment\n\n\nLearn more about working at SEB www.sebgroup.com/career \n\nI t is our fundamental belief that inclusion and diversity is crucial for our future success. We strive to have an inclusive, value-driven culture where employees feel valued, respected and involved irrespective of who they are, what they believe or where they come from. \nReady to join?\n\nFeel free to send in your application today, but no later than 2022-09-29. If you have questions about the position please contact Katarina Pihl, Talent Acquisition partner by mail katarina.pihl@seb.se. \nWelcome to a community of tech-savvy and passionate employees from all corners of the world. SEB is in fact one of the largest IT employers in the Nordics. Together we future proof a world of financial flows by exploring and implementing modern digital architecture and state-of-the-art technology. We are driven by collaboration, insight, and friendship. But also, a desire to change and improve. All in all, it creates a balance - where life and a stable yet exciting job can co-exist. If you want to shape tomorrow's bank - continue reading and apply today.\n\nRead more:sebgroup.com/techcareers"
    },
    {
        "position": "Senior Data Engineer \u2013 Volvo Group Connected Solutions",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Volvo Group",
        "sector": "Motor Vehicle Manufacturing",
        "companySize": "10,001+ employees",
        "location": "G\u00f6teborg, Vastra Gotaland County, Sweden",
        "post": "About the job \n\nPosition Description\n\nDo you want to be part of a global organisation leading the development of the\n Volvo Group\u2019s connected services and solutions? For us \u201cconnected for efficiency, sustainability and safety\u201d is much more than a tag-line. If this sounds interesting to you, keep on reading!\n\nAt Volvo Group Connected Solutions we work at the forefront of connectivity with data from over\n 1 000 000 Volvo Group customer assets. Together with customers, partners and the Volvo Group we create real value, not only for our customers but also for society at large.\n\nThis is us, your new colleagues\n\nAs you can imagine, keeping track of over 1 000 000 connected customer assets rolling around the world is indeed a challenge. Now ponder, that vehicles in a few years will be autonomous \u2013 and you\u2019ve got the challenge of your life. Our Technology team manages the development and maintenance of our global connectivity platform \u2013 and your experience is needed.\n We are now looking for a Senior Data Engineer within Data Management Group. Here you will be an integral part of the team focused on managing and delivering data centric services to VGCS and other stakeholders.\n\nKey Responsibilities\n\nDeveloping and maintaining Data Lake services. Build large-scale batch and real-time data pipelines with data processing frameworks in AWS. Creates and manages environments for advanced analytics/machine/deep learning and AI Leverages best practices in continuous integration and delivery Pre-process, clean and structures data to facilitate data exploration and advanced analytics/Machine Learning activities Learns and uses modern data preparation, integration and AI-enabled metadata management tools and techniques. Performs intelligent sampling and caching. Recommends and implements automation in existing and future integration flows. Helps improving data quality by driving advancements in data acquisition, testing and tooling Ensuring a solid operation and maintenance of our platform Automation of system installation and configuration Contributing to Roadmap and other improvements Providing Runtime support for services \n\n\nYour profile\n\n\nMinimum 5 years\u2019 experience in the Data Engineer role\nDegree in Computer Science or similar\nExperience in data analysis and data presentations.\nGood analytical and conceptual thinking skills.\nExperienced in AWS lake formation, AWS Glue, AWS Step Function and other AWS analytical Services\nExperience in Python Programming language\nExperience in PySpark\n\n\n\nGood-to-have Experience\n\nMicroservice architecture 24/7 Service delivery environment Experience from the Connected Vehicle Industry is a plus. Candidate should have a valid work permit. \n\n\n\nWhat can we offer you?\n\nYou will be part of a team that creates great results through amazing people, strong relationships and a high performance culture. We are of course using the latest technologies delivering a very modern micro service based service platform hosted in the cloud. We use agile methods and as we are adopting the DevOps model your work will cover a broad spectrum, all the way from developing prototypes of future world class applications to managing the lifecycle of the existing ones.\n Our main hub and headquarter is in Lindholmen Science Park in Gothenburg, a vibrant area that lives and breathes new technology like IoT, autonomous driving, electro mobility and digitalization.\n\nWelcome to the heart of connectivity at Volvo Group Connected Solutions!\n Want to know more? Contact us!\n\nPlease contact Sanjeev Singh , Manager Data Management & Data Lake Services, +46 703 9021237\n Kindly note that due to GDPR, we will not accept applications via mail. Please use our career site.\n\nAbout Us\n\nThe Volvo Group drives prosperity through transport solutions, offering trucks, buses, construction equipment, power solutions for marine and industrial applications, financing and services that increase our customers\u2019 uptime and productivity. Founded in 1927, the Volvo Group is committed to shaping the future landscape of sustainable transport and infrastructure solutions. Countless career opportunities are offered across the group\u2019s leading brands and entities that share a culture of Trust, Passion, High Performance, Change and Customer Success.\n www.volvogroup.com/career.\n\nVolvo Group Connected Solutions is a global organization that leads the development of Volvo\u2019s connected services and solutions of tomorrow. We work at the forefront of connectivity by collecting and analyzing data from over 1 000 000 Volvo customer assets. The organization is set-up to deliver competitive offerings, shorten time to market and provide an arena for new service innovations together with customers, partners and the Volvo Group.\n Come and visit us online !\n\nAuto req ID\n\n129932BR\n\nOrganization\n\nConnected Solutions\n\nState / Province\n\nV\u00e4stra G\u00f6taland\n\nCity/Town\n\nG\u00f6teborg\n\nEmployment/Assignment Type\n\nRegular\n\nTravel Required (maximum)\n\nOccasional Travel\n\nFunctional Area\n\nInformation Technology\n\nLast application date\n\n15-Oct-2022"
    },
    {
        "position": "Data Scientist Business",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Oriflame Cosmetics",
        "sector": "Personal Care Product\n                                                            Manufacturing",
        "companySize": "5,001-10,000 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nData Scientist Business, Global Digital Innovation Lab \nWe are Oriflame \nFounded in Sweden 1967, we are a social selling beauty company present in over 60 countries around the world. We have a different and holistic view on beauty \u2013 Beauty by Sweden. For us beauty is a way of life; to be healthy, enjoy beautiful skin and to find your personal expression. Our portfolio of nature-inspired beauty products powered by science are marketed through approximately 3 million Independent Oriflame Brand Partners. \n1.Purpose of the role: \n\nTo further strengthen our Global Digital Innovation Lab, we are searching for Data Scientist Business who will focus on data science application on marketing campaign planning and merchandising; discovering consumer purchasing behaviors and demand patterns to improve customer\u2019s offer personalization; providing advanced data analytics and data driven insights as a foundation for future AI/ML algorithms development and further digital transformation of Oriflame. We are a part of Global Business Tech & Digital Experience department. We create value through finding ways by applying new technologies to social selling and exploring new ways of doing business in rapidly changing environment. We partner with key business stakeholders, software vendors, Digital Services- and IT-teams to provide our Brand Partners with up-to-date digital solutions to empower them in building their business with Oriflame. Every big journey starts with small steps and GDIL has been in cooperation with various Oriflame markets where we can run our experiments before rolling out innovations globally.2.What will you do? \n\nAs a Data Scientist Business you will:\n\nConduct big data analysis to proactively identify insights and AI/ML solutions for automation of commercial processes.Apply data science to identify demand patterns in correlation with multiple factors like pricing, merchandising, promotion, and placement.Explore big data of Brand Partners\u2019 and Customers\u2019 behaviors to discover insights and enrich customer segmentation with new attributes for further improvement personalization.Design, train and implement new AI/ML algorithms to improve and streamline existing processes as well as finding new areas for application of data science to meet evolving business requirements.Actively participate in innovation testing projects and provide business with actionable insights based on advanced data analytics.\n\n\n3.Your background and your qualifications: \n\n\nUniversity degree in statistics, math, computer science, physics, or another related fieldKnowledge in Python, R and SQLPrevious experience in data science projects is a plus, but we also consider hiring talented graduates and post-graduatesOrganized, able to manage challenges and prioritize tasks at all project stagesInnovative, curious, and willing to learnFluent in written and spoken EnglishMore than anything, to love data and its exploration\n\n\n4.What do we offer? \n\n\nWith us you get the opportunity to work in an international and diverse environment with top level brand strategists, project managers, IT professionals, creatives, and innovative scientists, just to name a few. And we are all found at our headquarters in the heart of Stockholm city. We provide competitive salary and flexibility through hybrid way of working. We can also provide relocation support if the chosen candidate is outside of Sweden.Does this match your profile and expectations? \n\n\n\nThen don\u2019t hesitate and apply now. Or spread the word to people who might be the right match.\nInformation Technology"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Kindred Group plc",
        "sector": "Gambling Facilities and\n                                                            Casinos",
        "companySize": "1,001-5,000 employees",
        "location": "Stockholm City, Stockholm County, Sweden",
        "post": "About the job \n\nThe role\n\nKindred is looking for a highly skilled developer to join the Data Engineering team whose vision is to drive and support Kindred to be the most data-driven gambling company in the world!\nAs a Data Engineer in Kindred, you will be part of the Data Department under the overall Technology organization. Joining this team, you will be playing a big part in the way we shape our business by closely collaborating with different stakeholders across the business and ensure they get the most out of the data in terms of reporting, statistics and form the basis of the decision making and analytical processes.\nThe successful candidate will be responsible for the end to end solution from data ingestion, preparation of data to building segmentations and reporting solutions in both Cloud and On-Prem Data Warehouse.\nWhat You Will Do\n\n\nDesign, enhance and implement data ingestion from wider range of data sources like Oracle databases , event sourcing systems , Rest API , SFTP files into our Oracle based data warehouse. Develop and maintain data and reporting solutions in both Cloud and On-Prem Data Warehouse. Developing advanced Oracle PL/SQL, writing and optimizing/tuning queries over large data sets. Oracle APEX development. Developing dashboards and reporting solutions (e.g. Qlik Sense). Data investigations and problem-solving from internal and external stakeholders. Setting up Apache Kafka streaming jobs. Proactively engage with stakeholders and deliver their reporting requirements. Supporting Data Platforms (including occasional on-call support & incident management). Work in an Agile way with open communication, while delivering top quality products and services. \n\n\nWhat You Have Done\n\n\nStrong background of working with Oracle databases (12c and above) in a Developer/Analyst role using Oracle SQL and PL/SQL. Experience with dealing with large data volumes. Preferably 5+ years working with data. Good understanding of Data Warehouse concepts. Implementation of ETL processes and data structure. Experience with tuning of SQL queries, reports and processes. Experience with developing dashboards and reporting solution for business end-users. Knowledge of any basic cloud architecture (e.g. AWS). Good attitude and willingness to learn new skills and technologies. \n\n\nIn addition, it would be an advantage if you also have:\n\nExperience with reporting tools (e.g. Qlik). Hands on experience with cloud data warehouse like AWS Redshift. Hands on experience on Kafka. Working knowledge with other programming languages like Python or core Java. Exposure to other AWS service like S3, Glue, Lambda, EMR. Experience with building pipeline through Matillion or similar. \n\nApplication Process \n\nClick on the \"Apply Now\" button and complete the short web form. Please add a covering letter in English to let us know your motivation for applying and your salary expectation. Our Talent Acquisition team will be in touch soon.\nKindred is an equal opportunities employer committed to employing a diverse workforce and an inclusive culture. As such we oppose all forms of discrimination in the workplace. We create equal opportunities for all our applicants and will treat people equally regardless of and not limited to, gender, age, disability, race, sexual orientation. We are committed not only to our legal obligations but also to the positive promotion that equal opportunities bring to our operations as set out in our sustainability framework.Job Alerts \n\nNot suited to this role but interested in working at Kindred Group? \nWe are always on the lookout for talented, passionate people to join our global teams so if you'd like us to let you know when suitable jobs come up, please click on \u201cRegister for Alerts\u201d."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Hive Streaming",
        "sector": "Technology, Information and\n                                                            Internet",
        "companySize": "51-200 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n It\u2019s an exciting time to work at Hive Streaming! We have grown significantly over the last few years and now rank among the top SaaS companies in the Nordics. In 2021, Microsoft selected Hive to become the recipient of its prestigious ISV of the Year award.\n In these turbulent times, excellent employee video communication is crucial for enterprise companies to create engagement and alignment to survive and succeed. At Hive Streaming we are proud to offer an industry-leading solution to this demand. We help multiple Fortune 500 customers analyse, secure, and optimize their video experience on a daily basis.\n\nHive and Sustainable Growth\n\nWe have been a hypergrowth company for a long time, doubling our revenue yearly. For the next phase of our journey, we want to continue that growth by financing it ourselves. By the end of 2022, we will be able to drive additional growth without the need for external capital. This is an exciting thing!\n We want to grow sustainably when it comes to revenue, when it comes to our people and our customers; they are what truly makes us succeed.\n To help our customers to grow sustainably, we will help them by creating alignment and engagement of their employees. We will help them to reduce their carbon footprint through less travel and by increasing the lifespan of their existing infrastructure. All this is at the core of our product, the Hive Video Experience Platform.\n\nWant to join our journey?\n\nWe are looking for a versatile Data Engineer with strong software engineering skills to join our Video Analytics team. You will be part of our hybrid workplace, which means you will be working partly remotely and at our office in Stockholm.\n In this role, you will be a major contributor in designing and implementing the big data pipelines - real-time and batch - powering our innovative video analytics products! You will, together with the team, help to evolve our state-of-the-art data platform and share the responsibility for delivering high quality reliable data solutions on top of it.\n\nWhat is Hive Video Analytics?\n\nThe Video Analytics team is a part of Hive Streaming's Product Office and works from Hive\u2019s office in Stockholm. The team is responsible for Hive\u2019s industry leading video analytics products. We offer actionable and personalized insights on our customers' video communications based on unique data on employee engagement, network performance, video quality and reach.\n Our wide skill set allows us to independently handle product and feature requests from design to release. From the ingestion of data and live or \u201con-time\u201d data processing, to presenting the valuable insights through powerful, user-centric data visualizations. In our team we share the responsibility for our work and strive for empowerment and innovation.\n\nThe Perks of Working at Hive\n\n\ud83c\udfc2\ud83c\udffc Have it your way! At the office, at home or on the ski slope (did I go too far?) - your way is the best way but flexibility is everyone's way at Hive! We use Microsoft Teams to collaborate, we have digital kick-off's and provide you opportunities to work either remotely or in a hybrid setting.\n \ud83e\udde1 Without you = no Hive? We are a fast-paced, global (over 35 nationalities among our 100 co-workers around the globe) scale-up company that empowers every single co-worker. Everyone is unique and important for our growth. You will play an important role in the company\u2019s future success.\n \ud83e\uddd8\ud83c\udffd\u200d\u2640\ufe0f Flexibility (cannot say it enough)... we have flexible working hours to encourage work-life balance.\n \ud83c\udf0e Contribution to innovation and a better world! Hive helps enterprises to communicate through video instead of flying people in from across the globe, which means Hive employees directly contribute to a greener world!\n \ud83c\udf08 The boring but most important... salaries are good, insurances are good, awesome health benefits (did someone say free massage at the office?) and hopefully you stay good (& healthy)!\n\nWorking as a Data Engineer you will\u2026\n\n\nDesign and implement big data pipelines on top of our data platform.\nDevelop solutions leveraging our tech stack: Spark/Scala, Databricks and Delta lake.\nWork on end-to-end delivery of data to our analytical applications. \nContribute in shaping our product by bringing insights and innovative ideas to discussions. \nCollaborate with the team to engineer high quality and reliable solutions.\n\nPrevious Experience\n\n\n2+ years working as a Software/Data Engineer.Designing, implementing and troubleshooting data pipelines. \nApache Spark and/or other distributed data processing frameworks.\nDelivering tested and maintainable code in projects with multiple contributors.\nCloud environments and familiar with common cloud-native data storage.\n\nThe perfect match will\nbe\u2026\n\n\nan effective communicator (in English, both verbal and written), seeking first to understand and then to be understood. \nsomeone who enjoys collaborative problem solving in an Agile environment.\naligned and want to live by our Core Values: customer-centricity, innovation, empowerment.\n\nWe hope you are excited about this opportunity and look forward to your application!"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Formulate by RELEX",
        "sector": "Retail",
        "companySize": "11-50 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nDo you want to be part of our exciting growth journey and help our customers optimise their promotion campaigns through our world class retail analytics platform?\n\n\nWe are currently hiring for the position as Data Engineer to join our growing team in our office in central Stockholm.\n\n\nAbout Formulate\nOur mission is to help retailers make better, data-enabled decisions that save time, drive sustainable revenues, and (perhaps most importantly) reduce waste. We help campaign planners at bricks-and-mortar retailers (like Coop and 7-ELEVEN) and online retailers (like Mathem), to optimize their promotions. To do this most effectively, we\u2019ve developed a solution that\u2019s part analytics suite, part planning tool. We provide insights; we also make sure they\u2019re actionable.\n\n\nAs you\u2019ve probably grasped, Formulate is a rich solution, with multiple functions and user stories. We need someone who thrives on this complexity; who relishes large, complex challenges, and is ready to tackle them as part of a smart, supportive team. Work with us and you\u2019ll learn a lot, quickly, in an environment where everyone is rooting for you to succeed. Read more about Formulate and our values here.\n\n\nIn May 2022 Formulate joined RELEX Solutions, a hyper-growth Finnish supply chain scaleup with a $5bn valuation. Together we\u2019re building the next generation of unified retail solutions. So join us! Get all the benefits of an agile startup plus the muscle and resources of a global scaleup. \n\n\nAbout the position \nAs Data Engineer at Formulate you'll be part of the core of what we are - without our Data science/engineering team - no Formulate. working as Data Engineer at Formulate you could expect tasks and challenges like:\n\n\n\nDesign, build and test data models \nContribute to building and enhancing our data infrastructure \nTesting ideas and hypotheses\nSupport and collaborate with your team in order to optimize processes for collecting, testing, and governing data across the data stack\n\n\n\nWe would love to get in touch if you have\n\nB.Sc. or higher within engineering, statistics or similar\nSome real experience in a Data Engineering role\nYou're comfortable in at least one of the following: Python, Go \nYou have an understanding of how to maintain a modern data stack \nYou have have a deep understanding of advanced data processing pipelines and repositories\nExperience with modern data engineering techniques\nUnderstanding of data modeling techniques and how to use them \n\n\n\nWhat you can expect from us\n\nCompetitive salary \nBenefits including pension, wellness allowance, health insurance and more\nAn opportunity to work with great engineers \nFlexible remote; work set up\nModern office in central Stockholm\n\n\n\nIf you join us, you'll work with a colourful mix of people from across the world, with bundles of creativity, drive, empathy, and humour!\n\n\nsounds interesting? drop us a line, we would definitely like to get in touch with you!"
    },
    {
        "position": "CX Data Analyst",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Polestar",
        "sector": "Motor Vehicle Manufacturing",
        "companySize": "1,001-5,000 employees",
        "location": "G\u00f6teborg, Vastra Gotaland County, Sweden",
        "post": "About the job \n\nWe\u2019re expanding, and we need people who share our vision and want to be part of something different. We are now looking for an experienced Customer Experience Data Analyst, to be a part of Polestar's Measurement & Analytics team.\n\n\n\n\nLet us describe the challenge we offer\nAs Data Analyst at Polestar, you will be an important contributor to improving the customer experience by establishing a data-driven culture within our organization. You will be a member of our Measurement & Analytics team with other analysts, data scientists, and user researchers within Customer Experience. Our Measurement & Analytics team is a part Polestars global Insights & Analytics team, which is part of our whole Customer Experience department.\n\n\nThis position is based at our HQ in Gothenburg, Sweden. We understand that work-life balance isn\u2019t easy, and of course, welcome our employees to work flexible hours and from home a couple of days per week if needed. We believe in empowerment.\n\n\n\n\nWhat you\u00b4ll do\nThis role is within Customer Insight & Analytics and you will therefore focus on our customer-related data which includes accessing raw data and transforming them into actionable insights as well as responsibilities for tools and other external resources to establish a global scalable framework.\n\n\nYour focus will be to work closely with our associated team Insights & Research to combine your quantitative insights together with their qualitative research. We believe that when you combine qualitative and quantitative analysis your deliveries will be much stronger.\n\n\nOther tasks you will be accountable for:\n\nSimplifying, explaining and with the help of insights making a change\nCollaborate with data scientists and data analysts to solve business challenges by applying ML/AI and statistics to various data sets\nCalculate the significance of data variances and applies an array of statistical methods\n\n\n\n\n\nWho you are\nTo be successful in this role we believe you have:\n\n\n\nA strong proven knowledge within deep dive analysis of everything from Customer care data, survey data, and other structured data sets, BigQuery, SQL, R or Python and Salesforce (or similar).\nIn addition to methods like regression analysis, you are probably familiar with free text analysis, sentiment score and n-grams. NPS, CES and CSAT are metrics you should feel comfortable using and calculating.\nYou should be comfortable in visualizing and presenting your insights as well as working with Microsoft Power BI or Qlik. \nKnowledge of GCP, Azure, and various Google APIs (ie. translation, NLP) is a plus.\n\n\n\nAt Polestar, you will be part of a cross-functional and international team, with English as a natural language for written and spoken communication.\n\n\n\n\nPeople at Polestar\nWe know that a change is needed. We also know that each one of us can help bring about that change. Our commitment to becoming climate-neutral by 2040 is just as important to us as being inclusive, diverse, and innovative. Together, we are creating, collaborating and experimenting to usher in a new era of sustainable mobility.\n\n\nWe are an electric performance brand, determined to improve the society we live in.\n\n\n\n\nIs this you? If you are interested in joining the Polestar family, don't wait with submitting your application. We apply a continuous selection process and the job post will be open until the position is filled.\n\n\nAre you ready for the journey? Which is electric by the way..."
    },
    {
        "position": "Lead Data Intelligence Engineer",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Volvo Cars",
        "sector": "Motor Vehicle Manufacturing",
        "companySize": "10,001+ employees",
        "location": "G\u00f6teborg, Vastra Gotaland County, Sweden",
        "post": "About the job \n\nYour leadership will make a difference.\n\nAt Volvo Cars, we are always looking for world-class leaders who bring out the best in our people. If you want to be part of leading and inspiring our mission to change the automotive experience and make people\u2019s lives less complicated, then we have the job for you.\n\nWhat\u2019s in it for you in this role?\n\nAs Lead Data Intelligence Engineer you will be spearheading the establishment and competence to derive business insight and intelligence from multiple data sources to unearth new perspectives and business actions levers. The scope and opportunities within this role are vast, from identifying use cases and assessing the related data acquisition complexity to defining and implementing the data infrastructure and technologies, processes, and roadmaps.\n Equally important as taking advantage from the rise in AI, new tools and services, is establishing the premise and foundation for data management, integration, and integrity. This role will allow a business-driven data science capability to develop a human centric, data-led and technology driven approach to deliver on our intelligent enterprise ambitions.\n You will be part of driving the transformation in the way we work, underpinned by sound business processes and digital solutions, whilst cultivating a continuous improvement culture to meet the ever-increasing business expectations. The ambition is clear \u2013 we will automate all transactional processes and attain full visibility and control over our global activities.\n\nWhat You\u2019ll Do In This Important Role.\n\nYou will be part of the Global Customs and Export Controls (GC&EC) Tools team consisting of about 5-10 experienced customs professionals in Europe, USA, and China. Together with the GC&EC, broader Supply Chain Management (SCM) and Digital Office, you will:\nCreate new value by identifying use cases for growth impact, internal process optimization, duty savings, utilization of preferential agreements.Moving our data to intelligent platforms on the cloud. Untrap original and existing data to build a data supply chain that handles internal and external data.Apply automation to unify big data from multiple sources, curate and make it easily consumable.Transition from legacy enterprise data warehouse to a highly scalable and agile platforms.Identify where data comes from, define the sourcing strategy, and generate a data pipeline that ensures data preparation is suitable for processing in line with data quality principles. Maximise value from data lakes that embeds governance, lineage, and security.Stay abreast of the latest technologies that are constantly evolving and which Volvo Cars can take advantage of.Manage the delivery process: Scoping definition, data identification and data preparation/initial insights, modeling, and industrialization (deployment, model monitoring and end user feedback).\n\nIt is important to equip our business/functional leads to co-create on our data journey.\n\nDo you fit the profile? \n\nThe job of our Lead Data Intelligence Engineer will be split into several aspects such as: programming tools, data analysis, data visualization, machine learning, data engineering among many others.\n You are a systems thinker that critically analyses and formulates the business requirement and drive initiatives to fruition that is not afraid to challenge the status quo to achieve the best possible outcome for the company. You are proactive and takes ownership for the business outcomes, with a strong drive and problem-resolution approach.\n From a technical perspective, this role would require you to have:\nB.E, MCA, BSc, MSc, or equivalent training in Industrial Engineering, Data Science, Computer Science, or other relevant subject area.Ability to understand data modeling techniquesAbility to interact with end users and translate business needs to technical specificationsDesign, build and deploy BI solutions (e.g., reporting tools) Work closely with the various teams to consume new data sources, refine existing data source, and build out data visualizations and self-service data access capabilitiesExposure to deep learning frameworks (Tensorflow/Keras) and data mining projects (CRISP-DM)\n\nSkill and prior experience with the following applications:\nBI Reporting: PowerBI/TableauDatabase: MS SQL Server/Teradata/MySQL/SnowflakeStrong experience in SQL programming and debugging skillsProficient in writing Data Analysis Expression (DAX) queries Knowledge in any ETL tools like ADF/Wherescape/Matillion/InformaticaKnowledge in Python and able to integrate with PowerBISkilled in data visualization through various PowerBI report componentsWorking knowledge in Cloud AWS, Azure, GCPBig Data experience in Spark SQL, Scala, PySparkGood understanding on data governance and master data management\n\nHow To Learn More And Apply.\n\nFor questions about the position please contact Senior Manager Tools \u2013 Global Customs and Export Controls, Jacobus de Wet at email: jacobus.de.wet@volvocars.com or telephone + 46 72 191 7636. For questions regarding the recruitment process, please contact recruiter Ayla Kutlay at email: ayla.kutlay@volvocars.com. The closing date for this opportunity is: September 20, 2022. Please note that applications via email will not be accepted.\n\nWho are we?\n\nEverything we do starts with people. Our purpose is to provide freedom to move, in a personal, sustainable and safe way. We are committed to simplifying our customers\u2019 lives by offering better technology solutions that improve their impact on the world and bringing the most advanced mobility innovations to protect them, their loved ones and the people around them.\n Volvo Cars\u2019 continued success is the result of a collaborative, diverse, and inclusive working environment. The people of Volvo Cars are committed to making a difference in our world. Today, we are one of the most well-known and respected car brands, with over 40,000 employees across the globe. We believe in bringing out the best in each other and harnessing the true power of people. At Volvo Cars your career is designed around your talents and aspirations so you can reach your full potential. Join us on a journey of a lifetime as we create safety, autonomous driving and electrification technologies of tomorrow."
    },
    {
        "position": "Experienced Data Engineer - Autonomous Vehicle Logging",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Scania Group",
        "sector": "Motor Vehicle Manufacturing",
        "companySize": "10,001+ employees",
        "location": "S\u00f6dert\u00e4lje, Stockholm County, Sweden",
        "post": "About the job \n Scania is now undergoing a transformation from being a supplier of trucks, buses and engines to a supplier of complete and sustainable transport solutions.\nWe are looking for an experienced Data Engineer to strengthen our team to create valuable and earily consumable information from operational data and enabling more accessible analytics. \n\nAbout The Team\n\nThe Data Engineering team\u2019s mission is to enable Scania Autonomous and our users to make collaborative decisions through data and insight. The current mission is to centralize the data and decentralize its usage. The volume and variety of data we are dealing with are growing rapidly. The team consists of people from various backgrounds so you will be collaborating with a diverse group; we work closely with our Data Scientists and Machine Learning Engineers. We have solved many technical challenges, but we have many more left to tackle to achieve our mission. You will be working as part of an agile team, which is responsible for the complete process from requirement handling to production and maintenance.\nAbout The Role\n\nData Engineers at Scania provide vital service to analysts, data scientists, and everyone who uses data-based insights in their work. We are looking for someone who will help us develop data pipelines, build self-serve data import, and export tools for our partner teams. In this role, you will see the direct impact of your work on our initiatives in improving the Scania Autonomous product, growing the user base, and providing insights.\nWhat You\u2019ll Do\n\n\n\nBuild and maintain the data platform for Scania Autonomous \nDevelop custom ETL pipelines using Apache Spark \nPerform platform work for our Databricks environment hosted on AWS (Amazon Web Services) \nHelp to drive key platform capabilities such as data quality, governance, and discoverability \nDesign and implement solutions to challenges that grow \n\n\nWhat You\u2019ll Need\n\n\n\nExperience working as a Data Engineer for 3y+ on mid to generous-size projects. \nHands-on experience using industry-standard tools, Spark, Databricks, for data pipelines in cloud environments \nProven programming skills with (any of) Python and SQL \nSolid interpersonal skills, experience collaborating with diverse types of data consumers \nAbility to propose and implement technical solutions to business problems \nDegree in Computer Science, IT, or similar field alternative equivalent work experience \nProficiency in English \n\n\nWhat\u2019s In It For You\n\nAn amazing opportunity to work on innovative autonomous vehicle research, processing, and managing PB+ scale of data (Camera, Lidar, Radar e.g.). You will also be a key driver in helping internal research stakeholders leverage the latest technologies in Big Data and machine learning technologies. But most important of all, you will work with an amazing group of people having loads of fun while doing it!\nAbout Scania ATS (Autonomous Transport Solution)\n\nAutonomous vehicle development at Scania is advancing at an extremely high pace and self-driving trucks and buses on public roads will soon become exposed. Autonomous Transport Solutions\u202f(ATS)\u202fResearch at Scania is responsible for developing, testing, and piloting future\u202fautonomous\u202fconcepts. This work is done using agile and self-steered teams with the ambition to detect and evaluate upcoming technologies and prepare these for industrialization.\u202f\nA Glance Into Projects We Work With\n\n\n\nSelf-driving truck on E4 motorway \nMaking of Scania AXL prototype \n\n\nWhat Scania Offers\n\nAs an employee at Scania, we offer other benefits, such as a personal car, performance bonus, occupational pension, flexible working hours, lunch at reduced prices, and much more, in addition to career and development opportunities. If you live in Stockholm, we offer a direct bus between Stockholm and S\u00f6dert\u00e4lje with Scania Jobexpress. From November this year, Scania also offers possibilities to work from central Stockholm.\nApplication\n\nWe look for individuals who dream big, work hard, and stay humble. Collaboration is at the heart of what we do and through our work together we hope to create a supportive, welcoming, and innovative environment. We strive to play as a team to win the world and create a better version of ourselves every day. If this sounds like something that excites you, we want to hear from you!\nWelcome with your application at the latest 29th of September. Your application should include a CV and copies of yourgraduation diploma/certificate. Selection is ongoing throughout the application period.\nA background check might be conducted for this position.\nScania is a world-leading provider of transport solutions. Together with our partners and customers we are driving the shift towards a sustainable transport system. In 2020, we delivered 66,900 trucks, 5,200 buses as well as 11,000 industrial and marine power systems to our customers. Net sales totalled to over SEK 125 billion, of which over 20 percent were services-related. Founded in 1891, Scania now operates in more than 100 countries and employs some 50,000 people. Research and development are mainly concentrated in Sweden. Production takes place in Europe and Latin America with regional product centres in Africa, Asia and Eurasia. Scania is part of TRATON GROUP. For more information visit: www.scania.com."
    },
    {
        "position": "Data Engineer \u2013 Data platform & device telemetry",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Axis Communications",
        "sector": "Computer Networking Products",
        "companySize": "1,001-5,000 employees",
        "location": "Lund, Sk\u00e5ne County, Sweden",
        "post": "About the job \n\nJob Title\nData Engineer \u2013 Data platform & device telemetry\n\nJob Description\nAxis is a fast growing and highly innovative company that offers intelligent security solutions. We are market leaders in network and surveillance cameras and are using this as the core around our solutions to create a safer and smarter world. Our success is largely due to our highly skilled staff and our strong culture of daring to succeed and allowing ourselves to constantly break new ground. The people here at Axis are innovative, dedicated and energetic and for us it is not just about creating products \u2014 we form and shape industry leading solutions giving highest values to our customers \nYou have the possibility to work as a Data Engineer at the Diagnostic and Data Management team with competent and collaborative colleagues.\nHow is your future team?\nThe Diagnostic and Data Management team is growing. The team consists of experienced SW Engineers, Data Engineers, and Data Scientists and the area is of strategic importance for Axis with great development potential moving forward. You will be a part of an inclusive and supportive team with the responsibility of collecting, processing, and storing anonymized data from IoT devices, in the cloud and on-prem. The team provides solutions to access and visualize the data as well as analysis of the data. Together the team strives to provide data solutions that enable data-driven decisions within Axis. We are convinced that self-managed teams where all members are listened to are the foundation of innovative work culture. Decisions should be close to those that are affected, and bureaucratic processes should be limited. Trust in each other is incredibly important. That is the only way to keep our innovation speed and stay ahead of our competitors.\n\nWhat You Will Do As a Data Engineer\nAs a Data Engineer, you will work across different code bases and at different levels of the software stack. You will mainly develop in Python on Linux machines and have the code under version control with Git in a team collaboration tool called Gerrit. We believe that code-review is important to share knowledge and improve code quality, and we try our best to follow best practices with automatic linters, tests, and other checks. The team has full freedom to deploy changes, on both staging and production infrastructure. We share the responsibility for the underlying infrastructure, data pipeline, databases, and visualization tools and we are expected to have a high level of understanding of the entire data platform. This is an important role within Diagnostic and Data Management, usage of data has increased, and the expectations of data solutions and pipelines have grown from nice to have into an essential part of Axis product & solution development. Future use of data will require higher reliability and larger data volumes within our data platform. You will, together with the team, put in place and maintain solutions, ensuring up-time and ease of use of our data platform. This work will contain both cloud and on-prem solutions. Parts of the work are done in collaboration with our IT department where communication of our use cases and requirements is of key importance. The team aspires to handle data volumes in the range of petabytes. You will be a central part of driving the collection of anonymous data from multiple sources to improve our products & solutions.\nWho are we looking for?\nWe are looking for a committed engineer with a supportive mindset. Suitable education could be Computer, Electrical, Physics science/engineering or similar and with some experience from working in the field of data engineering. Python programming and Linux are common knowledge for you and Git is a natural way of working. You are a self-going person that likes to take responsibility for your tasks, and you are good at seeing the big picture. You are curious and want to learn new things and share your knowledge with others. Furthermore, you have an interest in k8s and/or cloud as well as relational, document, search, or other databases (ClickHouse, PostgreSQL, Elasticsearch, MySQL, MongoDB, etc.). You recognize the importance of networking with others, inside as well as outside the team. Other skills that are seen as merit:\n\nEnjoy sharing knowledge with others and working transparently. \nActive in open source.\nBroad knowledge of new and emerging tools for extracting, ingesting, and processing large datasets.\nInterested in enhancement and maintenance of data platforms and pipelines.\nExperience in working closely with Data Scientists/Analysts. \nPassionate about development tools.\nExperience in visualization/BI-tool (ex. Apache Superset or other)\nExperience in container orchestration technology.\nStructured and skilled in writing and especially documentation of requirements.\nGood presentation and communication skills in English.\n\n\nAs teamwork is crucial for Axis as a whole, we believe it is important that you can contribute to a good team spirit promoting a creative and stimulating work environment.\nWhat Axis can do for you?\nAxis is a young, exciting company, already the world leader in our field - network video. As an engineer at Axis, you have the opportunity to steer your competence development and grow in the fields that you find interesting. Axis values creativity and promotes personal growth. Here you will have the opportunity to work with colleagues from all parts of the organization, making it possible to connect and exchange knowledge and experience. We welcome your application and look forward to meet our new colleague!\nReady to act?\nAxis is a company realizing the benefits of a diverse workforce. We know that diversity in groups creates a better working environment and promotes creativity, something that is fundamental for our success. Would you like to grow with us? Find out more from the recruiting manager, Tory Li, by phone at +46 46 272 1800 or by mail at Tory.Li@axis.com We review applications continuously!\n Type of Employment \n Permanent Employment\n\n Posting End Date \n 2022-09-30\n\n\n About Axis Communications\nWe enable a smarter, safer world by creating innovative solutions for improving security and business performance. As a network technology company and industry leader, we offer solutions in video surveillance, access control, intercom, and audio systems, enhanced by intelligent analytics applications. With around 4000 committed employees in over 50 countries, we collaborate with partners worldwide. Together, we thrive in our friendly, open, and collaborative culture and inspire each other to think beyond the expected. United by our commitment to inclusion, diversity, and sustainability, we consistently seek to develop our skills and way of working.\nLet\u00b4s create a smarter, safer world \nFor more information about Axis, please visit our website www.axis.com. Listen to Get To Know Axis \u2013 Podcast"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Process Automation Solutions",
        "sector": "Automation Machinery\n                                                            Manufacturing",
        "companySize": "1,001-5,000 employees",
        "location": "Amsterdam, North Holland, Netherlands",
        "post": "About the job \n\nJob Description\n\nLooking to further expand our Digitalization business unit, you\u2019ll be joining a team of colleagues well versed in cloud-based data solutions.\n As a Data Engineer at Process Automation Solutions, you will be part of our team that designs, develops and maintains IoT based solutions for the industry. You will work closely with our customers and PA Solutions stakeholders and developers and are responsible for the correct design and implementation of scalable, cloud and edge based Industry 4.0 solutions.\n We support manufacturing companies, machine builders and OEMs gain insights into their machine and productivity data, improve operational efficiency and offer data driven services by leveraging Industrial IoT solutions based on MS Azure, without the burden of building everything from scratch or the need to become a technical expert.\n Your colleagues will be professionals with a strong work ethic and a good sense of humor. You\u2019ll be able to enjoy an attractive workplace in a pleasant atmosphere. Together, we forge trust and mutual respect towards each other and our customers.\n\nYour function\n\n\nYou understand the functional and technical requirements and turn them into a best-practice design\nYou are responsible for the development and maintenance of complete data pipelines, mainly in MS Azure, both at the Edge and in the Cloud\nEnsure that your solutions can be deployed automatically using Azure Devops\nYou are willing to work from one of our offices or one of our customers onsite\nYou follow-up new evolutions and trends with respect to Industrial IoT solutions and Data Analytics\nYou are responsible for the documentation of your solutions\nYou will be working a lot with data and data visualizations in multiple ways \n\nYour skillset\n\n\nYou have a bachelor degree in ICT (or similar experience)\nYou are fluent in Dutch and English, verbal and written\nYou have experience with MS SQL, MS Azure, scripting and (ideally) also some .net development\nYou have at least 2 years hands-on experience in a cloud based or hybrid environment\nIf you have experience with high frequency, real-time data processing and large data volumes, that\u2019s an asset\nYou can work in a structured and accurate way and care about quality and documentation\nYou have strong analytical and troubleshooting skills\nYou are a team player but you can work independently as well \n\nOffer\n\n\nAn interesting and varied field of work in an international growing company\nA salary tailored to your qualities and experience with great employee benefits\nPersonal growth and challenging work with endless possibilities to realize your ambitions\nAn informal working environment with innovative colleagues who strive for the very best\nAn attractive workplace in a friendly and pleasant atmosphere \nA fulltime job offer in a dynamic team\n\nInterested?\n\nJoin us by applying via our career portal https://jobs.atsautomation.com/ with your motivational letter and a recent CV.\n In case of questions regarding your application, our HR team is eager to answer your questions\n +32 (0)3/710 99 70.\n Process Automation Solutions is one of the leading manufacturer-independent suppliers of complete automation solutions for the process and manufacturing industries. The company currently employs more than 1,400 people with a global presence in Europe, the Americas, and Asia. Our operational activities focus on the design of process control systems and their vertical integration into the overall business process. Our Digitalization business unit with more than 220 employees offers services in the areas of data analytics, cloud solutions, MES and ERP systems. PA Solutions offers complete services from the concept to commissioning, from the field level through process control level to corporate management level. Process Automation Solutions is a company of ATS Automation Tooling Systems Inc.\n\nAnswers to Automation\n\nProcess Automation Solutions is \u00e9\u00e9n van de toonaangevende spelers op vlak van totale automatiseringsoplossingen voor de process- en productie industrie. Het bedrijf telt momenteel 1450 medewerkers en is zowel actief in diverse continenten waaronder Europa, Amerika alsook Azi\u00eb. De core activiteiten van onze onderneming situeren zich op het ontwerp van process controle systemen en de verticale integratie in het algemene bedrijfsprocess. Wij bieden complete totaaloplossingen startende van conceptfase tot opstart. Dit zowel in de field laag, process controle laag alsook binnen de bovenliggende MES en ERP lagen. Process Automation Solutions is onderdeel van het Canadees beursgenoteerde bedrijf ATS Automation Tooling Systems Inc.\n\nInteresse?\n\nBezorg je CV met motivatiebrief aan ons HR departement door deze te mailen naar jobs.be@pa-ats.com of klik op de \u2018solliciteer nu\u2019 knop op onze jobpagina via https://jobs.atsautomation.com/PA en we garanderen je dat je sollicitatie discreet behandeld zal worden.\n Acquisitie naar aanleiding van deze vacature wordt niet op prijs gesteld.\n Heb je nog vragen omtrent jouw kandidatuur bij PA Solutions?\n Ons HR team helpt je graag verder op het nummer +32 (0)3 710 99 70.\n Bezoek onze website voor verdere bedrijfsinformatie: www.pa-ats.com\n\nProcess Automation Solutions NV\n\nHR Departement\n Schaarbeekstraat 23C\n 9120 Melsele\n Belgi\u00eb"
    },
    {
        "position": "Service Engineer, Industrial Storage, EMEA",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Tesla",
        "sector": "Motor Vehicle Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Amsterdam, North Holland, Netherlands",
        "post": "About the job \n\nWhat to Expect The Tesla Energy Product and Service Engineering team is looking for a passionate, collaborative, and skilled Product Engineer to join the team to support the explosive growth of our Industrial Storage fleet. As the Industrial Storage fleet grows, Tesla is also committed to having an industry-leading uptime in our deployed fleet of commercial and utility scale batteries. We use data collected from our highly connected systems to find problems before the customer does, and to systematically eliminate the causes of downtime. The product engineer will lead the identification and root cause of design, process, firmware and software failures in our fleet of energy storage systems. You will work with a team of engineers to diagnose why the power converters, battery modules, digital control systems, heating and cooling systems in Tesla\u2019s industrial batteries occasionally malfunction. Once the root cause has been identified, you will lead the effort to devise corrective actions that will prevent these failures from reoccurring. Ultimately, you will be responsible for improving the uptime in Tesla\u2019s stationary batteries used by commercial and utility-scale customers in grid connected and microgrid applications. To be successful in this role you will need to be skilled at troubleshooting electronic systems, mechanical systems, and computer networks in person and remotely. You should be comfortable developing your own code, manipulating SQL data, and working in the lab. If you are a \u201cmaker\u201d that loves to solve problems, this is the role for you. Work travel is expected to be around 15% for this role. This would include traveling to customer sites as well as our manufacturing and engineering facilities in the US. What You\u2019ll Do\n\n\nTroubleshoot and resolve hardware, software, and firmware issues that cause downtime for Tesla\u2019s Industrial Storage customers Lead cross-functional efforts to drive actions with manufacturing, design, field service, and the technical support teams as required to systematically prevent known issues from reoccurring\nMine data logged by Tesla\u2019s Industrial Storage fleet to define the fingerprint for a failure mode and utilize Tesla automation tools to programmatic diagnosis and react to future occurrences of that failure mode\nDefine the actions that need to be taken by the field service and technical support teams when a specific failure mode occurs, publish those actions in Tesla\u2019s Service tools, and develop any specialized training required to complete those actions\nQuantify the benefit of a product or manufacturing improvement opportunity and work with the engineering and manufacturing teams to implement the improvement for existing and future products as appropriate\nProvide support on escalated customer cases from around the world in order to minimize system downtime for Tesla\u2019s customers.\nExplain the root cause and resolution of issues to commercial and utility customers as needed\nWork with field service and technical support teams to create the documentation and training necessary to commission, operate, repair, and service Tesla\u2019s Industrial Storage products installed globally \nMaintain the list of serviceable parts currently available for all Industrial Storage Products and provide engineering guidance on the replacement strategy for obsolete partsWhat You\u2019ll Bring\n\n\nBS in electrical engineering, computer engineering, or mechanical engineering with 5 years of experience, or MS with 3 years of experience, or equivalent practical experience in development, reliability engineering, failure analysis, systems test engineering, product quality, or service engineering\nExperience using Python or equivalent for data analysis on very large databases\nStrong engineering fundamentals and intuition, applied to firmware/software-enabled systems\nPrior experience troubleshooting electrical, system, firmware, or process failure modes\nProven cross-functional leadership and collaborative skills\nExcellent oral and written communication skills\nAn ability to prioritize and execute many tasks in parallel. \nAn excellent attention to detail and an ability to produce clear and concise written documents and diagrams.\n\nPreferred\n\n\nExperience with battery systems and power systems\nKnowledge of CAN Bus communication\nExperience with managing or maintaining equipment running Linux based applications"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Prodrive Technologies",
        "sector": "Appliances, Electrical, and\n                                                            Electronics Manufacturing",
        "companySize": "1,001-5,000 employees",
        "location": "Eindhoven, North Brabant, Netherlands",
        "post": "About the job \n As a data engineer you work on various aspect of data: collecting, mining, pre-processing, analyzing, and visualizing. Your primary goal is to accelerate the data driven decision making within Prodrive. During your day-to-day job, you may encounter technical issues within data engineering like exploring new data sources, mathematical challenges, or statistical problems. Together with your colleagues of the Advanced Analytics team, you are facilitating to share objective information to other Prodrivers in various ways like reports.\n Within the Advanced Analytics team, you can focus on the technical backend or the frontend applications/customer interaction, depending on your interest and competence. Due to the organizational culture, you are not fixed to either frontend or backend. You may switch to your preference over time. Furthermore, you choose your field of interest (supply chain, finance, product manufacturing).\n When focusing on the technical backend, your responsibility involves the full development cycle of correct transformations, efficient transformations, reviewing new pull requests, and writing test cases. In case you like to work on the frontend, your responsibility contains application development, gaining field knowledge and explanation/demo to customers. The Advanced Analytics team is balanced between backend and front-end data engineers. Are you up for the challenge and do you want to join this team?\n\nBSc, BEng, MSc or PhD in Data Science, in Engineering or any quantitative or engineering field (econometrics, computer science, etc.)\nPreferred: programming skills (either school, professional, or hobby projects. Show us!)\nEager to learn about the manufacturing processes and systems \nEntrepreneurial spirit and drive to succeed\nCompetitive attitude and the need to constantly keep improving yourself\nStrong communication skills"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Process Automation Solutions",
        "sector": "Automation Machinery\n                                                            Manufacturing",
        "companySize": "1,001-5,000 employees",
        "location": "Amsterdam, North Holland, Netherlands",
        "post": "About the job \n\nJob Description\n\nLooking to further expand our Digitalization business unit, you\u2019ll be joining a team of colleagues well versed in cloud-based data solutions.\n As a Data Engineer at Process Automation Solutions, you will be part of our team that designs, develops and maintains IoT based solutions for the industry. You will work closely with our customers and PA Solutions stakeholders and developers and are responsible for the correct design and implementation of scalable, cloud and edge based Industry 4.0 solutions.\n We support manufacturing companies, machine builders and OEMs gain insights into their machine and productivity data, improve operational efficiency and offer data driven services by leveraging Industrial IoT solutions based on MS Azure, without the burden of building everything from scratch or the need to become a technical expert.\n Your colleagues will be professionals with a strong work ethic and a good sense of humor. You\u2019ll be able to enjoy an attractive workplace in a pleasant atmosphere. Together, we forge trust and mutual respect towards each other and our customers.\n\nYour function\n\n\nYou understand the functional and technical requirements and turn them into a best-practice design\nYou are responsible for the development and maintenance of complete data pipelines, mainly in MS Azure, both at the Edge and in the Cloud\nEnsure that your solutions can be deployed automatically using Azure Devops\nYou are willing to work from one of our offices or one of our customers onsite\nYou follow-up new evolutions and trends with respect to Industrial IoT solutions and Data Analytics\nYou are responsible for the documentation of your solutions\nYou will be working a lot with data and data visualizations in multiple ways \n\nYour skillset\n\n\nYou have a bachelor degree in ICT (or similar experience)\nYou are fluent in Dutch and English, verbal and written\nYou have experience with MS SQL, MS Azure, scripting and (ideally) also some .net development\nYou have at least 2 years hands-on experience in a cloud based or hybrid environment\nIf you have experience with high frequency, real-time data processing and large data volumes, that\u2019s an asset\nYou can work in a structured and accurate way and care about quality and documentation\nYou have strong analytical and troubleshooting skills\nYou are a team player but you can work independently as well \n\nOffer\n\n\nAn interesting and varied field of work in an international growing company\nA salary tailored to your qualities and experience with great employee benefits\nPersonal growth and challenging work with endless possibilities to realize your ambitions\nAn informal working environment with innovative colleagues who strive for the very best\nAn attractive workplace in a friendly and pleasant atmosphere \nA fulltime job offer in a dynamic team\n\nInterested?\n\nJoin us by applying via our career portal https://jobs.atsautomation.com/ with your motivational letter and a recent CV.\n In case of questions regarding your application, our HR team is eager to answer your questions\n +32 (0)3/710 99 70.\n Process Automation Solutions is one of the leading manufacturer-independent suppliers of complete automation solutions for the process and manufacturing industries. The company currently employs more than 1,400 people with a global presence in Europe, the Americas, and Asia. Our operational activities focus on the design of process control systems and their vertical integration into the overall business process. Our Digitalization business unit with more than 220 employees offers services in the areas of data analytics, cloud solutions, MES and ERP systems. PA Solutions offers complete services from the concept to commissioning, from the field level through process control level to corporate management level. Process Automation Solutions is a company of ATS Automation Tooling Systems Inc.\n\nAnswers to Automation\n\nProcess Automation Solutions is one of the leading manufacturer-independent suppliers of complete automation solutions for the process and manufacturing industries. The company currently employs more than1,400 people with a global presence in Europe, the Americas, and Asia. Our operational activities focus on the design of process control systems and their vertical integration into the overall business process. We offer complete services from the concept to commissioning, from the field level through process control level to corporate management level. Process Automation Solutions is a company of ATS Automation Tooling Systems Inc.\n\nInterested?\n\nPlease submit your resum\u00e9 and cover letter to this posting by clicking \u2018Apply now\u2019.\n Further opportunities can be found on our career portal jobs.atsautomation.com/PA , where you can also Join Our Talent Community by submitting a resume. We guarantee that your application will be handled with care.\n\nDo you have any further questions about your candidacy? \n\nPlease contact our HR team by email jobs.be@pa-ats.com or by phone at +32 (0)3 710 99 70. You may also visit our website for further information: www.pa-ats.com\n\nProcess Automation Solutions NV\n\nHR Department\n Schaarbeekstraat 23C\n 9120 Melsele\n Belgium"
    },
    {
        "position": "Data Support Engineer",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Lely",
        "sector": "Machinery Manufacturing",
        "companySize": "1,001-5,000 employees",
        "location": "Maassluis, South Holland, Netherlands",
        "post": "About the job \n\nWhat is your role?\n\nThis is your chance to come and work at the largest robot manufacturer in the Netherlands, the family business of the year with a high-tech campus in beautiful Westland. Lely develops and produces robots and digital services for the agricultural sector, especially dairy farms, and supplies them worldwide in more than 40 countries. Are you interested in the latest technologies, and would you like to work in an innovative environment where you can really contribute to the well-being of our customers, the dairy farms?\n This function is positioned in the Digital Operations Center (DOC) existing of multiple teams (Application, Security, Cloud, Continues Improvement, Learning & Development). These teams are together operationally responsible end-to-end. The team for this role will be Cloud Operations operationally responsible together with multiple cloud engineers for activities in the cloud environment of Lely.\n You interact with customers and colleagues all over the world, from Service Technicians to Product Developers, from Application Specialists to Lead Data Engineers, the role is super versatile and it offers plenty of opportunities for personal development and growth opportunities.\u202f\n\nYour activities \n\nLely Horizon is the management system for modern dairy farming. All data is collected from the various Lely products that are active on the farm. Think of the milking robot, feeding robot and the manure robot.After an internal training, you will provide third-line support on questions, problems and bugs related to our data products that are connected to our new farm management solution Lely Horizon.\n\nBut Also\n\n\nDelve into complex data issues and questions by gathering technical information from the field \nAnalyzing the cause of common problems and testing variables and scenarios \nWork along with colleagues from the Product Development Data Teams focusing on improving the products \nDaily monitoring, management and support of our digital services in a third-line position. \nResponsible for thinking from the perspective of the customer (the farmer), translating business visions to technical requirements and presenting the solutions to stakeholders and engineering teams. \n\nTo be able to build up a good relationship with colleagues abroad, you occasionally visit a Lely cluster\n\nWhat is your experience?\n\n\nHigher education or academic background (HBO/WO) in Computer Science or Informatics; \nMinimum of 2 years of working experience in a related field; \nExperience with Agile/Scrum/Lean methodologies; \nExperience in Python, SQL, Spark, API design; \nExperience with Microsoft Azure; \nExperience in Infrastructure as Code, working in CI/CD DevOps team; \nExcellent communication skills, written and spoken in English; \nNo distaste for cows :-) \n\nRegular travel to other countries inside and outside Europe is part of this role.\n\nWhat do we offer you?\n\nAn interesting job, in which you will be faced with complex technical issues as well as being part of the introduction of new Lely solutions. A pleasant working environment at an international family-owned business where innovation is always key.\n\nYou Will Also Benefit From\n\n\nGood salary that matches the responsibilities; \nflexibility in terms of working times and conditions; \n8% holiday pay and 40 days off if you work fulltime;\nDynamic role with a lot of space for own initiatives; \nTravel expenses, smartphone and laptop;\nA beautiful office in Maassluis which is easily accessible by car or public transport; \nOpportunities and facilities to also work from home. \nPlenty of room for personal growth and development. \n\nAbout Lely\n\nAt Lely, we believe in achieving a sustainable, profitable and agreeable future for dairy farmers by combining robotisation, engineering and farming expertise.\n It all started with a dream cherished by two brothers in Maassluis 70 years ago, and ever since, we have worked to become innovative market leaders in automated systems for dairy farmers across the globe. With a team of 2,300 professional specialists, we work constantly to bring about revolutionary solutions for the agro industry. We are based at our Maassluis Campus, a building which features the highest sustainability performance possible, not just in the Netherlands, but on a global scale. Our overall objective: making dairy farming interesting, also for the coming generations."
    },
    {
        "position": "Data Engineering Manager (Remote)",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Stuart",
        "sector": "Transportation, Logistics,\n                                                            Supply Chain and Storage",
        "companySize": "501-1,000 employees",
        "location": "France",
        "post": "About the job \n\nStuart (DPD Group) is a sustainable \ud83c\udf31 last-mile logistics company that connects retailers and e-merchants to a fleet of geolocalised couriers across several countries in Europe.\n\n\nOur Mission \ud83d\ude80\nWe are an impact-driven company that aims to build the future of logistics for a more sustainable world: shared, efficient and reliable. We are committed to creating a new standard for urban deliveries that meet today\u2019s environmental and social challenges while offering a premium delivery experience blending speed, flexibility and convenience.\n\n\nOur motto: \u201cMake every delivery a moment all of us can truly celebrate!\u201d More than 3000+ leading brands already partner with us across Restaurants, Grocery, Retail & Luxury, eCommerce and Professional Services to deliver all types of goods at the tap of a button. Stuart is a highly diverse and inclusive company of 700+ employees with 90+ nationalities working across France \ud83c\uddeb\ud83c\uddf7, Italy \ud83c\uddee\ud83c\uddf9, Poland \ud83c\uddf5\ud83c\uddf1, Portugal \ud83c\uddf5\ud83c\uddf9, Spain \ud83c\uddea\ud83c\uddf8 and the U.K. \ud83c\uddec\ud83c\udde7\n\n\nIt\u2019s the right moment and the right place for us to make an impact on millions of people, as home delivery services hit a record high. And guess what? You can help us fulfil our vision \ud83d\ude4c\n\n\n\ud83d\udc8e The Position\n\n\nWe are looking for an Engineering Manager to join us at Stuart to drive our machine learning initiatives. Engineers at Stuart operate as part of cross-functional teams: you will join a team of five Python and Scala Data Engineers collaborating with data scientists, product managers and product analysts.\n\n\nYou will ensure a good collaboration between the engineers and the other teams by helping them refine their ways of working and development trajectories. Your team will deliver solutions for fraud detection, supply & demand management and time of arrival estimation.\n\n\nOur vision is twofold: \n\ntake down the barriers between data science and data engineering by encouraging constant collaboration in unified teams\nbuild a common MLOps infrastructure while working on our key product initiatives\n\n\n\nYou will collaborate closely with our ML Staff Engineer in charge of the technical aspects of our ML efforts and benefit from the support and experience of our Managers and Directors.\n\n\nLearn more about our team via our engineering blog: Stuart Engineering \u2013 Medium \ud83e\udd13\n\n\nWhat will I be doing? \ud83e\udd14\n\nBe responsible for the sustainable delivery of your team focusing on reliable, scalable, and maintainable software.\nMentor and support the engineers on your team, helping them grow via coaching, mentoring, regular feedback, and performance reviews.\nWork in partnership with the product manager and product designer of the team, helping to define roadmaps, OKRs, and manage projects.\nEnsure organisational agility and efficiency, both inside the team and in the ways they collaborate with other teams.\nBe active in the hiring process, and pro-actively hire to ensure the continued delivery of the team.\nShare company vision and strategy with the team and provide clear context.\n\n\n\nWhat do we need from you? \ud83d\ude0e\n\n2 years or more experience in a leadership role.\nSolid technical experience (as an individual contributor at a senior level or above) \nGood grasp of the key management concepts we support: servant leadership and agility.\nExcellent written and spoken communication skills.\nFluent in English.\n\n\n\nNot sure if this is you?\nWe understand that experiences are broad and come from many places. We appreciate that everyone potentially has something to contribute to our team and we'd still love to hear from you if your background doesn't completely match!\n\n\nThe stuff you wanna know \ud83d\ude09\n\nFamily-friendly work-life balance - work from home and flexible hours \ud83c\udfe1\nOption to work remotely anywhere in France \ud83c\uddeb\ud83c\uddf7 \nTicket Restaurant by Swile (\u20ac13 daily with 60% paid by the company) \ud83e\udd57\nUnlimited access to Udemy for all your learning and development needs \ud83d\udcda\nStuart Academy with regular workshops, Stu-Classes, and Stu-Talks \ud83c\udf93\nStuart is putting Mental Health Awareness first! Wellness Allowance (\u20ac40 monthly) to use in any gym or sport class \ud83e\uddd8\nPrivate healthcare provided by Alan \ud83e\uddd1\u200d\u2695\ufe0f\nWork in an international, dynamic and passionate environment with a company culture focused on learning and development \ud83c\udf89 \n\n\n\nYou\u2019ve read all this way but you\u2019re missing a skill or two? No problem, it\u2019s our job to up-skill you to take your career to the next level. What we\u2019re trying to say is, don\u2019t be afraid to apply if you don\u2019t tick all the boxes \ud83d\udcaa\n\n\nAt Stuart, we believe that employees today want to evolve in collaborative, high-growth environments where they can demonstrate their abilities and thrive both professionally and personally. We are convinced that employees need to find alignment between their inner values and their company\u2019s culture and mission to unlock their full potential. We work to create a culture of empowerment, continuous learning and growth where everyone can bring expertise, own projects and easily measure their impact \ud83d\ude4c\n\n\nStuart is proud to be an equal opportunity workplace dedicated to promoting diversity. We don\u2019t discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status \ud83d\udc99\n\n\nPlease note: Our Talent Acquisition Team is international coming from across the world \ud83c\udf0d We kindly ask you to please submit your CV and application in English so that it can be reviewed correctly (unless the job posting is in a language other than English). Thank you \ud83e\udd17"
    },
    {
        "position": "Senior Software Engineer -  Data Engineering",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Kindred Group plc",
        "sector": "Gambling Facilities and\n                                                            Casinos",
        "companySize": "1,001-5,000 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nThe role \nKindred is looking for a highly skilled developer to join the Data Engineering team whose vision is to drive and support Kindred to be the most data-driven sports betting and gambling company in the world! \nAs a Data Engineer in Kindred, you will be part of the Data Department under the overall Technology organization. Joining this team, you will be playing a big part in the way we shape our business by closely collaborating with different stakeholders across the business, ensuring they get the most out of the data in terms of reporting, statistics and to form the basis of decision making and analytical processes. \nThe successful candidate will be responsible for the end to end solution from data ingestion, preparation of data to building segmentations and reporting solutions in both Cloud and On-Prem Data Warehouse. \nWhat you will do \n\nDesign, build and operationalize data solutions on our AWS data platform \nBuild data pipelines and applications that handle multiple sources of data to create exceptional quality data products \nDesign, enhance and implement data ingestion from wider range of data sources into our Data platform. \nDeveloping advanced Oracle PL/SQL, writing and optimizing/tuning queries over large data sets. \nDeveloping dashboards and reporting solutions \nData investigations and problem-solving from internal and external stakeholders. \nSetting up Apache Kafka streaming jobs. \nProactively engage with stakeholders and deliver their requirements. \nSupporting Data products maintenance and monitoring initiatives (including occasional on-call support & incident management). \nWork in an Agile way with open communication, while delivering top quality products and services. \n\nAbout you \n\nExtensive knowledge and hands on experience on Apache Spark/EMR, AWS Glue, Lambda, S3. \nStrong background of working with RDBMS \nExperience with dealing with large data volumes. \nPreferably 5+ years working with data. \nHands on experience on Kafka. \nWorking knowledge with Java/Spring/Spring boot \nGood understanding of Data Warehouse concepts. \nExperience deploying software into containerised environments, including Docker and Kubernetes. \nImplementation of ETL processes and data structure. \nKnowledge of any basic cloud architecture (e.g., AWS). \nGood attitude and willingness to learn new skills and technologies. \nA problem-solving growth mindset with the ability to pick up new tools and concepts quickly \nOpen-mindedness, able to interact in a constructive manner with the Data Engineering teams, stakeholders and other contributors to Data solutions. \n\nIn addition, it would be an advantage if you also have: \n\nExperience with cloud formation and terraform. \nExperience with building pipeline through Matillion or similar. \n\nApplication Process \nClick on the \"Apply Now\" button and complete the short web form. Please add a covering letter in English to let us know your motivation for applying and your salary expectation. Our Talent Acquisition team will be in touch soon. \nKindred is an equal opportunities employer committed to employing a diverse workforce and an inclusive culture. As such we oppose all forms of discrimination in the workplace. We create equal opportunities for all our applicants and will treat people equally regardless of and not limited to, gender, age, disability, race, sexual orientation. We are committed not only to our legal obligations but also to the positive promotion that equal opportunities bring to our operations as set out in our sustainability framework. \nJob Alerts \nNot suited to this role but interested in working at Kindred Group? \nWe are always on the lookout for talented, passionate people to join our global teams so if you'd like us to let you know when suitable jobs come up, please click on \u201cRegister for Alerts\u201d."
    },
    {
        "position": "Senior Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "MSCI Inc.",
        "sector": "Financial Services",
        "companySize": "1,001-5,000 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nYour Team Responsibilities\n\nMSCI provides best-in-class commercial real estate data and analytic products to customers both in the U.S. and globally. As a company, we take tremendous pride in our offerings and as such, have invested wholesale in the people, processes, and technology behind them. We want you to be a part of it by joining our Engineering team\u2014becoming immersed in developing these products with cutting edge technology, proven processes, and some of brightest minds in the business.\n\nWhat we will offer you: Depending on your location of your role, you can expect\n\n\nCompetitive fixed and variable compensation, holiday/vacation allowance & retirement savings plans/pensionsEmployee Resource Groups to support you in and out of the officeA wide range of benefits including \u2013 healthcare, dental plans, risk insurances and (location dependent) \u2013 cycle-to-work schemes, gym benefits, retail discountsA purposeful approach to Wellbeing including training, support networks, membership to wellness platforms and vendors, and active local office communitiesA specific and deliberate planning to the physical offices in which we work, and support for everyone spending periods of time working remotely or at home. This approach mirrors our commitment to transparency and sustainability and puts the safety and wellness of our employees at the center of all we do. We aim to provide productive and sustainable work environments and technology that encourages collaboration, creativity and innovation.\n\n\nYour Key Responsibilities\n\n\nDevelop and support scalable, extensible and highly-available data pipelines on heterogeneous datasets that power downstream applications and systems and serve content to our web and API productsClosely collaborate with partners across product and design, engineering, and business teams to drive innovations that improve our customers\u2019 experienceFollow software-development best practices including test-driven development, contributing to documentation, feature flagging, etcHelp to maintain and improve existing ETL pipelinesWork with your team to troubleshoot and fix issues in ingest and processing, taking into account the dependencies and integration pointsCollaborate with DevOps to plan resources and continuously optimize the infrastructure and configuration of our data pipelines to ensure a healthy and high-performance production deployments\n\n\nYour Skills And Experience That Will Help You Excel\n\n\nBachelors degree in Computer Science, or a related fieldWorking knowledge and experience of databricks and/or data solutions in azure cloudSolid comprehension of common design patterns, algorithms, and data structuresSolid understanding of distributed systemsWorking knowledge of containerization2+ years of relevant back-end programming experience using languages such as Python, Node.js, Scala, or JavaExcellent communication and presentation skills\n\n\nPreferred Skills\n\n\nExperience with event-driven processing within a microservices oriented architectureKnowledge of Test Driven Development, Refactoring, Clean Code and Clean ArchitectureExperience working in an Agile software development organizationExperience in several areas of our technology stack, including: Kafka, Dremio, MongoDB, MS SQL, ElasticSearch\n\n\nHow We\u2019ll Support You\n\n\nCoaching and support from experts in your teamA performance and growth-oriented culture and valuesOpportunities for continuous learning to aid progressionGoal based objectives and development plansTransparent performance-based compensation schemesEmployee resource groups such as the Women\u2019s Leadership Forum, MSCIPRIDE, and Eco-Groups.\n\n\nAbout MSCI And Our Teams\n\nMSCI is a market leader in Global Indexes, Smart Beta, ESG and Risk Management, and is at the forefront of the secular trends dominating the financial services landscape today. We are committed to the future sustainability and transparency of the financial markets. We create innovative products and services that allow our clients to make more informed investment decisions, and we provide investors with critical performance measurement and risk management data and analytics.\n Our values define the working environment we strive to create. We are inclusive, we champion bold ideas, we always pursue excellence, and always act with integrity. Personal accountability and responsibility are key to success, and we always work as a team to remain client centric.\n MSCI is committed to developing a culture and workforce that reflects the clients and communities in which we operate. Increasing our diversity expands our talent pool which helps to accelerate innovation in all we do. We especially encourage members of historically underrepresented groups to apply, including women, ethnic minorities and those in the LGBTQ community.\n\nTo all recruitment agencies: MSCI does not accept unsolicited CVs/Resumes. Please do not forward CVs/Resumes to any MSCI employee, location or website. MSCI is not responsible for any fees related to unsolicited CVs/Resumes.\n\nMSCI Inc. is an equal opportunity employer committed to diversifying its workforce. It is the policy of the Firm to ensure equal employment opportunity without discrimination or harassment on the basis of race, color, religion, creed, age, sex, gender, gender identity, sexual orientation, national origin, citizenship, disability, marital and civil partnership/union status, pregnancy (including unlawful discrimination on the basis of a legally protected pregnancy/maternity leave), veteran status, or any other characteristic protected by law.\n\nAnnual"
    },
    {
        "position": "SCE Software operations engineer",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Atlas Copco",
        "sector": "Machinery Manufacturing",
        "companySize": "10,001+ employees",
        "location": "G\u00f6teborg, Vastra Gotaland County, Sweden",
        "post": "About the job \n\nPassionate people create exceptional things\n\nAre you a \u201dDigital Native\u201d? Do you like to talk, learn and challenge concepts like cloud computing, process visualization, artificial inteligence, big data?\nAt Atlas Copco we belive that by digitisation its possible to help People, increase Profit and save the Planet.\nFactories are digitising now, do you want to be part of it?\nJoin us on our journey for a better tomorrow.\n\nThe role \n\nYour mission will be to accompany the installations (technical implementation and resources organization). It will span from the project\u2019s initial phase and beyond the project\u2019s final phase, to secure further support within software services scope to ensure customer satisfaction. This is called Software Operations Journey.\nYou will be the crucial part of the team making sure the Software Operations Journey (SOJ) is successfully in place, and it is through the SOJ we can bring our customer`s manufacturing to a next level of productivity, quality, efficiency, and sustainability.\nWhat You Can Expect From Us\n\n\n\nA friendly, family-like atmosphere \nPlenty of opportunities to grow and develop \nA culture known for respectful interaction, ethical behavior, and integrity \nPotential to see your ideas realized and to make an impact \nNew challenges and new things to learn every day \nAccess to global job opportunities, as part of the Atlas Copco Group \n\n\nYour profile \n\n\n\nTechnical degree or corresponding experience \nUnderstanding and focus on customer satisfaction \nCustomer interaction experience \nDriver\u2019s license \nGood communication skills in the English language, both in spoken and written word \n\n\nAs a person you are a self-organized team player, who has the ability to take responsibility and manage your own workload. You have good technical knowledge and approach tasks in a professional manner. You are innovative and solving various problems makes you tick. You are also flexible and open-minded with customers focus on a high level and have a sense when it\u2019s urgent to step in and solve their needs. We communicate daily through many different platforms and good communicative skills is a plus.\nLocation: The position is located in Gothenburg, Sweden.\nSounds interesting? \n\nThen don\u2019t hesitate to apply to this challenging position with the opportunity of personal growth!\nYou are welcome to contact hiring manager Livia Petrechi [email protected] for more information.\nWe are looking forward to receiving an application from you!\nDiverse by nature and inclusive by choice\n\nBright ideas come from all of us. The more unique perspectives we embrace, the more innovative we are. Together we build a culture where difference is valued and we share a deep sense of purpose and belonging."
    },
    {
        "position": "Data Engineer, Business Steering (Malm\u00f6) Group Digital, Ingka Group",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "IKEA",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Malm\u00f6, Sk\u00e5ne County, Sweden",
        "post": "About the job \n\nWHO YOU ARE  We are looking for a Senior Data Engineer to join us in developing new revolutionizing ways for IKEA to build data products that support strategic decision making, performance management and data science. We are using cutting edge methodologies within cross-functional teams to keep IKEA leading in an exciting and fast-moving environment. Our diverse and global team within Data & Analytics is growing even more and we would love to talk with you, if you recognize yourself in some of the following:\n \u2022 Strong knowledge of advanced data structures, distributed computing and cloud-based services \u2022 Strong knowledge of SQL for data processing and analysis \u2022 Extensive knowledge of programming languages (e.g. Java, Go, Python, or Scala), including concepts from functional and object-oriented programming paradigms  \u2022 Broad knowledge of new and emerging tools for extracting, ingesting, and processing of large datasets (Apache Spark, Beam, Kafka, or equivalent)  \u2022 Good knowledge of data science and business intelligence products and how they rely on data feeds for their implementation \u2022 Broad knowledge of digital product development principles and the importance of rapid validated learning cycles to optimise performance long term \u2022 Broad knowledge of collaborative software engineering practices (Git, Agile, DevOps), in which solutions evolve through the effort of self-organising cross-functional teams \u2022 A team player who takes ownership, builds cross-functional relationships with senior peers and loves sharing knowledge with more junior team members \u2022 A curious world class problem solver who wants to keep learning! \u2022 Experience with cloud platforms like Google Cloud Platform, AWS or Azure \u2022 Work Experience of 5 years in a similar role\n This is our wish list! If you don\u2019t recognize yourself in all these points, you might still be an excellent candidate for the role. We like to think long-term and invest in people\u2019s development together with us. The IKEA culture and values are very much a part of our business and day to day work life. For you to thrive and grow with IKEA it\u2019s important for us that you share our values! You can read more regarding our values and life at IKEA on our website www.ikea.com. \n\nWHAT YOU'LL BE DOING DAY TO DAY  You\u2019ll lead the transformation of IKEA into a more data driven company by ensuring that data and insights are frequently and widely used in product teams in Group Digital to reinforce, alter, or largely impact present and future decisions on business and product strategy.\n As a Senior Data Engineer you will work closely with Data Scientists and Data Analysts to drive the development of data products within the Business Support domain. Here, we are building the systems and tools for steering and planning our business at scale, often for top management stakeholders. You will work hands-on with building data pipelines in our data mesh on Google Cloud Platform, as well as be a thought partner on questions like: \n \u2022 What data products do we design, build, test and maintain to promote data consumption?  \u2022 How should we extract, merge, transform and serve data to enable usage at global scale?  \u2022 What user needs do we prioritise first, making the optimal trade-off between quick business impact and building for the future?  \u2022 What data products and mindsets should we evolve to empower not only our Data Analysts and Scientists, but all co-workers?  \u2022 How can we ensure the reliability, security, and quality of the data, and how do we educate team members in cross-functional teams about the importance of it?  \u2022 How can we transform a business problem into requirements for building data infrastructure? \u2022 How do we set up different environments (e.g. dev, test, prod) with appropriate security levels and data privacy requirements? \u2022 How should we coach and develop our junior team members to become world class Data Engineers? \n And perhaps you have your own ideas on problems to solve? We are on a journey towards becoming a data-driven company and you will have the opportunity to help shape our path, based on your knowledge and experience. \n\nOUR TEAM WITHIN IKEA  You will work in Data & Analytics together with other Data Engineers, Data Scientists, Data Analysts, Machine Learning Engineers, Data Stewards and Data Architects. Together you will be joining cross-functional teams consisting of colleagues from Technology, Product and Design from the business domain of Business Support. All of you together will be creating the best solutions to support strategic enterprise decisions, financial forecasting and business planning. \n IKEA has long been a global leader in home furnishing. We are proud of our vision to improve the everyday life of the many people. But our industry is quickly changing, and we need to adapt to stay competitive. To facilitate our digital growth ambition, we are working in different locations world-wide. The home office for this role will be Malm\u00f6, Sweden, but we act as one global team and work together on global solutions.\n We see so many opportunities for what we can accomplish and have the ambition to be a world class team. At the same time, we believe that our work is not just about solving business problems, but also about learning and having fun together.\n WHAT WE CAN OFFER YOU\n \u2022 Work on some exciting problems as described above, and you are encouraged to spot new opportunities or to collaborate with Data & Analytics colleagues in other specialist teams \u2022 Opportunities to have global impact with your work \u2022 Flexible and modern tools: we deploy on Google Cloud Platform and we use a lot of open-source tools across the board \u2022 Hardware and Operating System your choice \u2022 A team of great colleagues to learn with and from (with world-class experience across all aspects of Data & Analytics) \u2022 Continuous learning (we aim to spend 20% of our working time on learning) \u2022 Flexible and friendly working environment in a truly value-based company \u2022 Relocation support where applicable \n\nQUESTIONS AND SUPPORT? LET'S CONNECT!  Does this sound like your next challenge? IKEA offers an exciting and empowering work environment in a global workplace. And as the world\u2019s leader at life at home, you have exceptional opportunities to grow and develop together with us.\n If you have questions regarding the role, recruitment process or other practicalities please reach out to Pietro Mattei at pietro.mattei@ingka.ikea.com.  Please apply with your application in English. Note that we cannot process any applications through email. Thank you!"
    },
    {
        "position": "Data Engineer, Pricing, Group Digital, INGKA Group - Malm\u00f6",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "IKEA",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Malm\u00f6, Sk\u00e5ne County, Sweden",
        "post": "About the job \n\nWHO YOU ARE  IKEA is taking huge steps in its digital transformation and our Data Engineers are working in cross-functional teams to transform IKEA into a more data driven company by building state-of-the-art data products. \n You like solving hard problems with code. You are not afraid to innovate to find a better answer. And you like working on state-of-the art technologies. All the while you solve real problems for IKEA co-workers. You are a hands-on Data Engineer who can build great data products. You will join a diverse team within Data & Analytics consisting of data analyst, data scientist and data stewards based across Sweden, Netherlands and Spain. \n You recognize yourself in the following: \n \u2022 A curious world class problem solver who wants to keep learning! \u2022 Extensive knowledge of designing, developing and deploying efficient data pipelines using modern technologies. \u2022 Extensive software engineering experience and interest in software engg practices \u2022 Broad knowledge of new and emerging tools for extracting, ingesting, and processing of large datasets (Apache Spark, Beam, Kafka, or equivalent). And curious to learn the ones you don\u2019t know yet! \u2022 Good knowledge of Machine Learning models and strong understanding of what requirements ML puts on data pipelines \u2022 Broad knowledge of digital product development: you know how to make trade-offs between speed and quality \u2022 Broad knowledge of collaborative software engineering practices (Agile, DevOps) \u2022 Excited about IKEA\u2019s core values and vision of creating a better everyday life for the many people \u2022 Experience and interest in data modeling and data lifecycle management \u2022 Eager to drive the implementation of best practices for data engineering in our growing community\n At IKEA, you\u2019re welcome no matter where you come from, what you believe, and what you look like. We don\u2019t even care how you have furnished your home. We\u2019re interested in you simply because you\u2019re you. Our different views, backgrounds, and personalities make us better understand our customers, give us more fun at work and spark more and better ideas. Perhaps your unique take on something could lead to a great idea that creates a better everyday life for the many people\n The IKEA culture and values are very much a part of our business and day to day work life. For you to thrive and grow with IKEA it\u2019s important for us that you share our values! You can read more regarding our values and life at IKEA on our website www.ikea.com. \n\nWHAT YOU'LL BE DOING DAY TO DAY  This role will find a home in our Pricing sub-domain meaning that majority of the work will focus on making the IKEA pricing process better every day. Data Engineer in Pricing will not only be responsible for making adequate and relevant data available for exploration work but also for model training and downstream distribution for analytical use cases. Identify the best suited data model / schema for the purposes and data lifecycle for the data assets offered from the sub-domain.\n The Data Engineer will not only be expected to work hands-on with data pipelines and logic, but will also be a thought partner on questions like: \n \u2022 How can data products enable the transformation of IKEA into a data driven company? \u2022 What data products do we design, build, test and maintain to make data more discoverable and easier to use? \u2022 How should we ingest, merge, transform and serve data to enable usage at global scale? \u2022 What user needs do we prioritise first , making the optimal choice between quick business impact and building for the future? \u2022 What data products and mindsets should we evolve to empower not only our Data Analysts/Scientists/Stewards, but all co-workers? \u2022 How can we ensure the reliability and quality of the data, and how do we educate team members in cross-functional teams about the importance of it? \u2022 How do we coach and develop our junior team members to become world class Data Engineers? \n Perhaps you have your own ideas on problems to solve? Our ultimate goal is to create a better everyday life for the many people by creating a unique partnership with each customer. To do so, we want to give customers the most beneficial offer for them, exactly when they need it, and support them throughout their journey with IKEA in the best way possible. \n\nOUR TEAM WITHIN IKEA  You will work in Data & Analytics together with other Data Analysts, Data Scientists, Data Engineers, Data Stewards and Data Architects. Together you will be joining cross-functional teams consisting of colleagues from Technology, Product, Design, that designs, implements and deploys products that help to solve these kinds of problems. Your job will be a mix of translating business needs into data products, designing data solutions for scale, coaching other data engineers \u2013 and of course writing code. \n IKEA has long been a global leader in home furnishing. We are proud of our vision to improve the everyday life of the many people. But our industry is quickly changing, and we need to adapt to stay competitive. \n Pricing has been at the core of everything IKEA. We at Pricing are committed to embed intelligence throughout the pricing process to make IKEA offerings relevant for the many people across IKEA markets globally. We see so many opportunities for what we can accomplish and have the ambition to be a world class team. At the same time, we believe that our work is not just about building models, but also about learning and having fun together. \n We can offer you: \n \u2022 Work on some very interesting problems as described above, and you are encouraged to spot new opportunities or to collaborate with Data & Analytics colleagues in other specialist teams. \u2022 Opportunities to have global impact with your work. \u2022 Flexible and modern tools: we deploy mainly on Google Cloud Platform (and other cloud providers like Azure, Ali etc. when needed)  \u2022 We use a lot of open source tools across the board. \u2022 We use the latest programming languages Python, Java/Scala, Go, Rust \u2022 Hardware and OS of your choice. \u2022 A team of great colleagues to learn with and from (with world-class experience across all aspects of Data & Analytics). \u2022 Continuous learning (we aim to spend 20% of our working time on learning). \u2022 Flexible and friendly working environment. \n\nQUESTIONS AND SUPPORT? LET'S CONNECT!  Does this sound like your next challenge? IKEA offers an exciting and empowering work environment in a global workplace. And as the world\u2019s leader at life at home, you have exceptional opportunities to grow and develop together with us. \n Studies show that members of underrepresented communities don\u2019t apply for jobs unless they\u2019re 100% \u201cqualified\u201d. If this is part of the reason you hesitate to apply, we like you to reconsider and give it a chance. Maybe your profile fits our needs much better than you think. We look forward to receiving your application.\n From: \u201cWhy Women Don\u2019t Apply for Jobs Unless They\u2019re 100% Qualified\u201d by Tara Sophia Mohr, August 2014\u201d\n If you have questions regarding the recruitment process, please reach out to Recruitment Specialist Annette Bj\u00f6rkquist-\u00c5stedth at annette.bjorkquist-ahstedt@ingka.ikea.com.\n Please apply with your application in English. Note that we can\u2019t process any applications through email. Thank you!"
    },
    {
        "position": "DevOps Engineer",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Cambio Group",
        "sector": "Software Development",
        "companySize": "501-1,000 employees",
        "location": "Link\u00f6ping, Ostergotland County, Sweden",
        "post": "About the job \n\nCambio is a market-leading supplier with a comprehensive offering for the entire healthcare and care chain. The goal is to offer the most innovative and cohesive solutions for regions and municipalities. We are growing continuously and now have about 800 employees in several countries. Cambio is certified by Great Place To Work and we are placed in the top 15 list and have received the award \"Sweden's Best Workplace\" 2020 and 2021!\n\n\nThe position\nAs a DevOps engineer you will be part of our internal infrastructure service team. The team is distributed and works with infrastructure services, running in Sweden and Sri Lanka, that supports the development, delivery, and deployment pipelines at Cambio.\n\n\nYou will be working with defining, configuring, supporting, and maintaining services, such as Bitbucket, Gitlab, Jenkins, SonarQube, Artifactory to name a few. In that work you will work closely with our development organizations and our delivery organization. You will have close day to day collaboration with our team in Sri Lanka. \n\n\nAt Cambio, we encourage taking initiatives that contribute to the development of the company and ourselves. For us, it is important that you should have the opportunity to grow, both as a person and as an employee. Our culture is described through the words \u201cTrust\u201d, \u201cCare\u201d and \u201cTogether\u201d which permeate everything we do. \n\n\nAbout you\nTo succeed in this role, we believe that you have great technical skills and have a keen interest in CI/CD pipelines and its infrastructure. You enjoy putting together technical solutions with your team as well as developing and coaching the team further in your area of expertise. \n\n\nRequirements \n\nExperience in working with development infrastructure or related areas.\nExperience in CI/CD pipeline development.\nUnderstanding of software development.\nExperience using on-prem virtualization solutions such as VMWare.\nExperience on infrastructure automation using Ansible or similar frameworks.\nExperience in Linux systems.\nExpertise in developing tools using scripting languages such as PowerShell, Bash, and Python.\nGood communication skills in English.\n\n\n\nIt's a bonus if you\n\nHave experience in utilizing cloud solutions.\nHave experience as a software developer.\nCan communicate fluently in Swedish.\n\n\n\nPlace of employment: Link\u00f6ping\n\n\nAt Cambio we value a healthy work-life balance, and to encourage that we apply a hybrid working-model. Together with your team you decide which days you work at the office. On the remaining days you can work remotely from home, but you are always more than welcome to work at the office too.\n\n\nScope: Full time \n\n\nForm of employment: Permanent employment, 6 months trial period \n\n\nOther: We screen the applications and hold interviews continuously so please send your application as soon as possible via the link. \n\n\nWe encourage and eagerly welcome all applications, but we will only consider candidates who are located and have the legal right to work in Sweden. We will ask for verification during the process. \n\nWe look forward to receiving your application!"
    },
    {
        "position": "Data Engineering Lead, Pipeline (487)",
        "jobType": "$115,000/yr - $229,000/yr (LinkedIn est.)",
        "jobLevel": "Full-time",
        "company": "Techstars",
        "sector": "Transportation, Logistics, Supply\n                                                            Chain and Storage",
        "companySize": "201-500 employees",
        "location": "Boulder, CO",
        "post": "About the job \n\nThis is a fully remote role and can be located anywhere in the continental US.\n\nAs a Data Engineering Lead, you will lead a team of engineers to build innovative solutions that empower entrepreneurs worldwide. Techstars already has one of the largest portfolios in early stage venture capital, with over 2,300 portfolio companies, a combined market cap of more than $193B, and 12 unicorns. In this role, you and your team will build backend streaming data pipelines, integrations with third party SaaS applications, complex analytics features and app facing platform data APIs. You will take an active role in architecture and solution design and help optimize solution performance and reliability. As a result you will help Techstars attract 10x more founders, and contribute directly to scaling the Techstars footprint to serve more entrepreneurs than ever before.\n We believe in sustainable software development using Agile Development methodologies and mature DevOps practices to quickly and consistently provide value. We believe in creating robust, performant, maintainable, observable solutions. As an organization we value innovation and collaboration.\n\nWhat You Will Do\n\n\nDesign, build and deploy quality data pipelines, models, integrations and APIs in an agile team environment.\nLead a team to deliver solutions that allow for 10x growth of Techstars pipeline of startups and our accelerator programs\nMentor team members on standards, best practices and implementation of technology.\nWork with Engineering Leadership on design and implementation of technical systems.\nSupport Product Owner with OKRs, Sprint planning and stakeholder meetings as a technical resource.\nMaintain uptime and SLA of deployed software systems.\nFoster technical growth within your team by encouraging collaboration and innovation.\n\nWhat You Bring\n\n\n5+ years creating secure, reliable and performant enterprise level data cleansing, statistical modeling and analytics solutions (prefer fintech experience).\n5+ years working on a data platform using open source technology (Kafka, K8s, Redis) and cloud infrastructure or operating as managed services.\n5+ years experience with relational and non-relational database architecture (Postgres a plus)\n3+ years as a senior engineer or lead engineer, leading and mentoring other engineers\nExperience developing robust APIs\nDiverse experience with languages (ie. SQL, Python, Node, Scala) \nKnowledge of methodologies for testing quality, release management, incident response and issue resolution\nAbility to create risk mitigation strategies for system upgrades and code releases\nAbility to analyze appropriate technology stacks and major infrastructural components.\nStrong DevOps skills \nTrack record of building reusable and cohesive architecture across applications\nExperience creating technical designs that fulfill product requirements\nA team mentality towards accomplishing projects\nAbility to breakdown, prioritize and sequence development tasks for other engineers for high team utilization\nDesire to mentor and grow engineers on the team\nCoding standards utilization (Unit tests, formats, use of libraries, well structured, reusable, high quality)\nStrong communication skills with an ability to work with the Product Owner and stakeholders to understand and manifest software outcomes \n\nCompensation range: $115,000 - $155,000 + 10% Bonus\n\nUS Benefits\n\nAbout Techstars\n\nTechstars is the worldwide network that helps entrepreneurs succeed. Founded in 2006, Techstars began with three simple ideas - entrepreneurs create a better future for everyone, collaboration drives innovation and great ideas can come from anywhere. Now we are on a mission to enable every person on the planet to contribute to, and benefit from, the success of entrepreneurs. In addition to operating accelerator programs and venture capital funds, we do this by connecting startups, investors, corporations and cities to help build thriving startup communities. Techstars has invested in more than 2,300 companies with a combined market cap of more than $29B.\n Techstars\u2019 mission is to help entrepreneurs succeed wherever they are in the world and whatever their background is. Regional accelerator programs all around the world are the cornerstone of the strategy. The investment approach is fundamentally driven by the worldwide network of managing directors, who interact with startup founders daily, guiding, mentoring and cultivating them along the journey. The scale of this reach results in a diversified strategy that provides investors with a uniquely qualified deal flow.\n We help Techstars founders connect with other entrepreneurs, experts, mentors, alumni, investors, community leaders, and corporations to grow their companies.\n www.techstars.com\n\nTechstars is an affirmative action, equal opportunity employer and does not discriminate on the basis of race, sex, age, national origin, religion, physical or mental handicaps or disabilities, marital status, Veteran status, sexual orientation, gender identity nor any other basis prohibited by law."
    },
    {
        "position": "Data Engineer - Data Foundations",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Schibsted",
        "sector": "Media Production",
        "companySize": "5,001-10,000 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n Schibsted is a growing and diverse family of over 50 brands whose mission is to empower people in their daily lives and each brand contributes to it in its own way. Amongst our brands you can find leading Nordic marketplaces like Finn and Blocket, world-class media houses like VG and Aftonbladet (we are the largest media group in Scandinavia) and other rapidly developing digital companies like Prisjakt and Lendo.\n Data Foundations is a central department within Schibsted that is responsible for the data platform and is working on data fueled products with emphasis on volume, velocity and privacy. We are building products at scale, serving the whole of Schibsted and its brands.\n We are responsible for developing and maintaining machine learning models that are empowering many use-cases in Schibsted such as: producing insights about our customers, segments for the online advertising on our sites and personalization of news. Currently, our pipelines process around 1.5-2 billion events per day and the output of our models is used by the majority of the Schibsted brands.\n As a part of Schibsted, you will also have the opportunity to share knowledge and learn from other data engineers across the organisation. We encourage a diverse, collaborative and creative work environment, where you will develop and push for state-of-the-art solutions in big data processing as well as building reliable and highly scalable services.\n\nAbout the role\n\n\n\nEngineer, implement, optimize and maintain highly scalable services and data pipelines\nMake use of - Pyspark, Scala, K8S and AWS\nHelp define our development environment and communicate the best development practices within the organization (i.e. code reviews, testing, etc)\nWork with the product management team to find the best solutions to meet our customers' needs\nEnsure compliance with data governance, security policies and privacy laws.\nEnable teams and local sites across the Schibsted organization to develop data-driven products and services through cross-team initiatives and collaboration\n\n\nCompetence\n\n\n\nA Bachelor\u2019s degree in Computer Science, Informatics or relevant work experience\nKnowledge and hands-on experience with Python and Spark which are our main technologies used in data processing\nExperience with Scala or other JVM languages - our services are implemented in Scala, so ability to get up to speed with Scala is expected (experience with Java/Kotlin is a bonus)\nFamiliarity with Kubernetes, orchestration frameworks (Airflow / Luigi), DevOps, CI/CD, cloud solutions (AWS / Azure / Google Cloud), container-based workflows or distributed systems are all regarded as positive\n\n\nA little peek at what we offer\n\n\n\nInternal career growth opportunities\nFlexibility of working from home\nExcellent work equipment of choice at home and at the office \nCentral office locations\nOpportunity for development of competencies, conferences and various knowledge sharing events such as hackathons, innovation days, etc.\nMentoring, since we have many senior engineers in the team and the department\n2 lab days every month to explore new technologies and development ideas connected to our work\nOpportunity to take on various learning courses and classes through our Schibsted Learning Lab and LinkedIn Learning\nPension scheme\nSchibsted share saving and matching plans\nWellness programs (e.g. running, yoga, classes with a coach...etc.)\n\n\nOur Interview process\n\n\n\nRecruiter screening (30 min) : An initial call with a talent acquisition partner. We\u2019ll tell you a bit about us, answer any questions you may have, learn about your background and what you\u2019re looking to do\nHome assessment and code review OR live coding interview (60 min) : Done in Python/Java/Scala a take-home exercise with follow-up discussion where you meet two of our engineers or a live refactoring coding interview\nSystem design interview (60 min): System Design interview and potentially some computer science fundamentals discussions with two engineers\nValues interview (30 min): meeting the Engineering Manager and Product Manager of the team for a short discussion\nOffer extended! If you are interested in talking to more potential coworkers or have additional questions, we will also arrange any additional chats for you"
    },
    {
        "position": "Data Engineering Lead, Pipeline (487)",
        "jobType": "$115,000/yr - $229,000/yr (LinkedIn est.)",
        "jobLevel": "Full-time",
        "company": "Techstars",
        "sector": "Transportation, Logistics, Supply\n                                                            Chain and Storage",
        "companySize": "201-500 employees",
        "location": "Boulder, CO",
        "post": "About the job \n\nThis is a fully remote role and can be located anywhere in the continental US.\n\nAs a Data Engineering Lead, you will lead a team of engineers to build innovative solutions that empower entrepreneurs worldwide. Techstars already has one of the largest portfolios in early stage venture capital, with over 2,300 portfolio companies, a combined market cap of more than $193B, and 12 unicorns. In this role, you and your team will build backend streaming data pipelines, integrations with third party SaaS applications, complex analytics features and app facing platform data APIs. You will take an active role in architecture and solution design and help optimize solution performance and reliability. As a result you will help Techstars attract 10x more founders, and contribute directly to scaling the Techstars footprint to serve more entrepreneurs than ever before.\n We believe in sustainable software development using Agile Development methodologies and mature DevOps practices to quickly and consistently provide value. We believe in creating robust, performant, maintainable, observable solutions. As an organization we value innovation and collaboration.\n\nWhat You Will Do\n\n\nDesign, build and deploy quality data pipelines, models, integrations and APIs in an agile team environment.\nLead a team to deliver solutions that allow for 10x growth of Techstars pipeline of startups and our accelerator programs\nMentor team members on standards, best practices and implementation of technology.\nWork with Engineering Leadership on design and implementation of technical systems.\nSupport Product Owner with OKRs, Sprint planning and stakeholder meetings as a technical resource.\nMaintain uptime and SLA of deployed software systems.\nFoster technical growth within your team by encouraging collaboration and innovation.\n\nWhat You Bring\n\n\n5+ years creating secure, reliable and performant enterprise level data cleansing, statistical modeling and analytics solutions (prefer fintech experience).\n5+ years working on a data platform using open source technology (Kafka, K8s, Redis) and cloud infrastructure or operating as managed services.\n5+ years experience with relational and non-relational database architecture (Postgres a plus)\n3+ years as a senior engineer or lead engineer, leading and mentoring other engineers\nExperience developing robust APIs\nDiverse experience with languages (ie. SQL, Python, Node, Scala) \nKnowledge of methodologies for testing quality, release management, incident response and issue resolution\nAbility to create risk mitigation strategies for system upgrades and code releases\nAbility to analyze appropriate technology stacks and major infrastructural components.\nStrong DevOps skills \nTrack record of building reusable and cohesive architecture across applications\nExperience creating technical designs that fulfill product requirements\nA team mentality towards accomplishing projects\nAbility to breakdown, prioritize and sequence development tasks for other engineers for high team utilization\nDesire to mentor and grow engineers on the team\nCoding standards utilization (Unit tests, formats, use of libraries, well structured, reusable, high quality)\nStrong communication skills with an ability to work with the Product Owner and stakeholders to understand and manifest software outcomes \n\nCompensation range: $115,000 - $155,000 + 10% Bonus\n\nUS Benefits\n\nAbout Techstars\n\nTechstars is the worldwide network that helps entrepreneurs succeed. Founded in 2006, Techstars began with three simple ideas - entrepreneurs create a better future for everyone, collaboration drives innovation and great ideas can come from anywhere. Now we are on a mission to enable every person on the planet to contribute to, and benefit from, the success of entrepreneurs. In addition to operating accelerator programs and venture capital funds, we do this by connecting startups, investors, corporations and cities to help build thriving startup communities. Techstars has invested in more than 2,300 companies with a combined market cap of more than $29B.\n Techstars\u2019 mission is to help entrepreneurs succeed wherever they are in the world and whatever their background is. Regional accelerator programs all around the world are the cornerstone of the strategy. The investment approach is fundamentally driven by the worldwide network of managing directors, who interact with startup founders daily, guiding, mentoring and cultivating them along the journey. The scale of this reach results in a diversified strategy that provides investors with a uniquely qualified deal flow.\n We help Techstars founders connect with other entrepreneurs, experts, mentors, alumni, investors, community leaders, and corporations to grow their companies.\n www.techstars.com\n\nTechstars is an affirmative action, equal opportunity employer and does not discriminate on the basis of race, sex, age, national origin, religion, physical or mental handicaps or disabilities, marital status, Veteran status, sexual orientation, gender identity nor any other basis prohibited by law."
    },
    {
        "position": "Data Engineer-Business intelligence",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "IBM",
        "sector": "IT Services and IT Consulting",
        "companySize": "10,001+ employees",
        "location": "Taipei, Taipei City, Taiwan",
        "post": "About the job \n 577812BR\nIntroduction\nAt IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.\nYour Role and Responsibilities\n\n\nDesign, develop, and test chatbot application and automation workflows, Deploy application components including code repositories, system integration and logging tools.\nSupport the launch and implementation of chatbot and RPA solutions.\nWork with Business Analysts, Consultants, Product Managers, and other cross-functional teams to deliver projects.\nCollaborate with development team members to ensure proper implementation and integration of the solutions.\nMaintain current knowledge of developed assets, related technologies, and business processes.\n\n\nRequired Technical and Professional Expertise\n\n\n\n3 or more years of experience in Javascript (Nodejs), basic knowledge of frontend framework, such as Vue or React, experience with Databases, such as SQL and NoSQL\nExperience with Agile development methodology\nBasic knowledge of Machine Learning (ML) and Artificial Intelligence (AI)\nAbility to design technical specification documents, Ability to present technical details to non-technical audiences\nExcellent problem solving/analytical skills and complex troubleshooting methods\n\n\nPreferred Technical And Professional Expertise\n\n\n\nExperience in Redis, Node-Red,experience in CI/CD\nExperience in IBM Cloud and IBM Watson Assistant\nExperience in UiPath RPA\n\n\nAbout Business Unit\n\nIBM Consulting is IBM\u2019s consulting and global professional services business, with market leading capabilities in business and technology transformation. With deep expertise in many industries, we offer strategy, experience, technology, and operations services to many of the most innovative and valuable companies in the world. Our people are focused on accelerating our clients\u2019 businesses through the power of collaboration. We believe in the power of technology responsibly used to help people, partners and the planet.\nYour Life @ IBM\n\nAre you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.\nEvery IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change \u2013 to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.\n\nIt's time to define your career.\nAbout IBM\n\nIBM\u2019s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we\u2019re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business. At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it\u2019s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.\nLocation Statement\n\nFor additional information about location requirements, please discuss with the recruiter following submission of your application.\n\nBeing You @ IBM\n\nIBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status."
    },
    {
        "position": "Integration Software Engineer",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Volvo Group",
        "sector": "Motor Vehicle Manufacturing",
        "companySize": "10,001+ employees",
        "location": "V\u00e4stra Fr\u00f6lunda, Vastra Gotaland County, Sweden",
        "post": "About the job \n\nPosition Description\n\nJoin us on our transformation journey to the digital future\n\nAt Group Digital & IT, we have a clear ambition to enable value creation at scale for the Volvo Group. With a new product centric operating model and digital technologies, we will produce digital offerings that are profitable, scalable, and differentiated. With Group Digital & IT, you will be part of a global and diverse team of highly skilled professionals, who learn continuously and embrace change to stay ahead. We have a very important role to play in reaching the Volvo Group ambitions for 2030. Do you want to be part of our transformation journey towards becoming the digital capability of the Group? The time is now.\nThis will be us - your new colleagues within Foundational Products & Chapters\n\nFoundational Products & Chapters is part of Technology, a new function within Volvo Group Digital & IT with a big stake in the Group\u2019s digital transformation. Technology will modernize Volvo\u2019s core digital backbone making it a platform for digital products. Foundational Products & Chapters are responsible for API & Integration, DevSecOps, Cloud and Development Platforms. Our Foundational IT products are used by digital product teams and enable them and their products to outperform Volvo\u2019s competitors. Our digital talents develop capabilities and digital technologies to improve business performance and create value for the Group with speed and at scale.\nWe collaborate with other parts of the organization, both in Group Digital & IT and the rest of the Volvo Group. We foster an environment where ideas, thoughts and opinions can be shared. We are team players with clear common ambitions, and we win together.\nWHO ARE YOU?\n\nAre you interested in digitalization, the latest technology and an organization that cares about its employees?\nDo you want to work with a bunch of incredibly driven, passionate, and skilled people?\nAs a person, you have analytical skills, and you love to solve problems. You are good in communication, both when it comes to technical details as well as business needs. You have ability to build relationships and networks. You act with a sense of ownership and work with the team in mind. You like multi-tasking and to take ownership. Being a team player with positive mindset and a customer-oriented attitude is in your nature, and you know the various challenges. You must care for empowerment, inspiration and a \u201ccan do\u201d attitude. You love to see the possibilities in continues improvements.\nYou will take on the responsibility for driving features in collaboration with product owners and the design team. You will create innovative solutions and technologies to improve quality and performance. You make sure know-how and capabilities build-up cohort.\n\nYou maintain all software engineering activities across products/teams and develop high quality, scalable and maintainable systems using service-oriented architecture. You will write and test code, refining and rewriting it as necessary and communicate with any team member involved in the project. You will support end-users in runtime.\nYou understand WebSphere MQ Concepts, types, connection patterns (Queues, topics, subscriptions) and troubleshooting. Having hands on experience in MQ Tools like RFHUTIL, MQMON and experience in WebSphere Message broker (WMB), IBM integration bus (IIB) & ACE with coding knowledge in ESQL, Java and Maven is good.\nYou are familiarity with multiple message formats in XML (XSDs, WSDLs), JSON, fixed formats and custom formats using Message sets and integration with SOAP and REST Services. You have knowledge on database clients, connections and queries to work with tables during integrations with IIB, Broker. You have knowledge in cloud set up like sprint boot, containers.\nYou are curious to understand and work on all layers of a solution or service stack, from the presentation layer down to the infrastructure layer. You will be part of a global team where you will be driving analysis and maintaining the architecture.\nAre you curious and have some questions? Call us!\n\nContacts:\n\nFredrik Blom, Head of API and integration, Volvo Group Digital & IT, +4670 91 19 930\nTherese Envall, HRBP, Volvo Group Digital & IT\nThe location for the position is flexible, with G\u00f6teborg, (SE), Wroclaw (PL) or Lyon (FR) as preferred locations.\nUnion representatives for Swedish applicants:\n\nAkademikerna \u2013 Therese Koggdal, +46 470 387855\nUnionen - Johan Svedberg, +46 31 3222712\nLedarna \u2013 Ulrika Holmberg, +46 31 3225071\nWe are looking forward to reading your application!\nKindly note that due to GDPR, we will not accept applications via mail. Please use our career site.\nAbout Us\n\nThe Volvo Group drives prosperity through transport solutions, offering trucks, buses, construction equipment, power solutions for marine and industrial applications, financing and services that increase our customers\u2019 uptime and productivity. Founded in 1927, the Volvo Group is committed to shaping the future landscape of sustainable transport and infrastructure solutions. Countless career opportunities are offered across the group\u2019s leading brands and entities that share a culture of Trust, Passion, High Performance, Change and Customer Success.\nwww.volvogroup.com/career.\nGroup Digital & IT has the ambition to enable value creation at scale for the Volvo Group. Digital solutions are becoming more and more key in the industries, where we are operating. The solutions and emerging technologies, provided by Group Digital & IT, enable our customers and their customers to do more with less, better for others and best for the future.\nWe are 3,600 employees located in more than 30 countries, present at all major Volvo Group locations, and we are working in a completely global organization.\nIn Group Digital & IT we strive for something bigger, we are truly customer centric, and we collaborate with inclusion, together cross the Volvo Group. We learn to stay ahead, we are curious and eager to acquire new and deeper knowledge, both as individuals and as teams.\nAuto req ID\n\n133826BR\nOrganization\n\nGroup Digital & IT\nState / Province\n\n\nFlexible\n\n\n\n\nCity/Town\n\n\nFlexible\n\n\n\n\nEmployment/Assignment Type\n\nRegular\nTravel Required (maximum)\n\nOccasional Travel\nFunctional Area\n\nInformation Technology\nFlexible locations\n\nFrance,Lyon,Auvergne-Rh\u00f4ne-Alpes, Poland,Wroc\u0142aw,dolno\u015bl\u0105skie, Sweden,G\u00f6teborg,V\u00e4stra G\u00f6taland\nLast application date\n\n30-Oct-2022"
    },
    {
        "position": "Senior Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Telia",
        "sector": "Telecommunications",
        "companySize": "10,001+ employees",
        "location": "Solna, Stockholm County, Sweden",
        "post": "About the job \n Do you want to work with lots of data, use modern technologies and join a passionate, fun team of individuals working in the telecommunication and streaming industry? Will you take part in building a data-driven and personalized user experience in one of Sweden's largest telecommunication?\n We are looking for a Senior Data Engineer to strengthen our team working on products that turn mobile network data into actionable insights, improve TV users' experience and content, enable decision makers building a sustainable society based on real-world data they can trust.\n\nIs this your next opportunity? \n\nAt Telia Company, you will have a key role in our group common Data & Analytics team and help us to create true business value through data and analytics and make Telia Company a more data-driven organization. To succeed, we need to shorten time to insight and build even more amazing data products. This is where we need your help.\n Our team consists of data engineers, data analysts, data scientists, solution architects and product owners, working together in different cross-functional, domain-oriented agile DevOps teams building analytical solutions to for example TV & Media, Crowd Insights, Telia Finance, Connectivity and Networks to name a few.\n\nIs this you? \n\nTelia Company is changing every day and so are we in the Data & Analytics team. To fit the bill, you need to master technology and be a team player. You want to constantly learn and you're not afraid to challenge how things are done today. We are a big team and we reach success together, which means we don't have any room for solo players. You are also able to think long-term and design sustainable data pipeline architectures.\n As a Senior Data Engineer, you will have a central role in implementing robust data pipelines and storage solutions that are capable of handling very large data sets \u2013 we currently handle over a billion data points per day in on-prem and cloud solutions.\n\nYou love being a developer and creating insights! In addition, you find it extra exciting with data, data transformations and setting high data engineering standards. You put a lot of pride in your code, and think interaction with others is important for your own and your colleagues' development. You enjoy taking responsibility and think simplification is something to seek for. We are a good mix of people and are looking for you who are not only good at what you do, but who can add positive energy to the team.\n\nYour personality: \n\n\nEager and flexible to learn new skills and adapt to new technologies.\nDare to challenge yourself and colleagues to continuously improve \nStrong problem solver, enthusiastic about combing through sometimes complex, structured and unstructured data\nStrong customer focus and committed to deliver best possible value for users \nAbility to prioritize between speed, quality and value \nExcellent collaboration with colleagues and stakeholders\n\nYour Experience: \n\n\n7-10 years of experience as a data specialist with solid SQL skills and can write clean, performance-optimized queries\nPrior experience with BigData, and ETL tools and technologies like SQL, Scala, Python. Experience in cloud technologies, e.g. AWS, GCP and terraform will be a plus.\nExperience in CI/CD, Aiflow, and a good understanding of big data concepts, cloud technologies, data modelling, data governance, and BI presentation\nExperience developing and maintaining efficient ETL workflows, navigate through complex scripts and workflows, and can make enhancements or code fixes, if needed\nExperience in agile workflow and strong knowledge in DevOps\nMaster's Degree in Computer Science or similar field\nStrong English communication skills. Swedish is a plus\n\nIt\u2019s more than just a job! \n\nRegardless of the position you are looking for, we will give you the tools and support you need to grow both as a professional and as a person, with us. We can offer you your next big opportunity in a creative, motivating, and welcoming company where everyone can be themselves, with equal access to opportunities. We respect and value the diversity of people. In addition to an attractive and inclusive work environment, we also enable flexibility and offer a wide variety of employee benefits.\u202f\n\nInterested? \n\nIf you fancy joining our team, don\u2019t hesitate to apply! If you want to know more about the job you are welcome to contact me at hassan.z.shahbaz@teliacompany.com\n We look forward to receiving your application and to make sure that your personal data is kept safely, we kindly ask you to apply through our recruitment system. We are not able to handle resumes via e-mail or equivalent. Selection will take place on an ongoing basis and this position might be filled before the application deadline. Application deadline is\u202f2022-11-15\n\nRequired controls will be performed\n\nWelcome to Telia \u2013 Home to your next big opportunity!"
    },
    {
        "position": "Data Engineer - QuantumBlack",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "QuantumBlack, AI by McKinsey",
        "sector": "IT Services and IT Consulting",
        "companySize": "1,001-5,000 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nQualifications\n\n\nDegree educated in computer science, engineering, mathematics or related field\nAbility to write clean, maintainable and robust code in Python and SQL; familiarity with Java and Scala is a plus\nKnowledge of software engineering concepts and best practices \nFamiliarity with the latest OSS, cloud, container, query and database technologies as well as query languages\nExperience with big data tools such as Hadoop, Spark, Kafka, Hive is a plus\nPrevious commercial experience in a data-driven role\nConfirmed experience building data pipelines in production and ability to work across structured, semi-structured and unstructured data\nExperience preparing data for analytics and following a data science workflow\nCommercial client-facing or senior stakeholders management experience is a plus\nBusiness level fluency in the local language and English (verbal and written)\n\nWhat You'll Do\n\nAs a data engineer at QuantumBlack, you will work in multi-disciplinary environments harnessing data to provide real-world impact for organisations globally. You will influence many of the recommendations our clients need to positively change their businesses and enhance performance.\n\nRole Responsibilities\n\n\nPartner with our clients, from data owners and users to C-level executives, to understand their needs and build impactful analytics solutions\nDesign and build data pipelines to support data science projects following software engineering best practices\nUse state of the art technologies to acquire, ingest and transform big datasets\nMap data fields to hypothesis, curate, wrangle and prepare data to be used in advanced analytics models\nCreate and manage data environments in the cloud or on premise \nEnsure information security standards are maintained at all time \nContribute to cross-functional problem-solving sessions with your team and deliver presentations to colleagues and clients \nBe flexible to travel to our clients' offices to deliver presentations, gather information or share knowledge\n\nOur tech stack\n\nWhile we advocate for using the right tech for the right task, we often leverage the following technologies Python, PySpark, SQL, Airflow, Databricks, Kedro (an OSS developed by QuantumBlack), container technologies such as Docker and Kubernetes, cloud solutions such as AWS, GCP or Azure, and more!\n\nWho You'll Work With\n\nYou will join our Copenhagen, Oslo or Stockholm office as part of QuantumBlack. You will work with other data engineers, data scientists, designers and strategy consultants on interdisciplinary projects.\n You'll work hands in hands with our clients, from data owners and users to C-level executives."
    },
    {
        "position": "Data and Software Engineer (Senior / Staff Engineer) (m/f/d) - Arriver Munich, Germany",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Qualcomm",
        "sector": "Wireless Services",
        "companySize": "10,001+ employees",
        "location": "Munich, Bavaria, Germany",
        "post": "About the job \n\nCompany\n\nArriver Software GmbH\n\nJob Area\n\nEngineering Group, Engineering Group > Software Engineering\n\nAbout The Team\n\nGeneral Summary:\n\nIn the Data Management area, we develop and operate automated cloud and on-premises solutions for large-scale performance evaluation of ADAS (advanced driver assistance systems) / AD (autonomous driving) sensors and functions.\n The focus for developing our applications follows the cloud first approach but might also include running our applications on-premises. Our goal is to design and build a highly scalable, efficient, and modular data platform. This platform will be used by engineers to run re-simulation pipelines, machine learning workloads, perform in-depth data analysis/analytics, visualize results, and more.\n We are looking for very motivated colleagues with a strong Data Engineering background combined with a very strong Software Engineering knowledge to further extend our team in Unterschlei\u00dfheim. We are looking for engineers with different levels, ranging from Senior Engineer to Staff Engineer.\n The Data Management team(s) develop, own, and run the applications that together form a platform-like layer in between the cloud provider\u2019s managed services and the applications / pipelines run on top of it. We are facing most challenging problems that require clear dedication and passion for solving complex problems. The team does work in a distributed environment, where international cooperation with Automotive OEMs plays an as important role as cooperating with Qualcomm colleagues from all over the world.\n\nWhat You'll Do\n\n\nDevelop, maintain, and operate our Data Management cloud applications for ADAS/AD testing\nResearch and implement state-of-the-art concepts and techniques in Cloud and Big Data scopes\nAdapt and apply our solutions within international customer projects in close cooperation with our function development teams\nLearn every day to leverage the best knowledge to solve the complex world\u2019s problems of tomorrow\nWork in a highly motivated, international team using SAFE (or similar frameworks) as the overarching agile framework for coordination\nChallenge yourself and your teammates in delivering the best software we possibly can\nCollaborate with internal teams, teams from cooperation partners and external teams from contractors\n\n\nWhat You'll Bring\n\n\nUniversity degree in Computer Science, or a similar field\nSolid background in Data and Software Engineering principles \n4-6+ years of proven hands-on experience in using Hadoop-like Big Data frameworks \u2013 any Hadoop distribution and Apache Spark \u2013 or similar frameworks in cloud environments\nHands-on experience with cloud platforms like AWS or Azure.\n4-6+ years of proven hands-on experience using Docker and Kubernetes\n4-6+ years of proven hands-on experience using infrastructure and configuration management tools such as Terraform, Ansible, and Helm\n4-10+ years of proven hands-on experience in writing clean, well-documented, reusable code in Scala, Java, JavaScript, Python, or similar languages, other languages are beneficial \nUnderstanding of RDBMS, NoSQL DB technologies, and data warehousing solutions and tradeoffs\nGeneric knowledge in standard software development processes, such as code review, unit testing, CI/CD, infrastructure as code and similar\nADAS/AD sensor and software development/testing experience is very beneficial\nHands-on skills in creating RESTful APIs are required and knowledge in creating web UIs is beneficial\nProduct awareness and maker mindset\nStrong interpersonal skills and demonstrated ability to work with multi-functional teams\nExcellent communication skills and fluent in English language\n\n\nMinimum Qualifications\n\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Engineering or related work experience.\n\n\nOR\n Master's degree in Engineering, Information Systems, Computer Science, or related field and 1+ year of Software Engineering or related work experience.\n OR\n PhD in Engineering, Information Systems, Computer Science, or related field.\n2+ years of experience with Programming Language such as C, C++, Java, Python, etc.\nReferences to a particular number of years experience are for indicative purposes only. Applications from candidates with equivalent experience will be considered, provided that the candidate can demonstrate an ability to fulfill the principal duties of the role and possesses the required competencies.\n\n\nAlthough this role has some expected minor physical activity, this should not deter otherwise qualified applicants from applying. If you are an individual with a physical or mental disability and need an accommodation during the application/hiring process, please call Qualcomm\u2019s toll-free number found here for assistance. Qualcomm will provide reasonable accommodations, upon request, to support individuals with disabilities as part of our ongoing efforts to create an accessible workplace.\n Qualcomm is an equal opportunity employer and supports workforce diversity.\n\nTo all Staffing and Recruiting Agencies: Our Careers Site is only for individuals seeking a job at Qualcomm. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications or resumes, and any such submissions will be considered unsolicited. Qualcomm does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications.\n If you would like more information about this role, please contact Qualcomm Careers."
    },
    {
        "position": "Senior Database Developer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Trustly",
        "sector": "Financial Services",
        "companySize": "501-1,000 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nAt Trustly, we\u2019re passionate about simplifying the way people pay and get paid online. We\u2019re a licensed payment institution and our B2B products available across Europe, North America and Australia attract global merchants in segments such as e-commerce, telecom, travel, financial services, and gaming. In June 2018, private equity firm Nordic Capital acquired a majority stake in Trustly with ambitions to support us in becoming the leading global online banking payments provider.\n\nWe are a diverse and fast-growing team with our headquarters in Stockholm, Sweden, and 9 additional offices across Europe and North America. Together we are leading the development of the payments industry and the work you\u2019ll do here will make a great impact. Trustly is a tech company at heart. Two of our three founders are developers and you\u2019ll get the chance to work alongside many talented and motivated colleagues who will help you learn and grow.\n\nAbout The Role\n\nTrustly is growing rapidly and we work continuously to maintain, improve and modernize the current product platform. We are very humble and grateful that our products are attracting more and more customers in e-commerce, travel, gaming, and financial services. Due to the fast growth of our business and the number of transactions we are looking for Database Developers to join our team.\n In this position, you will work with new development as well as maintenance of our transaction system. Most of Trustly's backend system is written using an extensive collection of PostgreSQL functions, SQL & PL/pgSQL, as well as other languages, where appropriate, to implement the business logic. For future work, however, we have decided on SQL, PL/pgSQL & Python3. The team is experienced and several developers are active in the PostgreSQL Community and have contributed to the DB Core.\n What you'll do:\n\nDevelop the Trustly db-application, which is written mainly in PostgreSQL functions, it\u2019s the base of our product and heavily relied upon by all other backend systems.\nCollaborate with product owners, team leads, and other developers to discuss requirements and implement solutions.\nManage code reviews and support other developers with feedback. \nContribute as a team player and mentor junior developers.\n\nWe believe you have:\n\nExperience with PostgreSQL\nExcellent SQL skills\nExperience with tuning and optimization of databases and queries \nExperience creating database designs, database architectures and data-intensive database solutions\nExperience with Python and/or PHP\nExperience with Linux systems, preferably Ubuntu/Debian\nExperience with GIT\nStrong communication skills\nEnglish fluency \n\nTrustly Tech-stack:\n\nPostgreSQL, Kafka, Redis\nAWS \nKubernetes, EKS, Docker, Istio\nGitHub actions, ArgoCD\nUbuntu Linux, CentOS Linux\nHashicorp Terraform\nAnsible\nGit\nJava\nPrometheus & Grafana"
    }
]