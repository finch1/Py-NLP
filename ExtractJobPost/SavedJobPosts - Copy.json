[
    {
        "position": "Machine Vision System Engineer",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Boston Scientific",
        "sector": "Medical Equipment Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Galway, County Galway, Ireland",
        "post": "About the job \n More than the opportunity of a lifetime...the chance to improve lives\n Boston Scientific is one of the world\u2019s largest medical device companies, employing over 36,000 employees. It develops, manufactures and markets more than 13,000 products in over 120 countries, treating approximately 30 million patients annually. The medical devices are used in various interventional medical specialities, including interventional cardiology, peripheral interventions, neuromodulation, neurovascular intervention, electrophysiology, cardiac surgery, vascular surgery, endoscopy, oncology, urology and gynaecology.\n We are excited to add a new Machine Vision System Engineer to our Equipment Engineering Group here at our Galway site.\n As our successful candidate, you will work with our manufacturing partners to develop new and innovative vision solutions in line with our Industry 4.0-Smart Factory strategies. Innovative vision solutions offer the opportunity to deliver intelligent manufacturing machines and optimise production systems while working in a purpose-built technology innovation laboratory. You will also have the chance to assist R&D and Operations on New Product Development Programs and Sustaining Programs by participating in the Prototyping, Design, Build, Commissioning and Qualification of New Equipment as well as Equipment Upgrades.\n The role is primarily based in Galway, a world-class facility, although travelling abroad may be required from time to time for short periods. Working times are usually Monday to Friday, although some periodic weekend work may be needed per production schedules.\n\nKey Activities Of The Role\n\nDefine, implement and maintain architectures to retrieve, archive and analyse production image data. Develop, test, validate and deploy computer vision systems using open-source and proprietary tools such as VisionPro, Insight and MVTech. Provide strong leadership and problem solving to enable equipment technology innovation. Work closely with the customer to understand product visual inspection requirements and propose creative and cost-effective solutions to automate inspections. Generate quotations, concepts and business cases for new and upgraded business systems. Ensure equipment and business requests are processed promptly and effectively and manage the execution of results. Determine project schedules and work with the team and other departments across the plant to ensure adherence. Manage projects and portions of projects as part of a larger team. Lead and participate in cross-functional Design Reviews. Draft and Review Design and Compliance Quality System documentation. Write detailed functional design requirements. Contribute to all phases of software development, including design, implementation, unit test, integration, release and validation support. \n\n\nQualifications & Experienced\n\nEngineering qualification equivalent to or above NFQ Level 8 Three plus years of experience developing Vision Systems is essential. Proprietary Machine Vision / Image Processing tools (e.g. Cognex VisionPro and Insight, MVTec, LabVIEW). Optics, sensors and lighting applied to industrial machine vision. C#.NETor similar. Digital Image Processing techniques and dataflows applied to industrial machine vision. Advance Statistical analysis knowledge. Proprietary Machine Learning software (e.g. Cognex VIDi, MVTec, Matlab) is preferred. Basic knowledge of deep learning theory and techniques is desirable. TensorFlow 2+, OpenCV, and Pandas in Python environments are desirable. Knowledge of Robotics and Controls. GAMP / Documentation life cycle for regulated industries Imaginative and creative approach to problem-solving and continuous improvement. \n\n\nAt Boston Scientific, we recognise that nurturing a diverse and inclusive workplace helps us be more innovative. It is essential in advancing science for life and improving patient health. We stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve. Boston Scientific is proud to be an equal opportunity and affirmative action employer. #IJ"
    },
    {
        "position": "Senior Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Crayon",
        "sector": "IT Services and IT Consulting",
        "companySize": "1,001-5,000 employees",
        "location": "Sweden",
        "post": "About the job \n\n\nInterested in an exceptional career opportunity for a true data enthusiast?\nEnjoy a role that involves the latest cloud data platform technologies and frameworks?\nKeen to join a technologist driven growing global company?\n\n\nApply now and join our global team as a Senior Data Engineer for Crayon!\n\n\nCrayon's data platform is developed as the cornerstone that enables the company to be data-driven, from enabling business intelligence, to supporting products and services, to AI-enabled solutions for greater efficiency across Sales, Finance and more. We leverage modern technologies and best practices, including Azure DevOps, Synapse and Purview, a hybrid data mesh ownership model on top of a lake house, ability to build self-service reporting. All with proper security, privacy and governance in mind.\n\n\nAs a data platform team member, you will drive best practices to make data sources available to business, including dependency resolution and data governance. You will also have the opportunity to work with the team in building the overall platform, from data architecture design to CI/CD pipelines, from implementing privacy by design to defining the access model.\n\n\nKey responsibilities to highlight:\n\nIdentify data sources, design and integrate entities that allow meeting requirements from business stakeholders\nDiagnose data quality issues and liaise with data source owners to come up with potential preventive or corrective measures\nImplement pipelines using a combination of technologies, including git, SQL, Spark, Python and the Azure data tech stack \nBuild datasets that create data-driven insight, influence operational decision-making, and enable data-driven products and services\nWork with your colleagues to build a flexible and scalable platform, both implementation-wise and operationally\n\n\n\nWe envisage you to be a self-managing and self-motivated individual, with strong organizational and time management skills, who works structured and methodically through your daily tasks. Furthermore, you are a team player with effective collaboration and communication skills. Moreover, you have solution-oriented mindset, and you deliver excellent service to our clients.\n\n\nDesired competency & experience:\n\n5 years+ professional experience in designing, building, and maintaining scalable, high-performance data solutions\nFluency in Python\nStrong practical experience with ETL and ELT, as well as with the Azure data ecosystem (DevOps, ADF, ADLS, Synapse) or, alternatively, equivalent in another cloud\nUnderstanding of software development best practices\nExperience with Delta Lake, APIs (REST, GraphQL), data from CRM and/or ERP systems, Spark, and related technology ecosystem, as well as Azure Data Engineer Associate certification are valuable \n\n\n\nPRACTICAL INFORMATION:\n\nLocation for this job: Remote, Sweden, Austria, Serbia, UK or Spain\nLanguage requirements: Excellent written and verbal English skills\nApplication deadline: ASAP. We will evaluate candidates continuously.\nVisa requirements: Must have work permit/visa. We are looking for someone who is ideally already based in one of the mentioned countries, and that could start relatively quickly"
    },
    {
        "position": "NLP Data Scientist/Engineer",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Roche",
        "sector": "Biotechnology Research",
        "companySize": "10,001+ employees",
        "location": "Pozna, Wielkopolskie, Poland",
        "post": "About the job \n The Position\n\nNLP Data Scientist/Engineer\n\nIT INNOVATORS IN HEALTHCARE\n\nWe do #Code4lLife creating innovative software that helps doctors, patients, and scientists around the world.\n\nWho We Seek\nIdeal candidate for this position has:\n\nUnderstanding of basic concepts from area of Text Mining, NLP and NLU, hands-on experience with regular expressions\nKnowledge from area of embedding representations and deep learning based solutions for NLP (word2vec, Gensim)\nExperience with our typical NLP tools used in daily work:\nscikit learn, numpy, pandaspytorch or tensorflowspaCy, NLTK\n\n\n\nExperience in NLP/AI software engineering, especially\n\nproficiency with Python\nexperience with Git, Gitlab\nknowing Jira, CI/CD tools is nice to have\nunderstanding of software testing (unit tests, integration tests, smoke tests)\nbash/shell scripting\n\n\nEXAMPLE PROJECTS ACTIVITIES YOU MAY WORK ON\n\n\nDeveloping pipelines for solving NLP tasks (predictions, clustering, deviations detection) for generating insights and extracting knowledge from millions of internal documents\nImplementing fully working AI/NLP powered applications for supporting our colleagues from all the departments, for instance: pharma, molecules development, clinical trials, sales, marketing, people & culture or IT\nBuilding toolset and re-usable components for our future projects and ideas\n\n\nWhat We Appreciate\n\n\nAbility to learn new technologies (we can teach you them as well!)\nAnalytical mindset and critical thinking\nGood communication skills\nOpenness for knowledge sharing\n\n\nWhat You Get\n\n\nSalary range 10 000 - 14 000 PLN gross\nAnnual bonus payment based on your performanceContract of employment \nEmphasis on continuous personal and professional self-development supported by a dedicated training budget (training, certifications, conferences, diversified career paths etc.)\nExperienced and professional colleagues and workplace that supports innovation and new ideas\nHighly flexible working hours (starting your day at 7-11) and workplace according to employee\u2019s needs and preferences* (regular office/home office)\nA chance to work on solutions which can improve patients\u2019 lives\n\n\nAdditional Benefits\n\n\nRelocation package\nPrivate healthcare and insurance\nHealth, well-being and sport promotion\nSupport for parents and families\nStock share purchase additions\nYearly sales of company laptops and cars\nAdditional vacation time for long-term employees and more\n\n\nAPPLY DIRECTLY\n\nApply directly via Workday, pressing the blue button at the top.\n If you feel this offer suits a friend of yours, we\u2019ll appreciate you letting them know! Simply copy and share the link from the browser.\n If you have any questions regarding the offer and would like to contact us directly, please write to us at <\n katarzyna.wisniewska@roche.com>\n WANT TO KNOW MORE?\n Check our website for more details, e.g. the career path, recruitment process, etc.\n https://it.roche.pl/work-with-us\n Want to know what it\u2019s like to be a part of Roche IT first-hand? Check out our blog! You will meet the community members there, sharing their experience and impressions from diverse perspectives, not only about their job but also their lives.\n https://www.roche.com/careers/weareroche.htm\n Please note that during the pandemic we are working and recruiting 100% remotely.\n \u2026..\n\nRoche is an equal opportunity employer. We care about inclusion in terms of gender, age, race, skin colour, nationality, religion, marital status, sexual orientation, background, physical or mental disabilities and on every other grounds. Applying for our position, we assure you that we will assess your application solely on the basis of your competencies.\n\nAdministratorem Pani/Pana danych osobowych jest sp\u00f3\u0142ka Roche Polska Sp. z o.o., ul. Domaniewska 39 B, 02-672 Warszawa. Dane przetwarzane s\u0105 w celu prowadzenia rekrutacji. Przys\u0142uguje Pani/Panu prawo dost\u0119pu do tre\u015bci swoich danych, ich sprostowania, usuni\u0119cia, ograniczenia przetwarzania, przenoszenia oraz \u2013 w sytuacji, gdy s\u0105 one przetwarzane na podstawie udzielonej zgody \u2013 cofni\u0119cia tej\u017ce zgody w dowolnym momencie. Kontakt do Inspektora Ochrony Danych:ochrona.danych@roche.com. Wi\u0119cej informacji o zasadach przetwarzania przez Roche Pani/Pana danych osobowych pod linkiem: \n\n https://www.roche.pl/pl/content/klauzula-informacyjna-rekrutacja-pl.html\n\nThe controller of your personal data is Roche Polska Sp. z o.o., ul. Domaniewska 39 B, 02-672 Warsaw. The data is processed for the purpose of recruitment. You have the right to access your data, rectify it, delete it, limit processing, transfer it and - if processing is based on your consent - withdraw this consent at any time. Contact the Data Protection Officer at: Ochrona.danych@roche.com. More information on the principles of processing your personal data by Roche at the link: \n\n https://www.roche.pl/pl/content/klauzula-informacyjna-rekrutacja-en.html\n Who we are\n At Roche, more than 100,000 people across 100 countries are pushing back the frontiers of healthcare. Working together, we\u2019ve become one of the world\u2019s leading research-focused healthcare groups. Our success is built on innovation, curiosity and diversity.\n At Roche Poland, we are more than 800 professionals working together on one mission. We are proud of who we are, what we do and how we do it. Join us in the area of Clinical Research, Medical, Marketing, IT or business departments.\n Roche is an Equal Opportunity Employer."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Roche",
        "sector": "Biotechnology Research",
        "companySize": "10,001+ employees",
        "location": "Pozna, Wielkopolskie, Poland",
        "post": "About the job \n The Position\n Data Engineer\n\nIT INNOVATORS IN HEALTHCARE\n\nWe do #Code4Life creating innovative software that helps doctors, patients, and scientists around the world.\n\nWho We Seek\n\n\nProven experience in the designing and delivery of complex Data Engineering solutions\nKnowledge about designing and developing at-scale ETL/ELT processes and frameworks on the cloud platforms - preferably AWS \nProgramming skills in scripting languages like Python, R, and Bash as well as knowledge about data processing using SQL\nExperience with Docker and Kubernetes and knowledge about designing CI/CD data processing pipelines\n\n\nYour main responsibilities will be:\n\n\nCollaboration with Architects, Tech Leaders and development team to identify and implement automation strategies that enable high-quality, faster delivery of data products\nWork on strategy, plan, and execution of Data Engineering / DataOps concepts on a large scale\nActing as a Data Engineering evangelist promoting DataOps culture among development teams within the organization\n\n\nWhat We Appreciate\n\n\nExperience with data processing tools like Airflow (standalone or AWS MWAA), AWS Glue, Lambda, and AWS Step Functions, DBT\nExperience with the data quality tools and frameworks \n\n\nWhat You Get\n\n\nSalary range 16 000 - 21 000 PLN gross\nAnnual bonus payment based on your performance\nEmphasis on continuous personal and professional self-development supported by a dedicated training budget (training, certifications, conferences, diversified career paths etc.)\nExperienced and professional colleagues and workplace that supports innovation and new ideas\nHighly flexible working hours (starting your day at 7-11) and workplace according to employee\u2019s needs and preferences* (regular office/home office)\nA chance to work on solutions which can improve patients\u2019 lives\n\n\nAdditional Benefits\n\n\nRelocation package\nprivate healthcare and insurance\nhealth, well-being and sport promotion\nsupport for parents and families\nstock share purchase additions\nyearly sales of company laptops and cars\nadditional vacation time for long-term employees and more\n\n\nAPPLY DIRECTLY\n\nApply directly via Workday, pressing the blue button at the top.\n If you feel this offer suits a friend of yours, we\u2019ll appreciate you letting them know! Simply copy and share the link from the browser.\n If you have any questions regarding the offer and would like to contact us directly, please write to us at katarzyna.wisniewska@roche.com\n\nWANT TO KNOW MORE?\n\nCheck our website for more details, e.g. the career path, recruitment process, etc.\n https://it.roche.pl/work-with-us\n Want to know what it\u2019s like to be a part of Roche IT first-hand? Check out our blog! You will meet the community members there, sharing their experience and impressions from diverse perspectives, not only about their job but also their lives.\n https://www.roche.com/careers/weareroche.htm\n Please note that during the pandemic we are working and recruiting 100% remotely.\n\nRoche is an equal opportunity employer. We care about inclusion in terms of gender, age, race, skin colour, nationality, religion, marital status, sexual orientation, background, physical or mental disabilities and on every other grounds. Applying for our position, we assure you that we will assess your application solely on the basis of your competencies.\n\nAdministratorem Pani/Pana danych osobowych jest sp\u00f3\u0142ka Roche Polska Sp. z o.o., ul. Domaniewska 39 B, 02-672 Warszawa. Dane przetwarzane s\u0105 w celu prowadzenia rekrutacji. Przys\u0142uguje Pani/Panu prawo dost\u0119pu do tre\u015bci swoich danych, ich sprostowania, usuni\u0119cia, ograniczenia przetwarzania, przenoszenia oraz \u2013 w sytuacji, gdy s\u0105 one przetwarzane na podstawie udzielonej zgody \u2013 cofni\u0119cia tej\u017ce zgody w dowolnym momencie. Kontakt do Inspektora Ochrony Danych:ochrona.danych@roche.com. Wi\u0119cej informacji o zasadach przetwarzania przez Roche Pani/Pana danych osobowych pod linkiem: \n\n https://www.roche.pl/pl/content/klauzula-informacyjna-rekrutacja-pl.html\n\nThe controller of your personal data is Roche Polska Sp. z o.o., ul. Domaniewska 39 B, 02-672 Warsaw. The data is processed for the purpose of recruitment. You have the right to access your data, rectify it, delete it, limit processing, transfer it and - if processing is based on your consent - withdraw this consent at any time. Contact the Data Protection Officer at: Ochrona.danych@roche.com. More information on the principles of processing your personal data by Roche at the link: \n\n https://www.roche.pl/pl/content/klauzula-informacyjna-rekrutacja-en.html\n Who we are\n At Roche, more than 100,000 people across 100 countries are pushing back the frontiers of healthcare. Working together, we\u2019ve become one of the world\u2019s leading research-focused healthcare groups. Our success is built on innovation, curiosity and diversity.\n At Roche Poland, we are more than 800 professionals working together on one mission. We are proud of who we are, what we do and how we do it. Join us in the area of Clinical Research, Medical, Marketing, IT or business departments.\n Roche is an Equal Opportunity Employer."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Tyson Foods",
        "sector": "Food and Beverage Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Lisbon, Portugal",
        "post": "About the job \n\nTechnical qualifications\nRequired Skills:\n\u00b7 Experience building analytics solutions in cloud-based platforms such as GCP (Big Query, Dataflow, Cloud Storage) & AWS (Redshift, S3, AWS Glue, Greengrass).\n\u00b7 Hands on experience with SQL and Query Optimization.\n\u00b7 Java/Apache Beam.\n\u00b7 Python.\n\u00b7 The ideal candidate would have 3 years of data ingestion and integration experience.\nPreferred Skills:\n\u00b7 CI/CD & DevOps Principles.\n\u00b7 Kubernetes.\n\u00b7 Terraform.\n\u00b7 Metadata management, data quality, data visualization, and agile methodologies.\n\n\nAbout the job\nTyson Foods Core+ Development team is seeking a Senior Data Engineer who will build Analytics solutions on cloud platforms like GCP & AWS. The primary focus is to design and build data pipelines using open-source technologies to bring in data from IoT devices, external data sources, and internal data sources. This role will translate requirements to build integrated solutions with automated deployments and monitoring following cloud platform best practices. \nYou can be part of a team that is constantly fostering the innovation and the implementation of cutting-edge technologies while building high-performance and scalable solutions. This team is primarily responsible for data integration across Tyson\u2019s applications and will be collaborating with most areas within IT. If you enjoy working in a rapidly changing environment and influencing the strategic direction of a large global organization, this position will provide you with that opportunity.\n\n\nCheck out Tyson Technology!\n\n\nTyson Foods\u2019 Equal Opportunity Employer Statement:\n\nTyson Foods is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will be considered without regard to race, national origin, color, religion, age, genetics, sex, sexual orientation, gender identity, disability or veteran status.\n\n\n*** In case we do not contact you within three weeks of your application please consider this a negative response. Thank you for understanding ***"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Amgen",
        "sector": "Biotechnology Research",
        "companySize": "10,001+ employees",
        "location": "Lisboa, Lisbon, Portugal",
        "post": "About the job \n\nHOW MIGHT YOU DEFY IMAGINATION?\n\nTHE AMGEN CAPABILITY CENTER IN LISBON, PORTUGAL (ACCP) will be home to over 300 multi-national and multi-cultural employees, representing a broad range of cross functional capabilities, including Commercial, General and Administrative, Research and Development and more. The ACCP will offer rich career growth and development opportunities, regional and global exposure and the opportunity to LIVE, WIN and THRIVE in one of Europe\u2019s most attractive cities.\n Our ACCP offices will be temporarily located at the Maleo \u2013 Saldanha, Av. da Rep\u00fablica 18, 1050-191 Lisbon, while we work toward finding a permanent office in the vibrant city center of Lisbon.\n\nData Engineer\n\nLive\n\nWhat You Will Do\n\nLet\u2019s do this. Let\u2019s change the world. Global Commercial Operational IS is looking for a talented Data Engineer, who is curious to learn and able to develop data engineering and data analytics solution in a fast-moving environment. Candidate will work closely with senior data engineer and product owner/business analyst to understand the requirement. This role will be part of the newly established technical/engineering team, develop data flow pipelines to extract, transform, and load data from various data sources in various data format to enterprise data lake and data warehouse system in three regions in AWS. Provide data analytics and predictive analysis to business users.\n The Data Engineer will be based out of Amgen\u2019s Capability Center in Lisbon. At Amgen, our mission is simple: to serve patients. Our Capability Center provides essential services that enable us to better pursue this mission. This state-of-the-art center serves as a base for finance, information systems, and human resources professionals to make a meaningful impact at one of the world\u2019s leading biotechnology companies.\n\n\nBe a key team member assisting in design and development of the data pipeline for Global Data and Analytics team\nCollaborate with Data Architects, Business SME\u2019s, and Data Scientists to design and develop end-to-end data pipeline to meet fast paced business need across geographic regions\nServe as system admin to manage AWS and Databricks platform; \nAdhere to best practices for coding, testing and designing reusable code/component\nAble to explore new tools, technologies that will help to improve ETL platform performance\nParticipate in sprint planning meetings and provide estimations on technical implementation; Collaborate and communicate effectively with the product teams\n\n\nWin\n\nWhat We Expect Of You\n\nWe seek a self-starter with these qualifications:\n\nBasic Qualifications\n\nMaster\u2019s Degree\n OR\n Bachelor\u2019s degree with 2 years Data Engineering and/or and Software Engineering experience\n OR\n Associate\u2019s degree 6 years of Data Engineering and/or Software Engineering experience\n OR\n High school diploma and 8 years of Data Engineering and/or Software Engineering experience\n\nPreferred Qualifications\n\n\n\nExperience with software development (Java, Python preferred), end-to-end system design\nExperience with data modeling for both OLAP and OLTP databases, hands-on experience with SQL, preferred Oracle, PostgreSQL, and Hive SQL; SQL performance tuning\nExperience with web development, java script, html, CSS, any web framework or microservice architecture\nExperience with software DevOps CI/CD tools, such Git, Jenkins \nExperience on AWS, familiar with EC2, S3, Redshift/Spectrum, Glue, Athena, RDS, Lambda, DynamoDB, and API gateway\nExperience with docker container, Kubernetes container orchestration\nExperience with Apache Airflow and Apache Spark; Spark performance turning\nExperience with Tableau Dashboard and Tableau Server\nSupport the creation of customizations and integrations required to solution delivery\nDevelop technical designs for new features and capabilities\nAccountability of technical implementation aspects of new features including planning, architecture, design, development, and testing\nAbility to learn quickly, be organized and detail oriented\nAgile/SAFe experience and/or understanding\n\n\nThrive\n\nSome of the vast rewards of working here\n\nAs we work to develop treatments that take care of others, so we work to care for our teammates\u2019 professional and personal growth and well-being.\n\n\nFull support and career-development resources to expand your skills, enhance your expertise, and maximize your potential along your career journey\nA diverse and inclusive community of belonging, where teammates are empowered to bring ideas to the table and act\nGenerous Total Rewards Plan\u2014comprising health, finance and wealth, work/life balance, and career benefits\u2014with compensation and benefits rated above 4 stars (out of 5) on Glassdoor\n\n\nApply now\n\nfor a career that defies imagination\n\nObjects in your future are closer than they appear. Join us.\n\ncareers.amgen.com\n\nReady to Apply for the Job?\n\nJoin Us\n If you're seeking a career where you can truly make a difference in the lives of others, a career where you can work at the absolute forefront of biotechnology with the top minds in the field, you'll find it at Amgen.\n Amgen, a biotechnology pioneer, discovers, develops and delivers innovative human therapeutics. Our medicines have helped millions of patients in the fight against cancer, kidney disease, rheumatoid arthritis and other serious illnesses.\n As an organization dedicated to improving the quality of life for people around the world, Amgen fosters an inclusive environment of diverse, ethical, committed and highly accomplished people who respect each other but compete intensely to win. Together, we live the Amgen values as we continue advancing science to serve patients."
    },
    {
        "position": "Data Scientist / Data Engineer (m/f/d)",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Siemens",
        "sector": "Automation Machinery Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Lisbon, Lisbon, Portugal",
        "post": "About the job \n\nThe time to change is now! \n\nIt's time to build a sustainable future and define how we evolve through technology with purpose.\n At Lisbon Tech Hub we create value in the business digital transition, from Portugal to the world, and IT solutions with purpose. Our team has more than 1300 experts working in areas such as Analytics & Business Intelligence, Application Lifecycle Management, Cybersecurity, IT Infrastructure Management, IT Project & Service Management and IT Strategy & User Experience.\n Lisbon Tech Hub innovates, designs, transforms the information technology solutions and services for Siemens through our delivery units.\n Transforming our future starts with every day!\n Lisbon Tech Hub is the home of the new technologists - Dream Builders, Impact Creators & Future Makers.\n Are you one of them? Join us!\n\nWhat role will you play?\n\n\n\nPerform strategic data analysis to support business processes and strategy and discuss results with team leads and customers. \nProcess large amounts of data from multiple sources and extract relevant insights.\nBuild and operationalize predictive models.\nArchitect and build cloud infrastructure for both the data engineering and the analytics pipelines\nBe part of an international team of data scientists and machine learning engineer with diverse backgrounds, utilizing AI and data analytics methods to accelerate Siemens internal digitalization\n\nWe are looking for:\n\n\n\nA degree in Mathematics, Physics, Statistics, Computer Science, Engineering, a similar quantitative field, or equivalent practical experience.\nExperience with statistical software and scripting languages (e.g., R, Python, SAS).\nFirst experience with cloud technology (AWS, Azure, GCP) and infrastructure as code (e.g., Terraform)\nProficiency in SQL.\nExperience analyzing and modeling data sets.\nExperience with statistical and machine learning methods.\nThe ability to communicate technical concepts into simple terms to present to non-technical audiences.\nEffective written and verbal communication skills\n\nWhat we have to offer: \n\nA flexible home office and schedule policy, virtual budget to improve your home office setup, health insurance, a Pension Plan and a Siemens Share Program time and financial support to your studies, medical center in the facilities, sport groups, 2 days for volunteering initiatives and a cool and relaxed environment.\n Access to e-learning platforms (Learnlight, Linkedin Learning and more), discounts with partners.\n\n#Siemens #LXTechHub #ITMakesUsMove \n\nWe recognize that building a diverse workforce is crucial to the success of our business. Therefore, Siemens provides equal employment opportunities to all qualified individuals without regard to race, creed, color, religion, national origin, age, gender, marital status, sexual orientation, or non-disqualifying physical or mental handicap or disability.\n We strongly encourage applications from a diverse talent pool and welcome the opportunity to discuss workplace adjustments with all our applicants to develop agile working and innovation.\n\nOrganization: Smart Infrastructure\n\nCompany: Siemens S.A.\n\nExperience Level: Experienced Professional\n\nJob Type: Full-time"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "GreenVolt - Energias Renovveis",
        "sector": "Renewable Energy Semiconductor Manufacturing",
        "companySize": "201-500 employees",
        "location": "Lisbon, Portugal",
        "post": "About the job \n\nGreenVolt is looking for a Data Engineer to integrate our international IT Development team, with the following main responsibilities:\n\nWorking with project team to clarify the requirements and then implement them;\nResearch, Design, Plan and Develop Azure Cloud-based Data Acquisition and Data Engineering solutions for developed Use Cases;\nDesigning and develop functionality and solution data pipelines as a data engineer developer and data architect;\nDevelop data transformation functions and database processing mechanism (SQL Server)\nDesigning, testing and implementing application - C#, ASP.NET, Blazor, Azure;\nDesign data pipeline test cases, Conducting performance test; \nTroubleshoot and resolve technical problems in timely and accurate manner to improve application performance and functionality;\nPlanning and reporting project work progress.\n\nProfile:\n\nBSc/MSc degree in Computer Science, Information Systems or equivalent;\n3-5 years of experience in development team, with strong competences in the following areas:\n\n-Software Programming Languages (SQL, Scala, PySpark, Python, Java) \n-Data Collection / Transformation Tools (Azure EventHub, Azure Functions, Azure Data Factory)\n-Azure Platform (Compute component, Containers component, Networking component, Storage component, Analytics component, Azure Data Explorer (ADX), Azure tools CLI)\n-Analytics Engine (e.g. Azure Synapse)\n-Agile and continuous Delivery and methodologies\n\nAbility to identify problems, analyze key information and propose the best solution;\nLearn quickly and want to expand your knowledge;\nFluent English (work 100% in international environment).\n\n\n\nWhat do we have to offer?\n\nCompetitive salary aligned with experience;\nAttractive benefits package including health insurance, pension plan and meal card;\nFlexible work environment and work-life balance;\n25 days of holidays;\n75 days per year of flexible work;\nFree birthday day;\nBeing part of an international environment.\n\n\n\n\n\nWe want an energy transition for everyone from everyone!"
    },
    {
        "position": "Data Engineer with Development Skills",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "H&M Group",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nCompany Description\n\nAt H&M, we are on an exciting journey where fashion and tech make magic together. As rapid technological development and new customer behaviors are transforming the fashion retail industry, our mission is to meet and exceed our customers' expectations. All while keeping in mind sustainable practices. We know that the best ideas evolve when great minds with different backgrounds and perspectives get together.\n At H&M, we are all on the same team in a global environment where we learn from each other and grow together. We live our values and know that sharing knowledge is the best way to continuously improve our ways of working and creating.\n We are proud to foster a workplace free from discrimination. We strongly believe that diversity of experience, perspectives, and background will lead to a better environment for our employees and a better product for our users. H&M Group \u2013 Business Tech.\n There are countless reasons for you to consider joining H&M, but here is a list we think summarizes the most important ones:\n\nThere are tremendous amounts of growth opportunities: we have many courses and workshops running so that you can become your best-self;\nYou will be surrounded by incredible colleagues from all around the globe;\nYou will experience what being part of a large organization means;\nThe opportunity to always be on the forefront of tech and fashion\n\nAre you a Data Engineer with development skills. Do you have a passion for large scale cutting edge analytics and data platforms? Do you think Kubernetes is the way forward in a multi cloud world? Do you think that everything could be automated with pipelines? Do you want to work in an enablement team building cool stuff that empowers a multitude of product teams? Then this is the opportunity for you!\n\nJob Description\n\nIn Common Tools and Services we empower all product teams by building the tools and services that makes sure H&M Group\u2019s data and analytic platforms are awesome. You will build self-service data platforms and integrations solutions at enterprise level. You will join a team of amazing professionals with great opportunity to contribute with your own creative ideas. As a team we have innovation sprints and lab days so we can evolve and develop new ideas.\n\nSome of your daily tasks include:\n\n\nDesign and develop our large scale Apache Kafka platform in Kubernetes. You will work both on a strategic level and with hands-on implementation and also support other teams in data platform and integration advisory including advanced troubleshooting.\nDesign and develop our test automation framework that is an important tool for our data engineers.\nDesign and develop our deployment pipelines used by many product teams.\nTranslate strategies and requirements into modern, innovative and scalable solutions\n\nQualifications\n\nWe are looking for someone that is smart, humble and hungry in helping us build our next modern data platform, you will play a key role in our data transformation journey. We believe you have the ability to understand and\u202fanalyze\u202fcomplex information as well as being able to communicate with others regardless of their IT knowledge.\n You work proactively and with continuous improvements in a fast transforming environment. You enjoy working with implementation and taking operational aspects into account.\n\nTo do this, we think you have a curious mindset, excellent communication skills as well as:\n\n\nExperience in Cloud (Azure, GCP)\nExperience in Kubernetes, Docker and containerization.\nExperience in Python and/or Java\nMeritorious with experience in Devops\nMeritorious with experience in Apache Kafka\n\nLeadership? In this role you will act as a thought leader towards other product team. You should be in the frontline on both new technology and H&M strategies.\n\nAdditional Information\n\nThis is a full-time position with a placement in Stockholm.\n Please apply with CV and cover letter as soon as possible, as a part of the process you may be asked to complete a test connected to engineering. Interviews will be held continuously. And We love code! So If you have contributed to Github project(s), also send those to us together with the CV. We are more than happy to take a look!"
    },
    {
        "position": "Senior Data Engineer (Advanced Engineering & Analytics)",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "TVNZ",
        "sector": "Broadcast Media Production and Distribution",
        "companySize": "501-1,000 employees",
        "location": "Auckland, New Zealand",
        "post": "About the job \n\nTe Reo Tataki (TVNZ) translates to \"the leading voice\" and our kaupapa (purpose) is to \"inspire the conversations of Aotearoa.\" Each day TVNZ reaches more than two million Kiwis through channels TVNZ 1, 2, DUKE and our digital entertainment platform, TVNZ+. TVNZ's news site 1news.co.nz and our digital news youth brand Re: ensure we connect with people on the issues that matter to them wherever they are. \n\n\nThe opportunity - Te t\u016branga \n\n\nWe are looking for a curious and collaborative Senior Data Engineer (Advanced Engineering & Analytics), reports to Data & Integration Lead who is passionate about building data solutions and driving change through data to join our Data Engineering team. \nThis is an exciting new role within our Data Engineering team. As the Senior Data Engineer (Advanced Engineering and Analytics) you will act as the bridge between our data engineering squad and TVNZ's business users, data analysts, data scientists & research analysts. \nYou will be responsible for: \n\n\n\nPartnering with internal stakeholders to build complex engineering solutions that answer strategic business questions with data \nLeading the development of advanced data engineering solutions using our Azure Data Platform\nDeveloping and maintaining highly complex feature layer data models & pipelines that allow TVNZ to get maximum value from its data, with high quality, clean, maintainable analytic code. \nBuilding a robust, repeatable MLOpsframework that allows the Data Engineering team to rapidly deliver predictive model input layer datasets to Data Scientists. \nCurating, organising and documenting data definitions, metrics and reporting environments across Azure Data Lake, Synapse and PowerBI to unlock value and drive efficiency while ensuring data quality.\nCollaborate with data engineers, data analysts & data scientists to develop innovative analytical products.\nWork closely with stakeholders to drive automation and identify where we can leverage our data to improve processes & decision making across the company\nSupporting the Data Engineers and Data Visualisation teams to build, maintain and provide self-serve data and corporate dashboarding and reporting\nProviding technical support to Data Scientists, Research Analysts and Data Analysts \n\n\n\nWhat we're looking for - Ta matou e kimi nei \n\n\nAnalytics Engineering: \n\nRelevant experience in the data space as an analyst, scientist, engineer or similar role\nDemonstratable experience leading multiple advanced engineering projects from concept to operationalisation\nDemonstratable hands-on experience with SQL, Python or other statistical programming languages \nFamiliarity with using Juypter Notebooks or cloud data workbenches is preferrable\nExperience tackling Big Data problems using the Hadoop ecosystem \nExperience with metadata management and data governance \n\n\n\nData visualisation \n\nRelevant experience building and operationalising end-to-end data analytics visualisations and dashboards, delivering demonstrable value to the business and stakeholders.\nSolid and demonstrable experience synthesising complex functional requirements into clean, intuitive visuals that provide insight and support decision making\nExperience a broad knowledge of data visualisation approaches including the use of rapid prototyping to create positive and engaging user experience\n\n\n\nData Engineering: \n\nExperience adapting software engineering Best Practice to data analytics\nFamiliar with the design and build of robust ELT pipelines using ARM templates and automation for resources provisioning (Azure PowerShell)\nGood working understanding of Azure services (Synapse Studio, Azure Data Lake, Databricks, Cognitive Services, Azure ML, Azure App Service, Azure SQL, Databricks, LogicApps)\nExperience with source control collaborative tools such as Git \nFamiliarity with SCALA an advantage\n\nWorking at TVNZ - Te mahi ki Te Reo Tataki\n\nA vibrant culture where we celebrate our content and our successes, and where we're encouraged to continue learning and growing our careers\nA $350 up front allowance to contribute to home office set up expenses.\nComprehensive parental leave - topping up the Government's offering to 6 months at full pay, as well as 6 weeks working at 80% of your normal time at full pay when you return to work, plus 4 week's paid leave and an optional extra 2 week's unpaid for partners.\nLifestyle Leave - the option to buy an extra week or two of leave annually if you want it, to take leave without pay if circumstances allow, or to cash up leave if you've got more than you need.\nA $350 annual wellbeing allowance, discounted Southern Cross health insurance, free flu shots, and access to a confidential support, guidance and counselling service.\nSuperannuation covered - with employee contributions matched up to 5% of salary.\nHauora Leave - A bonus 5th week off annually to find your balance and focus on you - whether that's by connecting with whanau, taking time for yourself, or escaping the everyday.\nA new Broadband and Mobile benefit offer so you'll be able to work from anywhere and be free to stream and binge watch with no limits.\n\n\n\nIf you would like to find out more about this amazing opportunity, please feel free to call our Head of Talent Acquisition, Philly Irvine, mobile 021 564 691, she loves to chat about new careers."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "HEMA",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Amsterdam, North Holland, Netherlands",
        "post": "About the job \n\nDo you have experience in end-to-end design and deploy of data pipelines and analytics solutions?\n\n\nHEMA is looking for a Data Engineer for our Data & Analytics team\n\n\nyou have\n\nExperience in Design, Build, Test and Deploy data pipelines to process massive amount of data\nExperience in building data pipelines to collect, transform, and load data from various sources (e.g. REST, Kafka) into data lakes and/or databases\nAdvanced knowledge of data processing and analysis (e.g. with SQL, Pyspark)\nExtensive programming know-how (e.g. in Python, Scala, Java, NodeJs)\nExperience with some IaC framework (terraform, cloud formation) \nExtensive knowledge of software engineering best practices, tools and methods (e.g. TDD, CI/CD, GIT)\nExperience in using workflow orchestration tools (e.g., Apache Airflow)\nExperience working in self-organised, cross-functional teams \n\n\n\na day as Data Engineer\nHEMA is a data-driven company. Many decisions are made on data, which requires that this data is available, complete and correct. As a Data Engineer, you are responsible for end-to-end design and deploy of data pipelines and analytics solutions that all HEMA employees and partners can work with data by making it available via a state-of-the-art platform and tooling.\nTogether with the others Data Engineers, you have open space to discuss, test and implement new ideas and concepts related with new technologies. You help HEMA to have the most curated up to date dataset available in the AWS Analytics platform supporting business questions, machine learning models and stakeholders to improve internal process and support business decisions.\nYou work in a data platform team together with the data engineers. Together with Business intelligence, data science and analytics & insights, you form the Data & Analytics team at HEMA."
    },
    {
        "position": "Data Engineer - Economics & Experimentation (all genders)",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Zalando",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Berlin, Berlin, Germany",
        "post": "About the job \n\nTHE OPPORTUNITY\n\nYou will join a brand-new team in Economics and Experimentation to productionalize causal machine learning models developed by our Applied Scientists. Our team is highly visible. The causal models and experimentation platforms we develop are used for decision-making for both the senior management board and all Zalando product teams.\n As one of the very first hires in this new team, you are key to bridge the gap between research and production. You also have opportunities to shape ways of working in this new team. Your technical decisions will help people across the whole company benefit from our causal machine learning models reliably.\n\n\nWHERE YOUR EXPERTISE IS NEEDED\n\n\nCollaboratively design and implement a reliable and performant data infrastructure Continuously improve existing data systems with the aspiration of stress-free operations and a sustainable work pace Provide high-quality, performant datasets for machine learning and causal inference research. Provide guidance and supportive feedback for your colleagues\u2019 work to help them grow as professionals \n\nWHAT WE\u2019RE LOOKING FOR\n\n\nBachelor or higher in computer science, software engineering, mathematics, or closely related discipline Demonstrated real-world working experience in designing and setting up high volume, performant databases (experience with feature stores is a big plus) Strong understanding of data engineering tools (e.g. Spark, database, data format) Proficiency in programming skills in Python (Scala or other JVM language is a plus). Proficiency with professional software engineering practices (e.g. software design, data structure) Hands-on experience with cloud infrastructure, ideally AWS Experience working with Applied Scientists \n\nPERKS AT WORK\n\n\nA workplace run on trust, empowerment and feedback; positive, inspiring working atmosphere Competitive salary, employee share shop, 40% Zalando shopping discount, discounts from external partners, centrally located offices, public transport discounts, municipality services, great IT equipment, flexible working times, additional holidays and volunteering time off, free beverages and fruits, diverse sports and health offerings Mentoring and personal development opportunities and an international team of experts Relocation assistance for internationals, PME family service and parent & child rooms We celebrate diversity and are committed to building teams that represent a variety of backgrounds, perspectives and skills. All employment is decided on the basis of qualifications, merit and business need. \n\nABOUT ZALANDO\n\n\nZalando is Europe\u2019s leading online platform for fashion, connecting customers, brands and partners across 23 markets. We drive digital solutions for fashion, logistics, advertising and research, bringing head-to-toe fashion to more than 45 million active customers through diverse skill-sets, interests and languages our teams choose to use.\n\nPlease note that all applications must be completed using the online form - we do not accept applications via email."
    },
    {
        "position": "Analytics Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Cabify",
        "sector": "Technology, Information and Internet",
        "companySize": "1,001-5,000 employees",
        "location": "Madrid, Community of Madrid, Spain",
        "post": "About the job \n\nAbout the job\nDo you want to change the world? At Cabify, that's what we're doing. We aim to make cities better places to live by improving mobility for the people living in them, connecting riders to drivers at the touch of a button. Maybe one day cities will be places where nobody needs a private car. But we've still got a long way to go\u2026fancy joining us?\n\n\nAbout the position:\n\n\nAt Cabify we claim to be a data-driven company. Our team builds and maintains a robust warehouse where the Analytics team can find not only raw data, but also complex etls processes to provide the insights they need.\n\n\nBut where can I see all that data? We have a Tableau server instance that contains thousands of workbooks and is consulted by many users every day. We own that instance so we work hard to make sure everything works properly. We also created, and keep on creating, tooling around Tableau and our data warehouse, in order to keep on improving the way our users interact with data.\n\n\nAt Analytics Engineering we manage our own cloud infrastructure (AWS). Our in-house etls platform has more than 300 processes (Python, Airflow, Redshift, S3, Spectrum, Glue, RDS) that we visualize with our Tableau server instance (Tableau Server, Ec2, Python).\n\n\nYou will:\n\n\nWe are looking for new members, and this is how you will play an important part in helping us achieve our mission:\n\nMaintain & evolve our data warehouse, making sure the data is easily accessible, reliable & accurate.\nCreate data models, applying business logic to data. Evaluate all proposals and requests to improve the structure of the data warehouse.\nCoordinate with other data stakeholders to ensure overall health and performance of the data warehouse environment.\nDesign, develop, test, monitor, manage, and validate data warehouse activity. Including defining standards for the data warehouse as well as troubleshooting ETL processes and resolving issues effectively.\n\n\n\nOur Ideal candidate has:\n\nGreat alignment with our principles, we take this very seriously.\nAt least 5 years tenure in coding and delivering complex data projects.\nProven track record in Data Modeling.\nYou continuously find ways to derive more value in our raw data and lower the amount of effort our end users spend on getting answers.\nYou have proper DBA skills, with which you should ensure high standards in DWH data accessibility, integrity, security & performance monitoring.\nYou have intermediate level SQL skills, which allows you to understand subqueries, pivots, joins, and how indexes work.\nYou can take a complex concept and make it sound simple. You're accomplished at orienting business users within the data domain, understanding their needs, and translating them into technical requirements to ultimately design effective data solutions.\nYou have experience integrating data from multiple sources including DBs, product tracking, and APIs. You get excited by seeing your jobs run like clockwork.\nUnderstanding of Microsoft technologies (Azure, Data Factory and Microsoft SQL) is a plus.\n\n\n\nThe good stuff:\n\n\nWe're a company full of happy, motivated people and we never want that to change. Here are some more reasons why it rocks to be part of our family.\n\nExcellent Salary conditions: L3: 40000EUR - 48000EUR, L4: 45000EUR - 65000EUR\nWe also offer a very competitive stock options plan.\nRecharge day: Every 3rd Friday monthly off!\nRemote Position\nFlexible work environment & hours.\nRegular team events.\nCabify staff free rides.\nPersonal development programs based on our career paths.\nAnnual budget for training.\nFlexible compensation plan: Restaurant tickets, transport tickets, healthcare and childcare\nAll the equipment you need (you only have to bring your talent). \nA pet room ,so you don't have to leave your furry friend at home \nAnd last but not least...free coffee and fruit!\n\n\n\nSounds good? Joing us!!"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Stuart",
        "sector": "Transportation, Logistics, Supply Chain and Storage",
        "companySize": "501-1,000 employees",
        "location": "France",
        "post": "About the job \n\nStuart (DPD Group) is a sustainable \ud83c\udf31 last-mile logistics company that connects retailers and e-merchants to a fleet of geolocalised couriers across several countries in Europe.\n\n\nOur Mission \ud83d\ude80\nWe are an impact-driven company that aims to build the future of logistics for a more sustainable world: shared, efficient and reliable. We are committed to creating a new standard for urban deliveries that meet today\u2019s environmental and social challenges while offering a premium delivery experience blending speed, flexibility and convenience.\n\n\nOur motto: \u201cMake every delivery a moment all of us can truly celebrate!\u201d More than 3000+ leading brands already partner with us across Restaurants, Grocery, Retail & Luxury, eCommerce and Professional Services to deliver all types of goods at the tap of a button. Stuart is a highly diverse and inclusive company of 600+ talents from 90+ countries working in Paris \ud83c\uddeb\ud83c\uddf7, London \ud83c\uddec\ud83c\udde7, Barcelona, Madrid \ud83c\uddea\ud83c\uddf8, Poland \ud83c\uddf5\ud83c\uddf1, Portugal \ud83c\uddf5\ud83c\uddf9 and remotely around the world \ud83c\udf0d\n\n\nIt\u2019s the right moment and the right place for us to make an impact on millions of people, as home delivery services hit a record high. And guess what? You can help us fulfil our vision \ud83d\ude4c\n\n\nWe are looking for a Data Engineer \ud83e\udd16 to take part in the scaling of our data platform and support the team\u2019s and company\u2019s growth.\n\n\nOur stack currently relies mostly on the Python & Scala languages and It includes technologies like Apache Airflow, Docker, Apache Kafka, Tensorflow, etc. and we extensively use AWS products like S3, Redshift, and Athena.\n\n\nWhat will I be doing? \ud83e\udd14\n\nDesigning, implementing and maintaining a solid Data Lake and Data Warehouse that collects, stores, and processes data, focusing on scalability and reliability.\nWorking closely with the Business Intelligence and Data Science teams to help them design and build machine-learning algorithms and tooling to explore and visualize data.\nGrowing with us and sharing: https://medium.com/stuart-engineering \ud83e\udd13\n\n\n\nWhat do we need from you? \ud83d\ude0e\n\nFluency in English\n3+ years experience working with Python or Scala\n3+ years of experience design and implementing data platforms \nExperience with Apache Kafka or other streaming platforms\nExperience with query engines like AWS Athena, Hive, SparkSQL or similar technologies\n\nWant to put a smile on our face?\n\nExperience in designing data lakes in Amazon S3\nExperience with Apache Airflow\nExperience with Hadoop, Apache Spark, Flink or similar technologies\nExperience with data quality processes\n\n\n\nThe stuff you wanna know \ud83d\ude09\n\nFamily-friendly work-life balance - work from home and flexible hours \ud83c\udfe1\nOption to work remotely anywhere in Spain \ud83c\uddea\ud83c\uddf8\nTicket Restaurant by Edenred (\u20ac11 daily) \ud83e\udd57\nUnlimited access to Udemy for all your learning and development needs \ud83d\udcda\nPersonal Engineering Learning Budget of \u20ac1,000 per year \ud83e\uddd1\u200d\ud83d\udcbb \nStuart Academy with regular workshops, Stu-Classes, and Stu-Talks \ud83c\udf93\nStuart is putting Mental Health Awareness first! Wellness Allowance (\u20ac40 monthly) to use in any gym or sport class \ud83e\uddd8\nPrivate healthcare provided by Sanitas \ud83e\uddd1\u200d\u2695\ufe0f\nWork in an international, dynamic and passionate environment with a company culture focused on learning and development \ud83c\udf89 \n\n\n\nYou\u2019ve read all this way but you\u2019re missing a skill or two? No problem, it\u2019s our job to up-skill you to take your career to the next level. What we\u2019re trying to say is, don\u2019t be afraid to apply if you don\u2019t tick all the boxes \ud83d\udcaa\n\n\nAt Stuart, we believe that employees today want to evolve in collaborative, high-growth environments where they can demonstrate their abilities and thrive both professionally and personally. We are convinced that employees need to find alignment between their inner values and their company\u2019s culture and mission to unlock their full potential. We work to create a culture of empowerment, continuous learning and growth where everyone can bring expertise, own projects and easily measure their impact \ud83d\ude4c\n\n\nStuart is proud to be an equal opportunity workplace dedicated to promoting diversity. We don\u2019t discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status \ud83d\udc99\n\n\nWant to learn more about us? Visit https://stuart.com/about-us/"
    },
    {
        "position": "Data Modeller",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Flight Centre Travel Group",
        "sector": "Travel Arrangements",
        "companySize": "5,001-10,000 employees",
        "location": "West End, Queensland, Australia",
        "post": "About the job \n\nAbout your opportunity...\n\n\nDo you enjoy untangling complex, enterprise information? Do you enjoy the challenge of ensuring that the right information is delivered to the right people at the right time to drive the business? Do you thrive in a fast-paced environment that presents new challenges every day that also nurtures talent and emphasizes collaboration?\n\n\nWithin Flight Centre Travel Group (FCTG) Australia, we are seeking a highly motivated Data Modeller with experience in logical/conceptual data design, semantic layer modelling, and data stewardship to take on the challenge of transforming how FCTG manages and shares critical information assets.\n\n\nIn this role you will provide a graphical representation of the entities that interoperate within the organisation in support of the organisation business processes and the relationships among these entities. You will be responsible for developing the data models. They transform business information into models by engaging with the business users and soliciting their requirements and iteratively refine the conceptual, logical, and physical data models. You will work with the business intelligence, artificial intelligence, data analysts and data scientists on modelling of the curated data and the common semantic layer.\n\n\nReporting to the Data Governance Manager within the Data Science and Engineering (DSE) team, this role goes beyond the role of a typical application level \"data modeller\" in that it requires modelling not just from a single business perspective but from an organisational perspective with Global reach. Additionally, this role will have responsibilities in working on data governance initiatives within DSE and be an advocate for data governance best practices throughout the organisation.\n\n\n\n\nWhat You\u2019ll Do...\n\n\n\nEngage the business users to assess their information needs\nReview the business process and conceptualize the entities that interoperate within the business process\nDetermine how the various entities are related and develop entity relationship diagrams that represent the connections among the entities\nIdentify each entity's characteristics and properties and ensure that the entities can be differentiated within the model\nDevelop a logical data model and validate the model to ensure that it serves the needs of the business application and its consumers\nTransform the logical representation of the model into a physical representation and work with data engineers to instantiate and manage the data\nCollaborate with the BI and Analytics teams on creating the optimized, reusable semantic models, complete with metadata and lineage information\n\n\n\nWho you are\u2026\n\n\n\nExperience with Business Intelligence products e.g., Power BI \nExcellent teaming and communication skills\nStrong consultative, facilitation and consensus building skills \nProven experience in an enterprise environment developing relational datasets\nProven experience developing models for Business Intelligence solutions\nStrong analytical, data profiling and problem-solving skills \nStrong verbal and written communication skills\nAdvanced SQL skills\nIn depth knowledge of Azure technologies\nIn depth knowledge of Databricks \n\n\n\nDesirable Competencies...\n\n\n\n3+ years of data modelling experience\nIn depth knowledge of the data modelling tools being proficient in at least one\nExperience with Microsoft\u2019s Purview\nMandatory: Bachelor's degree in management Information Systems, Computer Science, Computer Information Systems, or equivalent Information Technology discipline\n\n\n\nLet\u2019s skip to the good part\u2026\n\n\n\nGenerous remuneration structure\nTravel discounts, in-house financial and health services, access to internal 24/7 gym\nGlobal career opportunities in a network of brands and businesses\nOngoing training and professional development\nFun and flexible work environment\nProud Corporate Social Responsibility platform through the Flight Centre Foundation\nRole can be a contract or full-time\n\n\n\nWe do things a little differently\u2026\n\n\nWe do things a little differently around here. We do things the FCTG Way.\n\n\nWe have a unique culture and an irreverent DNA based on a proven mix of ideas, values and ways of working that have helped shape our business over the past 40+ years.\n Across all our brands, we take our business seriously but not ourselves. We take leaps of faith, have trust in our teams and work collaboratively to achieve our goals. That\u2019s the FCTG Way.\n\n\nIf you think you have FCTG DNA, reach out today."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Mars",
        "sector": "Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Netherlands",
        "post": "About the job \n\nData and Analytics is foundational to Royal Canin and will drive our transformation to a business that is powered by data. To deliver on this ambition we are looking to recruit a Data Engineer who will work remotely from the Netherlands and be able to attend meetings in Amsterdam and travel to the Global HQ in South of France.\nThe role reports to the Royal Canin Global Data Engineering Lead. \nWhat are we looking for?\n\nDeep and rich experience in working with data (Python / Spark / Databricks) and delivering robust data transformation pipelines. \nPrevious experience working in a cloud environment would be a plus (Azure preferred). \nGreat at developing new relationships, driving positive change, and matching analytics opportunities to data acquisition strategy.\nExcellent planning and prioritization skills.\nGood understanding of Data Protection and Privacy principles and practices including GDRP.\nWork comfortably in an agile and fast paced environment.\n\nWhat will be your key responsibilities?\n\nEngineer and orchestrate data flows & pipelines using high quality, easily deployable,\nrepeatable and extensible codebases that ingest and integrate data from many disparate\ndata sources in a cloud environment using a progressive tech stack.\nDesign and build complex data models to support performant and accurate analytical insight, science research and marketing activation purposes removing excessive data preparation from the solution users to expedite their processes and reduce effort duplication and subsequent errors. \nSupporting the global data engineering lead to adapt data architectures, analytical data platforms & related processes (i.e. designing and specifying data structures and processing frameworks based on local functional and technical requirements. )\nDeveloping local strategies for data acquisition and democratization\nManaging data transformation and troubleshooting data processing issues\nEU Platform Support, alerting and monitoring to ensure high platform reliability in compliance with Mars\nCyber Security Standards and Privacy Policies\nData Lifecycle Management through Global Metadata and Access Control Management\nPartner with functions and divisions to ensure RC data capabilities roadmap, operating model and governance principles are best serving the organization data strategy and are effectively activated across RC Europe\n\nWhat can you expect from Mars?\n\nAt Mars, we believe in a relationship of mutual trust, dignity and respect between our company and Associates that is more meaningful than the standard employer/employee relationship. \nAs Associates, we can expect to be respected, supported and valued as individuals, to be treated fairly and equitably.\nThe opportunity to learn and develop, taking charge of your own career across Mars.\nAn environment where you are empowered to be proactive and to take initiatives to make a difference.\nYou will work in a multicultural environment (more than 40 nationalities)"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Wilhelmsen group",
        "sector": "Maritime Transportation",
        "companySize": "10,001+ employees",
        "location": "Oslo, Norway",
        "post": "About the job \n\nFounded in Norway in 1861, Wilhelmsen is now a comprehensive global maritime group providing essential products and services to the merchant fleet, along with supplying crew and technical management to the largest and most complex vessels ever to sail. Committed to shaping the maritime industry, we also seek to develop new opportunities and collaborations in renewables, zero-emission shipping, and marine digitalization. Supporting a diverse and inclusive workplace, with thousands of colleagues in more than 70 countries, we take competence, sustainability, innovation, and unparalleled customer experiences one step further.\n\n\nAnchor your career in the maritime industry and dive into a sea of opportunities with us now! Empowering people through technology is our aspiration and so is setting the standard for how we work with technology across Wilhelmsen as shapers of the maritime industry. Creating actionable insights from data is a strategic priority and we are continuing to build and invest in our data & analytics platforms to support our ever-changing data driven ambitions as a company.\n\n\nThe Data & Analytics team plays a key role in Wilhelmsen Ships Service delivering operational, financial and management reporting to business divisions across the organization. This agile team consists of both internal and external data engineers, having full responsibility for both development and operations, from creating the data pipelines to visualising the data to end users. Our ideal candidate is looking for new challenges and would like to join a team of experienced professionals who are passionate about innovation, technology, and transformation.We can offer a great culture and work environment, career development, work-life balance and a job that is both challenging and stimulating.\n\n\nWe are looking for a Data Engineer to strengthen our Data & Analytics team by taking a key role in making our data driven ambitions a reality. We have recently completed our migration to Snowflake in Azure and are now looking for someone who can play a key role in the journey of taking it to the next level. The right person will help with designing and developing data pipelines, data models, reports, and dashboards, as well as functioning as our Power BI subject matter expert.\n\n\nYou will also be involved in continuously improving Self Service BI as well as driving Power BI competence within the organization. The right candidate will also have the possibility to work with use-cases related to advanced analytics, including Process Mining, ML and IoT/streaming data. The role will report to the Data & Analytics Manager.\nThis is the perfect role for you if you enjoy getting your hands dirty with data and code, and thrive in solving complex challenges and testing out new technologies.\n\n\n\n\nYour main responsibilities:\n\nDevelop and maintain Power BI reports in collaboration with key stakeholders across the organization\nDesign, develop and quality assure data pipelines and dimensional models (star-schema)\nMaintain Power BI service, including workspace, report and app management\nDrive the competency build related to Power BI throughout the organisation, to ensure that WSS are in the forefront when it comes to utilizing Power BI and the surrounding Microsoft application eco-system\nRun bi-weekly \u201cCenter of Excellence\u201d forums, with Power BI as one of the focus areas to share ideas, best-practices and other cool stuff\n\n\n\n\n\nQualifications:\n\nMinimum 2 years of experience with Power BI and building data visualisations, as well as building and maintaining data pipelines and dimensional data-modelling\nBachelor\u2019s degree from business/finance, computer science, engineering or similar.\nExperience with Power BI, Snowflake, WhereScape and/or other ETL and visualisation tools\nExperience with Azure and/or other cloud platforms\nExperience with DAX/SQL/Python and/or other data preparation languages\nProficient in English, written and verbal with great communication skills\n\n\n\nThe firm aspires to be the leading enablers of sustainable global trade. Committed to shaping the maritime industry, we also seek to develop new opportunities and collaborations in renewables, zero-emission shipping, and marine digitalization. Please apply for the position to be a part of the change!\n\n\nWe will review applicants on a rolling basis."
    },
    {
        "position": "Software Engineer (Data) - Economics & Experimentation",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Zalando",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Berlin, Berlin, Germany",
        "post": "About the job \n\nTHE OPPORTUNITY\n\nYou will join a brand-new team in Economics and Experimentation to productionalize causal machine learning models developed by our Applied Scientists. Our team is highly visible. The causal models and experimentation platforms we develop are used for decision-making for both the senior management board and all Zalando product teams.\n As one of the very first hires in this new team, you are key to bridge the gap between research and production. You also have opportunities to shape ways of working in this new team. Your technical decisions will help people across the whole company benefit from our causal machine learning models reliably.\n\n\nWHERE YOUR EXPERTISE IS NEEDED\n\n\nCollaboratively design and implement a reliable and performant data infrastructure Continuously improve existing data systems with the aspiration of stress-free operations and a sustainable work pace Provide high-quality, performant datasets for machine learning and causal inference research. Provide guidance and supportive feedback for your colleagues\u2019 work to help them grow as professionals \n\nWHAT WE\u2019RE LOOKING FOR\n\n\nBachelor or higher in computer science, software engineering, mathematics, or closely related discipline Demonstrated real-world working experience in designing and setting up high volume, performant databases (experience with feature stores is a big plus) Strong understanding of data engineering tools (e.g. Spark, database, data format) Proficiency in programming skills in Python (Scala or other JVM language is a plus). Proficiency with professional software engineering practices (e.g. software design, data structure) Hands-on experience with cloud infrastructure, ideally AWS Experience working with Applied Scientists \n\nPERKS AT WORK\n\n\nA workplace run on trust, empowerment and feedback; positive, inspiring working atmosphere Competitive salary, employee share shop, 40% Zalando shopping discount, discounts from external partners, centrally located offices, public transport discounts, municipality services, great IT equipment, flexible working times, additional holidays and volunteering time off, free beverages and fruits, diverse sports and health offerings Mentoring and personal development opportunities and an international team of experts Relocation assistance for internationals, PME family service and parent & child rooms We celebrate diversity and are committed to building teams that represent a variety of backgrounds, perspectives and skills. All employment is decided on the basis of qualifications, merit and business need. \n\nABOUT ZALANDO\n\n\nZalando is Europe\u2019s leading online platform for fashion, connecting customers, brands and partners across 23 markets. We drive digital solutions for fashion, logistics, advertising and research, bringing head-to-toe fashion to more than 45 million active customers through diverse skill-sets, interests and languages our teams choose to use.\n\nPlease note that all applications must be completed using the online form - we do not accept applications via email."
    },
    {
        "position": "Senior Data Engineer (GNFR Conversion)",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Woolworths Group",
        "sector": "Retail",
        "companySize": "10,001+ employees",
        "location": "Auckland, Auckland, New Zealand",
        "post": "About the job \n\n\nJoin one of the biggest Data & Analytics teams in Aotearoa \nArtificial Intelligence & Machine Learning Environment\nPurpose-built offices in Ponsonby, Agile delivery model\n\nReady to make an impact? We are!\n\nAnalytics and Insights underpin Countdown\u2019s business operations, customer experience, critical decision making and strategy development. Our team is highly talented and works with some of the latest Google technologies to deliver data-driven insights through advanced analytics. You\u2019re going to love working with our fast paced A&I team-they understand, collaborate, analyse and solve! They disseminate vast and complex information, bringing it to life in a variety of new and different ways.\n We are innovators, instigators and love solving complex problems. We test and we learn but remain humble whilst sharing our success. We work end-to-end within an Agile model that allows us to deliver quickly and be ahead of the game.\n\nAbout the Role | M\u014d te T\u016branga\n\nAs a Senior Data Engineer you will be part of a high performing, cross functional Analytics and Insights team. You have the opportunity to work alongside a group of talented architects, data engineers, data scientists and senior analytics professionals.\n We are famous for focusing on outcomes and delivering tangible business value right across our retail operation. We make a difference by working collaboratively on high impact business problems for the Countdown supermarket chain and our digital stores.\n This is a key role responsible for designing, building, manipulating and optimising our data, data pipelines and data architecture in our ambition to be a data driven business to create the best experiences for our customers through analytics led decisions. We are responsible for analytics across all aspects of our business so there is no limit to what you will get to experience & learn working in our team.\n\nAbout You | M\u014du\n\nYou must be comfortable working on cloud data platforms, handling large volumes of data and be passionate about the influence and value you will create from data. You will need to understand the importance of managing our data assets in a high integrity environment that always strives to do the right thing for our customers, our partners and our employees. Whether you prefer - solution design, new technology, engineering, constant learning of cutting edge skills and knowledge of tools such as Python and SQL, you will be in a tightly knit and supportive community that cares for your career development.\n If you are looking to broaden your horizons and work within some of the largest datasets in the country-apply today!\n\nWorking with Countdown | Te Mahi ki Countdown\n\nOur purpose is to make Kiwis' lives a little better every day.\n We\u2019re friendly, down-to-earth, and energetic - we work hard and we have a great time doing it, and we are passionate about what we do. There is plenty of scope for new ideas, lots of room for you to add value, and importantly, you\u2019ll be working with a business that touches the lives of three million New Zealanders a week.\n\nCome as you are | Haere mai r\u0101\n\nWe\u2019re an equal opportunity employer and are committed to the principle of equal opportunity for all.\n If you\u2019re smart and good at what you do, come as you are."
    },
    {
        "position": "Data Analyst (f/m/d) technical lead at Computed Tomography",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Siemens Healthineers",
        "sector": "Hospitals and Health Care",
        "companySize": "10,001+ employees",
        "location": "Forchheim, Bavaria, Germany",
        "post": "About the job \n Do you want to help create the future of healthcare? Our name, Siemens Healthineers, was selected to honor our people who dedicate their energy and passion to this cause. It reflects their pioneering spirit combined with our long history of engineering in the ever-evolving healthcare industry.\n We offer you a flexible and dynamic environment with opportunities to go beyond your comfort zone in order to grow personally and professionally. Sound interesting?\n\nThen come and join our global team as Data Analyst (f/m/d) technical lead at Computed Tomography (CT) to shape the future of CT by applying your technical skills, analytical mindset and product intuition.\n\nChoose the best place for your work - within the scope of this position, it is possible, in consultation with your manager, to work mobile (within Germany) up to an average volume of 60% of the respective working hours.\n\nThis position is limited to 24 months.\n\nYour tasks and responsibilities:\n\n\n\nYou will drive the mindset of data driven decisions and promote the benefits and value of our data analytics solutions\nAs a product owner of business-critical data analytics applications, you will support the analysis of stakeholder objectives, assess the problems needing to be solved using Data Analytics methods and communicate the requirements to other Data Analysts and Data Scientists\nYou will design, ideate, implement, validate, and deploy data analytics and data science projects in CT to analyze data, generate insights, create business value, and support decision-making\nAs a recognized Data Science expert, you will actively contribute to our Communities of Practice and knowledge sharing events and thereby shape our analytics methods, standards, and guidelines\nYou will provide a technical leadership to the team of data analysts and data scientists\n\n\nTo find out more about the specific business, have a look at Computed tomography\n\nYour qualifications and experience:\n\n\n\nYou hold a Master's degree in science, technology, engineering and mathamatics or a related field with a strong quantitative focus\nYou have several years of experience as a data analyst with successful execution of a variety of practical projects\nYou have strong understanding and experience in execution of data science workflows like CRISP-DM\nYou know the principles of agile development and have already worked as a member of an agile development team\nYou have solid understanding of Machine Learning (supervised and unsupervised learning, NLP, explainable AI) and you are strong in exploratory data analysis and feature engineering\nYou have a successful track record of running diverse data analytics / data science projects\nYou have experience in Visual Analytics, building data-driven applications for end users with BI tools (Qlik, Power BI)\n\n\nYour attributes and skills:\n\n\n\nYou have excellent professional communication skills (English, written and oral), German would be a plus\nYou are flexible and curious to learn new technologies and business areas fast\nYou confidently interact with developers and business stakeholders and can present your work to technical and non-technical audiences\nYou have an entrepreneurial and performance-driven mindset and a team player mentality with the ability to drive results under own initiative in an agile and fast driving environment\nYou have strong technical grasp on task prioritization and effort estimation\nYou are motivated to drive a range of data analytics projects and to lead strategic visions and benefit our team with your active, energetic mindset\nYou have experience / strong potential to functionally lead the team\n\n\nOur global team:\n\nSiemens Healthineers is a leading global medical technology company. 66,000 dedicated colleagues in over 70 countries are driven to shape the future of healthcare. An estimated 5 million patients across the globe benefit every day from our innovative technologies and services in the areas of diagnostic and therapeutic imaging, laboratory diagnostics and molecular medicine, as well as digital health and enterprise services.\n\nOur culture:\n\nOur culture embraces different perspectives, open debate, and the will to challenge convention. Change is a constant aspect of our work. We aspire to lead the change in our industry rather than just react to it. That\u2019s why we invite you to take on new challenges, test your ideas, and celebrate success.\n Check our Careers Site at https://www.siemens-healthineers.com/de/careers\n As an equal opportunity employer, we welcome applications from individuals with disabilities.\n Wish to find out more before applying? Contact us: +49 (9131) / 17 \u2013 1717, if you wish to discuss any initial questions with our recruitment team. The contact person handling this job ad is\n Laura Roos.\n We care about your data privacy and take compliance with GDPR as well as other data protection legislation seriously. For this reason, we ask you not to send us your CV or resume by email. We ask instead that you create a profile in our talent community where you can upload your CV. Setting up a profile lets us know you are interested in career opportunities with us and makes it easy for us to send you an alert when relevant positions become open. Click here to get started.\n Siemens Healthineers Germany was awarded the Great Place to Work\u00ae certificate.\n\nOrganization: Siemens Healthineers\n\nCompany: Siemens Healthcare GmbH\n\nExperience Level: Mid-level Professional\n\nJob Type: Full-time"
    },
    {
        "position": "Data Scientist",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Sanofi",
        "sector": "Pharmaceutical Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Barcelona, Catalonia, Spain",
        "post": "About the job \n\nAbout Sanofi:\n\nWe are an innovative global healthcare company, driven by one purpose: we chase the miracles of science to improve people\u2019s lives. Our team, across some 100 countries, is dedicated to transforming the practice of medicine by working to turn the impossible into the possible. We provide potentially life-changing treatment options and life-saving vaccine protection to millions of people globally, while putting sustainability and social responsibility at the center of our ambitions.\n\nOur vision for digital, data analytics and AI\n\nSanofi has recently embarked into a vast and ambitious digital transformation program. A cornerstone of this roadmap is the acceleration of its data transformation and of the adoption of artificial intelligence (AI) and machine learning (ML) solutions. This has enabled us, to accelerate R&D, improve manufacturing and commercial performance, and bring novel drugs and vaccines to patients faster, all in order to improve health and save lives.\n The Digital Team at Sanofi is a unique data-driven team. We pride ourselves on being data obsessed and highly focused on using state of the art processes along with global technologies to drive impact to our solutions. We measure our insights and products based on how they preform across the globe and hold ourselves to the highest regard as our solutions can impact millions of lives. When tackling a problem, we do not just ask how we will create a solution, but how we will create a solution that reaches across the world with the best possible societal outcome.\n If you are passionate about improving the health and wellness of people across the globe using Data as your means, then you should look no farther than the Digital Team here at Sanofi.\n Join us on our journey in enabling Sanofi\u2019s Digital Transformation through becoming an AI first organization. This means:\n\n\nAI Factory - Versatile Teams Operating in Cross Functional Pods: Utilizing digital and data resources to develop AI products, bringing data management, AI and product development skills to products, programs and projects to create an agile, fulfilling and meaningful work environment.\nLeading Edge Tech Stack: Experience build products that will be deployed globally on a leading-edge tech stack.\nWorld Class Mentorship and Training: Working with renowned, published leaders and academics in machine learning to further develop your skillsets\n\n\nThere are multiple vacancies across our Digital organisation. Further assessments will be completed to determine specific function and level of hired candidates. \n\nJob Highlights: \n\n\n\nApply data science expertise in machine learning, statistics, text-mining/NLP, forecasting and optimization to multiple analytics projects. \nBuild models, algorithms, simulations, and experiments by writing highly optimized code and using state-of-the art machine learning technologies. \nWork on full-spectrum of activities, from conducting ML experiments to delivering production-ready models. \nUse data analysis, visualization, storytelling, and data technologies to scope, define and deliver AI-based data products. \nWork with developers, engineers, and MLOps to deliver AI/ML solutions. \n\n\nKey Functional Requirements & Qualifications:\n\n\n\nHands-on AI/ML modeling experience of complex datasets combined with strong understanding of theoretical foundations of AI/ML. \nExpertise within most of the following areas: supervised learning, unsupervised learning, deep learning, reinforcement learning, federated learning, time series forecasting, Bayesian statistics, optimization \nExperience developing deployable code and deploying models in product-focused development under an agile environment \nComfortable working in cloud and high-performance computing environments (e.g. AWS, GCP, Databricks, Apache Spark) \nExperience in production-ready software development \nExcellent written and verbal communication, business analysis, data visualization and data storytelling skills \nA demonstrated ability to work and collaborate in a team environment \nNice to have: Experience in life sciences and healthcare and experience in a complex global organization \n\n\nKey Technical Requirements & Qualifications:\n\n\n\nPhD in mathematics, computer science, engineering, physics, statistics, economics, or a related quantitative discipline with strong coding skills, OR Master\u2019s\u202fDegree in relevant domain with 4+ years of analytical experience \nExpertise with core data science languages (such as Python, R, Scala), and familiarity with different database systems (e.g. SQL, NoSQL) \nDisciplined AI/ML development (CI/CD, Orchestration) \nKnowledge of\u202fTableau, Power BI, Plotly or similar \nExperience with various enterprise-level Application Programming Interfaces (APIs) \n\n\nLocation: \n\nGlobal Innovation center - Barcelona - Spain\n At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all.\n Sanofi is committed to welcoming and integrating people with disabilities.\n\nNote:\n\nOnly those candidates selected for interviews will be contacted.\n Thank you in advance for your interest.\n You can learn more about our opportunities:\n www.sanofi.com\n www.linkedin.com/company/sanofi\n\nPursue Progress. Discover Extraordinary.\n\nOwn your future. Make your move!\n\n#DDBBCN \n\n#Hybrid\n At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all."
    },
    {
        "position": "CSCE-A Data Scientist: Real-World Analytics and Machine Learning",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Intel Corporation",
        "sector": "Semiconductor Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Leixlip, County Kildare, Ireland",
        "post": "About the job \n\nJob Description\n\nCorporate Services (CS) touches the lives of every Intel employee every day. CS creates an environment where employees can prosper while creating the innovative technologies that make amazing possible. Our scope is vast and includes operating and maintaining all Intel sites, offices, labs and factories globally as well onsite services and experiences that help employees stay safe and productive. CS also helps to make Intel and our community a greener place by supporting Intel commitment to environmental sustainability, including investing in conservation projects, setting company-wide environmental targets and driving reductions in greenhouse emissions, energy use, water use and waste generation.\n CS Central Engineering (CSCE) owns the strategic and systematic development, standardization, implementation, and measurement of key central engineering functions to drive efficiency, reliability, and world class cost optimization to support our global facilities portfolio. The scope of the Central Engineering Organization within Corporate Serviced consists of asset management, cost engineering, enabling growth, and automation.\n Central Engineering - Automation team is looking for an innovative, creative, and intellectually curious Data Scientist with experience in developing Machine Learning software to join our CS Central Engineering Automation team. This is an exciting opportunity to work in one of the world's leading semiconductor manufacturers working with real-world analytics to help our clients maximize equipment uptime, reduce risk and make more informed decisions. We are at a unique point in our company's journey. As we scale to more manufacturing sites worldwide, we must be efficient in the way we monitor and maintain our systems. Only by striving for excellence in our maintenance strategy and remaining at the technological edge can we ensure that we achieve our mission of creating world-changing technology that improves the life of every person on the planet.\n\nAs a CSCE-A Data Scientist your responsibilities will include but are not limited to:\n\n\nWork alongside our multi-disciplinary Automation team and apply data science techniques to predict anomalies and faults in complex, large-scale time-series data.\nApply your data science skills and statistical knowledge to build an autonomous fault detection and root cause platform using Machine Learning methodologies.\nSupport consulting activities to identify data availability, quality, and modelling requirements and participate in our customers' engagement.\n\nWhat We Offer\n\n\nWe give you opportunities to transform technology and create a better future, by delivering products that touch the lives of every person on earth. As a global leader in innovation and new technology, we foster a collaborative, supportive, and exciting environment-where the brightest minds in the world come together to achieve exceptional results.\nWe offer a competitive salary and financial benefits such as bonuses, life and disability insurance, opportunities to buy Intel stock at a discounted rate, and Intel stock awards (eligibility at the discretion of Intel Corporation).\nWe provide benefits that promote a healthy, enjoyable life: excellent medical plans, wellness programs and amenities, flexible work hours, time off, recreational activities, discounts on various products and services, and many more creative perks that make Intel a Great Place to Work.\nWe're constantly working on making a more connected and intelligent future, and we need your help. Change tomorrow. Start today.\n\nMinimum Qualifications\n\nQualifications\n\n\nBachelors/Masters with 8 yrs experience in Computer Science or related field or a PhD in Computer Science or related field with 4 yrs experience in Statistical analysis, machine learning and deep learning methodologies.Large datasets and scaling ML models and information extraction. Computing fundamentals in algorithm design, data structures, complexity analysis, problem-solving and diagnosis.\nGood understanding of data science concepts, such as regression analysis, predictive modelling, and data visualization.\n\nPreferred Qualifications\n\n\nUnderstanding of what it takes to write clean code and experience with software development lifecycle.\nKnowledge of system identification of dynamic models and control systems.\nExperience with Vibration analysis, Fault Detection and Root Cause Diagnosis.\nPractical experience of predicting Remaining Useful Life.\nExtraction of conditional indicators using signal processing techniques and analyzing data from physical sensors.\n\nAt Intel inclusion means we recognize and respect the worth and dignity of every employee. We promote and sustain a sense of belonging, valuing diverse talents, beliefs, backgrounds, and experiences to help Intel win. Our success depends on Intel\u2019s amazing employees. Make Intel your workplace of choice today. Intel provides equal employment opportunity for all applicants and employees in all areas of employment.\n Intel does not discriminate based on race, characteristics that are commonly or historically associated with race including hair, color, religion, religious creed, sex, national origin, ancestry, age, physical or mental disability, medical condition, genetic information, military and veteran status, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or ordinance.\n\nInside this Business Group\n\nAs the world's largest chip manufacturer, Intel strives to make every facet of semiconductor manufacturing state-of-the-art -- from semiconductor process development and manufacturing, through yield improvement to packaging, final test and optimization, and world class Supply Chain and facilities support. Employees in the Technology Development and Manufacturing Group are part of a worldwide network of design, development, manufacturing, and assembly/test facilities, all focused on utilizing the power of Moore\u2019s Law to bring smart, connected devices to every person on Earth.\n\nWork Model for this Role\n\nThis role will be eligible for our hybrid work model which allows employees to split their time between working on-site at their assigned Intel site and off-site."
    },
    {
        "position": "Big Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Solera, Inc.",
        "sector": "IT Services and IT Consulting",
        "companySize": "5,001-10,000 employees",
        "location": "Madrid, Community of Madrid, Spain",
        "post": "About the job \n\nThe Role\n\n\nOn this position, you will be required to have:\n\n\n\nStrong analytical skills with the ability to collect, organize, analyze, and disseminate significant \n\namounts of information with attention to detail and accuracy. Enhance data collection procedures to \ninclude information that is relevant for building analytic systems. \n\nObsession by accuracy data and automate processes.\nSolid problem-solving skills, supported by a logical, methodical, and thorough approach to \n\nimplementation.\n\nKnowledge of data cleaning, wrangling, visualization, and reporting, with an understanding of the best, \n\nmost efficient use of associated tools and applications to complete these tasks\n\nSpecify quality checks that assure QA in data and one SVOT\nExcellent interpersonal and communication skills to establish and maintain collaborative work \n\nrelationships at all levels.\n\nFluent English on business level (written and spoken)\n\n\n\n\n\nWhat You\u2019ll Do\n\n\n\nRead, extract, transform, stage and load data to selected tools and frameworks (cloud and on \n\npremise)\n\nWork closely to product and reporting team to integrate your work into current production solutions.\nProcess unstructured data into a form suitable for analysis\nSupport business decisions with ad hoc analysis as needed\nFilter and \u201cclean\u201d data by reviewing computer reports, printouts, and performance indicators to locate \n\nand correct code problems\n\nMonitoring data performance and modifying infrastructure as needed\nImprove big data performance jobs and adapt them to different environments\n\n\n\n\n\nWhat You\u2019ll Bring\n\n\n\nBachelor\u2019s degree in computer science or numerate discipline \nExperience with SQL \nTechnical expertise on big data environments such Hadoop or Azure Ecosystem\nExperience processing large amounts of structured and unstructured data, including integrating data from multiple sources.\nProgramming experience ideally in Spark, Java or Python and ability to learn new coding languages and programs\nTechnical expertise regarding data models, database design development and data mining.\nExperience in production support and troubleshooting.\nHands on with \u201ccan do\u201d attitude.\nDeep knowledge of data mining, machine learning, natural language processing, or information retrieval\nExperience in MapReduce is a plus.\nAgile methodologies\nPlatform experience, JIRA, Confluence"
    },
    {
        "position": "Algorithm Engineer - Natural Language Processing, Search",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Shopee",
        "sector": "Technology, Information and Internet",
        "companySize": "5,001-10,000 employees",
        "location": "Singapore, Singapore",
        "post": "About the job \n\nAbout The Team\n\nThe search algorithm team is responsible for Shopee\u2019s product and store search. Our main mission is to continuously build world class search algorithms and become a power engine for the company's sustainable growth. We welcome passionate and experienced talents to join us and serve our customers from all over the world.\n\nJob Description\n\n\nResponsible for the design and optimisation algorithms, including category prediction, entity matching, semantic models, etc.\nDesign and optimisation of the recall algorithm model, including query rewriting, vector retrieval, deep personalised retrieval model, multi-modal retrieval model, etc.\nConstruct and apply knowledge graphs and knowledge bases, data annotation and data mining and apply them to relevance, query rewrite and etc.\nEnhance user shopping experience through improving features such as prefill, suggestion and related search.\n\n\nRequirements\n\n\nMore than 4 years of relevant work experience\nMaster degree or above in computer science, computational linguistics and other related majors\nHave excellent coding skills, hands-on online code development experience, and proficiency in at least one language among C++/Golang/Python/Java"
    },
    {
        "position": "Software Engineer",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "The Coca-Cola Company",
        "sector": "Food and Beverage Services",
        "companySize": "10,001+ employees",
        "location": "Sofia, Sofia City, Bulgaria",
        "post": "About the job \n\nPosition Overview\n\nCoca-Cola is one of the most recognizable brands in the world. We were the first company to ever utilize coupons and for decades our marketing practices have been cutting edge. Today we\u2019re using world class Marketing Technology (MarTech) to continue to market our brands to billions of consumers globally.\n The Coca-Cola Company\u2019s IT organization is in the midst of a digital transformation that allows our employees to use world class technology to connect our products to our customers all over the world. This journey is a very exciting time for Coca-Cola and our employees are big contributors to our Success and Growth. Our large, scale and complex environment offers an incredible opportunity to address challenges, enable innovative solutions to make a difference for our customers, leveraging technology such as Adobe Experience Platform (AEP), AWS, MS Azure, and many more.\n To continue this digitalization, we are looking for a software engineer to join our dynamic team to help build scalable, cutting-edge technologies for today and tomorrow. This position is part of a globally networked team that utilizes deep technical skills to create and improve software applications that empower the Coca-Cola Company to reach our growth objectives. If you enjoy a dynamic, innovative environment, are eager to learn and highly motivated, we\u2019d love to speak with you!\n\nWhat You\u2019ll Do For Us\n\n\nDevelop and implementation of new capabilities and enhancements within Coca-Cola\u2019s Adobe Experience Platform (AEP) and Cloud environments\nIntegrate AEP with Coca-Cola\u2019s internal Consumer Data Services (CDS) platform, Adobe\u2019s Experience Cloud ecosystem (Target, Magento, Campaign), and 3rd party destinations including: social, mobile, Google, Demand Side Platforms (DSPs), and other Ad Tech capabilities\nDesign and code the interfaces between TCCC\u2019s Consumer Data Services (CDS) platform and AEP, AEP to TCCC\u2019s enterprise data lake, identity graph, Google Big Query, and Adobe Web SDK JavaScript library\nCreate Customer Journey Analytics dashboards providing insights to business stakeholders\n\nQualifications And Requirements\n\n\nBachelor's degree in Computer Science, Computer or Electrical Engineering or related fields\n2 years as Full Stack Software Engineer with experience of creating elegant, efficient, and testable code\nBack-end programming experience with Java, JavaScript, Python, plus front-end JavaScript development frameworks such as ReactJS, NodeJS, AngularJS, SQL, etc.\nWorking knowledge of AWS and/or Azure serverless products (network, storage, compute, database)\nExperience using cloud database systems and services such as AWS Aurora/Dynamo DB/Redshift or Azure alternatives\nExperience implementing REST APIs and web services\nExperience in dev-ops delivery/support models as well as iterative software delivery methodologies \u2013 Agile, SCRUM, etc. \nSolid understanding of Git-based version control\n\nPreferred Experience \u2013 if you don\u2019t have it, we\u2019ll train you on it!\n\n\nAt least 1 year of experience with Adobe Experience Platform including managing Experience Data Model (XDM) schemas, AEP setup through API, REST & Postman\nMarketing Automation experience with Consumer Data Platforms (CDPs) including: audience segmentation & activation, multichannel campaign management, and real-time interaction management, and consumer database, work for diverse global companies preferred\nAmazon Web Services (AWS) and/or Microsoft Azure Certifications \nExperience with personal (PII) data privacy and security best practices\nExperience with Azure B2C and Consumer Data (Consumer Identity and Access Management) is a strong plus\nExperience working in a multinational, distributed team, with in-house and external delivery resources\nProficiency in Jira, or similar Agile life cycle management tools\n\nWhat We Can Do For You\n\n\nInnovation & Technology: The ability to work with an award-winning team that is on the cutting edge of innovation. \nLearning & Development:\u202fAt\u202fThe\u202fCoca-Cola Company we believe innovation can't happen without continuous learning and we provide our employees many ways to grow professional and personally.\nAgile Work Environment: We embrace agile with management that believes in removing barriers, so you are empowered to experiment, iterate and innovate.\n\nSkillsAngularJS; Hyper Text Markup Language (HTML); React.js; Cascading Style Sheets (CSS); Customer Service; Chatbots; Algorithms; Agile Methodologies; Adobe Experience; Data Modeling; Natural Language Processing (NLP); Analytical Techniques; Oral Communications; Server Side Development; Azure Bot Service; JavaScript; Artificial Intelligence Technologies; Written Communication; Problem Solving; Data Mining; Teamwork; Adaptability; Adobe Experience Platform; Self-Starter; Machine Learning\n\nOur Purpose And Growth Culture\n\nWe are taking deliberate action to nurture an inclusive culture that is grounded in our company purpose, to refresh the world and make a difference. We act with a growth mindset, take an expansive approach to what\u2019s possible and believe in continuous learning to improve our business and ourselves. We focus on four key behaviors \u2013 curious, empowered, inclusive and agile \u2013 and value how we work as much as what we achieve. We believe that our culture is one of the reasons our company continues to thrive after 130+ years. Visit Our Purpose and Vision to learn more about these behaviors and how you can bring them to life in your next role at Coca-Cola.\n We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and/or expression, status as a veteran, and basis of disability or any other federal, state or local protected class. When we collect your personal information as part of a job application or offer of employment, we do so in accordance with industry standards and best practices and in compliance with applicable privacy laws.\n R-74898"
    },
    {
        "position": "Data Scientist",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Symptoma",
        "sector": "Hospitals and Health Care",
        "companySize": "51-200 employees",
        "location": "Vienna, Vienna, Austria",
        "post": "About the job \n\nWE WANT TO SAVE LIVES. ARE YOU ON BOARD?\n\nWe are doers. Our amazing team joined forces for a bold mission worth fighting for: To give every patient access to the right diagnosis and treatment.\n We know that each and every one of us can make a difference with our unique skills, powers & passions. As a team, we are powerful and overcome even the biggest challenges. Take this chance to become part of Symptoma - read on!\n\nTHESE TASKS AWAIT YOU:\n\n\nDesign and implement models to improve the diagnostic capabilities of Symptoma\nCommunicate data-driven results to both key stakeholders and company-wide\nOwn projects from development to deployment, either working independently or as part of a team\n\nWHAT YOU BRING ALONG:\n\nMust-haves:\n\nDegree in a quantitative field (e.g., computer science, statistics, math, physics, informatics)\nWorking experience in data science\nAbility to work independently or as part of a team\nExperience in Python\nExperience with LINUX operating systems\nFluency in English, both written and spoken\n\nNice-to-haves:\n\nExperience with Java\nExperience in Natural Language Processing (NLP), especially when applied to medical data\nExperience in Deep Learning and neural nets\nExperience with ElasticSearch\nExperience in software engineering, including code versioning and test-driven development\nExperience with containerization (Docker) and cloud computing \nDomain knowledge in medical informatics and/or digital health\n\nWHY YOU SHOULD APPLY:\n\n\nImpact: Leave a dent in this universe and use your skills for a good cause.\nGrowth: Work at a fast-growing scale-up company with great opportunities for career progression.\nAppreciation: Your input and creative ideas are highly appreciated \u2013 we want YOU with all your abilities, talents and (soft) skills.\nResponsibility: You are responsible for what you do - you\u2019re not only able to implement what you envision but also to work without supervision. Don\u2019t hesitate to bring in all your strengths, knowledge and experience to reach your full potential.\nFlexibility: Being productive before the earliest early birds, taking an extra long coffee break or working in the dark, you can find your rhythm with us.\nHome Office: We have an output-orientated mindset and trust our team members to decide for themselves where they can work the best (amount of home office days may differ depending on the position).\nDiversity: Our team is anything but boring \u2013 Do you speak Arabic, Swedish or Chinese? We\u2019ll be able to understand you! \nEquipment: We offer state-of-the-art workstations (multiple monitors, powerful laptops, height-adjustable desks)\nAmazing office: in vibrant Vienna (excellent accessibility in the heart of the third district)\n\nGreat performers must be paid appropriately. We offer a monthly salary starting at 3.200 Euro gross per month following internal company agreements for this position. Your professional experience, qualifications, and industry standards will guide the actual remuneration package.\n\nWE MIGHT BE THE PERFECT FIT FOR YOU. LET'S FIND OUT!\n\n__Please send us the following file:\n\nonly your CV (Please include the code-word \"Better Diagnosis\" as text in your CV)\n\nApply now and help us take healthcare to the next level.__"
    },
    {
        "position": "Data Scientist - Senior Level",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Temple & Webster",
        "sector": "Retail",
        "companySize": "201-500 employees",
        "location": "Sydney, New South Wales, Australia",
        "post": "About the job \n\nSenior Data Scientist \n\n\n\nAustralia's #1 furniture and homewares online retailer\nGrowing business with a fantastic culture\nHybrid working arrangement - work from home and our St Peters Office\n\n\n\nTo lead and execute data science activities for Temple & Webster, empowering this business to make better decisions when it comes to designing and importing new product.\n\n\nWhat we\u2019re looking for\n\n\n\n\nMain responsibilities of this role include:\n\n\n\nDevelop scalable machine learning solutions to support forecasting, purchasing and pricing.\nUtilising modern NLP methods to derive additional features and insights from products and customer behaviour\nLead data projects that support business growth, e.g. drive increases in customer acquisition and retention, engagement, purchase frequency and average order value\nManage data projects end to end, including opportunity identification, data gathering, data cleansing and analysis, \nAnalyse customer behavioural data to develop insights and identify performance improvement and growth opportunities\nCollaborate with the data team (Data Science, Data Engineering, BI and Analytics), reviewing solutions, sharing knowledge, and improving coding standards\nCoach cross-functional teams to understand where and when different models or analyses should be used and can create value.\n\n\n\nWhat you already have\n\n\n\n5+ years of experience as a Data Scientist or related working experience, e.g. Machine Learning Engineer\nTertiary qualification in a quantitative discipline (e.g. Statistics, Engineering, Mathematics)\nBackground in statistical analysis techniques, including logistical regression, linear regression, K-Means clustering, random forest, factor analysis, and text analysis.\nExperience with Prediction/Forecasting economic growth from transactions and customer behaviour\nExperience extracting informations from images and text\nStrong technical experience using SQL, Python or R (GCP is a bonus)\nExperience developing machine learning algorithms\nCapable of working with high volumes of structured and unstructured data\n\n\n\nNice to have\u2026\n\neCommerce experience\nExperience in a high-growth digital business\nExcellent communication and presentation skills\nAble to work directly with a variety of internal and external stakeholders\nStrong planning and project management skills\nComfortable working in a fast-moving environment\nCurious mind and strong problem-solving skills\n\n\n\nIt is expected that you will also make a contribution to:\n\n\n\nCultural, social and behavioural standards within the business through leadership by example (i.e. Walk the Talk)\nManagement presentations as required\nAny other responsibilities/duties as required by the group\n\n\n\nNaturally, there's the expectation that you'll bring good humour, a strong sense of personal style!\n\n\nAdditional benefits\n\nAmazing culture\nCompetitive salary\nGenerous employee discounts across our entire range\nFlexible working arrangements\nPaid leave on your birthday\nPaid parental leave\nCatered lunch provided 3 days per week\nSubsidised breakfast daily\nFree mindfulness practice daily\nRegular celebrations and team socials\nOpportunities to volunteer with our charity partner"
    },
    {
        "position": "Data Warehouse Developer/Data Modeler",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Watercare Services Limited",
        "sector": "Utilities",
        "companySize": "501-1,000 employees",
        "location": "Auckland, New Zealand",
        "post": "About the job \n\nWatercare is the largest water and wastewater utility in New Zealand more than 400 million litres of water to Auckland every day. Now is an exciting time to join Watercare, we're planning to spend $18.5 billion over the next 20 years to ensure we can continue to support our growing city in a climate-resilient way. When you average that out, that's an investment of $2.5 million every day.\nIt doesn't just stop there; we ensure that sustainability lies at the heart of everything that we do to help protect our water resources for future generations. This means that we are continuously focused on how we can reduce our carbon footprint with initiatives likes solar panels, electric cars, revegetation programmes and much, much more. We really are a company that wants to make a positive difference.\n\n\nHe whakam\u0101rama m\u014d te t\u016branga mahi | About the role\n\n\n\nAs the provider of water to the majority of Auckland, Watercares data is critical to understanding the ins-and-outs of our services to Tamaki Makaurau. We thrive on the optimism and innocation of current systems and learning new technologies to provide better visibility, allow more informed decisions to improve out business processes and the end experience for our customers.\nAs our Date Warehouse Developer/Data Modeler, you will design, implement and document data modelling solutions which include the use of relational, dimensional and NoSQl databases. In this role you will be responsible for the development of conceptual, logical and physical data models, the implementation of RDBMS, operational data store, data marts and data lakes on target platforms. Additionally, you will define and govern data modelling and design standards, tools, best practices and related development methodologies. You will also oversee and govern the expansion of existing data architecture and the optimisation of data query performance based on best practices.\n\n\nYou will work closely with our Data Engineering team to create optimal physical data models of datasets, as well as creating and maintain data maps and system interrelationship diagrams. This is a key enabler role for Analytics at Watercare - you will open up a world of opportunities related to data for our internal and external customers.\n\n\n\n\nNg\u0101 p\u016bkenga e rapu nei m\u0101tou | About you\n\n\nWe are looking for passionate, analytical people who have a high attention to detail. In this role you will bring:\n\n\n\nTertiary level qualification in an appropriate discipline\n3+ years of hands-on relational, dimensional, and/or analytic experience (using RDBMS, dimensional, NoSQL data platform technologies, and ETL and data ingestion protocols)\nExperience in collecting and translating business rules into conceptual, logical & physical models for data platforms. \nExperience with building data models using Kimball methodology - alternatively, experience in data vault would also be considered.\nProven commercial experience working in an agile environment, as well as recognised and relevant technology industry qualifications\nExperience with data warehouse, data lake and enterprise big data platforms in multi-data-centre contexts required\nGood knowledge of metadata management, data modelling, and related tools (Erwin, ER Studio or others)\n\n\n\nNg\u0101 hua m\u014du | What's in it for you\n\n\nWe offer a competitive salary and staff benefits package including: \n\n\n\nTraining and development opportunities\nLife and income protection insurance plans\nGenerous parental leave\nEmployee discounts at a range of large retailers\nKiwisaver contribution\nFree on-site gym\nDiscounted parking options available\n\n\n\nMe p\u0113hea te tono mai | How to Apply\n\n\nCome and join our team! If you are looking for an exciting career opportunity with a fantastic team then please apply online today - www.careers.watercare.co.nz."
    },
    {
        "position": "Data Modeling Specialist",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "PepsiCo",
        "sector": "Food and Beverage Services",
        "companySize": "10,001+ employees",
        "location": "Barcelona, Catalonia, Spain",
        "post": "About the job \n\nAuto req ID: 284447BR\n\nJob Description\n\n#Locations: Barcelona, Spain; Vitoria-Gasteiz, Spain\n PepsiCo is using the power of data to transform the way our world-famous portfolio of brands are sold every day. Our Data Science & Analytics group influences every aspect of how we sell and move our products. In just a short period of time, they\u2019ve built new capabilities that have defined the data science roadmap across all of our brands. Members of our team solve complex problems facing our rapidly changing business and get to see their work come to life in the real world.\n Join PepsiCo\u2019s Enterprise Data Operations team which develops quality data collection processes, maintains the integrity of our data foundations and enables business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation.\n As a Data Modeling Specialist, your focus would be to partner with D&A Data Foundation team members to create data models for Global projects. This would include independently analyzing project data needs, identifying data storage and integration needs/issues, and driving opportunities for data model reuse, satisfying project requirements. The role will advocate Enterprise Architecture, Data Design, and D&A standards, and best practices. You will be a key technical expert performing all aspects of Data Modeling working closely with Data Governance, Data Engineering and Data Architects teams.\n As a member of the data modeling team, you will create data models for very large and complex data applications in public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. The primary responsibilities of this role are to work with data product owners, data management owners, and data engineering teams to create physical and logical data models with an extensible philosophy to support future, unknown use cases with minimal rework. You'll be working in a hybrid environment with in-house, on-premise data sources as well as cloud and remote systems. You will establish data design patterns that will drive flexible, scalable, and efficient data models to maximize value and reuse.\n Key Accountabilities:\n\nIndependently complete conceptual, logical and physical data models for any supported platform, including SQL Data Warehouse, EMR, Spark, DataBricks, Snowflake, Azure Synapse or other Cloud data warehousing technologies.\nGoverns data design/modeling \u2013 documentation of metadata (business definitions of entities and attributes) and constructions of database objects, for baseline and investment-funded projects, as assigned.\nProvides and/or supports data analysis, requirements gathering, solution development, and design reviews for enhancements to, or new, applications/reporting.\nSupports assigned project contractors (both on- & off-shore), orienting new contractors to standards, best practices, and tools.\nAdvocates existing Enterprise Data Design standards; assists in establishing and documenting new standards.\nContributes to project cost estimates, working with senior members of team to evaluate the size and complexity of the changes or new development.\nEnsure physical and logical data models are designed with an extensible philosophy to support future, unknown use cases with minimal rework.\nDevelop a deep understanding of the business domain and enterprise technology inventory to craft a solution roadmap that achieves business objectives, maximizes reuse.\nPartner with IT, data engineering and other teams to ensure the enterprise data model incorporates key dimensions needed for the proper management: business and financial policies, security, local-market regulatory rules, consumer privacy by design principles (PII management) and all linked across fundamental identity foundations.\nDrive collaborative reviews of design, code, data, security features implementation performed by data engineers to drive data product development.\nAssist with data planning, sourcing, collection, profiling, and transformation.\nCreate Source To Target Mappings for ETL and BI developers.\nShow expertise for data at all levels: low-latency, relational, and unstructured data stores; analytical and data lakes; data streaming (consumption/production), data in-transit.\nDevelop reusable data models based on cloud-centric, code-first approaches to data management and cleansing.\nPartner with the Data Governance team to standardize their classification of unstructured data into standard structures for data discovery and action by business customers and stakeholders.\nSupport data lineage and mapping of source system data to canonical data stores for research, analysis and productization.\n\n\nQualifications/Requirements\n\nQualifications:\n\n\n8+ years of overall technology experience that includes at least 6+ years of data modeling and systems architecture.\n3+ years of experience with Data Lake Infrastructure, Data Warehousing, and Data Analytics tools.\n6+ years of experience developing enterprise data models.\nExpertise in data modeling tools (ER/Studio, Erwin, IDM/ARDM models).\nExperience with integration of multi cloud services (Azure) with on-premises technologies.\nExperience with data profiling and data quality tools like Apache Griffin, Deequ, and Great Expectations.\nExperience with at least one MPP database technology such as Redshift, Synapse, Teradata or SnowFlake.\nExperience with version control systems like Github and deployment & CI tools.\nExperience with building solutions in the retail or in the supply chain space is a plus\nExperience of metadata management, data lineage, and data glossaries is a plus.\nWorking knowledge of agile development, including DevOps and DataOps concepts.\nBA/BS in Computer Science, Math, Physics, or other technical fields.\n\n\nSkills, Abilities, Knowledge:\n\n\nExcellent communication skills, both verbal and written, along with the ability to influence and demonstrate confidence in communications with senior level management.\nStrong change manager. Comfortable with change, especially that which arises through company growth.\nAbility to understand and translate business requirements into data and technical requirements.\nPositive and flexible attitude to enable adjusting to different needs in an ever-changing environment.\nStrong organizational and interpersonal skills; comfortable managing trade-offs.\nProactively drives impact and engagement while bringing others along.\nConsistently attain/exceed individual and team goals\nAbility to work with virtual teams (remote work locations); lead team of technical resources (employees and contractors) based in multiple locations across geographies\nLead technical discussions, driving clarity of complex issues/requirements to build robust solutions\n\n\nWhat makes us different?\n\n\nHybrid work model & collaborative office experience to enable innovation\nEntrepreneurial environment in leading international company \nProfessional growth possibilities & learning opportunities \nVariety of benefits to support your physical, emotional and financial wellbeing\nVolunteering opportunities to help external communities\nDiverse team from over 25 countries\nHave a stake in D&I strategy and Bring your whole self to work \n\n\nAbout PepsiCo\n\nWe believe that culture should be at the cornerstone of everything we do at PepsiCo. We operate with start-up mindset \u2013 agile, innovative and not afraid of failure. We want our team to come to work every day excited to explore new ways bring enjoyment, refreshment and fun to the world.\n PepsiCo Positive (pep+) is the future of our organization \u2013 a strategic end-to-end transformation, with sustainability at the center of how we will create growth and value by operating within planetary boundaries and inspiring positive change for the planet and people. https://www.youtube.com/watch?v=PO5CdBmWjUY\n So, if you\u2019re ready to be a part of a playground for those who think big, we\u2019d love to chat.\n\nWe encourage the diversity of applicants across gender, age, ethnicity, nationality, sexual orientation, social background, religion or belief and disability\nRelocation Eligible: Eligible for Standard Relocation\n\nJob Type: Regular"
    },
    {
        "position": "Remote | Data Scientist - Pricing and Valuation team",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "OLX Group",
        "sector": "Software Development",
        "companySize": "10,001+ employees",
        "location": "Pozna\u0144, Wielkopolskie, Poland",
        "post": "About the job \n WELCOME TO OLX GROUP\nOver 300 Million monthly active users; US $1.6 billion in revenue and 18% revenue growth (FY 2021; 36% growth in FY2020); Part of Naspers\u2019 Prosus, one of the biggest technology investors in the world (An early investor in Tencent and the owner of StackOverFlow). +30 countries. +20 Brands. Powered by +10,000 employees representing 81 nationalities. \nThat\u2019s what\u2019s on our plate at OLX Group.\nAnd that's why we need your help. Join Us. Shape your career with us.\nThe team\nThe Pricing and Valuation team at OLX Group is responsible for unlocking hidden value using data and artificial intelligence. We analyze the status quo, improve buyer & seller interactions, optimize the user experience and monetize on the delivered customer value. For us revenue growth is the good fruit of our work and not the goal itself. We invite you to join a team which works with OLX, Real Estate platforms (Otodom, Storia) and Automotive platforms (Otomoto, Standvirtual) across the entire EU region. A team that breaks through walls and builds cross-functional connections with everyone around. A team where a common mission and goals matter more than reporting lines. We build on each other, asking for help and support when needed, and we proactively support others. In your day to day routine you will have the opportunity to develop supervised models for behavioral classification, deep learning models for image classification, regression models for value estimation as well as NLP models for object and actor entity recognition. All in Python and the AWS cloud. You will be exposed to key stakeholders, having direct contact with internal customers. You will have the carte-blanche to experiment and test things. And most importantly, you will also witness how your work impacts the day to day business of OLX Group customer units. We have offices in Poznan and Warsaw, but this role can be based anywhere in Poland. \nWhat You Will Be Doing\n\n\nYour primary role will be to increase business value by finding opportunities where data science and machine learning can make an impact.\nYou will maintain strong relationships with stakeholders. This means asking a lot of questions to business people, translating their requirements into achievable projects. It also means collaborating with other teams, like infrastructure and data engineering to get things done in an elegant and timely manner. \nYou will build models, tinker around them to make them work, test them and eventually deploy to production. You will see your stuff in action and you will be able to measure the true impact of your models.\nYou will work in multi-functional teams, in a diverse, multinational environment, filled with people from Portugal, Bulgaria, Romania, Poland, Ukraine, Kazakhstan and Uzbekistan. \nMost importantly you will have fun working with us :)\n\nWhat Are We Looking For\n\n\nAnalytics and Modeling: \n\nVery strong analytical skills. Like really strong! So strong that truth and light are your two middle names. Solid background in statistics and modeling. Good knowledge of Python, which means having experience with at least one of the following: Scikit-Learn, TensorFlow, PyTorch, Pandas.\n\nMachine Learning Engineering: \n\nGood understanding of engineering best practices, that is: testing, CI/CD, monitoring, alerting, containers. Hands-on experience with SQL. Ability to work with big data at scale: experience with columnar storage clusters.\n\nStakeholder Management:\n\nProficient in English with excellent written and oral communication skills! Strong presentation skills. Able to work in multi-functional teams with people from different backgrounds.\nNice To Have\n\n\nDeploying models to production and serving models at scale.\nUsing AWS for deploying machine learning solutions.\nBuilding data pipelines using tools like Spark and Airflow.\nA/B testing.\nDocker.\n\nWhat We Offer\n\n\nStrengths-based personal career development.\nCompany mobile phone, MacBook Pro or Windows Dell along with necessary accessories to make your work comfortable.\nCompetitive compensation and benefits (medical care, sports package and others).\nTraining and conference budget.\nThe opportunity to learn from each other and become better every day.\nA passionate and diverse team of data scientists spanning across several tech hubs in Europe and around the world.\n\nWe look forward to receiving your application! OLX Group Talent Acquisition team\na Bit More About Us\nCheck our careers website here. Discover why you should join the OLX Group Now Check out our talent, product, engineering and design blogs here Follow us on Linkedin We encourage people of all races, ethnicities, disabilities, ages, gender identity or expression, backgrounds and experiences to consider applying for this role. We are committed to building an inclusive culture that seeks out the diverse perspectives and experiences of our people and becomes a company superpower and strategic competitive advantage. The OLX Group (OLX Group consists of OLX Global B.V. and its affiliated companies) will handle your personal data with care and will process your personal data to assess your fit for the position you are applying for. You can give your consent (optional) to allow us to store your data for up to 12 months after the application process. So that in case you are not fit for the role at stake we can consider you for other suitable roles. Please refer to our Privacy Statement to find out more about how your application data will be processed."
    },
    {
        "position": "Data Scientist",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "DEPT\u00ae",
        "sector": "Technology, Information and Internet",
        "companySize": "1,001-5,000 employees",
        "location": "Veenendaal, Utrecht, Netherlands",
        "post": "About the job \n Apply\n For our Data Science team, we are looking for a Data Scientist who knows exactly how to handle Algorithms, Big Data, Machine Learning and build predictive models. Please note you MUST HAVE at least 2 years of hands-on working experience in a data science role, preferably related to digital marketing data and/or working at a digital agency to be eligible for this role. Please only send in your application if you can confidently say you have this experience.\n\nThis vacancy is open for relocation to the Netherlands. Read all about our relocation process here.\n\nAs a data scientist, you know how to structure and clean giant datasets meticulously, in order to apply your algorithms on them. You recognise patterns in data that no-one else would and this enables you to make our campaigns better and smarter. From the output of a calculated dataset, you can start with the analysis for a client and eventually you are able to communicate your advice in a clear fashion to your team and your client.\n You will be working on new concepts and innovations regarding:\n\nPredicting customer propensity.\nForecasting supply and demand.\nSegmenting customer groups based on behavioural data.\nRecommending products and/or content. \n\n\nYou will work in a vibrant environment with clever minds who work for a variety of large global clients. Yes, we are eager to hire the most talented experts in the game but we are also looking for a perfect DEPT\u00ae-fit. Someone who is eager to learn, inspires, strives towards a better world, takes the stage, a futurist at heart, and someone who will toast to a successful week with us.\n\nYOU:\n\n\nMUST HAVE at least 2 years of hands-on working experience in a data science role, preferably related to digital marketing data and/or working at a digital agency;\nHave studied Business IT or similar (Computer Science, Data Science, Information Management);\nHave experience with Amazon Web Services, Azure or Google Cloud Platform;\nHave experience with Google Analytics and/or other Web Analytics software;\nAre an expert in Python (MUST);\nAre experienced in SQL;\nHave experience with both supervised and unsupervised problems and solutions;\nAre having knowledge of NLP;\nAre familiar with MLOps;\nHave an affinity with marketing and technology;\nAre analytical, flexible, independent and communicatively strong;\nAre one of those ambitious people who can switch from serious to play in a heartbeat.\n\n\nWE OFFER:\n\n\nAn open company culture; \nPossibilities to work from our offices and hubs in Rotterdam, Amsterdam, Veenendaal, Zwolle, and Maastricht \u2013 or from the comfort of your own home; \nWorking from home setup;\nPension scheme;\nPossibilities to develop your skills even further via training and certifications; \nHealthy and tasty food; \nFree Bootcamp training twice a week; \nFriday drinks/open bar to wrap up the week; \nGreat fringe benefits; laptop, mobile phone, NS business card and many other goodies.\n\n\nAbout DEPT\u00ae:\n\nDEPT\u00ae is a pioneering technology and marketing services company that creates integrated end-to-end digital experiences for brands such as Google, KFC, Philips, Audi, Twitch, Patagonia, eBay and more. Its team of 2,500+ digital specialists across 30+ locations on 5 continents delivers pioneering work on a global scale with a boutique culture. DEPT\u00ae is committed to making a positive impact on the planet and since 2021 has been Climate Neutral and B Corporation certified. www.deptagency.com\n Learn more about our diversity, equity, and inclusion efforts here."
    },
    {
        "position": "DATA SCIENTIST",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Ferrero",
        "sector": "Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Kirchberg, Luxembourg, Luxembourg",
        "post": "About the job \n Job Location: Luxembourg\n\nCompany Description\n\nFerrero is a family-owned company with a truly progressive and global outlook and iconic brands such as Nutella\u00ae, Tic Tac\u00ae, Ferrero Rocher\u00ae, Raffaello\u00ae, Kinder Bueno\u00ae and Kinder Surprise\u00ae. As the love for our brands continues to grow, so too does our global reach. Represented in 55 countries, with products sold in more than 170, the Ferrero Group is loved by generations around the world. The secret to our global success? Nearly 35,000 dedicated employees who celebrate care and quality to craft a business, careers and brands we are proud of. Join us, and you could be one of them.\n Diversity Statement\n Ferrero is committed to building a diverse and inclusive culture in which all employees feel welcomed and appreciated and have the same opportunities. We believe all of our people are equally talented in their own way. In nurturing the curiosity and natural abilities of our employees, we provide them, generation after generation, the means to succeed personally and professionally, enabling them to craft their journey at Ferrero. The diversity of our talents is what makes our work environment multicultural, innovative and highly rewarding.\n\nAbout the Role:\n\nFor our Ferrero Headquarter in Luxembourg we are currently looking for a talented DATA SCIENTIST supporting our Advanced Analytics pillar.\n Reporting to the Advanced Analytics Leader, the successful candidate will be focal point for:\n\nBusiness stakeholders across categories and geographies\nFerrero Luxembourg IT department\nColleagues in BI&A Unit working in Business Partnership pillar to support identification of potential solutions for business problems\nColleagues in BI&A Unit working in Data Governance pillar to identify current and new potential datasets for use in analysis \nPotentially work with external agencies and data brokers as needed.\n\n\nMain Responsibilities:\n\n\nDevelop, test and rollout statistical models to support analytics and business reporting functions\nCreate procedures to clean and classify data from disparate sources like retail sell-out, shopper behavior, consumer surveys, marketing and other 3rd party sources for use in modeling and reporting\nPractical experience of media measurement including digital to support business decision making\nScript automation procedures for analytical flows\nVisualizing analytic results for business stakeholders in PowerBI\nCreate dashboard templates and help BI colleagues to create and customize their own\nGuide and mentor junior data scientists on existing analyses and new capabilities creation.\n\n\nWho we are looking for:\n\nProfile\n\n\nBachelor\u2019s degree in quantitative area like Mathematics, Econometrics, Statistics, Engineering etc. Advanced degree preferred\nMinimum 3 \u2013 5 years of experience in applied work on Advanced Analytics, preferably at a FMCG manufacturer company\nExperience in modeling techniques and advanced statistical concepts: Regression, Classification, Text mining, Random Forest etc\nAnalytical creativity and desire to test & learn. Interpretation of analytic outputs from business standpoint\nExperience using external third-party data sources including Nielsen, IRI, consumer surveys\nStrong understanding of media data including traditional and digital\nRelevant communication skills.\n\n\nIT Skills\n\n\nExcellent knowledge and best practice analysis/programming of SQL, PowerBI, Azure, Spark, Scala, Power BI, Google Analytics, SAP HANA\nStrong knowledge of best practice analysis and programming techniques with R and Python.\n\n\nLanguages\n\n\nFluent in English is mandatory\nAny other language is a plus.\n\n\nHow to be successful in the role and at Ferrero:\n\nConsumers, quality and care are at the heart of everything we do. So, to be successful at Ferrero, you\u2019ll need to be just as consumer and product centric as we are - dedicated to crafting brilliant results for consumers around the world."
    },
    {
        "position": "Data Scientist",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Lufthansa Systems Hung\u00e1ria",
        "sector": "IT Services and IT Consulting",
        "companySize": "501-1,000 employees",
        "location": "Szeged, Csongr\u00e1d, Hungary",
        "post": "About the job \n\nJoin us as a Data Scientist and work on our market leading Operations Control solution, a machine learning module, preventing disruptions at the day of operations and automating the work of the Ops Controller.\n\n\nYour tasks will include:\n\nWork with aviation data to build a new data-driven product and develop innovative uses of machine learning for the airline industry\nProvide clarity and generate new insights from complex data sets by applying advanced analytical models\nContribute to the development of end-to-end data solutions in collaboration with cross-functional data experts and business stakeholders.\n\n\n\nYou are looking for us if you have experiences/ qualification in the following fields:\n\nA Master\u2019s or Bachelor\u2019s degree in a quantitative discipline such as computer science, mathematics, physics, or a related subject\nProficiency using one or more programming or scripting language to work with data, especially Python\nSome experience and/or project course work performing data analysis and applying statistics\nGood knowledge of machine learning fundamentals\nExperience with version control systems (e.g. Git)\nFamiliarity with the fundamentals of SQL\nStrong communication skills (our working language is English) and comfort delivering results to stakeholders and colleagues \nA strong desire to learn every day and a self-starter mentality \n\n\n\nYou will be successful in this position if you have the following skills or experience:\n\nApplying machine learning in fields such as Computer Vision, NLP, or Reinforcement Learning\nWorking in cloud computing environments, especially Microsoft Azure\nData science software platforms (e.g. SAS, Databricks)\nData science libraries (e.g. pandas, NumPy, SciPy, scikit-learn) \nProject management, particularly knowledge of agile project setups (e.g. Kanban, Scrum)\n\n\n\nAdvantage if You have\n\nAirline know-how, OPS basics knowledge\n\n\n\nWhat are the benefits of joining us as an employee?\n\n\nEven when you work hard, you will still have time for your personal life: our flexible working hours based on core time, the exact observance of the designated number of working hours, the occasional option of working from home, and the benefits that can be extended to cover your family you can also improve your non-working life!\nWe have long-term plans for you! We have carefully designed career paths (and a career management system), we provide the appropriate training courses and projects to accomplish your aims.\nOur community is characterized by mutual respect and an attitude of helpfulness. This high professional quality level and the colorful personalities will help you spend your everyday life in a good mood, why you make the best of your skills and talents. \nWe are happy when you are open and help you discover the world: after six months you will receive substantial discounts that you can use to visit any place in the world taking Lufthansa flights!\nIn addition to an inclusive and helpful atmosphere, trust is also an important value for us. You can rely on us with anything right from your first day, and we also trust you to the utmost extent."
    },
    {
        "position": "Senior Data Scientist",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Orange Quarter",
        "sector": "Staffing and Recruiting",
        "companySize": "11-50 employees",
        "location": "Berlin, Berlin, Germany",
        "post": "About the job \n We are working with a MedTech company who have just been acquired by an industry giant in a bid to destabilise the monopoly held by corporate giants in the US market. How long have you spent on hold waiting to get through to a doctor so you can ask them a simple question you probably already knew the answer to? This is one of the problems they are solving by building an asynchronous communication platform so you can instant message your doctor. Additionally, they are introducing telemedicine solutions as well as features that allow you to book/amend/cancel appointments and renew prescriptions, and book video appointments for appointments that can be done remotely. The mission is simple, to improve patient care and communications as much as possible.\n\nIndustry\n\nOQ-industries MedTech\n\nWhat To Expect\n\nYou will be part of a small cross functional team of data professionals. You will be tasked with owning E2E machine learning products, from working with your product stakeholders to identify problem areas, translating these into data science problem statements and then developing and deploying these products to add business value. They already have strong machine learning infrastructure resources in place to the emphasis of this role is on the earlier \u2018data science\u2019 part of the ML pipeline. This is a communications product at its core so much of the products you will build will leverage NLP so experience is this space is a must for this role, although you do not need production experience.\n\nPerks\n\n\nWork on a truly impactful product, bettering the lives of millions\nGet the chance to build real Data Science and ML products\nFully remote, but they have an office in Berlin if you want to use it\nGreat salary and benefits package, including unlimited paid holiday\n\nRequirements\n\n\n3+ years of experience in Data Science and Machine Learning\nGood knowledge of NLP-specific machine learning tools and libraries\nYou want to create business value through machine learning and NLP, you need to have a product mindset\nSounds good?Apply now"
    },
    {
        "position": "Natural Language Processing Scientist",
        "jobType": "Full-time",
        "jobLevel": "",
        "company": "Novo Nordisk",
        "sector": "Pharmaceutical Manufacturing",
        "companySize": "10,001+ employees",
        "location": "M\u00e5l\u00f8v, Capital Region, Denmark",
        "post": "About the job \n As part of the digitalisation of early research at Novo Nordisk we are looking for outstanding candidates with a strong background in computational science and natural language processing (NLP) who can bring value to the organisation by turning text into data for analysis and insights, via application of NLP and analytical methods.\n This is an exciting position where you will help scientists in the early research organisation to transform their decision-making from a document-centric view of finding documents and reading them, to a data-centric view of uncovering new insights by the use of natural language processing-based text mining. This will help the researchers to overcome the limitations of unstructured data and uncover previously hidden relationships.\n This is your chance to join forces with a competent information research department and help democratize external and internal scientific information and data. The position offers you a unique combination of science and information research.\n\nAbout The Department And Area\n\nYou will join 20 dedicated colleagues within the Novo Nordisk Global Information and Analysis department (GLIA), which offers a worldwide information service and scientific intelligence function to Research & Early Development (R&ED), at headquarter and affiliates.\n Our purpose is to provide modern digital solutions to the organisation and to ensure that internal customers have easy and global access to quality information sources and professional information research services supporting their needs.\n GLIA is part of a new area, Digital Research & Intelligence, which is being establised to provide a modern scientific intelligence unit, drive external collaborations and access to emerging technologies in the digital space of drug discovery, facilitate idea maturation and develop an educational framework to drive our digital jounney.\n Digital & Research Intelligence is part of Digital Science & Innovation (DSI), which was recently established to drive digitalisation across R&ED. DSI participates in drug development projects across the value chain, from early discovery to pre-clinical development.\n\nThe position\nYou will work as a NLP specialist and be a key expert within your field. By combining NLP text mining, artificial intelligence, mechanistic modelling and knowledge graphs you will help scientists in early research to extract key information from unstructured text, rapidly and effectively, to provide decision support. You will be working with textual documents of multiple format like scientific literature, patents, patient literature, internal safety reports, drug labels, clinical trial data, social media, electronic health records, Google slides, Electronic Lab Notebooks etc.\n\nKey Responsibilities\n\n\nDevelopment of algorithms for information extraction \nRelationship extraction/semantic similarities, summarization, Natural Language inference\nNeural network models for language understanding tasks like BERT, GTP-3 etc\nEvaluate the performance of neural models and validate the accuracy of extracted knowledge\nSupport GLIA and relevant part of DSI with knowledge enriching analysis results via natural language generation \nWork closely with relevant Digital Science & Innovation teams to translate best-performance techniques into production \nResponsible for presentation and reporting of scientific results \nParticipate in line/digital projects progression with strong NLP and knowledge graph expertise\nEncourage, propose and participate in projects boosting the use of advanced text mining and knowledge graphs\n\n\nQualifications\n\nWe are looking for a highly motived person preferable with a PhD in Computer Science, AI, Computational Linguistics, Applied Mathematics, Physics or similar. Further we expect you to have the skills and expertise listed below:\n\nProfound knowledge of Deep Learning methods applied to NLP\nStrong Experience with Natural Language Processing and Machine Learning technologies\nDemostrated strong track record of developing and applying NLP solutions\nExcellent written, verbal presentation and graphical communication skills \nEffective communication skills with the desire to work with dispersed teams across multiple time zones\nAttention to detail, diligent and tenacious\nHigh degree of personal motivation and ability to self-manage\n\n\nTitle and conditions are evaluated based on the individual experience and contribution.\n\nContact\nFor further information, please contact Lilian Nilsson by email lznl@novonordisk.com\n\nDeadline\nAugust 31, 2022\n We commit to an inclusive recruitment process and equality of opportunity for all our job applicants.\n At Novo Nordisk we recognize that it is no longer good enough to aspire to be the best company in the world. We need to aspire to be the best company for the world and we know that this is only possible with talented employees with diverse perspectives, backgrounds and cultures. We are therefore committed to creating an inclusive culture that celebrates the diversity of our employees, the patients we serve and communities we operate in. Together, we\u2019re life changing."
    },
    {
        "position": "Data Engineering Manager (open to full remote in Germany)",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Back Market",
        "sector": "Internet Marketplace Platforms",
        "companySize": "501-1,000 employees",
        "location": "Berlin, Berlin, Germany",
        "post": "About the job \n Back Market is the world\u2019s leading refurbished electronics marketplace with a team of more than 650, powering operations in 16 countries (and counting!).\n Back Market is undergoing meteoric growth and has raised $884 million, with a valuation of $5.7 billion. Our mission is simple: empowering people to buy tech sustainably by offering folks a high quality, accessible, and more eco-friendly alternative to buying new electronics. Why? Refurbished tech helps lower our collective environmental impact .\n Be part of a great and growing adventure that will change the way the world consumes tech.\n Data is a key enabler for a company like Back Market. Do you want to help your team build reliable, high-performing and secure data infrastructures and tools? Do you want to have a meaningful impact through your job? Here is your opportunity.\n Data engineering at Back Market is split into three teams, based on their stakeholders: Customer (Back Market\u2019s end users), Supply (sellers at Back Market), and Finance & Customer Care. We are looking for a manager to lead the Supply data team (data engineers and analytics engineers) and develop this scope from end to end. The supply data scope includes all data (from collecting to serving the data to internal and external stakeholders like our sellers) linked to the Back Market catalog, sellers\u2019 performance and the pricing of our offer.\n This senior team of 5 people is distributed between our different offices and full remote.\n\nWhat you'll be doing :\n\n\nManagers at Back Market build sustainable and efficient teams, by empowering people and building the proper environment.\nCollaborating with your product manager and your stakeholders: the BI, and other tribes to align the team with company objectives and initiatives across engineering and the wider business\nEnsuring the development of people and teams through open communication, feedback, and continuous coaching\nCreating an inclusive team environment, where team members feel like they belong and are supported to do their best work\nWorking in an agile \"build it and run it\" environment where engineering teams build, launch, monitor and support the sections they own\nWorking with the team to identify and make improvements in our processes, practices, and product\nHelp your team take the right technical decisions thanks to a strong technical data background\n\n\nYou are in the right place if : \n\n\nYou are people-first oriented and know how to build and run a high-performing team ;\nYou embrace the servant leadership principles as much as you value empathy and cordial debates over a \"top-down\" management posture ;\nProduction health is a priority for you ;\nYou are able to understand the tech challenges of your team and guide them through decisions. Our stack is AWS (Lambda, dynamodb), GCP (Big Query, Data Catalog), Spark (Delta), Terragrunt, Terraform, Datadog, Python, Scala. \nYou have great communication skills in English\n\n\nWHY SHOULD YOU JOIN US ?\n\nA meaningful job: through hard work, you will help avoid thousands of tons of electronic waste and fight against planned obsolescence. It counts!An attractive salary, equity, multiple benefits (meal tickets, health insurance, etc...), parental benefits, #remote friendly company, relocation package, internal events, etc\u2026Technical challenges all day every day: you will have the freedom to innovate and adopt new ideas!Work with passionate experts who will share their knowledge and help you develop and grow! (Backademy, technical guilds, Meet-up & Conference)Grow your career with a flexible career path, BackMarket can help you evolve!A booming scale-up: our environment is rapidly growing in Europe, the USA and soon in Asia!A lot of fun: you will have the opportunity to work in a fast-paced, open-minded and friendly environment.\n\n\nBackMarket is an Equal Opportunity Employer for any minority, disability, gender identity or sexual orientation."
    },
    {
        "position": "Engineering Manager, Data Engineering Team",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Toptal",
        "sector": "Software Development",
        "companySize": "1,001-5,000 employees",
        "location": "Slovakia",
        "post": "About the job \n\nAbout Toptal\n\nToptal is a global network of top freelance talent in business, design, and technology that enables companies to scale their teams, on-demand. With $200+ million in annual revenue and over 40% year-over-year growth, Toptal is the world\u2019s largest fully remote company.\n We take the best elements of virtual teams and combine them with a support structure that encourages innovation, social interaction, and fun. We see no borders, move at a fast pace, and are never afraid to break the mold.\n Position Description\n As an Engineering Manager for the Data Engineering team, you will be leading and growing a team of data engineers to scale our data warehouse and pipelines. You will work with Business Analysts on improving and adding more sources to our data lake. The team will look to you for advice on data and operational issues facing the team, you will mentor your team across stakeholder management, project management, and overall technical architecture.\n Data Engineering Team is responsible for delivering a top-notch data warehousing experience for Toptal, making sure data is correct and accessible on demand. Data Engineers are working closely with Business Analysts and Data Scientists and they are responsible for building and maintaining data processing infrastructure and building new data and automation tools.\n This is a remote position that can be done from anywhere. Due to the remote nature of this role, we are unable to provide visa sponsorship. Resumes and communication must be submitted in English.\n\nResponsibilities\n\nYou will be leading a team of highly skilled professionals to create and maintain world-class data products used by our Business Analysts, Data Scientists, and engineering teams across the company.\n\nIn The First Week, Expect To\n\n\nStart at the team by being introduced to Toptal and its culture, meeting colleagues, and get access to documentation and repositories.\n\nIn The First Month, Expect To\n\n\nComplete onboarding, understand the team\u2019s immediate roadmap and become acquainted with your team and processes.\nConduct regular 1:1s with your teammates, and begin to understand their strengths and aspirations.\n\nIn The First Three Months, Expect To\n\n\nShip impactful initiatives that significantly changes the way in which clients interact with us\nBe working with your team and understand its mission and domain. \nBe leading your team\u2019s efforts from planning to delivery.\n\nIn The First Six Months, Expect To\n\n\nSet and follow through at least one full quarter of OKRs.\nBuild a deep understanding of the mission, constraints, and capabilities of your team and squad.\nDevelop relationships with engineers, engineering managers, and other colleagues to maximize cross-collaboration whenever beneficial.\nContribute improvement suggestions at an Engineering-wide and even Company-wide level.\n\nIn The First Year, Expect To\n\n\nMake a big impact on the product.\nOrganize at least one team gathering.\nDefine yearly OKRs with and for your team.\n\nRequirements\n\n\nHave 2+ years of previous experience leading a data engineering or a product development team.\nHave 5+ years of data engineering experience.\nHave a track record of making an impact as an engineer and as an engineering manager.\nHave a solid understanding of development and quality assurance methodologies and concepts.\nHave experience guiding the continuous improvement of processes and technology.\nThrive on providing and receiving honest but always constructive feedback.\nOutstanding communication and interpersonal skills.\nBe eager to help your teammates, share your knowledge with them, and learn from them.\nBe first and foremost a leader, not a developer. However, you are able to code and you stay up to date with programming-related topics and work shoulder-to-shoulder with your team when required.\nYou must be a world-class individual contributor to thrive at Toptal. You will not be here just to tell other people what to do.\n\nFor Toptal Use Only: #individualcontributoreurope #individualcontributorSA"
    },
    {
        "position": "Team Lead (f/m/d) Data Engineering",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Siemens Energy",
        "sector": "Renewable Energy Semiconductor Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Lisbon, Lisbon, Portugal",
        "post": "About the job \n You will be building and guiding your team of Data Engineers who are responsible for enabling technically the translated business requirements into analytical products, helping to bring new insights alive. As a leader, you are part of our transformation journey to become a data driven company in future.\n Passionate about the environment and climate change? Ready to be part of the future of the energy transition? The Siemens Energy Data Analytics & AI team plays a significant role in driving the energy transformation.\n Honestly, we don\u2019t have all the answers. Honestly, given the scale of the challenge we need many types of perspectives to help reimagine the future. And honestly, we can\u2019t do it alone.\n Our team is looking for innovative, enthusiastic, and versatile data, digital, and AI professionals that will drive us forward on this exciting venture.\n\nLet\u2019s Talk About You\n\nYour profile\n\n\n\nCollege degree in information technology or related field\nExtensive experience leading data architecture and data-related initiatives \nIn-depth knowledge of data acquisition, data modeling and analytics, and the ability to deal with performance and development issues on Hadoop\nExperience with database modeling (e.g., Snowflake, Star) and experience developing streaming and batch data pipelines for cloud and hybrid infrastructures\nKnowledge of streaming frameworks (e.g. Spark, Storm, or Kafka) and hands-on experience with modern software development tools such as GitHub, Jenkins, and other build automation tools\nExtensive knowledge of data analytics and the ability to slice and dice data as needed\nExperience in data architecture for cloud providers (e.g., AWS, Azure, GCP)\nKnowledge of data warehouses that support analytical workloads (e.g., Snowflake)\nInitial exposure to working with ETL, ESB and web service containers\nExcellent writing and communication skills in English, German language skills or knowledge of another language is a plus\nStrong customer focus and excellent communication skills and exceptional leadership and coaching skills to collaborate and develop technical talent in multicultural, global teams\nOpen-minded and willing to learn and continuously improve your skills\nEnthusiasm for data and analytics and leveraging data across all aspects of a business and ecosystem \n\n\nYour Responsibilities\n\n\n\nLead a team of data engineers focused on leveraging data and information across the SE to improve data-related operations and drive risk-related insights\nDrive technical implementation and accountability for strategy and execution\nDetermine the scope of the Minimum Viable Product (MVP) for upcoming initiatives and outline the future roadmap for enhancements and potential improvements\nCollaborate with data owners on planning and execution of key initiatives\nOversee the performance and quality of integration pipelines created in close collaboration with the data integration team \nDrive architecture design and discussions, advising teams\nDrive data literacy towards visualization through self-service capabilities for end user communities\nEnsure that the development model supports high velocity and good quality deliverables, with the ability to develop faster, develop in parallel, and release frequently\nAdvocate for modern software development methodologies and use Scrum and SAFe frameworks\nConduct code reviews and ensure teams adhere to appropriate standards, as well as develop and monitor KPIs / metrics to optimize data quality\nDocument and present methodologies, procedures, and project deliverables to senior stakeholders across multiple functions \nKnowledge of emerging technologies and latest trends in the data science space\nLeading a team and helping team members reach their full potential\nParticipate in an inspiring team of true thought leaders and data science experts within the global ED&AA team\n\n\nLet\u2019s Talk About Us\n\n\"Let\u2019s make tomorrow different today\" is our genuine commitment at Siemens Energy to all customers and employees on the way to a sustainable future.\n In our Business Functions we enable our organization to reach their targets by providing best-in class services and solutions in the areas of IT, HR, Finance, Real Estate, Strategy & Technology and more.\n Check out this video to see what we do here! https://bit.ly/3IfnlaR\n\nMORE INSIGHTS\n\nBe Energized. Be you.\n Lucky for us, we are not all the same. Through diversity we generate power. We run on inclusion and compassion. Our combined creative energy is fueled by at least 130 nationalities. Siemens Energy celebrates character \u2013 no matter what ethnic background, gender, age, religion, identity, or disability. We energize society. All of society.\n\nJobs & Careers: https://www.siemens-energy.com/global/en/company/jobs.html\n We value equal opportunities and welcome applications from people with disabilities."
    },
    {
        "position": "Big Data Engineer for the Services Analytics Plateau (d/f/m)",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Airbus",
        "sector": "Aviation and Aerospace Component Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Manching, Bavaria, Germany",
        "post": "About the job \n\nJob Description\n\nAirbus Defence and Space is looking for a\n\nBig Data Engineer for the Services Analytics Plateau (d/f/m)\n\nThe successful applicant will join the department TASSI6 Data Diagnostics & Analysis Systems.\n The project you will be working on introduces Airbus Defence and Space's Analytics capabilities to our largest customers. The project is the cornerstone of data consolidation and analytics for the Eurofighter programme. It delivers improved performance and customer experience and enables a rapid understanding of the potential of digitalisation for our customers.\n You will be at the forefront of further developing our Data Analytics solutions. The main task will be to find new ways to address challenges with data and digital technologies and support the creation of new services.\n We are in production and already have a large pool of data.\n\nYour location\n\nLocated about an hour\u2019s drive north of Munich, Manching is an up-and-coming market town that offers a wide range of leisure and cultural activities. Here, you can enjoy the quality of life in the countryside while the pleasures of near-by cities are still within easy reach.\n\nYour Benefits\n\n\n\nAttractive salary including holiday pay, Christmas bonus and profit sharing\n30 days holidays and extra days-off for special occasions\nExcellent upskilling opportunities and great development prospects\nSpecial benefits: employer-funded pension, employee stock options, discounted car leasing, special conditions for insurances, public transport subsidy, discounts at local businesses\nOn-site-facilities: Medical officer for check-ups and other health-related services, canteen and cafeteria, kindergarten nearby\n\n\nAt Airbus, we support you to work, connect and collaborate more easily and flexibly. Wherever possible, we foster flexible working arrangements to stimulate innovative thinking.\n\nYour Tasks And Responsibilities\n\n\n\nCollecting data and \"data wrangling\", i.e. transforming, cleansing and linking with other data\nProvide data sets for (machine learning) data models; determine relationships between data source attributes\nApply data mining techniques and perform statistical analysis \nDevelopment and implementation of prototypes, e.g. in Python and Bash, Java or similar\nSupport in the implementation of proof-of-concept and projects within the Military Air Systems Community\nPromote new working methods and new data governance models\n\n\nDesired Skills And Qualifications\n\n\n\nM.Sc. or equivalent in Computer Science or a similar field\nExpertise in data integration and management, in particular in the automated integration of a variety of data sources as well as a Secure handling of the usual software engineering practices: continuous integration (Jenkins, etc.), DevOps (Ambari, etc.), version control (git, etc.), code quality (pylint, etc.), design reviews, ETL (Airflow, etc.), testing (DocTest, pyTest, etc.)\nExpertise in automated data pre-processing\nKnowledge of HDFS or other file systems \nDeep knowledge of programming in Python (in particular: pySpark, pandas, matplolib, sci-kit learn, etc.); ideally also working knowledge of C# and/or R\nBeing fluent in English; knowledge of German is not strictly necessary but recommended\n\n\nNot a 100% match? No worries! Airbus supports your personal growth with customized development solutions.\n You have a question regarding this job offer? Please do not hesitate to get in touch by writing to questions@airbus.com.\n Take your career to a new level and apply online now!\n This job requires an awareness of any potential compliance risks and a commitment to act with integrity, as the foundation for the Company\u2019s success, reputation and sustainable growth.\n\nCompany\n\nAirbus Defence and Space GmbH\n\nContract Type\n\nPermanent Contract / CDI / Unbefristet / Contrato indefinido\n\nExperience Level\n\nProfessional / Exp\u00e9riment\u00e9(e) / Professionell / Profesional\n\nJob Family\n\nCustomer Eng.&Technical Support&Services\n By submitting your CV or application you are consenting to Airbus using and storing information about you for monitoring purposes relating to your application or future employment. This information will only be used by Airbus.\n Airbus is committed to achieving workforce diversity and creating an inclusive working environment. We welcome all applications irrespective of social and cultural background, age, gender, disability, sexual orientation or religious belief.\n Airbus is, and always has been, committed to equal opportunities for all. As such, we will never ask for any type of monetary exchange in the frame of a recruitment process. Any impersonation of Airbus to do so should be reported to emsom@airbus.com.\n At Airbus, we support you to work, connect and collaborate more easily and flexibly. Wherever possible, we foster flexible working arrangements to stimulate innovative thinking."
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Hemnet",
        "sector": "Real Estate",
        "companySize": "51-200 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nHemnet has more than 60 million visits every month. People come to us to find joy, inspiration and - most important - their new homes. We are now looking for a Data Engineer to join us as we are strengthening our platform team.\nThe Platform Team\nOur team's mission is to enable the product development teams to release and maintain their products by providing a powerful, approachable and stable application platform. The team consists of six developers and a development manager with different focus areas such as Data and Devops/Infrastructure. We work closely together to develop and evolve our platform.\n\n\nSome of the team\u2019s main responsibilities:\n\nApplication and data infrastructure\nServing analytics and product teams with high integrity data \nTools for CI/CD, release pipeline and monitoring\nSystem security, performance, stability and data integrity\nExternal integrations\n\n\n\nA peek at our tech stack\n\nAWS\nRedshift\nPostgres\nDatadog\nDocker\nRuby & Python\nBash/Shellscript\nSnowplow\nCircleCI\nTerraform\n\n\n\nWhat you\u2019ll do:\nAs part of the platform team at Hemnet you\u2019ll be working with core functionality in an area that is being highly prioritized in the company. We see great opportunities ahead leveraging from our vast data sources to both broaden and deepen our analytics department and build new data driven products to serve our customers. This will put increasing demands on both infrastructure and data engineering to keep data fresh and accessible with a high integrity. You\u2019ll be part of a team that puts great emphasis on using the right tool for the right task and keeping our data stack modern and up to date. This includes among other things:\n\n\n\nBuilding and managing ELT data pipelines (Extract, Load & Transform).\nEnsuring data integrity and observability.\nDeploying machine learning models\n\n\n\nWho are you?\nWe believe you are an experienced Data Engineer or an Developer who recently started your journey within Data Engineering. You have previously worked with data pipelines and infrastructure, and have good knowledge of best practices. Personal qualities are important for us, and you should be someone who thrives in a very collaborative environment, and who continuously strives to get the best solution in place.\n\n\nBackground/Skills:\n\nSkilled in at least one programming language (e.g. Ruby, Python, Java or C#)\nExperience working with SQL\nExperience with working with Git\nKnows your way around databases (relational & non-relational)\n\n\n\nBonus points:\n\nAWS\nsnowplow\ndbt\nPostgreSQL\nredshift\nstatistics/machine learning\ndynamoDB\nRuby\ngraphQL\n\n\n\nWay of working after the pandemic:\nAll employees at Hemnet will have the possibility to work from the office in the central parts of Stockholm. We will also have the opportunity to work the majority of time (but not 100%) remotely from home.\n\n\nDoes this sound intriguing? We look forward to reading your application and learning more about what makes you tick!"
    },
    {
        "position": "Director Data & ML Engineering",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Brenntag",
        "sector": "Chemical Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Amsterdam, North Holland, Netherlands",
        "post": "About the job \n Our team in Amsterdam currently has an opening for a Director Data & ML Engineering\n\nBrenntag is undergoing a group-wide transformation to deliver profitable organic growth and sustained group efficiencies. Data & Analytics is a key pillar which will allow us to \u2018liberate\u2019 our data and thus improve our decision-making at speed.\n As part of the Data & Analytics leadership team, this role has accountability for the creation of Data Products to enable decision-making throughout Brenntag. You will serve as an evangelist for the power of analytics, engaging key stakeholders to illustrate proven successes.\n You will lead Brenntag Data & ML Engineering function who is responsible for:\n Liberating our data from source system, making them fit for consumption by analytics and other systems across the organization.\n Working with data scientist to create machine learning models and embed them in our systems and processes.\n\nYOUR ROLE & RESPONSIBILITIES\n\n\nEstablish and drive organization\u2019s strategic direction for enterprise, end-to-end data analytics solutions in alignment with Brenntag\u2019s strategic priorities.\nSet strategy, roadmap, plans and priorities to ensure reliable, high quality development operations to support speedy deployment and improved performance of data solutions.\nPromote the development of innovative products in collaboration across D&A, Digital, Core IT and Architecture.\nLead engineering and delivery of data lineage capabilities intended to trace data usage across Brenntag\u2019s Analytics Platforms.\nCollaborate with Data Governance team to create data management capabilities that enhance data quality data and prevent bad data propagation to downstream processes.\nContribute to organizational wide initiatives around Machine Learning and Automation.\nActs as a business owner and manages long-term and short-term strategic initiatives for analytics products within analytics platforms and analytics APIs to operational systems.\nThe role will work with cross-functional at a global and market to ensure successful design, development, and delivery of unified analytics data platform.\nDevelop and lead DevOps professionals responsible for supporting data and analytics solutions deployment and maintenance.\nPartner across D&A teams to accelerate and leverage data capabilities and insights as part of the Brenntag\u2019s integrated data offense.\nBuild, manage, mentor, and inspire team(s); managing performance, goals and development potential.\n\n\n\nYOUR PROFILE\n\n\nBachelor\u2019s degree in computer science, engineering or related field, or relevant equivalent.\n10 years of experience specializing in advanced data analytics, BI, and/or data products .\nStrong experience in DevOps, DataOps or systems administration. \nStrong understanding of data structures and algorithms.\nStrong understanding of solution and technical design.\nStrong problem solving and analytical mindset.\nExperience with cloud environments such as Microsoft Azure, Google Cloud, and AWS. Experience with Big Data and NoSQL technologies like Hadoop, HBase, Spark, Impala, Cassandra, Storm, Flume, Pig, or Hive.\nAble to influence and communicate effectively, both verbally and written, with team members and business stakeholders.\nAble to quickly pick up new programming languages, technologies, and frameworks.\nProven ability to influence critical business outcomes in a matrix based, global environment.\nExcellent critical thinking skills.\nExpert understanding of and proven ability to deliver complex data systems.\nExperience leading or working with DevOps / DataOps / MLOps engineers.\nSolid understanding of software development life cycle, test driven development, Agile methodologies, continuous integration, continuous delivery.\nAbility to educate, inform, persuade, and achieve understanding and buy-in on technical and business needs across different functions, levels and customers.\nGood understanding of key topics in data science and applied analytics.\nUnique greenfield environment to drive change in a global business\nOpen space in a vibrant start-up corporate incubator\nLots of possibilities for professional development\nInternational team\nFriendly and supportive colleagues\nCompetitive compensation package\n\n\n\nINTERESTED?\n\nWe look forward receiving your application."
    },
    {
        "position": "Senior Software Engineer -  Data Engineering",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Kindred Group plc",
        "sector": "Gambling Facilities and Casinos",
        "companySize": "1,001-5,000 employees",
        "location": "Stockholm, Stockholm County, Sweden",
        "post": "About the job \n\nThe role \nKindred is looking for a highly skilled developer to join the Data Engineering team whose vision is to drive and support Kindred to be the most data-driven sports betting and gambling company in the world! \nAs a Data Engineer in Kindred, you will be part of the Data Department under the overall Technology organization. Joining this team, you will be playing a big part in the way we shape our business by closely collaborating with different stakeholders across the business, ensuring they get the most out of the data in terms of reporting, statistics and to form the basis of decision making and analytical processes. \nThe successful candidate will be responsible for the end to end solution from data ingestion, preparation of data to building segmentations and reporting solutions in both Cloud and On-Prem Data Warehouse. \nWhat you will do \n\nDesign, build and operationalize data solutions on our AWS data platform \nBuild data pipelines and applications that handle multiple sources of data to create exceptional quality data products \nDesign, enhance and implement data ingestion from wider range of data sources into our Data platform. \nDeveloping advanced Oracle PL/SQL, writing and optimizing/tuning queries over large data sets. \nDeveloping dashboards and reporting solutions \nData investigations and problem-solving from internal and external stakeholders. \nSetting up Apache Kafka streaming jobs. \nProactively engage with stakeholders and deliver their requirements. \nSupporting Data products maintenance and monitoring initiatives (including occasional on-call support & incident management). \nWork in an Agile way with open communication, while delivering top quality products and services. \n\nAbout you \n\nExtensive knowledge and hands on experience on Apache Spark/EMR, AWS Glue, Lambda, S3. \nStrong background of working with RDBMS \nExperience with dealing with large data volumes. \nPreferably 5+ years working with data. \nHands on experience on Kafka. \nWorking knowledge with Java/Spring/Spring boot \nGood understanding of Data Warehouse concepts. \nExperience deploying software into containerised environments, including Docker and Kubernetes. \nImplementation of ETL processes and data structure. \nKnowledge of any basic cloud architecture (e.g., AWS). \nGood attitude and willingness to learn new skills and technologies. \nA problem-solving growth mindset with the ability to pick up new tools and concepts quickly \nOpen-mindedness, able to interact in a constructive manner with the Data Engineering teams, stakeholders and other contributors to Data solutions. \n\nIn addition, it would be an advantage if you also have: \n\nExperience with cloud formation and terraform. \nExperience with building pipeline through Matillion or similar. \n\nApplication Process \nClick on the \"Apply Now\" button and complete the short web form. Please add a covering letter in English to let us know your motivation for applying and your salary expectation. Our Talent Acquisition team will be in touch soon. \nKindred is an equal opportunities employer committed to employing a diverse workforce and an inclusive culture. As such we oppose all forms of discrimination in the workplace. We create equal opportunities for all our applicants and will treat people equally regardless of and not limited to, gender, age, disability, race, sexual orientation. We are committed not only to our legal obligations but also to the positive promotion that equal opportunities bring to our operations as set out in our sustainability framework. \nJob Alerts \nNot suited to this role but interested in working at Kindred Group? \nWe are always on the lookout for talented, passionate people to join our global teams so if you'd like us to let you know when suitable jobs come up, please click on \u201cRegister for Alerts\u201d."
    },
    {
        "position": "Data Engineering Manager (Remote)",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Stuart",
        "sector": "Transportation, Logistics, Supply Chain and Storage",
        "companySize": "501-1,000 employees",
        "location": "France",
        "post": "About the job \n\nStuart (DPD Group) is a sustainable \ud83c\udf31 last-mile logistics company that connects retailers and e-merchants to a fleet of geolocalised couriers across several countries in Europe.\n\n\nOur Mission \ud83d\ude80\nWe are an impact-driven company that aims to build the future of logistics for a more sustainable world: shared, efficient and reliable. We are committed to creating a new standard for urban deliveries that meet today\u2019s environmental and social challenges while offering a premium delivery experience blending speed, flexibility and convenience.\n\n\nOur motto: \u201cMake every delivery a moment all of us can truly celebrate!\u201d More than 3000+ leading brands already partner with us across Restaurants, Grocery, Retail & Luxury, eCommerce and Professional Services to deliver all types of goods at the tap of a button. Stuart is a highly diverse and inclusive company of 700+ employees with 90+ nationalities working across France \ud83c\uddeb\ud83c\uddf7, Italy \ud83c\uddee\ud83c\uddf9, Poland \ud83c\uddf5\ud83c\uddf1, Portugal \ud83c\uddf5\ud83c\uddf9, Spain \ud83c\uddea\ud83c\uddf8 and the U.K. \ud83c\uddec\ud83c\udde7\n\n\nIt\u2019s the right moment and the right place for us to make an impact on millions of people, as home delivery services hit a record high. And guess what? You can help us fulfil our vision \ud83d\ude4c\n\n\n\ud83d\udc8e The Position\n\n\nWe are looking for an Engineering Manager to join us at Stuart to drive our machine learning initiatives. Engineers at Stuart operate as part of cross-functional teams: you will join a team of five Python and Scala Data Engineers collaborating with data scientists, product managers and product analysts.\n\n\nYou will ensure a good collaboration between the engineers and the other teams by helping them refine their ways of working and development trajectories. Your team will deliver solutions for fraud detection, supply & demand management and time of arrival estimation.\n\n\nOur vision is twofold: \n\ntake down the barriers between data science and data engineering by encouraging constant collaboration in unified teams\nbuild a common MLOps infrastructure while working on our key product initiatives\n\n\n\nYou will collaborate closely with our ML Staff Engineer in charge of the technical aspects of our ML efforts and benefit from the support and experience of our Managers and Directors.\n\n\nLearn more about our team via our engineering blog: Stuart Engineering \u2013 Medium \ud83e\udd13\n\n\nWhat will I be doing? \ud83e\udd14\n\nBe responsible for the sustainable delivery of your team focusing on reliable, scalable, and maintainable software.\nMentor and support the engineers on your team, helping them grow via coaching, mentoring, regular feedback, and performance reviews.\nWork in partnership with the product manager and product designer of the team, helping to define roadmaps, OKRs, and manage projects.\nEnsure organisational agility and efficiency, both inside the team and in the ways they collaborate with other teams.\nBe active in the hiring process, and pro-actively hire to ensure the continued delivery of the team.\nShare company vision and strategy with the team and provide clear context.\n\n\n\nWhat do we need from you? \ud83d\ude0e\n\n2 years or more experience in a leadership role.\nSolid technical experience (as an individual contributor at a senior level or above) \nGood grasp of the key management concepts we support: servant leadership and agility.\nExcellent written and spoken communication skills.\nFluent in English.\n\n\n\nNot sure if this is you?\nWe understand that experiences are broad and come from many places. We appreciate that everyone potentially has something to contribute to our team and we'd still love to hear from you if your background doesn't completely match!\n\n\nThe stuff you wanna know \ud83d\ude09\n\nFamily-friendly work-life balance - work from home and flexible hours \ud83c\udfe1\nOption to work remotely anywhere in France \ud83c\uddeb\ud83c\uddf7 \nTicket Restaurant by Swile (\u20ac13 daily with 60% paid by the company) \ud83e\udd57\nUnlimited access to Udemy for all your learning and development needs \ud83d\udcda\nStuart Academy with regular workshops, Stu-Classes, and Stu-Talks \ud83c\udf93\nStuart is putting Mental Health Awareness first! Wellness Allowance (\u20ac40 monthly) to use in any gym or sport class \ud83e\uddd8\nPrivate healthcare provided by Alan \ud83e\uddd1\u200d\u2695\ufe0f\nWork in an international, dynamic and passionate environment with a company culture focused on learning and development \ud83c\udf89 \n\n\n\nYou\u2019ve read all this way but you\u2019re missing a skill or two? No problem, it\u2019s our job to up-skill you to take your career to the next level. What we\u2019re trying to say is, don\u2019t be afraid to apply if you don\u2019t tick all the boxes \ud83d\udcaa\n\n\nAt Stuart, we believe that employees today want to evolve in collaborative, high-growth environments where they can demonstrate their abilities and thrive both professionally and personally. We are convinced that employees need to find alignment between their inner values and their company\u2019s culture and mission to unlock their full potential. We work to create a culture of empowerment, continuous learning and growth where everyone can bring expertise, own projects and easily measure their impact \ud83d\ude4c\n\n\nStuart is proud to be an equal opportunity workplace dedicated to promoting diversity. We don\u2019t discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status \ud83d\udc99\n\n\nPlease note: Our Talent Acquisition Team is international coming from across the world \ud83c\udf0d We kindly ask you to please submit your CV and application in English so that it can be reviewed correctly (unless the job posting is in a language other than English). Thank you \ud83e\udd17"
    },
    {
        "position": "Senior IT Professional - Natural Language Processing",
        "jobType": "Full-time",
        "jobLevel": "Associate",
        "company": "Roche",
        "sector": "Biotechnology Research",
        "companySize": "10,001+ employees",
        "location": "Pozna\u0144, Wielkopolskie, Poland",
        "post": "About the job \n The Position\n\nSenior IT Pro - Natural Language Processing\n\nIT INNOVATORS IN HEALTHCARE\n\nWe do #Code4lLife creating innovative software that helps doctors, patients, and scientists around the world.\n\nWho We Seek\nA person who has:\nUnderstanding of basic concepts from area of Text Mining, NLP \nExperience with modern deep learning architectures for NLP (encoder-decoder, transformers, attention), including:\nhands-on experience with using Huggingface Transformers, SBert, GPT-2/GPT-3 (one of) capability to build ML/DL pipeline for training/tuning model\n\nAt least 3 years of experience with our typical NLP tools used in daily work:\nscikit learn, numpy, pandaspytorch or tensorflowspaCy, NLTK\n\n3+ years of general experience in NLP/AI software engineering, especially\n\nproficiency with Python\nexperience with Git\nCI/CD tools is nice to have\nunderstanding of software testing (unit tests)\nbash/shell scripting\nexperience with Docker, API development\nexperience with cloud platforms (preferred AWS) and ready to use tools (SageMaker)\n\nAbility to deliver fully working products (deployment activities):\nGeneral understanding of SCRUM and its principles (PSM I or PSD certificate is nice to have)\n\n\nEXAMPLE PROJECTS ACTIVITIES YOU MAY WORK ON\n\n\nDesigning and developing pipelines for solving NLP tasks (predictions, clustering, deviations detection) for generating insights and extracting knowledge from millions of internal documents\nImplementing fully working AI/NLP powered applications for supporting our colleagues from all the departments, for instance: pharma, molecules development, clinical trials, sales, marketing, people & culture or IT\nBuilding toolset and re-usable components for our future projects and ideas\n\n\nWhat We Appreciate\n\n\nAbility to learn new technologies (we can teach you them as well!)\nAnalytical mindset and critical thinking\nGood communication skills\nOpenness for knowledge sharing\n\n\nWhat You Get\n\n\nSalary range 13 000 - 17 500 PLN gross\nAnnual bonus payment based on your performanceContract of employment \nEmphasis on continuous personal and professional self-development supported by dedicated training budget (training, certifications, conferences, diversified career paths etc.)\nExperienced and professional colleagues and workplace that supports innovation and new ideas\nHighly flexible working hours (starting your day at 7-11) and workplace according to employee\u2019s needs and preferences* (regular office/home office)\nA chance to work on solutions which can improve patients\u2019 lives\n\n\nAdditional Benefits\n\n\nRelocation package\nPrivate healthcare and insurance\nHealth, well-being and sport promotion\nSupport for parents and families\nStock share purchase additions\nYearly sales of company laptops and cars\nAdditional vacation time for long-term employees and more\n\n\nAPPLY DIRECTLY\n\nApply directly via Workday, pressing the blue button at the top.\n If you feel this offer suits a friend of yours, we\u2019ll appreciate you letting them know! Simply copy and share the link from the browser.\n If you have any questions regarding the offer and would like to contact us directly, please write to us at katarzyna.wisniewska@roche.com\n\nWANT TO KNOW MORE?\n\nCheck our website for more details, e.g. the career path, recruitment process, etc.\n https://it.roche.pl/work-with-us\n Want to know what it\u2019s like to be a part of Roche IT first-hand? Check out our blog! You will meet the community members there, sharing their experience and impressions from diverse perspectives, not only about their job but also their lives.\n https://www.roche.com/careers/weareroche.htm\n Please note that during the pandemic we are working and recruiting 100% remotely.\n \u2026..\n\nRoche is an equal opportunity employer. We care about inclusion in terms of gender, age, race, skin colour, nationality, religion, marital status, sexual orientation, background, physical or mental disabilities and on every other grounds. Applying for our position, we assure you that we will assess your application solely on the basis of your competencies.\n\nAdministratorem Pani/Pana danych osobowych jest sp\u00f3\u0142ka Roche Polska Sp. z o.o., ul. Domaniewska 39 B, 02-672 Warszawa. Dane przetwarzane s\u0105 w celu prowadzenia rekrutacji. Przys\u0142uguje Pani/Panu prawo dost\u0119pu do tre\u015bci swoich danych, ich sprostowania, usuni\u0119cia, ograniczenia przetwarzania, przenoszenia oraz \u2013 w sytuacji, gdy s\u0105 one przetwarzane na podstawie udzielonej zgody \u2013 cofni\u0119cia tej\u017ce zgody w dowolnym momencie. Kontakt do Inspektora Ochrony Danych:ochrona.danych@roche.com. Wi\u0119cej informacji o zasadach przetwarzania przez Roche Pani/Pana danych osobowych pod linkiem: \n\n https://www.roche.pl/pl/content/klauzula-informacyjna-rekrutacja-pl.html\n\nThe controller of your personal data is Roche Polska Sp. z o.o., ul. Domaniewska 39 B, 02-672 Warsaw. The data is processed for the purpose of recruitment. You have the right to access your data, rectify it, delete it, limit processing, transfer it and - if processing is based on your consent - withdraw this consent at any time. Contact the Data Protection Officer at: Ochrona.danych@roche.com. More information on the principles of processing your personal data by Roche at the link: \n\n https://www.roche.pl/pl/content/klauzula-informacyjna-rekrutacja-en.html\n Who we are\n At Roche, more than 100,000 people across 100 countries are pushing back the frontiers of healthcare. Working together, we\u2019ve become one of the world\u2019s leading research-focused healthcare groups. Our success is built on innovation, curiosity and diversity.\n At Roche Poland, we are more than 800 professionals working together on one mission. We are proud of who we are, what we do and how we do it. Join us in the area of Clinical Research, Medical, Marketing, IT or business departments.\n Roche is an Equal Opportunity Employer."
    },
    {
        "position": "Principal Scientist, Natural Language Processing",
        "jobType": "Full-time",
        "jobLevel": "Director",
        "company": "Amazon",
        "sector": "Technology, Information and Internet",
        "companySize": "10,001+ employees",
        "location": "Berlin, Berlin, Germany",
        "post": "About the job \n\nDescription\n\nAs a Principal Scientist on this growing team, you will take on a leading role in the Natural Language Processing (NLP) teams for Amazon Search. We are developing NLP components that cover a wide range of languages, from English and other Indo-European languages to Turkish, Arabic, Japanese and many more, and play a central role in search query processing, product description indexing, string normalization and vector embeddings for queries and products.\n You will guide team members on the use of machine learning, tuned on terabytes of product and traffic data, to build or improve NLP technology that we integrate with the production search engine and evaluate using techniques like A/B tests. You will work with the Amazon Search leadership to set direction for the NLP approaches, model architectures and training methods, balancing business-defined performance indicators with the needs of millisecond response times. You will propose and explore publication-worthy innovation.\n You will build relationships with stakeholders and partner teams across multiple countries, analyze data for trends, track down the source and meaning of anomalies, select suitable rule-based or machine-learning based techniques and advise team members as they make improvements, closing the loop through data, model, application and customer feedback.\n\nResponsibilities\n\nDefine standards for the analysis of customer-focused problems in an industrial settingGuide team members and the leadership team on accurate, efficient and innovative NLP/ML solutionsGet hands-on when building NLP models that can be applied to multiple languagesPublish the developed innovative solutions in leading academic scientific venues in NLP/ML\n\n\nBasic Qualifications\n\nBASIC QUALIFICATIONS\n\nPhD degree or equivalent, in a quantitative field (computer science, mathematics, natural language processing, artificial intelligence, or similar)At least 3 recent publications in a leading journal or conference related to computer science, natural language processing or applied mathematics10+ years experience using machine learning or other NLP techniques, including but not limited to Deep Learning4+ years experience implementing machine learning related techniques using Python or Scala in a distributed system, suitable for large scaleExperience coaching or mentoring team mates (not necessarily in a manager role)Fluency in written and spoken English (German is not required)\n\n\nPreferred Qualifications\n\nPREFERRED QUALIFICATIONS\n\nExperience working in data or applied science in a consumer product companyExperience using Java or C++ writing production-ready codeFamiliarity with Deep Learning and machine learning frameworks such as SageMaker, PyTorch or TensorFlowExperience in low-level optimization of large-scale neural networksFluency in one or more languages other than English\n\n\nCompany - Amazon Development Center DEU\n Job ID: A1088214"
    },
    {
        "position": "Data Scientist - Text Analytics and Natural Language Processing",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Merck Group",
        "sector": "Pharmaceutical Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Mollet del Vall\u00e8s, Catalonia, Spain",
        "post": "About the job \n Job description:\n\n\n\nA career at our company is an ongoing journey of discovery: our 60,300 people are shaping how the world lives, works and plays through next generation advancements in Healthcare, Life Science and Electronics. For more than 350 years and across the world we have passionately pursued our curiosity to find novel and vibrant ways of enhancing the lives of others.\n\n\n\n\n\n\nWho you are: As the Data Scientist, you will work in our global Reporting and Analytics team of the CFO Digital Strategy & Realization Organization. Our mission is to architect, design and refines analytics solutions supplying substantial and effective answers to business problems. We provide Digital Leadership for Analytics Initiatives across the Group Functions such as Finance, Procurement and HR. With our expertise, we support initiatives to produce practical and impactful analytic solutions for our customers. Operating in an agile environment, we closely work with internal and external partners like our Product Owners, Scrum Masters, Functional Experts, Data Architects, Data Scientists and IT Engineers to deliver sustainable analytical solutions and drive informed business decisions.\n\n\nYour focus will be on performing analytics in the area of Natural Language Processing (NLP), Machine Learning and Predictive Modelling, from gaining data and business understanding through data preparation and modeling, model evaluation to the result presentation and the solution deployment. In your role, you will apply a variety of models on large-scale datasets to address various business problems using advanced techniques. You will write high-quality production code, build and maintain robust, scalable project pipelines, document and validate the approach, set up processes to monitor, operate and continually improve the efficiency and performance of the implemented solutions.\n\n\nWith your passion for data and analytics, let\u2019s create new business insights from unstructured and structured data!\n\n\n\n\nYour Profile\n\n\n\u2022 Graduated with a higher degree in computer science, information technology, information science, or similar fields\n\n\n\u2022 5+ years of working experience in designing, developing and implementing machine learning/deep learning models (supervised or unsupervised), preferably applied to the text data\n\n\n\u2022 Strong programming skills in Python\n\n\n\u2022 Excellent knowledge of commonly used NLP, machine learning, and deep learning libraries such as PyTorch, Keras, Transformers, SKLearn, Gensim, SpaCy, or NLTK.\n\n\n\u2022 Experience in preprocessing and parsing text data stored in various formats such as PPT, DOC, PDF, and especially scanned documents using OCR technology\n\n\n\u2022 Good understanding of document indexing systems such as Elastic search or Solr\n\n\n\u2022 Expertise in agile software development, version control (git), continuous integration/deployment (CI/CD)\n\n\n\u2022 Experience with distributed computing with Apache Spark (pyspark)\n\n\n\u2022 Knowledge of microservices, RESTful APIs, Dockers and AWS Container Services is a plus\n\n\n\u2022 Experience in services offered by cloud technologies, preferably AWS.\n\n\n\u2022 Proficient in English in written and verbal communication\n\n\n\nProfile description:\n\nPlease see Job Description\n\n\n\nWe offer:\n\nWhat we offer: We are curious minds that come from a broad range of backgrounds, perspectives, and life experiences. We celebrate all dimensions of diversity. Applications from individuals are encouraged regardless of age, disability, sex, gender reassignment, sexual orientation, pregnancy and maternity, race, religion or belief and marriage and civil partnerships. We believe that it drives excellence, innovation, and human progress. We care about our customers, patients, and our rich mix of people. This diversity strengthens our ability to lead in science and technology. We are committed to creating access and opportunities for all and empower you to fulfil your ambitions. Our diverse businesses offer various career moves to seek new horizons. Join us in building a culture of inclusion and belonging that impacts millions and empowers everyone to bring their curiosity to life!\n\n\n\n\nCurious? Chat with one of our curious minds on our interactive Q&A platform and catch a glimpse of our people, values, and culture. You can also apply and find more information at https://jobs.vibrantm.com\n\n\n\n\nIf you would like to know more about what diversity, equity, and inclusion means to us, please visit https://www.merckgroup.com/en/company/press-positions.html"
    },
    {
        "position": "\tData Scientist- Natural Language Processing",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Harnham",
        "sector": "Staffing and Recruiting",
        "companySize": "201-500 employees",
        "location": "Leiden, South Holland, Netherlands",
        "post": "About the job \n\nData Scientist - Natural Language Processing \nUp to \u20ac90,000\nLeiden\nThe Company\nThis company sits within the pharmaceutical industry and is using AI solutions to support the health care ecosystem. This company uses a suite of products that have been built in partnership with top life science companies- all with a focus on empowering the people to take action. They are the leaders in AI analytics for life sciences and pride themselves in giving their employees creative freedom in order to do their work and take pride in what they are doing. \nThe Role\nThe company is seeking a Data Scientist with a strong background in NLP to develop solutions based on the company's ground-breaking technologies. They pride themselves on their ability for their employees to influence the design, architecture, and refinement of the data processing applications in health care.\nYou will:\n\nPlay a crucial role in designing and building solutions using the leading AI engine for health care. \nBe part of a close team who have extensive experience in implementing machine learning for real-world applications.\nDefine and build systems to generate insights for clinical problems that NLP can solve \n\nDay to Day\n\nApply NLP techniques and statistical analysis to extract unstructured Textual Data Sets\nBuild and prototype NLP pipelines\nContribute to the defining and testing of products\nWork closely with the engineering and data science teams\n\n\n\nYour Skills and Experience\nThe ideal fit for this role is someone who:\n\nHas applied experience and knowledge of Natural Language Processing\nHas a Masters or PhD in NLP, Data Science, or other relevant quantitative fields\nIs comfortable with Python and solving problems using AI\nEnjoys and has strong problem-solving skills \nLanguage: English (Excelling verbal and written abilities)\n\n\n\nBenefits\n\nHybrid\nMonthly WFH budget and one-off set-up budget\n25 days holiday\nExcellent pension scheme\nPrivate health care\nFully covered public transport (NL)\n\n\n\nHow to Apply\nPlease register your interest by sending your CV via the Apply link on this page.\nKEYWORDS\nData science \u2013 Data scientist \u2013 NLP \u2013 Natural Language Processing - Healthcare"
    },
    {
        "position": "Natural Language Processing Specialist (m/f/diverse)",
        "jobType": "Full-time",
        "jobLevel": "Entry level",
        "company": "Continental",
        "sector": "Motor Vehicle Manufacturing",
        "companySize": "10,001+ employees",
        "location": "Berlin, Berlin, Germany",
        "post": "About the job \n\nDescription\n\nWould you like to accelerate Continental's journey towards an AI-empowered company?\n As a Natural Language Processing Specialist in the Artificial Intelligence and Robotics Labs you will drive innovation projects with focus on artificial intelligence technologies for a broad range of application fields in industry 4.0 and automotive domains. This includes also the development of sophisticated solutions to improve our company's internal processes and operations.\n We look for a highly motivated and creative person with proven experience in NLP technologies. A profound knowledge of related methods, solution frameworks and a solid scientific background are of advantage. You will drive the development of novel concepts and the implementation of the technical solutions. Many challenging problems demand exploration of the latest achievements from the scientific community. You will work in collaboration with excellent Universities and Research Institutes in this field.\n In this position you will also support the definition of our strategy for Artificial Intelligence, consult business, innovation managers, product, and process owners about these technologies. Excellent communication and presentation skills are of advantage.\n\nDescription\n\n\n\nDrive innovation projects in the field of artificial intelligence and cognitive process automation, focusing natural language processing (NLP), machine learning based dialog systems, knowledge representation and semantic technologies, smart digital assistants\nDevelop novel application concepts using artificial intelligence to enhance company\u2019s internal processes (Sales, Marketing, HR, Engineering, Quality etc.)\nDevelop novel application concepts using artificial intelligence for mobility and industry 4.0 services\nPromote adoption of state-of-art and novel technologies in this field\nConsult business, innovation managers and product owners\nUnderstand and translate business and application specific needs into technical requirements\nElaborate solution concepts. Contribute hands-on to implementation of prototypes and technology demonstrators\nCollaborate close with other specialists: IT, System Engineers, Data Engineers, Software developers etc.\nEnsure hand-over from innovation to solution industrialization \nTechnical responsible for projects executed collaboration with Universities and Research Institutes\nMonitor technologies, open source frameworks, commercial tools and supplier offers in this field\nContribute to shaping Continental's Artificial Intelligence and Machine Learning strategy\n\n\nWorking in the AI Campus in Berlin means being part of a highly motivated and growing team of researchers working in the field of artificial intelligence. Being located in one of the German centers for AI, we strive to work on the frontier of research by having open exchange with experts and highly influential players in the community. Frequent talks, gatherings, and discussions as well as formal and informal team events ensure prompt spread of information. In our freshly established team of mostly Ph.D. students, we are maintaining an harmonious atmosphere of easy-going collaboration and exchange. Despite this inviting culture of togetherness, we will provide you with enough flexibility in terms of working time and location. Doing a Ph.D. in Continental is going to equip you with exceptional qualification, network, and industrial experience in the future field of autonomous driving. We are looking forward to meet you at the campus!\n\nQualifications\n\n\n\nStudied or did the Ph.D. in artificial intelligence, (business) computer science, mathematics, physics, robotics, computational neuroscience, or related fields\nWorked for several years with artificial-intelligence-related algorithms, neural language processing and related technologies like NLU or NLG, machine learning based chatbots, question-answering systems, and/or digital assistants\nKnow about machine learning frameworks like Tensorflow, Theano/Keras, Scikit-Learn, Spark/Mlib, R, etc.\nImplemented algorithms in object oriented programming languages \nDesirable to know about autonomous systems or to be interested in\nAble to professionally speak and write in English language\nSpeaking or eager to learn German\nIndependent, creative, and proactive working style\nCommunicate effectively with the ability to present technical concepts to all stakeholders\nAttitude towards driving customer and quality needs\n\n\nApplications from severely handicapped people are welcome.\n\nWhat We Offer\n\n\n\nIn addition to the interesting field of activity of the function, the city of Berlin offers a high recreational value and stands for quality of life\nYou will work in an innovative work environment, namely the \"co-working space AI Campus\"\nBecome part of our motivated team - we are looking forward to you"
    },
    {
        "position": "Data Engineering Manager, Database Migration Accelerator",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Amazon",
        "sector": "Technology, Information and Internet",
        "companySize": "10,001+ employees",
        "location": "Gda\u0144sk, Pomorskie, Poland",
        "post": "About the job \n\nJob Summary\n\nDESCRIPTION\n\nAmazon\u2019s mission is to be the most customer centric company in the world. Database Migration Accelerator team helps our customers to migrate their solutions from legacy on-premise and cloud enterprise workloads into modern AWS native application architectures. This is accomplished through a variety of cutting edge tools, sophisticated engineering systems and database expertise. We provide fixed price and high speed migrations to the cloud. Database Migration Accelerator is combining various AWS cloud platform services into one product which would serve our customers.\n We are a team of professionals that are forward-looking and using latest technology offerings to build new capability to operationalise and automate migration methodologies. Databases Services at AWS cover a range of data platforms including: Amazon Aurora, DynamoDB, Redshift, Athena, QuickSight as well as AWS Database Migration Service, Data Pipeline, Glue and more. As each service grows, so does adoption by customers world-wide.\n We are looking for Data Engineer Managers to apply their talents on modernizing ETL/BI/DWH solutions, migrating them into AWS cloud. And also developing strong working relationships with other teams to analyze business demands and create automated solutions to accelerate migrations.\n Joining the AWS Database Migration Accelerator team as a Data Engineering Manager gives you the opportunity to:\nWork for a company that\u2019s at the forefront of the cloud computing space.Be involved in the fast growing managed services space \u2013 help build new service offering from scratch.\n\nMentorship & Career Growth\n Our team is dedicated to supporting new team members in an environment that celebrates knowledge sharing and mentorship. Our senior engineers mentor more junior engineers through one-on-one mentoring and collaborative code reviews.\n Projects and tasks are assigned in a way that leverages your strengths and helps you further develop your skillset.\n Inclusive Team Culture\n We get to build a really cool service and the mains contributing factor to our success is the inclusive and welcoming culture that we embody every day.\n We welcome teammates who are enthusiastic, empathetic, curious, motivated, reliable, and able to collaborate with a diverse team of peers\n As a Data Engineering Manager you will manage a team of Data and Database Engineers, which perform the following tasks:\nAnalyze ETL, ELT flows to determine the most appropriate migration strategies.Leverage the latest technologies and products to convert legacy ETL, ELT tools into modern AWS Glue and AWS Lambda solutions. Identify and remediate technical obstacles to migrations.Research and identify new opportunities for AWS to innovate on behalf of our customers.Operate test and development environments in the cloud, run and analyze test results, perform diagnostics and troubleshooting, open, prioritize, and help triage defects, track and report test status and results.Design solutions and tooling to execute automated deployments, upgrades and migrations.\n\nWhat makes this role different than all the others out there? Simple: scope. You get the opportunity to work with every product in AWS Services plus external customers ranging from the very small to the very large \u2013 everyone has data. You be working on a large number of complex migration projects and be given a lot of independence. This is a new focus area for AWS so you have the opportunity to put your stamp on it. Andy\u2019s tweets on DB Freedom have been frequent \u2013 here\u2019s your chance for visibility while delivering some results!\n Key job responsibilities\n Manage a team of Data and Database Engineers (career development, ongoing operational issues resolution, mentoring, team events). Team long-term strategy and tactical activities creation.\n\n\nBasic Qualifications\n\n\n3+ years of experience as Technical Manager or Data Engineer, or the similar role\nExperience with data modeling, data warehousing, and building ETL pipelines\nSkilled with writing, tuning, and troubleshooting SQL queries \nExperience with Big Data technologies such as Hive, Spark, Hadoop, NoSQL, AWS EMR, Glue, Lambda, Kinesis\nProficiency with Python, Java, or Scala\nGood grasp of software development life cycle and/or agile development environment\nStrong organizational and planning skills with attention to detail\nExperience in understanding system limitations, scaling factors, boundary conditions, and the reasons for architectural decisions \nExperience in Designing and building scalable data pipelines\n\nPreferred Qualifications\n\n\n5+ years of industry experience as Technical Manager or Data Engineer, or the similar role (e.g. Software Engineer, Business Intelligence Engineer, Data Scientist, ETL Developer) with a track record of manipulating, processing, and extracting value from large datasets\nExperience with orchestration tools such as AWS Step Functions. \nDeep knowledge of data warehouses, architecture, infrastructure components, ETL and reporting tools and environments\nNice to have experience with some enterprise ETL tool (IBM Datastage, Informatica, Talend or MS SSIS)\nExperience with orchestration tools such as AWS Step Functions\n\nExperience with Massively Parallel Processing (MPP) databases - Redshift, Teradata etc.\nExperience directing medium to large-scale data warehousing and BI projects, including using AWS technologies \u2013 Redshift, S3, EC2, Data-pipeline and other big data technologies\nGood communication skills and able to work with business owners to develop and define key business questions and to build data sets that answer those questions\nExperience providing technical direction and mentorship of engineers and scientists on best practices in the data engineering space\nComfort working with the Linux command line and shell scripting \nBe self-motivated and show ability to deliver on ambiguous situations and projects\n\nAmazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We make recruiting decisions based on your experience and skills. We value your passion to discover, invent, simplify and build. Protecting your privacy and the security of your data is a longstanding top priority for Amazon. Please consult our Privacy Notice (https://www.amazon.jobs/en/privacy_page) to know more about how we collect, use and transfer the personal data of our candidates.\n\n\nCompany - AMZN Dev Cntr Poland sp. z.o.o\n Job ID: A2193620"
    },
    {
        "position": "Lead Data Engineering",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "miDiagnostics",
        "sector": "Medical Equipment Manufacturing",
        "companySize": "51-200 employees",
        "location": "Leuven, Flemish Region, Belgium",
        "post": "About the job \n\nAbout miDIAGNOSTICS \nSpun out of the world-leading R&D and innovation hub in nanoelectronics and digital technologies, Imec, and a research collaboration with Johns Hopkins University, the leading US research and medical centre, miDiagnostics\u2019 goal is to enable fast, comprehensive and cost-effective health analysis, regardless of location. Based in Leuven, Belgium, miDiagnostics is a privately held company created in 2015.\nmiDiagnostics is using silicon chip technology which will bring miniaturized, rapid, easy-to-use, lab-quality PCR tests with built-in connectivity direct to the patient and clinician. Combining a nanofluidic processor on a chip and a compact reader, miDiagnostics can measure virtually any biomarker from an easily accessed sample such as drops of finger prick blood. The Company is developing an extensive portfolio of tests for screening, diagnosis and monitoring of a wide range of health conditions, including infectious diseases.\n\n\n\n\nThe Job\nmiDiagnostics is releasing its first product, an ultra-fast PCR test, into the market. This market introduction means rapid organization scaling and supporting the international growth ambitions of the company. For the further development of the Software team, miDiagnostics is looking for a Lead Data Engineering, who will report to the Director Software Engineering.\n\n\nJoin us on our exciting journey to enable the next generation of lab-on-a-chip diagnostics.\n\n\nAs our Lead Data Engineering, your responsibilities will include:\n\nLeads the Data Engineering team (small team of 3 in total) and has the ability to lead teams working in an agile set-up;\nDevelops, constructs, tests and maintains the data pipeline architectures;\nAligns data architecture with business requirements;\nSupports data acquisition from the lab all the way to cloud infrastructure and connected data visualization tools;\nUses structured tools, environments and coding languages to support and further develop sophisticated analytics programs, machine learning and statistical methods;\nIdentifies ways to improve data reliability, efficiency and quality;\nConducts research for industry and business questions;\nUses large data sets to address business issues;\nPrepares data for predictive and prescriptive modelling;\nData cleaning;\nData visualization;\nCascades the company priorities to the Data Engineering team and defines clear objectives and key results;\nEnsures the right talent is hired and supports hiring via his/her network;\nActs as an inspirational leader and promotes a growth mindset across the company;\n\n\n\n\n\nYour profile and competencies\n\nPhD or masters in a scientific field or equivalent through experience;\nExperience within the medical device industry, or other heavily regulated industries is considered a strong plus;\nExperience in IEC62304 and 13485 are considered a strong plus; \nSolid experience in cybersecurity aspects of data engineering; \nA solid experience in data cleaning, data mining, data analysis, data visualization, and shares our passion for accurate, accessible and transparent data;\nExperience with data visualization tools (experience in Tableau is a plus);\nExperience with the python and javascript (knowledge of additional programming languages is a plus);\nDeep understanding of databases and SQL (experience with mySql is a plus);\nFamiliarity with software for data cleanup (experience with OpenRefine is a plus);\nFamiliarity with Amazon Web Services (AWS) and REST API;\nFluent in English (written and verbal);\nStrong communication skills;\nService-minded, detail-oriented, result-focused and quality driven;\nStrong analytical and planning skills;\nAbility to build a high-performing team;\nTrue team-player;\nOur offices are located in Leuven (Belgium). Relocation to Belgium is needed. It is essential that you hold entitlement to work and live in Belgium.\n\n\nThe offer\n\nA job in a fast-growing and ambitious start-up in the medical diagnostics industry.\nmiDiagnostics is an international-oriented company with close connections to two world-class research institutions (imec and Johns Hopkins University).\nOpportunity to grow in a new and exciting cutting-edge field in point-of-care diagnostics.\n\n\n\nInterested? Please apply via our career website https://jobs.midiagnostics.com/"
    },
    {
        "position": "Data Engineering Manager",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Kraken Digital Asset Exchange",
        "sector": "Financial Services",
        "companySize": "1,001-5,000 employees",
        "location": "Ireland",
        "post": "About the job \n\nAbout Kraken\n\nAs one of the largest and most trusted digital asset platforms globally, we are empowering people to experience the life-changing potential of crypto. Trusted by over 8 million consumer and pro traders, institutions, and authorities worldwide - our unique combination of products, services, and global expertise is helping tip the scales towards mass crypto adoption. But we\u2019re only just getting started. We want to be pioneers in crypto and add value to the everyday lives of billions. Now is not the time to sit on the sidelines. Join us to bring crypto to the world.\n To ensure Kraken is the right fit for you, please ensure you read Kraken Culture Explained to find out more about us!\n The data engineering team is responsible for designing and implementing scalable solutions that allow Kraken to make data-driven decisions fast and accurately, while dealing with high volumes of data. The team maintains the company\u2019s data warehouse and data-lake, replicating data among different platforms, and answering the critical business needs that help Kraken scale and succeed. The data engineering teams deal with different both batch and streamed data, and split into different responsibilities and focus areas depending on Kraken\u2019s objectives.\n\nResponsibilities\n\n\n\nManage a team of highly qualified and experienced data engineers \nLead the building of scalable and reliable data pipelines that collect, transforms, loads and curates data from internal systems\nDrive data systems to be as accurate and performant as possible while advocating the engineers in the team.\nSupport design and deployment of the distributed data store that act as a central source of truth across the organization (EMs may remain partially hands-on)\nHelp scaling the team, hiring, interviewing, and assist in planning the right healthy growth and career progression\nCommunicate with different business owners and stakeholders, set OKRs aligned with Kraken\u2019s vision, then lead initiatives and people to achieve these goals\nMaintain a high security attitude from both technical and cultural perspectives\n\n\nRequirements\n\n\n\n9+ years of work experience in relevant fields around data engineering, data-warehousing, distributed-systems and software development\n8+ years of work experience in a major programming language (e.g. Scala, Python, Golang,..)\n5+ years of experience leading teams, preferably engineering and/or data teams\n3+ years of experience managing remote teams\nYou have a strong servant-leadership management style geared towards supporting, mentoring and growing engineers on the team \nYou are strategic and think at a high level, but are also hands-on, execution-oriented, and capable of getting things done quickly\nYou have a strong experience in data engineering, data-lakes, data warehousing, and building robust scalable organization-wide data solutions\nYou have experience leading teams of engineers across all levels of skill and experience with a track record of managing, recruiting, and retaining strong engineering leadership and engineering talent\nYou have an ability to translate a long-term vision into a near-term, executable plan\nYou have experience working in different development methodologies, understand the trade-offs, and can iterate to a process that supports you, the team, and the business\nYou are interested in cryptocurrency and actively involved in the space\nYou care deeply about people and their success\nYou\u2019re not afraid of hard conversations and are gifted at coaching your colleagues through difficult situations\n\n\nLocation Tagging: #EU #US\n We\u2019re powered by people from around the world with their own unique and diverse experiences. We value all Krakenites and their talents, contributions, and perspectives, regardless of their background. We encourage you to apply for roles where you don't fully meet the listed requirements, especially if you're passionate or knowledgable about crypto!\n As an equal opportunity employer we don\u2019t tolerate discrimination or harassment of any kind. Whether that\u2019s based on race, ethnicity, age, gender identity, citizenship, religion, sexual orientation, disability, pregnancy, veteran status or any other protected characteristic as outlined by federal, state or local laws.\n\nStay in the know\nKraken Culture Explained \nFollow us on Twitter \nCatch up on our blog \nFollow us on LinkedIn"
    },
    {
        "position": "Microsoft Data Analytics - Engineering Lead - Manager",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Accenture Italia",
        "sector": "IT Services and IT Consulting",
        "companySize": "10,001+ employees",
        "location": "Assago, Lombardy, Italy",
        "post": "About the job \n Are you ready to step up to the New and take your technology expertise to the next level? Join Accenture and help transform leading organizations and communities around the world in achieving their goals faster and more efficiently. The sheer scale of our capabilities and client engagements and the way we collaborate, operate, and deliver value provides an unparalleled opportunity to grow and advance. Choose Accenture and make delivering innovative work part of your extraordinary career. As part of our Accenture Microsoft Business Group (AMBG) practice, you will lead Technology Innovation to Shape World-Class Business Solutions for our Clients and deliver them at scale. There will never be a typical day and that\u2019s why people love it here. The opportunities to make a difference within exciting Client initiatives are unlimited in the ever-changing technology landscape. You will be part of a growing network of technology experts who are highly collaborative taking on today\u2019s biggest, most complex business challenges. We will nurture your talent in an inclusive culture that values diversity. Come grow Your Career in technology at Accenture! Microsoft Data Analytics-Engineering Lead - Manager will be responsible for working with our Clients and internal teams to help shape Industry Transformation solutions using the Microsoft technology platform and its wide eco-system of partners. Companies and entire Industries need help to reinvent themselves during these challenging times and your job will be to help Companies transform themselves to emerge stronger above and beyond complex contexts such as the current one.\n A solid understanding of challenges that Clients in an Industry are facing, and how to address them using Microsoft technology ecosystem is key for delivering value. This should be combined with experience and understanding of considerations for large scale cloud analytics solutions architecting, helping Clients transforming into a data driven business, developing new data service and data platforms using digital, becoming more agile and resilient.\n We are looking for candidates who have a broad set of technology skills across these areas and who can demonstrate an ability to design the right solutions with an appropriate combination of Microsoft and its 3rd party technologies for deploying on the Microsoft Intelligent Data Platform. Key responsibilities may include:\n\n\n\nAs a data analytics-engineering lead, you will work with implementation teams from concept to delivery, providing data and applied intelligence expertise for successfully deploying large scale digital data and analytics solutions in the enterprise, using modern digital technologies on premise and cloud\n\n\nYou will play a key role in leading the data engineering workstream of analytics transformation projects across multiple areas / domains, such as sales, marketing, supply chain, revenue management, etc.\n\n\nYou will act as lead and supervisor in data ingestion, preparation, and storage activities, such as:\n\n\ndefining Microsoft data architecture layers and data models for proof of concepts, pilots, projects\n\n\ndefining key data interfaces and transformation logics\n\n\ndefining and reviewing code for data cleansing, data checks and data transformations / preparations steps for data science (i.e. time series preparation, internal vs external data matching, base price smoothing, price imputation).\n\n\nLead cloud analytics solution and scoping to generate estimates and approaches for proposals and SOWs for Clients\n\n\nYou will work closely with:\n\n\nClient data leads to transfer / explain input data requirements and perform data assessment\n\n\nAccenture data engineering programmers to coach and grow junior resources on data curation and data transformation / harmonization activities\n\n\nAccenture and Client data scientists to gather advanced analytics data preparation requirements, back and forth on statistical data validation / QA, \u2026\n\n\nCreate detailed target state technical, security, data and operational architecture and design blueprints incorporating modern digital technologies and cloud services, demonstrating modernization value proposition\n\n\nCo-lead and/or support detail technical assessments of current state of analytics architectures and data platforms and architect a path to transformation into a modern data powered enterprise / landscape\n\n\nConduct full technical discovery, identifying pain points, business, and technical requirements, \u201cas is\u201d and \u201cto be\u201d scenarios\n\n\nCompare solution alternatives across both technical and business parameters which support the definition of cost and service requirements\n\n\nApply methodology, reusable assets, and previous work experience to deliver consistently high-quality work\n\n\nDeliver written or oral status reports regularly\n\n\nStay educated on new and emerging analytics technologies/patterns/methodologies and market offerings that may be of interest to our Clients\n\n\nAdapt to existing methods and procedures to create possible alternative solutions to moderately complex problems\n\n\nUse considerable judgment to define solutions and seeks guidance on complex problems\n\n\nSupport answers to RFPs issued by Clients\n\nRequired Qualifications\n\nTechnical\n\n\n\n\nAn academic degree on Computer Science / Information Technology or Industrial Engineering\n\n\nSignificant experience in technical solutions implementation, architecture design, and engineering programming / coding on MSFT platform\n\n\nSignificant experience (or similar) in the following technologies and tools:\n\n\nAzure Databricks (primary)\n\n\nPython (PySpark)\n\n\nScala\n\n\nSQL\n\n\nAzure SQL DWH / Synapse (primary)\n\n\nAzure Datafactory (ADF)\n\n\nPower BI\n\n\nDAX\n\n\nPower Query / M\n\n\nSpecial focus on Dynamics Customer Insights, Customer Data Platform (CDP), Customer Data Architecture (CDA), Microsoft Common Data Model (CDM / IDW), etc.\n\n\nKnowledge of the Microsoft technologies including Microsoft Azure, Microsoft 365 (Office 365), Dynamics-365, Power-Platform\n\nFunctional\n\n\nDeep and strong knowledge and expertise in the broad analytics area cross industry\n\n\nMultiyear experience in activities such as: data maturity assessment and analysis, data ingestion, data cleansing and harmonization, data preparation and advanced analytics transformation through data science, machine learning, data visualization, data architecture, data security, etc.\n\n\nSpecific industry knowledge required with preference on Consumer Goods & Services and/or Retail\n\n\nKnowledge in Revenue Management (Trade Promotion Optimization, Pack Price Architecture, Assortment Optimization, Customer Segmentation, ...) is good to have\n\n\nKnowledge in Sales & Marketing topics (Customer Business Planning, Account Planning, Trade Promotion Management) is good to have"
    },
    {
        "position": "Data Engineering Specialist",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "HP",
        "sector": "IT Services and IT Consulting",
        "companySize": "10,001+ employees",
        "location": "Sant Cugat del Vall\u00e8s, Catalonia, Spain",
        "post": "About the job \n We are looking for a Software Developer/Data Engineer to join our data engineering team. If you are passionate about data and technology, we are eager to talk to you. The ideal candidate has both a willingness and desire to work in a dynamic environment, is able to apply Agile methodologies in day to day activities, and is a self-motivated developer who also enjoys working in a team environment. Our people have a creative, innovative, fun, and collaborative attitude, and are dedicated to creating new and valuable solutions for HP.\n The Data Engineering Specialist applies developed subject matter knowledge to solve common and complex business issues within established guidelines and recommends appropriate alternatives. Works on problems of diverse complexity and scope. May act as a team or project leader providing direction to team activities and facilitates information validation and team decision making process. Exercises independent judgment within generally defined policies and practices to identify and select a solution. Ability to handle most unique situations. May seek advice in order to make decisions on complex business issues.\n\nResponsibilities\n\nYou will design, develop, test, modify, deploy, and document solutions and services in both local and cloud based deployments of our Big Data infrastructure. Create solutions using current programming languages and tools and interact with team members, customers, and partners to define requirements. Collaborate with stakeholders and data scientists to analyze, extract, and report meaningful insights from data collected.\n\nThe Data Engineering Specialist\n\n\nDesigns and establishes secure and performant data architectures, enhancements, updates, and programming changes for portions and subsystems of data pipelines, repositories or models for structured/unstructured data.\nAnalyzes design and determines coding, programming, and integration activities required based on general objectives and knowledge of overall architecture of product or solution.\nWrites and executes complete testing plans, protocols, and documentation for assigned portion of data system or component; identifies and debugs, and creates solutions for issues with code and integration into data system architecture.\nLeads a project team of other data engineers to develop reliable, cost effective and high-quality solutions for assigned data system, model, or component.\nCollaborates and communicates with project team regarding project progress and issue resolution.\nRepresents the data engineering team for all phases of larger and more-complex development projects.\nProvides guidance and mentoring to less experienced staff members.\n\nQualifications\n\n\nTypically 4+ years of experience in software or data engineering.\nSolid experience in data modeling, data integration and processing of structured and unstructured data.\nProficient in one or more programming languages (Python preferred).\nStrong SQL proficiency as well as experience with NoSQL.\nExperienced with Apache Spark (PySpark experience - advantage). \nExcellent communication skills; mastery in English and local language.\nAbility to effectively communicate product architectures, design and change proposals.\n\nAdditional Preferred Qualifications\n\n\nData transformation using AWS services\nDatabricks\nDataiku\nFamiliar with best practices of the data and software engineering lifecycle and/or best practices of the above platforms and tools.\n\nWhat We Offer\n\n\nOpportunity to work in an international organization with colleagues coming from all over the world.\nAn attractive benefits package\nDiverse, continued internal growth and career opportunities. Including HP\u2019s own learning platform and LinkedIn Learning.\nHP product discount\nWork life balance /flexible working hours\nWomen, Pride, Young employees, Multicultural and DisAbility! Just a few of our fantastic global business networks you can get involved with locally.\n\nAbout HP\n\nYou\u2019re out to reimagine and reinvent what\u2019s possible\u2014in your career as well as the world around you.\n So are we. We love taking on tough challenges, disrupting the status quo, and creating what\u2019s next. We\u2019re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference.\n HP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere.\n Our history: HP\u2019s commitment to diversity, equity and inclusion \u2013 it's just who we are.\n From the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you\u2019re more innovative and that helps grow our bottom line. Come to HP and thrive!"
    },
    {
        "position": "Data Engineer",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Flying Tiger Copenhagen",
        "sector": "Retail",
        "companySize": "5,001-10,000 employees",
        "location": "Copenhagen, Capital Region, Denmark",
        "post": "About the job \n\nFlying Tiger Copenhagen is looking for a Data Engineer with ambitions and a strong desire to learn\n\n\nDo you have a desire to work with Data Platform development and engineering? Do you thrive in an environment where you can develop your skills and do you want to be part of developing and deploying leapfrog technologies in global company? Then you are exactly the person we are looking for at Flying Tiger Copenhagen.\n\n\nThe position:\nYou will become part of an international and highly competent team that is responsible for the further development of our Data Platform architecture. In your work, you will play a key role in ensuring that the current solution is further developed in accordance with applicable requirements and the interest of stakeholders in the business as well as ensuring that the required documentation is in place.\n\n\nThe task portfolio is broad - you will, among other things, help us implement BI, AA, ML and Insights solutions that are among the finest in Retail here in Denmark.\n\n\nAs Data Engineer, you will help bring our data platform solutions to a level where we can really benefit from all the data we have available. You are excellent in delivering effective and innovative solutions that will support our Advanced Analytics mindset. You are able to keep track of your tasks and ensure they are implemented while remaining focused on business needs.\n\n\nYour profile:\nYou are ambitious and take proactively responsibility for the development and implementation of the individual solutions. We expect you to be able to always challenge our current practice for the better. Additionally, we except that you are familiar with various cloud platforms such as Microsoft Azure, AWS and Google Cloud technologies that can be utilized in our Data Platform solutions and leapfrog technology to achieve innovative and state-of-the-art setup.\n\n\nIt is important that you have an eye for the details as well as having the ability to comply with deadlines. As a person, you are open and curious about all kinds of tasks and you want to help to contribute to a good climate in the team. You would also enjoy working together across the entire organization. You must be professional, analytically strong and be able to focus on multiple tasks without losing sight in a busy day with many working streams. \n\n\nWe expect you to have a good knowledge of the following:\n\nMS Azure product portfolio\nOn hands knowledge of Azure Data Lake and Azure Data Factory \nSQL skills and experience with stored procedures on MS SQL Server\nMicrosoft SQL Server\n\n\n\nIn addition, it would an advantage to be familiar with:\n\nAmazon Web Services\nGoogle Cloud technology\n\n\n\nYour success at work is measured in your ability to achieve high stability in relation to business-specific solutions developed through various platforms.\n\n\nAs Data Engineer you will report directly to the Head of BI, Insights & Digital Solutions.\n\n\nAbout us:\nAt Flying Tiger Copenhagen, we are undergoing a digital transformation where we are moving our services into new technologies and platforms. We offer a business-oriented and ambitious environment, where your professional and personal development are in outmost focus.\n\n\nYou will be part of a committed department with experienced and competent employees who work with the latest BI, AA, ML and insights principles on various platforms. We have a strong focus on supporting the business with data-driven solutions.\n\n\nFurthermore, you will be part of a highly engaged team where we work together and support each other. Along the way we make sure we also have fun and are very socially well-functioning team.\n\n\nApplication:\nWe are looking forward to hearing from you.\nSubmit your application and CV via the link below as soon as possible.\nWe are continuously calling in for conversations."
    },
    {
        "position": "Data Engineering Manager - BI (They/She/He)",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Glovo",
        "sector": "Consumer Services",
        "companySize": "1,001-5,000 employees",
        "location": "Barcelona, Catalonia, Spain",
        "post": "About the job \n\nAbout Glovo\n\nWe\u2019re a Barcelona-based startup and the fastest-growing delivery player in Europe, Hispanic America and Africa. With food at the core of the business, Glovo delivers any product within your city at any time of day.\n Our vision and ambition are not only to make everything immediately available in your city but it is also to offer our employees the job of their lives. A job where you'll be challenged and have the most fun working in through tech-enabled experiences.\n\nYour Work-life Opportunity\n\nWe are a product-centered company, and data is at the core of product development. In this role, you'll work with key business and product leads, analysts and data scientists to understand the business domain and how data can empower them. Your day-to-day will involve engaging with fellow engineers to develop a robust and scalable platform, to make the process of producing data and deriving insights efficient. You are passionate about the quality of the data you produce and take pride in having your data drive our business.\n\nBe a Part Of a Team Where You Will\n\n\nRecruit, lead and manage a team of Data Engineers- BI of different seniority levels\nCollaborate with business, product and engineering stakeholders to prioritise the most impactful work and ensure the teams' needs are accounted for\nManage the entire lifecycle of your team's projects\nDesign, implement and maintain pipelines that produce business-critical data reliably and efficiently using cloud technologies \nCollect, process, and clean data from different sources using SQL, Python, or other scripting languages \nImprove data discovery and literacy: create exploration and visualisation interfaces in our BI tools and promote the use of these sources across the company \nThink big and contribute to the strategy for better data quality within Glovo \nDesign and develop nimble dashboards to support the analytical needs of the business \nCollaborate with many Product, Engineering and Business teams to produce relevant data solutions that can be used across multiple use cases \n\nYou Have\n\n\nBetween 2 to 3 years of experience in a similar role, managing a team (5+ people) or multiple projects. Preferably in the digital/tech space \nExperience designing and building scalable and robust data pipelines to enable data-driven business decisions \nExperience in collecting requirements and creating data modeling designs \nKnowledge of modern data warehouses (Snowflake, Redshift, BigQuery) and big data structures \nExperience implementing enterprise dashboarding tools \nStrong proficiency and experience with SQL and Python \nExperience working with modern BI tools like Tableau, Looker, Qlikview \nGood understanding of software development and agile methodologies \nPassion for analyzing large complex datasets and converting them into information which drives business decisions \nExcellent spoken and written English. \n\nExperience Our Glovo Life Benefits\n\n\nEnticing Phantom Shares plan \nAttractive Relocation package (if applicable ;)) \nComprehensive Private Health Insurance \nCobee discounts on kindergarten, transportation, and food \nFree monthly Glovo credits to spend on our restaurant products (and zero Glovo delivery fee on all Glovo orders!) \nCool perks such as fresh fruit and healthy snacks every day, beers on Fridays, Culture Days every 2 months! \nDiscounted Gym memberships \nFlexible working environment \n\nWhat You\u2019ll Find When Working At Glovo\n\n\nGAS: Driven to deliver quality results quickly\nGood Vibes: Bring positivity and communicate openly\nStay Humble: Self-aware and open to learning\nCare: Uplift people and the planet\nGlownership: Act as proud owners\nHigh Bar: Focus on Top Performance\n\nIf you believe you match these values, we look forward to meeting you!\n At Glovo we believe that diversity adds incredible value to our teams, our products, and our culture. We know that the best ideas and solutions come by bringing together people from all over the world and by fostering a culture of inclusion where everyone feels heard and has the chance to make a real impact. It's because of this that we are committed to providing equal opportunities to talent from all backgrounds.\n Wanna take a peek into what it's like to work at Glovo? Follow us on Instagram and like us on Facebook!\n Glovo is transforming the way consumers access local goods, enabling anyone to get almost any product delivered in minutes. Our on-demand logistics connect customers with independent local couriers who acquire goods from any restaurant or store in a city, as well as deliver urgent packages for a variable fee. As of September 30, 2019, we\u2019re currently present in more than 26 countries across Europe, Latin America, Africa, and Asia.\n For additional information on Glovo, please visit https://glovoapp.com/ | Twitter: @Glovo_ES | Facebook: https://www.facebook.com/glovoappES/ | LinkedIn: https://www.linkedin.com/company/glovo-app/"
    },
    {
        "position": "Software Engineer, Data Engineering",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Bolt",
        "sector": "Internet Marketplace Platforms",
        "companySize": "1,001-5,000 employees",
        "location": "Berlin, Berlin, Germany",
        "post": "About the job \n\nBolt engineering teams are working on unique product challenges: complex algorithms for demand prediction, optimal real-time pricing, routing, fraud detection, distributed systems and much more. Volumes are growing at a steady pace. We are looking for an experienced engineer who is well-versed in data technologies.\n\n\nYour daily adventures will include:\n\nDesigning, building and optimizing elements of Bolt\u2019s Data Platform. Main areas include development of Storage and Analytical Systems (Data Lake, Data Warehouse), Data Pipelines (ETLs, ELTs, stream processing) and Machine Learning models infrastructure\nInvestigating and prototyping of new services to improve different aspects of our Data Platform: data quality, monitoring, alerting, performance and costs efficiency\nCoding mostly in Java, Python and TypeScript (previous experience is not required), occasionally in other languages. \nDesigning and optimizing SQL queries and data storage formats \nProactively solving technical challenges and fixing bugs\nContributing ideas to our product development roadmap\nWe are looking for language-agnostic generalists that are able to pick up new tools to solve the problems they face. Check out our blog to know more about all the exciting projects that we are working on: https://medium.com/bolt-labs.\n\nWe are looking for:\n\nExperience in at least one of the modern OO languages (Python, Scala, Java, JavaScript, C++, etc)\n4+ years of experience in software development\nExcellent English and communication skills\nExperience with micro-service and distributed systems\nSolid understanding of algorithms and data structures\nGood knowledge of SQL and experience in at least one of the popular online analytical processing (OLAP) technologies (AWS Redshift, ClickHouse, Presto, Snowflake, Google BigQuery, DataBricks etc)\nA university degree in a technical subject (Computer science, Mathematics or similar)\n\nYou will get extra credits for:\n\nExperience in building and designing real-time and asynchronous systems\nFamiliarity with streaming data technologies for low-latency data processing (Apache Spark/Flink, Apache Kafka, RabbitMQ, Hadoop ecosystem)\nUnderstanding of NoSQL databases (Redis, ElasticSearch, Apache Cassandra)\nExperience in building systems based on cloud service providers (AWS, Azure, Google Cloud)"
    },
    {
        "position": " Data Engineering Manager",
        "jobType": "Full-time",
        "jobLevel": "Mid-Senior level",
        "company": "Travix International",
        "sector": "Technology, Information and Internet",
        "companySize": "501-1,000 employees",
        "location": "Amsterdam, North Holland, Netherlands",
        "post": "About the job \n\nAbout Travix\nTravix is one of the leading global online travel agencies, operating with four brands: CheapTickets, Vliegwinkel, BudgetAir and Flugladen. In 2020 we took our next step becoming part of the Trip.com Group family, one of the largest online travel companies in the world, consisting of Trip.com, Ctrip, Skyscanner, Make my Trip and Qunar. Travix currently operates in over 40 countries expanding in 5 continents, so a global mindset comes natural to us. Our purpose is \u2018the next journey at your fingertips\u2019 which goes for both our customers and employees. We bring together passionate people, global partners, and an innovative platform to deliver the best end-to-end booking experience for our customers.\n\n\nMake your career at Travix\nAt Travix, everyone is welcome. Our global team has over 40 different nationalities and we embrace everyone\u2019s authenticity. We have proven to grow people internally, we are proud of our passionate company culture and we love to dream big. Ever since our company was founded, our aim has been to create a work environment where people can thrive, be creative and ultimately build their own legacy within the company. More now than ever we are at a pivotal moment in our company\u2019s existence: where we are preparing for when the world is ready to travel again. With cutting-edge technology, strong partnerships, a strategic vision and the resources and stability of the Trip.com Group, we provide an international playground where our employees can truly impact the future of traveling.\nTo accelerate this momentum, we're looking to grow our team. If you share the same values as we do, you are just as passionate and ready to build your own legacy, then there is plenty of room here at Travix.\n\n\nJob Purpose\nAs a hands-on Engineering Manager, you will work as part of a team to build products and services on Travix's data platform which runs on Google Cloud Platform. In addition, you will provide direct functional leadership to a group of Data Engineers, where you are responsible for the effectiveness and quality of the delivery of high-value products. You will foster an environment that will encourage creative thinking and an environment of innovation. You will leverage your technical experience to develop and nurture the engineers to create high performing and motivated developers.\n\n\nKey Responsibilities\n\nProviding direct functional leadership to a group of Data Engineers within a scrum team\nGuiding a team of Data Engineers in terms of developing products and services\nWorking with other Engineering Managers to provide technical alignment across teams\nInnovating and creating an environment that fosters innovation \nMentoring, coaching and supporting the career development of the Data Engineers\nLeveraging your deep software engineering expertise to coach less experienced engineers and guide them to solve challenging problems\nNurturing and encouraging creativity, as Travix offers a huge amount of freedom from a technology and ownership stand-point. \n\n\n\nWhat you bring to the table\n\nA degree in computer science, or a related degree, or similar work experience\nAt least 6-8 years of relevant work experience\nPrevious management or team lead experience\nProven experience in business intelligence products like data lake, data warehousing and data engineering (ETL/ELT)\nExperience developing data products in Java or Python in the cloud\nProficient in T-SQL\nExcellent interpersonal and communication skills\nFluent English speaker\nAffinity with working in an Agile development environment and established e-Commerce businesses\nProven experience in working with high volume websites and e-Commerce b2c retail product development.\nExperience with Google Cloud Platform is a plus\nAll this is in the travel industry is definitely an advantage but not essential.\n\n\n\nWhat you can expect from us\n\nCompetitive salary and other amazing benefits, such as covered travel costs, discounted ongoing cancellation / travel insurances and a bike plan.\n30,5 days of paid leave, so plenty of time to enjoy your global travel adventures!\nMany internal development courses to keep on learning and growing.\nAn environment where you can keep a healthy work-life balance: even when we can go back to the office to collaborate as teams, you will still continue having a balance between working from home and from the office.\nFlat hierarchy where your voice can be heard, welcomed and appreciated at all levels in the organization.\nA diverse, inclusive and multicultural working environment\nTop floor office in Amsterdam (close to Central Station) with an amazing view!\nFree fruit, company bar (free beer!), team drinks and company events.\n\n\n\nReady to start your own Travix journey?\nThink you have what it takes? Then, we would love to hear from you."
    }
]